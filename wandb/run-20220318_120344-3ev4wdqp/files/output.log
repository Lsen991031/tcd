ucf101: 101 classes
Method : OURS
----AGE 9----
current_task  [89, 0, 61, 1, 92]
current_head  96
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.04266145801540309]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=288, sigma=tensor([3.9242]), eta=tensor([3.2035])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=15, sigma=1.0, eta=1.0)
)
video number : 483
video number + exemplar : 938
DataLoader Constructed : Train 29
Optimizer Constructed
video number : 483
video number + exemplar : 483
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-18 12:04:11.721987
Epoch: [0][0/29], lr: 0.00100	Time 3.726 (3.726)	Data 1.942 (1.942)	Loss 0.3508 (0.3508)	Loss CE 0.2175 (0.2175)	Loss KD (Logit) 1.1315 (1.1315)	Loss KD (GCAM) 0.0633 (0.0633)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6603 (0.6603)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1771], device='cuda:0', requires_grad=True)
2022-03-18 12:04:39.993418
Epoch: [1][0/29], lr: 0.00100	Time 3.246 (3.246)	Data 1.726 (1.726)	Loss 0.4624 (0.4624)	Loss CE 0.3117 (0.3117)	Loss KD (Logit) 1.2042 (1.2042)	Loss KD (GCAM) 0.0917 (0.0917)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7187 (0.7187)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
Sigma : Parameter containing:
tensor([3.8679], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1726], device='cuda:0', requires_grad=True)
2022-03-18 12:05:07.961188
Epoch: [2][0/29], lr: 0.00100	Time 2.966 (2.966)	Data 1.728 (1.728)	Loss 0.2403 (0.2403)	Loss CE 0.0916 (0.0916)	Loss KD (Logit) 1.2308 (1.2308)	Loss KD (GCAM) 0.1058 (0.1058)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6443 (0.6443)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8608], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1693], device='cuda:0', requires_grad=True)
2022-03-18 12:05:33.781901
Epoch: [3][0/29], lr: 0.00100	Time 3.068 (3.068)	Data 2.062 (2.062)	Loss 0.2016 (0.2016)	Loss CE 0.0508 (0.0508)	Loss KD (Logit) 1.2007 (1.2007)	Loss KD (GCAM) 0.1094 (0.1094)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6670 (0.6670)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8399], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-18 12:05:59.274610
Epoch: [4][0/29], lr: 0.00100	Time 2.837 (2.837)	Data 1.643 (1.643)	Loss 0.2496 (0.2496)	Loss CE 0.1021 (0.1021)	Loss KD (Logit) 1.2113 (1.2113)	Loss KD (GCAM) 0.1171 (0.1171)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6066 (0.6066)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8229], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1491], device='cuda:0', requires_grad=True)
2022-03-18 12:06:22.780213
Epoch: [5][0/29], lr: 0.00100	Time 2.982 (2.982)	Data 2.009 (2.009)	Loss 0.1548 (0.1548)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 1.2258 (1.2258)	Loss KD (GCAM) 0.1111 (0.1111)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6545 (0.6545)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8330], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1557], device='cuda:0', requires_grad=True)
2022-03-18 12:06:46.095613
Epoch: [6][0/29], lr: 0.00100	Time 3.025 (3.025)	Data 1.742 (1.742)	Loss 0.1756 (0.1756)	Loss CE 0.0205 (0.0205)	Loss KD (Logit) 1.2235 (1.2235)	Loss KD (GCAM) 0.1075 (0.1075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7055 (0.7055)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1498], device='cuda:0', requires_grad=True)
2022-03-18 12:07:09.475960
Epoch: [7][0/29], lr: 0.00100	Time 3.099 (3.099)	Data 2.347 (2.347)	Loss 0.1774 (0.1774)	Loss CE 0.0205 (0.0205)	Loss KD (Logit) 1.2439 (1.2439)	Loss KD (GCAM) 0.1141 (0.1141)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6961 (0.6961)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8140], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1466], device='cuda:0', requires_grad=True)
2022-03-18 12:07:33.082407
Epoch: [8][0/29], lr: 0.00100	Time 3.127 (3.127)	Data 1.976 (1.976)	Loss 0.2672 (0.2672)	Loss CE 0.1164 (0.1164)	Loss KD (Logit) 1.2429 (1.2429)	Loss KD (GCAM) 0.1196 (0.1196)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6190 (0.6190)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8232], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1528], device='cuda:0', requires_grad=True)
2022-03-18 12:07:56.844200
Epoch: [9][0/29], lr: 0.00100	Time 3.178 (3.178)	Data 2.189 (2.189)	Loss 0.1639 (0.1639)	Loss CE 0.0141 (0.0141)	Loss KD (Logit) 1.2342 (1.2342)	Loss KD (GCAM) 0.1180 (0.1180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6175 (0.6175)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1619], device='cuda:0', requires_grad=True)
2022-03-18 12:08:20.894726
Epoch: [10][0/29], lr: 0.00100	Time 3.256 (3.256)	Data 2.187 (2.187)	Loss 0.1656 (0.1656)	Loss CE 0.0176 (0.0176)	Loss KD (Logit) 1.2106 (1.2106)	Loss KD (GCAM) 0.1039 (0.1039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6513 (0.6513)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1691], device='cuda:0', requires_grad=True)
2022-03-18 12:08:44.480789
Epoch: [11][0/29], lr: 0.00100	Time 3.115 (3.115)	Data 2.284 (2.284)	Loss 0.1488 (0.1488)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 1.1980 (1.1980)	Loss KD (GCAM) 0.1010 (0.1010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6293 (0.6293)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8586], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1741], device='cuda:0', requires_grad=True)
2022-03-18 12:09:08.402649
Epoch: [12][0/29], lr: 0.00100	Time 3.095 (3.095)	Data 1.799 (1.799)	Loss 0.1531 (0.1531)	Loss CE 0.0074 (0.0074)	Loss KD (Logit) 1.2185 (1.2185)	Loss KD (GCAM) 0.1050 (0.1050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6214 (0.6214)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8570], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1740], device='cuda:0', requires_grad=True)
2022-03-18 12:09:32.282725
Epoch: [13][0/29], lr: 0.00100	Time 3.315 (3.315)	Data 2.108 (2.108)	Loss 0.1582 (0.1582)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 1.2283 (1.2283)	Loss KD (GCAM) 0.1080 (0.1080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6748 (0.6748)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8542], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1723], device='cuda:0', requires_grad=True)
2022-03-18 12:09:56.429225
Epoch: [14][0/29], lr: 0.00100	Time 3.061 (3.061)	Data 1.648 (1.648)	Loss 0.1575 (0.1575)	Loss CE 0.0061 (0.0061)	Loss KD (Logit) 1.2160 (1.2160)	Loss KD (GCAM) 0.1059 (0.1059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6775 (0.6775)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8536], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1716], device='cuda:0', requires_grad=True)
2022-03-18 12:10:20.487002
Epoch: [15][0/29], lr: 0.00100	Time 3.066 (3.066)	Data 2.127 (2.127)	Loss 0.1555 (0.1555)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 1.2292 (1.2292)	Loss KD (GCAM) 0.1117 (0.1117)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6789 (0.6789)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8603], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1755], device='cuda:0', requires_grad=True)
2022-03-18 12:10:43.868945
Epoch: [16][0/29], lr: 0.00100	Time 3.055 (3.055)	Data 1.998 (1.998)	Loss 0.1574 (0.1574)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 1.2261 (1.2261)	Loss KD (GCAM) 0.1067 (0.1067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6965 (0.6965)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8667], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1789], device='cuda:0', requires_grad=True)
2022-03-18 12:11:06.922842
Epoch: [17][0/29], lr: 0.00100	Time 2.737 (2.737)	Data 1.651 (1.651)	Loss 0.1773 (0.1773)	Loss CE 0.0269 (0.0269)	Loss KD (Logit) 1.2176 (1.2176)	Loss KD (GCAM) 0.1053 (0.1053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6694 (0.6694)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8700], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1814], device='cuda:0', requires_grad=True)
2022-03-18 12:11:31.356157
Epoch: [18][0/29], lr: 0.00100	Time 3.158 (3.158)	Data 1.783 (1.783)	Loss 0.1510 (0.1510)	Loss CE 0.0060 (0.0060)	Loss KD (Logit) 1.2150 (1.2150)	Loss KD (GCAM) 0.1059 (0.1059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6140 (0.6140)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8782], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1863], device='cuda:0', requires_grad=True)
2022-03-18 12:11:59.932633
Epoch: [19][0/29], lr: 0.00100	Time 3.324 (3.324)	Data 2.275 (2.275)	Loss 0.1486 (0.1486)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 1.2055 (1.2055)	Loss KD (GCAM) 0.0961 (0.0961)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6457 (0.6457)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8850], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1903], device='cuda:0', requires_grad=True)
2022-03-18 12:12:28.111411
Epoch: [20][0/29], lr: 0.00010	Time 3.315 (3.315)	Data 1.968 (1.968)	Loss 0.1617 (0.1617)	Loss CE 0.0120 (0.0120)	Loss KD (Logit) 1.2311 (1.2311)	Loss KD (GCAM) 0.1112 (0.1112)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6382 (0.6382)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8855], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1905], device='cuda:0', requires_grad=True)
2022-03-18 12:12:56.403745
Epoch: [21][0/29], lr: 0.00010	Time 3.332 (3.332)	Data 2.150 (2.150)	Loss 0.1528 (0.1528)	Loss CE 0.0077 (0.0077)	Loss KD (Logit) 1.2161 (1.2161)	Loss KD (GCAM) 0.0974 (0.0974)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6395 (0.6395)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8858], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1907], device='cuda:0', requires_grad=True)
2022-03-18 12:13:25.089830
Epoch: [22][0/29], lr: 0.00010	Time 3.163 (3.163)	Data 2.104 (2.104)	Loss 0.1481 (0.1481)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 1.2125 (1.2125)	Loss KD (GCAM) 0.1045 (0.1045)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6404 (0.6404)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8860], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1908], device='cuda:0', requires_grad=True)
2022-03-18 12:13:53.573745
Epoch: [23][0/29], lr: 0.00010	Time 3.188 (3.188)	Data 2.111 (2.111)	Loss 0.1488 (0.1488)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 1.2075 (1.2075)	Loss KD (GCAM) 0.1013 (0.1013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6539 (0.6539)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8864], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1910], device='cuda:0', requires_grad=True)
2022-03-18 12:14:22.459193
Epoch: [24][0/29], lr: 0.00010	Time 3.418 (3.418)	Data 2.004 (2.004)	Loss 0.1466 (0.1466)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 1.1911 (1.1911)	Loss KD (GCAM) 0.0951 (0.0951)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6452 (0.6452)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8863], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1909], device='cuda:0', requires_grad=True)
2022-03-18 12:14:51.750821
Epoch: [25][0/29], lr: 0.00010	Time 3.484 (3.484)	Data 2.470 (2.470)	Loss 0.1502 (0.1502)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 1.2038 (1.2038)	Loss KD (GCAM) 0.0980 (0.0980)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6590 (0.6590)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8868], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1912], device='cuda:0', requires_grad=True)
2022-03-18 12:15:20.198580
Epoch: [26][0/29], lr: 0.00010	Time 3.412 (3.412)	Data 2.124 (2.124)	Loss 0.1459 (0.1459)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 1.2009 (1.2009)	Loss KD (GCAM) 0.0984 (0.0984)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6480 (0.6480)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8873], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1915], device='cuda:0', requires_grad=True)
2022-03-18 12:15:48.919085
Epoch: [27][0/29], lr: 0.00010	Time 3.215 (3.215)	Data 1.984 (1.984)	Loss 0.1532 (0.1532)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 1.2098 (1.2098)	Loss KD (GCAM) 0.1002 (0.1002)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6706 (0.6706)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8878], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1917], device='cuda:0', requires_grad=True)
2022-03-18 12:16:17.385270
Epoch: [28][0/29], lr: 0.00010	Time 3.091 (3.091)	Data 1.942 (1.942)	Loss 0.1476 (0.1476)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 1.2034 (1.2034)	Loss KD (GCAM) 0.0949 (0.0949)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6661 (0.6661)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8882], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1919], device='cuda:0', requires_grad=True)
2022-03-18 12:16:45.651792
Epoch: [29][0/29], lr: 0.00010	Time 3.147 (3.147)	Data 1.997 (1.997)	Loss 0.1400 (0.1400)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 1.1711 (1.1711)	Loss KD (GCAM) 0.0916 (0.0916)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5981 (0.5981)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8886], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1921], device='cuda:0', requires_grad=True)
2022-03-18 12:17:13.809488
Epoch: [30][0/29], lr: 0.00001	Time 3.248 (3.248)	Data 1.772 (1.772)	Loss 0.1486 (0.1486)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 1.1887 (1.1887)	Loss KD (GCAM) 0.0932 (0.0932)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6629 (0.6629)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8887], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1922], device='cuda:0', requires_grad=True)
2022-03-18 12:17:41.970446
Epoch: [31][0/29], lr: 0.00001	Time 3.077 (3.077)	Data 1.649 (1.649)	Loss 0.1524 (0.1524)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 1.1996 (1.1996)	Loss KD (GCAM) 0.1038 (0.1038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6808 (0.6808)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8887], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1922], device='cuda:0', requires_grad=True)
2022-03-18 12:18:10.479534
Epoch: [32][0/29], lr: 0.00001	Time 3.241 (3.241)	Data 2.076 (2.076)	Loss 0.1516 (0.1516)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 1.2032 (1.2032)	Loss KD (GCAM) 0.1009 (0.1009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6331 (0.6331)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8887], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1922], device='cuda:0', requires_grad=True)
2022-03-18 12:18:39.154757
Epoch: [33][0/29], lr: 0.00001	Time 3.521 (3.521)	Data 2.412 (2.412)	Loss 0.1439 (0.1439)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 1.1856 (1.1856)	Loss KD (GCAM) 0.0901 (0.0901)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6512 (0.6512)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8888], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1922], device='cuda:0', requires_grad=True)
2022-03-18 12:19:07.789005
Epoch: [34][0/29], lr: 0.00001	Time 3.231 (3.231)	Data 2.414 (2.414)	Loss 0.1418 (0.1418)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1816 (1.1816)	Loss KD (GCAM) 0.0903 (0.0903)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6398 (0.6398)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8888], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1922], device='cuda:0', requires_grad=True)
2022-03-18 12:19:36.256105
Epoch: [35][0/29], lr: 0.00001	Time 3.354 (3.354)	Data 1.956 (1.956)	Loss 0.1473 (0.1473)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 1.1983 (1.1983)	Loss KD (GCAM) 0.0950 (0.0950)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6663 (0.6663)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8889], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:20:04.521580
Epoch: [36][0/29], lr: 0.00001	Time 3.169 (3.169)	Data 1.806 (1.806)	Loss 0.1374 (0.1374)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 1.1757 (1.1757)	Loss KD (GCAM) 0.0839 (0.0839)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6070 (0.6070)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8889], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:20:32.696584
Epoch: [37][0/29], lr: 0.00001	Time 3.029 (3.029)	Data 1.806 (1.806)	Loss 0.1610 (0.1610)	Loss CE 0.0141 (0.0141)	Loss KD (Logit) 1.2055 (1.2055)	Loss KD (GCAM) 0.1013 (0.1013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6513 (0.6513)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8890], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:21:00.930565
Epoch: [38][0/29], lr: 0.00001	Time 3.305 (3.305)	Data 1.868 (1.868)	Loss 0.1417 (0.1417)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 1.1933 (1.1933)	Loss KD (GCAM) 0.0927 (0.0927)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6178 (0.6178)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8890], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:21:26.924584
Epoch: [39][0/29], lr: 0.00001	Time 3.402 (3.402)	Data 2.576 (2.576)	Loss 0.1447 (0.1447)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 1.1954 (1.1954)	Loss KD (GCAM) 0.0956 (0.0956)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6445 (0.6445)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8891], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:21:53.156104
Epoch: [40][0/29], lr: 0.00001	Time 3.000 (3.000)	Data 2.116 (2.116)	Loss 0.1455 (0.1455)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 1.1991 (1.1991)	Loss KD (GCAM) 0.0937 (0.0937)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6425 (0.6425)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8891], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1924], device='cuda:0', requires_grad=True)
2022-03-18 12:22:16.748431
Epoch: [41][0/29], lr: 0.00001	Time 3.064 (3.064)	Data 1.928 (1.928)	Loss 0.2411 (0.2411)	Loss CE 0.0984 (0.0984)	Loss KD (Logit) 1.1878 (1.1878)	Loss KD (GCAM) 0.0957 (0.0957)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6329 (0.6329)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8891], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:22:40.399695
Epoch: [42][0/29], lr: 0.00001	Time 3.058 (3.058)	Data 2.000 (2.000)	Loss 0.1431 (0.1431)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1912 (1.1912)	Loss KD (GCAM) 0.0911 (0.0911)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6464 (0.6464)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8891], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1924], device='cuda:0', requires_grad=True)
2022-03-18 12:23:04.041475
Epoch: [43][0/29], lr: 0.00001	Time 3.054 (3.054)	Data 2.053 (2.053)	Loss 0.1521 (0.1521)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 1.2139 (1.2139)	Loss KD (GCAM) 0.0950 (0.0950)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6906 (0.6906)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1924], device='cuda:0', requires_grad=True)
2022-03-18 12:23:27.765340
Epoch: [44][0/29], lr: 0.00001	Time 3.066 (3.066)	Data 2.092 (2.092)	Loss 0.1774 (0.1774)	Loss CE 0.0327 (0.0327)	Loss KD (Logit) 1.1909 (1.1909)	Loss KD (GCAM) 0.0900 (0.0900)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6688 (0.6688)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1924], device='cuda:0', requires_grad=True)
2022-03-18 12:23:51.254631
Epoch: [45][0/29], lr: 0.00001	Time 3.073 (3.073)	Data 2.188 (2.188)	Loss 0.1376 (0.1376)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 1.1641 (1.1641)	Loss KD (GCAM) 0.0878 (0.0878)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6053 (0.6053)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1924], device='cuda:0', requires_grad=True)
2022-03-18 12:24:15.210763
Epoch: [46][0/29], lr: 0.00001	Time 3.147 (3.147)	Data 2.454 (2.454)	Loss 0.1553 (0.1553)	Loss CE 0.0109 (0.0109)	Loss KD (Logit) 1.2030 (1.2030)	Loss KD (GCAM) 0.0940 (0.0940)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6493 (0.6493)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8893], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1924], device='cuda:0', requires_grad=True)
2022-03-18 12:24:38.883523
Epoch: [47][0/29], lr: 0.00001	Time 3.033 (3.033)	Data 1.750 (1.750)	Loss 0.1673 (0.1673)	Loss CE 0.0202 (0.0202)	Loss KD (Logit) 1.1902 (1.1902)	Loss KD (GCAM) 0.0965 (0.0965)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6732 (0.6732)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8893], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1925], device='cuda:0', requires_grad=True)
2022-03-18 12:25:02.919487
Epoch: [48][0/29], lr: 0.00001	Time 3.168 (3.168)	Data 1.901 (1.901)	Loss 0.1529 (0.1529)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 1.1858 (1.1858)	Loss KD (GCAM) 0.0924 (0.0924)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6715 (0.6715)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8894], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1925], device='cuda:0', requires_grad=True)
2022-03-18 12:25:27.082658
Epoch: [49][0/29], lr: 0.00001	Time 3.593 (3.593)	Data 2.586 (2.586)	Loss 0.1440 (0.1440)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 1.1969 (1.1969)	Loss KD (GCAM) 0.0933 (0.0933)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6472 (0.6472)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8894], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1925], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=288, sigma=tensor([3.8894]), eta=tensor([3.1925])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=15, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 483
video number + exemplar : 483
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
Load the Model
SplitCosineLinear(
  input_features=512, output_features=288, sigma=tensor([3.8894]), eta=tensor([3.1925])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=15, sigma=1.0, eta=1.0)
)
exemplar : 480
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-18 12:26:13.717780
Epoch: [0][0/15], lr: 0.00050	Time 2.855 (2.855)	Data 2.405 (2.405)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8898], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1926], device='cuda:0', requires_grad=True)
2022-03-18 12:26:23.504974
Epoch: [1][0/15], lr: 0.00050	Time 2.777 (2.777)	Data 1.971 (1.971)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8919], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1936], device='cuda:0', requires_grad=True)
2022-03-18 12:26:33.052548
Epoch: [2][0/15], lr: 0.00050	Time 2.747 (2.747)	Data 2.082 (2.082)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8932], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1940], device='cuda:0', requires_grad=True)
2022-03-18 12:26:42.863186
Epoch: [3][0/15], lr: 0.00050	Time 2.957 (2.957)	Data 2.125 (2.125)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8945], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1944], device='cuda:0', requires_grad=True)
2022-03-18 12:26:52.407156
Epoch: [4][0/15], lr: 0.00050	Time 2.644 (2.644)	Data 2.094 (2.094)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8940], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1940], device='cuda:0', requires_grad=True)
2022-03-18 12:27:01.155095
Epoch: [5][0/15], lr: 0.00050	Time 2.721 (2.721)	Data 1.859 (1.859)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8930], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1930], device='cuda:0', requires_grad=True)
2022-03-18 12:27:11.642793
Epoch: [6][0/15], lr: 0.00050	Time 3.177 (3.177)	Data 2.414 (2.414)	Loss 0.0054 (0.0054)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8922], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:27:22.897580
Epoch: [7][0/15], lr: 0.00050	Time 2.902 (2.902)	Data 2.016 (2.016)	Loss 0.0079 (0.0079)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8919], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1919], device='cuda:0', requires_grad=True)
2022-03-18 12:27:34.077977
Epoch: [8][0/15], lr: 0.00050	Time 2.787 (2.787)	Data 2.297 (2.297)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8923], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1918], device='cuda:0', requires_grad=True)
2022-03-18 12:27:45.457911
Epoch: [9][0/15], lr: 0.00050	Time 3.211 (3.211)	Data 2.354 (2.354)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8927], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1917], device='cuda:0', requires_grad=True)
2022-03-18 12:27:56.365804
Epoch: [10][0/15], lr: 0.00050	Time 2.844 (2.844)	Data 2.320 (2.320)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8935], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1921], device='cuda:0', requires_grad=True)
2022-03-18 12:28:07.598751
Epoch: [11][0/15], lr: 0.00050	Time 3.015 (3.015)	Data 2.234 (2.234)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8929], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1915], device='cuda:0', requires_grad=True)
2022-03-18 12:28:18.435621
Epoch: [12][0/15], lr: 0.00050	Time 2.663 (2.663)	Data 1.752 (1.752)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8938], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1918], device='cuda:0', requires_grad=True)
2022-03-18 12:28:29.543872
Epoch: [13][0/15], lr: 0.00050	Time 2.943 (2.943)	Data 1.910 (1.910)	Loss 0.0046 (0.0046)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8948], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1921], device='cuda:0', requires_grad=True)
2022-03-18 12:28:40.636110
Epoch: [14][0/15], lr: 0.00050	Time 2.782 (2.782)	Data 2.004 (2.004)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8955], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1923], device='cuda:0', requires_grad=True)
2022-03-18 12:28:51.798056
Epoch: [15][0/15], lr: 0.00050	Time 2.995 (2.995)	Data 1.905 (1.905)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8957], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1922], device='cuda:0', requires_grad=True)
2022-03-18 12:29:02.639243
Epoch: [16][0/15], lr: 0.00050	Time 2.930 (2.930)	Data 1.904 (1.904)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8961], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1921], device='cuda:0', requires_grad=True)
2022-03-18 12:29:13.501744
Epoch: [17][0/15], lr: 0.00050	Time 2.775 (2.775)	Data 2.181 (2.181)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8969], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1924], device='cuda:0', requires_grad=True)
2022-03-18 12:29:24.640988
Epoch: [18][0/15], lr: 0.00050	Time 3.017 (3.017)	Data 2.245 (2.245)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8976], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1926], device='cuda:0', requires_grad=True)
2022-03-18 12:29:35.416798
Epoch: [19][0/15], lr: 0.00050	Time 2.945 (2.945)	Data 2.456 (2.456)	Loss 0.0055 (0.0055)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8987], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1930], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
Load the Trained Model from checkpoint/ucf101/51/5/003/task_009.pth.tar
exemplar : 480
Computing the class mean vectors...
Eval Task 0 for Age 9
Current Task : [37, 97, 56, 55, 33, 84, 3, 4, 72, 59, 66, 48, 65, 91, 99, 39, 34, 22, 67, 74, 19, 35, 9, 86, 88, 63, 85, 38, 54, 25, 57, 62, 83, 76, 6, 13, 2, 53, 8, 24, 44, 12, 100, 29, 5, 17, 15, 73, 47, 27, 46]
video number : 1909
video number + exemplar : 1909
DataLoader Constructed
Test: [0/120]	Time 7.173 (7.173)	Prec@1 68.750 (68.750)
Test: [100/120]	Time 0.495 (0.565)	Prec@1 68.750 (57.983)
Testing Results: Prec@1 58.355
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 81.250 (66.275)
Testing Results (NME): Prec@1 66.632
Eval Task 1 for Age 9
Current Task : [98, 96, 18, 90, 75]
video number : 162
video number + exemplar : 162
DataLoader Constructed
Test: [0/11]	Time 4.417 (4.417)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 60.494
Classify using the NME Classifier...
Test (NME): [0/11]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 58.642
Eval Task 2 for Age 9
Current Task : [31, 95, 49, 43, 78]
video number : 191
video number + exemplar : 191
DataLoader Constructed
Test: [0/12]	Time 4.729 (4.729)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 65.445
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 73.298
Eval Task 3 for Age 9
Current Task : [23, 68, 16, 7, 26]
video number : 213
video number + exemplar : 213
DataLoader Constructed
Test: [0/14]	Time 5.112 (5.112)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 46.479
Classify using the NME Classifier...
Test (NME): [0/14]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 46.009
Eval Task 4 for Age 9
Current Task : [21, 50, 70, 32, 52]
video number : 189
video number + exemplar : 189
DataLoader Constructed
Test: [0/12]	Time 4.299 (4.299)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 62.963
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 70.370
Eval Task 5 for Age 9
Current Task : [11, 69, 93, 14, 79]
video number : 162
video number + exemplar : 162
DataLoader Constructed
Test: [0/11]	Time 4.125 (4.125)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 59.877
Classify using the NME Classifier...
Test (NME): [0/11]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 71.605
Eval Task 6 for Age 9
Current Task : [10, 80, 77, 81, 28]
video number : 189
video number + exemplar : 189
DataLoader Constructed
Test: [0/12]	Time 5.147 (5.147)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 70.370
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 67.725
Eval Task 7 for Age 9
Current Task : [82, 30, 20, 41, 58]
video number : 194
video number + exemplar : 194
DataLoader Constructed
Test: [0/13]	Time 5.039 (5.039)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 84.536
Classify using the NME Classifier...
Test (NME): [0/13]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 82.474
Eval Task 8 for Age 9
Current Task : [42, 60, 36, 40, 45]
video number : 186
video number + exemplar : 186
DataLoader Constructed
Test: [0/12]	Time 4.666 (4.666)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 85.484
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 73.118
Eval Task 9 for Age 9
Current Task : [89, 0, 61, 1, 92]
video number : 201
video number + exemplar : 201
DataLoader Constructed
Test: [0/13]	Time 4.782 (4.782)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.507
Classify using the NME Classifier...
Test (NME): [0/13]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 82.090
num_test_videos [1909, 162, 191, 213, 189, 162, 189, 194, 186, 201]
Method : OURS
----AGE 10----
current_task  [94, 64, 71, 87, 51]
current_head  101
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.04381780460041328]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([3.8987]), eta=tensor([3.1930])
  (fc1): CosineLinear(input_features=512, output_features=288, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=15, sigma=1.0, eta=1.0)
)
video number : 461
video number + exemplar : 941
DataLoader Constructed : Train 29
Optimizer Constructed
video number : 461
video number + exemplar : 461
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-18 12:35:17.517117
Epoch: [0][0/29], lr: 0.00100	Time 3.608 (3.608)	Data 2.544 (2.544)	Loss 0.1468 (0.1468)	Loss CE 0.0145 (0.0145)	Loss KD (Logit) 1.1127 (1.1127)	Loss KD (GCAM) 0.0528 (0.0528)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6768 (0.6768)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.8826], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1857], device='cuda:0', requires_grad=True)
2022-03-18 12:35:45.219168
Epoch: [1][0/29], lr: 0.00100	Time 3.377 (3.377)	Data 2.635 (2.635)	Loss 0.1907 (0.1907)	Loss CE 0.0431 (0.0431)	Loss KD (Logit) 1.1827 (1.1827)	Loss KD (GCAM) 0.0988 (0.0988)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6618 (0.6618)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8826], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1861], device='cuda:0', requires_grad=True)
2022-03-18 12:36:11.247600
Epoch: [2][0/29], lr: 0.00100	Time 3.246 (3.246)	Data 2.531 (2.531)	Loss 0.2379 (0.2379)	Loss CE 0.0951 (0.0951)	Loss KD (Logit) 1.2056 (1.2056)	Loss KD (GCAM) 0.0995 (0.0995)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6013 (0.6013)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8730], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1813], device='cuda:0', requires_grad=True)
2022-03-18 12:36:37.330681
Epoch: [3][0/29], lr: 0.00100	Time 3.193 (3.193)	Data 2.044 (2.044)	Loss 0.4257 (0.4257)	Loss CE 0.2789 (0.2789)	Loss KD (Logit) 1.1926 (1.1926)	Loss KD (GCAM) 0.0971 (0.0971)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6547 (0.6547)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
Sigma : Parameter containing:
tensor([3.8770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1842], device='cuda:0', requires_grad=True)
2022-03-18 12:37:00.932171
Epoch: [4][0/29], lr: 0.00100	Time 2.709 (2.709)	Data 1.863 (1.863)	Loss 0.1552 (0.1552)	Loss CE 0.0086 (0.0086)	Loss KD (Logit) 1.1953 (1.1953)	Loss KD (GCAM) 0.0926 (0.0926)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6647 (0.6647)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8781], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1852], device='cuda:0', requires_grad=True)
2022-03-18 12:37:25.680980
Epoch: [5][0/29], lr: 0.00100	Time 3.510 (3.510)	Data 2.717 (2.717)	Loss 0.1614 (0.1614)	Loss CE 0.0127 (0.0127)	Loss KD (Logit) 1.1909 (1.1909)	Loss KD (GCAM) 0.1035 (0.1035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6549 (0.6549)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8833], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1894], device='cuda:0', requires_grad=True)
2022-03-18 12:37:49.595239
Epoch: [6][0/29], lr: 0.00100	Time 3.354 (3.354)	Data 2.423 (2.423)	Loss 0.3247 (0.3247)	Loss CE 0.1790 (0.1790)	Loss KD (Logit) 1.1968 (1.1968)	Loss KD (GCAM) 0.1019 (0.1019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6268 (0.6268)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8810], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1890], device='cuda:0', requires_grad=True)
2022-03-18 12:38:13.743664
Epoch: [7][0/29], lr: 0.00100	Time 3.371 (3.371)	Data 2.234 (2.234)	Loss 0.1449 (0.1449)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 1.1990 (1.1990)	Loss KD (GCAM) 0.0974 (0.0974)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6142 (0.6142)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8862], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1917], device='cuda:0', requires_grad=True)
2022-03-18 12:38:38.147922
Epoch: [8][0/29], lr: 0.00100	Time 3.093 (3.093)	Data 2.021 (2.021)	Loss 0.1536 (0.1536)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 1.2105 (1.2105)	Loss KD (GCAM) 0.1017 (0.1017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6885 (0.6885)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8913], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1947], device='cuda:0', requires_grad=True)
2022-03-18 12:39:02.044214
Epoch: [9][0/29], lr: 0.00100	Time 3.189 (3.189)	Data 1.961 (1.961)	Loss 0.1548 (0.1548)	Loss CE 0.0149 (0.0149)	Loss KD (Logit) 1.1919 (1.1919)	Loss KD (GCAM) 0.0972 (0.0972)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5848 (0.5848)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9025], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2017], device='cuda:0', requires_grad=True)
2022-03-18 12:39:26.428398
Epoch: [10][0/29], lr: 0.00100	Time 3.117 (3.117)	Data 1.899 (1.899)	Loss 0.1682 (0.1682)	Loss CE 0.0242 (0.0242)	Loss KD (Logit) 1.1888 (1.1888)	Loss KD (GCAM) 0.0927 (0.0927)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6410 (0.6410)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9092], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2054], device='cuda:0', requires_grad=True)
2022-03-18 12:39:50.448328
Epoch: [11][0/29], lr: 0.00100	Time 3.089 (3.089)	Data 2.077 (2.077)	Loss 0.1691 (0.1691)	Loss CE 0.0248 (0.0248)	Loss KD (Logit) 1.1975 (1.1975)	Loss KD (GCAM) 0.0975 (0.0975)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6258 (0.6258)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9133], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2074], device='cuda:0', requires_grad=True)
2022-03-18 12:40:14.578973
Epoch: [12][0/29], lr: 0.00100	Time 3.221 (3.221)	Data 2.193 (2.193)	Loss 0.1417 (0.1417)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 1.1738 (1.1738)	Loss KD (GCAM) 0.0854 (0.0854)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6320 (0.6320)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9191], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2102], device='cuda:0', requires_grad=True)
2022-03-18 12:40:38.662192
Epoch: [13][0/29], lr: 0.00100	Time 3.083 (3.083)	Data 1.943 (1.943)	Loss 0.1462 (0.1462)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 1.1923 (1.1923)	Loss KD (GCAM) 0.0872 (0.0872)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6194 (0.6194)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2093], device='cuda:0', requires_grad=True)
2022-03-18 12:41:03.140410
Epoch: [14][0/29], lr: 0.00100	Time 3.155 (3.155)	Data 2.174 (2.174)	Loss 0.1506 (0.1506)	Loss CE 0.0050 (0.0050)	Loss KD (Logit) 1.1963 (1.1963)	Loss KD (GCAM) 0.0965 (0.0965)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6426 (0.6426)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9226], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2113], device='cuda:0', requires_grad=True)
2022-03-18 12:41:27.058902
Epoch: [15][0/29], lr: 0.00100	Time 3.196 (3.196)	Data 2.073 (2.073)	Loss 0.1479 (0.1479)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 1.1968 (1.1968)	Loss KD (GCAM) 0.0971 (0.0971)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6404 (0.6404)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2142], device='cuda:0', requires_grad=True)
2022-03-18 12:41:50.233204
Epoch: [16][0/29], lr: 0.00100	Time 3.334 (3.334)	Data 2.513 (2.513)	Loss 0.3046 (0.3046)	Loss CE 0.1607 (0.1607)	Loss KD (Logit) 1.1968 (1.1968)	Loss KD (GCAM) 0.0908 (0.0908)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6422 (0.6422)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9321], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2159], device='cuda:0', requires_grad=True)
2022-03-18 12:42:18.479925
Epoch: [17][0/29], lr: 0.00100	Time 3.162 (3.162)	Data 1.954 (1.954)	Loss 0.1504 (0.1504)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 1.1855 (1.1855)	Loss KD (GCAM) 0.0899 (0.0899)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6828 (0.6828)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9380], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2188], device='cuda:0', requires_grad=True)
2022-03-18 12:42:46.636986
Epoch: [18][0/29], lr: 0.00100	Time 3.456 (3.456)	Data 2.182 (2.182)	Loss 0.1428 (0.1428)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 1.1650 (1.1650)	Loss KD (GCAM) 0.0766 (0.0766)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6695 (0.6695)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9425], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2209], device='cuda:0', requires_grad=True)
2022-03-18 12:43:15.373560
Epoch: [19][0/29], lr: 0.00100	Time 3.417 (3.417)	Data 2.426 (2.426)	Loss 0.1457 (0.1457)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 1.1635 (1.1635)	Loss KD (GCAM) 0.0869 (0.0869)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6286 (0.6286)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9457], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2225], device='cuda:0', requires_grad=True)
2022-03-18 12:43:43.721191
Epoch: [20][0/29], lr: 0.00010	Time 3.303 (3.303)	Data 2.355 (2.355)	Loss 0.1415 (0.1415)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 1.1664 (1.1664)	Loss KD (GCAM) 0.0832 (0.0832)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6216 (0.6216)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9462], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2227], device='cuda:0', requires_grad=True)
2022-03-18 12:44:12.096624
Epoch: [21][0/29], lr: 0.00010	Time 3.299 (3.299)	Data 2.114 (2.114)	Loss 0.1404 (0.1404)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 1.1652 (1.1652)	Loss KD (GCAM) 0.0812 (0.0812)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6164 (0.6164)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9466], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2229], device='cuda:0', requires_grad=True)
2022-03-18 12:44:41.099179
Epoch: [22][0/29], lr: 0.00010	Time 3.483 (3.483)	Data 2.196 (2.196)	Loss 0.1509 (0.1509)	Loss CE 0.0113 (0.0113)	Loss KD (Logit) 1.1706 (1.1706)	Loss KD (GCAM) 0.0820 (0.0820)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6376 (0.6376)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9467], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2229], device='cuda:0', requires_grad=True)
2022-03-18 12:45:09.618780
Epoch: [23][0/29], lr: 0.00010	Time 3.523 (3.523)	Data 2.392 (2.392)	Loss 0.1425 (0.1425)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 1.1694 (1.1694)	Loss KD (GCAM) 0.0810 (0.0810)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6511 (0.6511)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9468], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2230], device='cuda:0', requires_grad=True)
2022-03-18 12:45:38.346767
Epoch: [24][0/29], lr: 0.00010	Time 3.344 (3.344)	Data 2.523 (2.523)	Loss 0.1410 (0.1410)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 1.1513 (1.1513)	Loss KD (GCAM) 0.0798 (0.0798)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6351 (0.6351)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9469], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2230], device='cuda:0', requires_grad=True)
2022-03-18 12:46:06.636976
Epoch: [25][0/29], lr: 0.00010	Time 3.147 (3.147)	Data 1.985 (1.985)	Loss 0.1349 (0.1349)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 1.1545 (1.1545)	Loss KD (GCAM) 0.0765 (0.0765)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6095 (0.6095)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9470], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2230], device='cuda:0', requires_grad=True)
2022-03-18 12:46:35.133951
Epoch: [26][0/29], lr: 0.00010	Time 3.229 (3.229)	Data 2.330 (2.330)	Loss 0.1384 (0.1384)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 1.1596 (1.1596)	Loss KD (GCAM) 0.0754 (0.0754)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6399 (0.6399)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9474], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2232], device='cuda:0', requires_grad=True)
2022-03-18 12:47:03.555453
Epoch: [27][0/29], lr: 0.00010	Time 3.271 (3.271)	Data 2.516 (2.516)	Loss 0.2736 (0.2736)	Loss CE 0.1378 (0.1378)	Loss KD (Logit) 1.1697 (1.1697)	Loss KD (GCAM) 0.0835 (0.0835)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5953 (0.5953)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9476], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2233], device='cuda:0', requires_grad=True)
2022-03-18 12:47:31.884000
Epoch: [28][0/29], lr: 0.00010	Time 3.225 (3.225)	Data 2.293 (2.293)	Loss 0.1350 (0.1350)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 1.1506 (1.1506)	Loss KD (GCAM) 0.0754 (0.0754)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5918 (0.5918)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9478], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2234], device='cuda:0', requires_grad=True)
2022-03-18 12:48:00.373458
Epoch: [29][0/29], lr: 0.00010	Time 3.293 (3.293)	Data 2.360 (2.360)	Loss 0.1479 (0.1479)	Loss CE 0.0066 (0.0066)	Loss KD (Logit) 1.1708 (1.1708)	Loss KD (GCAM) 0.0775 (0.0775)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6676 (0.6676)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9479], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2234], device='cuda:0', requires_grad=True)
2022-03-18 12:48:29.112480
Epoch: [30][0/29], lr: 0.00001	Time 3.608 (3.608)	Data 2.095 (2.095)	Loss 0.1378 (0.1378)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 1.1555 (1.1555)	Loss KD (GCAM) 0.0704 (0.0704)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6465 (0.6465)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9479], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2234], device='cuda:0', requires_grad=True)
2022-03-18 12:48:57.668292
Epoch: [31][0/29], lr: 0.00001	Time 3.377 (3.377)	Data 2.304 (2.304)	Loss 0.1284 (0.1284)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 1.1484 (1.1484)	Loss KD (GCAM) 0.0692 (0.0692)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5661 (0.5661)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9479], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:49:26.192761
Epoch: [32][0/29], lr: 0.00001	Time 3.400 (3.400)	Data 2.476 (2.476)	Loss 0.1326 (0.1326)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 1.1534 (1.1534)	Loss KD (GCAM) 0.0738 (0.0738)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5885 (0.5885)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9480], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:49:54.603471
Epoch: [33][0/29], lr: 0.00001	Time 3.434 (3.434)	Data 2.563 (2.563)	Loss 0.1356 (0.1356)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1688 (1.1688)	Loss KD (GCAM) 0.0772 (0.0772)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6093 (0.6093)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9480], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:50:23.356067
Epoch: [34][0/29], lr: 0.00001	Time 3.284 (3.284)	Data 2.528 (2.528)	Loss 0.1402 (0.1402)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 1.1361 (1.1361)	Loss KD (GCAM) 0.0787 (0.0787)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6636 (0.6636)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9480], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:50:51.601174
Epoch: [35][0/29], lr: 0.00001	Time 3.194 (3.194)	Data 2.153 (2.153)	Loss 0.1333 (0.1333)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 1.1562 (1.1562)	Loss KD (GCAM) 0.0728 (0.0728)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5943 (0.5943)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9480], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:51:19.762150
Epoch: [36][0/29], lr: 0.00001	Time 3.059 (3.059)	Data 1.822 (1.822)	Loss 0.1382 (0.1382)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1733 (1.1733)	Loss KD (GCAM) 0.0808 (0.0808)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6215 (0.6215)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9480], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:51:45.790639
Epoch: [37][0/29], lr: 0.00001	Time 3.275 (3.275)	Data 2.520 (2.520)	Loss 0.1337 (0.1337)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 1.1482 (1.1482)	Loss KD (GCAM) 0.0710 (0.0710)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6149 (0.6149)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9481], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:52:11.459043
Epoch: [38][0/29], lr: 0.00001	Time 3.250 (3.250)	Data 2.107 (2.107)	Loss 0.1388 (0.1388)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 1.1496 (1.1496)	Loss KD (GCAM) 0.0733 (0.0733)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6556 (0.6556)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9481], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:52:35.725793
Epoch: [39][0/29], lr: 0.00001	Time 3.232 (3.232)	Data 2.315 (2.315)	Loss 0.1467 (0.1467)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 1.1783 (1.1783)	Loss KD (GCAM) 0.0774 (0.0774)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7137 (0.7137)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9481], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2235], device='cuda:0', requires_grad=True)
2022-03-18 12:52:59.362241
Epoch: [40][0/29], lr: 0.00001	Time 3.236 (3.236)	Data 2.228 (2.228)	Loss 0.1327 (0.1327)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 1.1396 (1.1396)	Loss KD (GCAM) 0.0759 (0.0759)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5945 (0.5945)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:53:23.429767
Epoch: [41][0/29], lr: 0.00001	Time 3.491 (3.491)	Data 2.720 (2.720)	Loss 0.1354 (0.1354)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 1.1502 (1.1502)	Loss KD (GCAM) 0.0740 (0.0740)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6183 (0.6183)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:53:47.469659
Epoch: [42][0/29], lr: 0.00001	Time 3.466 (3.466)	Data 2.327 (2.327)	Loss 0.1381 (0.1381)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 1.1482 (1.1482)	Loss KD (GCAM) 0.0752 (0.0752)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6416 (0.6416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:54:11.332345
Epoch: [43][0/29], lr: 0.00001	Time 3.144 (3.144)	Data 2.268 (2.268)	Loss 0.1348 (0.1348)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 1.1644 (1.1644)	Loss KD (GCAM) 0.0775 (0.0775)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5951 (0.5951)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9483], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:54:35.414240
Epoch: [44][0/29], lr: 0.00001	Time 3.236 (3.236)	Data 2.306 (2.306)	Loss 0.1382 (0.1382)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 1.1538 (1.1538)	Loss KD (GCAM) 0.0766 (0.0766)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6373 (0.6373)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9483], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:54:59.349716
Epoch: [45][0/29], lr: 0.00001	Time 3.458 (3.458)	Data 2.438 (2.438)	Loss 0.1340 (0.1340)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 1.1635 (1.1635)	Loss KD (GCAM) 0.0775 (0.0775)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5885 (0.5885)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9483], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:55:23.489398
Epoch: [46][0/29], lr: 0.00001	Time 3.245 (3.245)	Data 2.519 (2.519)	Loss 0.1386 (0.1386)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 1.1621 (1.1621)	Loss KD (GCAM) 0.0765 (0.0765)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6322 (0.6322)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9483], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:55:47.510925
Epoch: [47][0/29], lr: 0.00001	Time 3.345 (3.345)	Data 2.182 (2.182)	Loss 0.1402 (0.1402)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 1.1557 (1.1557)	Loss KD (GCAM) 0.0792 (0.0792)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6432 (0.6432)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9483], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:56:11.822057
Epoch: [48][0/29], lr: 0.00001	Time 3.249 (3.249)	Data 2.336 (2.336)	Loss 0.1390 (0.1390)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 1.1476 (1.1476)	Loss KD (GCAM) 0.0721 (0.0721)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6598 (0.6598)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9484], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2236], device='cuda:0', requires_grad=True)
2022-03-18 12:56:36.257603
Epoch: [49][0/29], lr: 0.00001	Time 3.576 (3.576)	Data 2.681 (2.681)	Loss 0.1622 (0.1622)	Loss CE 0.0261 (0.0261)	Loss KD (Logit) 1.1512 (1.1512)	Loss KD (GCAM) 0.0740 (0.0740)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6350 (0.6350)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9484], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2237], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([3.9484]), eta=tensor([3.2237])
  (fc1): CosineLinear(input_features=512, output_features=288, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=15, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 461
video number + exemplar : 461
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
Load the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([3.9484]), eta=tensor([3.2237])
  (fc1): CosineLinear(input_features=512, output_features=288, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=15, sigma=1.0, eta=1.0)
)
exemplar : 505
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-18 12:57:22.637085
Epoch: [0][0/15], lr: 0.00050	Time 3.031 (3.031)	Data 2.354 (2.354)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9494], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2241], device='cuda:0', requires_grad=True)
2022-03-18 12:57:32.125772
Epoch: [1][0/15], lr: 0.00050	Time 3.129 (3.129)	Data 2.400 (2.400)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2243], device='cuda:0', requires_grad=True)
2022-03-18 12:57:43.437204
Epoch: [2][0/15], lr: 0.00050	Time 3.247 (3.247)	Data 2.496 (2.496)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2248], device='cuda:0', requires_grad=True)
2022-03-18 12:57:54.863240
Epoch: [3][0/15], lr: 0.00050	Time 3.061 (3.061)	Data 1.866 (1.866)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2251], device='cuda:0', requires_grad=True)
2022-03-18 12:58:06.472618
Epoch: [4][0/15], lr: 0.00050	Time 3.197 (3.197)	Data 1.931 (1.931)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9536], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2259], device='cuda:0', requires_grad=True)
2022-03-18 12:58:18.043477
Epoch: [5][0/15], lr: 0.00050	Time 3.223 (3.223)	Data 2.443 (2.443)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9543], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2262], device='cuda:0', requires_grad=True)
2022-03-18 12:58:29.486040
Epoch: [6][0/15], lr: 0.00050	Time 3.147 (3.147)	Data 2.080 (2.080)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9545], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2260], device='cuda:0', requires_grad=True)
2022-03-18 12:58:41.056799
Epoch: [7][0/15], lr: 0.00050	Time 3.141 (3.141)	Data 2.155 (2.155)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9540], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2257], device='cuda:0', requires_grad=True)
2022-03-18 12:58:52.799810
Epoch: [8][0/15], lr: 0.00050	Time 3.324 (3.324)	Data 2.580 (2.580)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9543], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2256], device='cuda:0', requires_grad=True)
2022-03-18 12:59:04.161508
Epoch: [9][0/15], lr: 0.00050	Time 3.139 (3.139)	Data 2.513 (2.513)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9548], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2257], device='cuda:0', requires_grad=True)
2022-03-18 12:59:15.764419
Epoch: [10][0/15], lr: 0.00050	Time 3.156 (3.156)	Data 2.438 (2.438)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2258], device='cuda:0', requires_grad=True)
2022-03-18 12:59:27.529253
Epoch: [11][0/15], lr: 0.00050	Time 3.328 (3.328)	Data 2.546 (2.546)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9557], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2258], device='cuda:0', requires_grad=True)
2022-03-18 12:59:39.099255
Epoch: [12][0/15], lr: 0.00050	Time 3.299 (3.299)	Data 2.600 (2.600)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9561], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2259], device='cuda:0', requires_grad=True)
2022-03-18 12:59:50.861295
Epoch: [13][0/15], lr: 0.00050	Time 3.244 (3.244)	Data 2.550 (2.550)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9561], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2258], device='cuda:0', requires_grad=True)
2022-03-18 13:00:01.808364
Epoch: [14][0/15], lr: 0.00050	Time 2.841 (2.841)	Data 1.923 (1.923)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2256], device='cuda:0', requires_grad=True)
2022-03-18 13:00:13.111420
Epoch: [15][0/15], lr: 0.00050	Time 3.191 (3.191)	Data 1.985 (1.985)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2258], device='cuda:0', requires_grad=True)
2022-03-18 13:00:24.642800
Epoch: [16][0/15], lr: 0.00050	Time 3.190 (3.190)	Data 2.428 (2.428)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9580], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2262], device='cuda:0', requires_grad=True)
2022-03-18 13:00:35.608366
Epoch: [17][0/15], lr: 0.00050	Time 2.760 (2.760)	Data 1.986 (1.986)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9591], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2265], device='cuda:0', requires_grad=True)
2022-03-18 13:00:46.977384
Epoch: [18][0/15], lr: 0.00050	Time 3.189 (3.189)	Data 2.519 (2.519)	Loss 0.0050 (0.0050)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2268], device='cuda:0', requires_grad=True)
2022-03-18 13:00:58.306482
Epoch: [19][0/15], lr: 0.00050	Time 2.959 (2.959)	Data 2.072 (2.072)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9603], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.2268], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
Load the Trained Model from checkpoint/ucf101/51/5/003/task_010.pth.tar
exemplar : 505
Computing the class mean vectors...
Eval Task 0 for Age 10
Current Task : [37, 97, 56, 55, 33, 84, 3, 4, 72, 59, 66, 48, 65, 91, 99, 39, 34, 22, 67, 74, 19, 35, 9, 86, 88, 63, 85, 38, 54, 25, 57, 62, 83, 76, 6, 13, 2, 53, 8, 24, 44, 12, 100, 29, 5, 17, 15, 73, 47, 27, 46]
video number : 1909
video number + exemplar : 1909
DataLoader Constructed
Test: [0/120]	Time 4.517 (4.517)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.433 (0.542)	Prec@1 68.750 (55.817)
Testing Results: Prec@1 56.312
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 81.250 (66.399)
Testing Results (NME): Prec@1 66.684
Eval Task 1 for Age 10
Current Task : [98, 96, 18, 90, 75]
video number : 162
video number + exemplar : 162
DataLoader Constructed
Test: [0/11]	Time 4.543 (4.543)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 59.259
Classify using the NME Classifier...
Test (NME): [0/11]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 60.494
Eval Task 2 for Age 10
Current Task : [31, 95, 49, 43, 78]
video number : 191
video number + exemplar : 191
DataLoader Constructed
Test: [0/12]	Time 4.599 (4.599)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 64.398
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 75.393
Eval Task 3 for Age 10
Current Task : [23, 68, 16, 7, 26]
video number : 213
video number + exemplar : 213
DataLoader Constructed
Test: [0/14]	Time 4.960 (4.960)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 43.662
Classify using the NME Classifier...
Test (NME): [0/14]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 45.540
Eval Task 4 for Age 10
Current Task : [21, 50, 70, 32, 52]
video number : 189
video number + exemplar : 189
DataLoader Constructed
Test: [0/12]	Time 4.512 (4.512)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 62.434
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 69.312
Eval Task 5 for Age 10
Current Task : [11, 69, 93, 14, 79]
video number : 162
video number + exemplar : 162
DataLoader Constructed
Test: [0/11]	Time 4.548 (4.548)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 64.815
Classify using the NME Classifier...
Test (NME): [0/11]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 66.667
Eval Task 6 for Age 10
Current Task : [10, 80, 77, 81, 28]
video number : 189
video number + exemplar : 189
DataLoader Constructed
Test: [0/12]	Time 4.370 (4.370)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 75.132
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 69.312
Eval Task 7 for Age 10
Current Task : [82, 30, 20, 41, 58]
video number : 194
video number + exemplar : 194
DataLoader Constructed
Test: [0/13]	Time 4.680 (4.680)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.928
Classify using the NME Classifier...
Test (NME): [0/13]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 77.320
Eval Task 8 for Age 10
Current Task : [42, 60, 36, 40, 45]
video number : 186
video number + exemplar : 186
DataLoader Constructed
Test: [0/12]	Time 4.284 (4.284)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 81.183
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 72.043
Eval Task 9 for Age 10
Current Task : [89, 0, 61, 1, 92]
video number : 201
video number + exemplar : 201
DataLoader Constructed
Test: [0/13]	Time 4.424 (4.424)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 94.527
Classify using the NME Classifier...
Test (NME): [0/13]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 79.104
Eval Task 10 for Age 10
Current Task : [94, 64, 71, 87, 51]
video number : 187
video number + exemplar : 187
DataLoader Constructed
Test: [0/12]	Time 4.600 (4.600)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 90.374
Classify using the NME Classifier...
Test (NME): [0/12]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 72.193
num_test_videos [1909, 162, 191, 213, 189, 162, 189, 194, 186, 201, 187]
n_vids [1909  162  191  213  189  162  189  194  186  201  187]
n_vids_pad [[1909.]
 [ 162.]
 [ 191.]
 [ 213.]
 [ 189.]
 [ 162.]
 [ 189.]
 [ 194.]
 [ 186.]
 [ 201.]
 [ 187.]]
tmp [[162000.         142300.         134200.         126800.
  125300.         121000.         119100.         116100.
  114000.         111400.         107500.        ]
 [-32400.          15600.          13300.          11100.
   11700.          11100.          10700.          11500.
    9900.           9800.           9600.        ]
 [-38200.         -38200.          18199.99992371  15500.
   15399.99996185  15199.99992371  13899.99996185  12800.
   13699.99996185  12500.          12300.        ]
 [-42600.         -42600.         -42600.          20200.
   17200.          14000.          12400.          10200.
   10800.           9900.           9300.        ]
 [-37800.         -37800.         -37800.         -37800.
   17999.99994659  16199.99997711  15299.99999237  12800.00000763
   13599.99999237  11900.00000763  11800.00000763]
 [-32400.         -32400.         -32400.         -32400.
  -32400.          14200.          13200.          11400.
   11300.           9700.          10500.        ]
 [-37800.         -37800.         -37800.         -37800.
  -37800.         -37800.          17300.          15700.00001526
   15299.99993134  13299.99994659  14199.99994659]
 [-38800.         -38800.         -38800.         -38800.
  -38800.         -38800.         -38800.          18900.
   17000.          16400.          15700.        ]
 [-37200.         -37200.         -37200.         -37200.
  -37200.         -37200.         -37200.         -37200.
   17500.          15900.          15100.        ]
 [-40200.         -40200.         -40200.         -40200.
  -40200.         -40200.         -40200.         -40200.
  -40200.          19800.          18999.99993896]
 [-37400.         -37400.         -37400.         -37400.
  -37400.         -37400.         -37400.         -37400.
  -37400.         -37400.          16900.        ]]
tmp [[ 19700.           8100.           7400.           1500.
    4300.           1900.           3000.           2100.
    2600.           3900.        ]
 [-48000.           2300.           2200.           -600.
     600.            400.           -800.           1600.
     100.            200.        ]
 [    -0.         -56399.99992371   2699.99992371    100.00003815
     200.00003815   1299.99996185   1099.99996185   -899.99996185
    1199.99996185    200.        ]
 [    -0.             -0.         -62800.           3000.
    3200.           1600.           2200.           -600.
     900.            600.        ]
 [    -0.             -0.             -0.         -55799.99994659
    1799.99996948    899.99998474   2499.99998474   -799.99998474
    1699.99998474    100.        ]
 [    -0.             -0.             -0.             -0.
  -46600.           1000.           1800.            100.
    1600.           -800.        ]
 [    -0.             -0.             -0.             -0.
      -0.         -55100.           1599.99998474    400.00008392
    1999.99998474   -900.        ]
 [    -0.             -0.             -0.             -0.
      -0.             -0.         -57700.           1900.
     600.            700.        ]
 [    -0.             -0.             -0.             -0.
      -0.             -0.             -0.         -54700.
    1600.            800.        ]
 [    -0.             -0.             -0.             -0.
      -0.             -0.             -0.             -0.
  -60000.            800.00006104]]
tmp [[19700.          8100.          7400.          1500.
   4300.          1900.          3000.          2100.
   2600.          3900.        ]
 [    0.          2300.          2200.          -600.
    600.           400.          -800.          1600.
    100.           200.        ]
 [    0.             0.          2699.99992371   100.00003815
    200.00003815  1299.99996185  1099.99996185  -899.99996185
   1199.99996185   200.        ]
 [    0.             0.             0.          3000.
   3200.          1600.          2200.          -600.
    900.           600.        ]
 [    0.             0.             0.             0.
   1799.99996948   899.99998474  2499.99998474  -799.99998474
   1699.99998474   100.        ]
 [    0.             0.             0.             0.
      0.          1000.          1800.           100.
   1600.          -800.        ]
 [    0.             0.             0.             0.
      0.             0.          1599.99998474   400.00008392
   1999.99998474  -900.        ]
 [    0.             0.             0.             0.
      0.             0.             0.          1900.
    600.           700.        ]
 [    0.             0.             0.             0.
      0.             0.             0.             0.
   1600.           800.        ]
 [    0.             0.             0.             0.
      0.             0.             0.             0.
      0.           800.00006104]]
tmp [19700.         10400.         12299.99992371  4000.00003815
 10100.00000763  7099.99994659 11399.99993134  3800.00013733
 12299.99993134  5600.00006104]
cumsum_n_vids [1909 2071 2262 2475 2664 2826 3015 3209 3395 3596]
fgt [10.31953903  5.02172863  5.43766575  1.61616163  3.79129129  2.51238498
  3.7810945   1.18416957  3.62297494  1.55728589]
fgt 3.8844296214957508
fgt [3.88442962]
n_vids [1909  162  191  213  189  162  189  194  186  201  187]
n_vids_pad [[1909.]
 [ 162.]
 [ 191.]
 [ 213.]
 [ 189.]
 [ 162.]
 [ 189.]
 [ 194.]
 [ 186.]
 [ 201.]
 [ 187.]]
tmp [[157000.         150100.         146600.         140400.
  140900.         135700.         135400.         133400.
  130300.         127200.         127300.        ]
 [-32400.          12900.          11500.          10500.
   10500.          10400.          10300.          10800.
    9200.           9500.           9800.        ]
 [-38200.         -38200.          15600.          14300.
   14199.99992371  13999.99992371  13899.99992371  13800.
   13900.          14000.          14399.99992371]
 [-42600.         -42600.         -42600.          13600.
   13300.          11600.          11300.          10500.
   10500.           9800.           9700.        ]
 [-37800.         -37800.         -37800.         -37800.
   15399.99997711  15399.99997711  14399.99997711  13699.99999237
   14599.99999237  13299.99999237  13099.99999237]
 [-32400.         -32400.         -32400.         -32400.
  -32400.          12500.          12300.          11100.
   11500.          11600.          10800.        ]
 [-37800.         -37800.         -37800.         -37800.
  -37800.         -37800.          15299.99993134  14299.99993134
   13899.99993134  12799.99993134  13099.99993134]
 [-38800.         -38800.         -38800.         -38800.
  -38800.         -38800.         -38800.          17700.
   16200.          16000.          15000.        ]
 [-37200.         -37200.         -37200.         -37200.
  -37200.         -37200.         -37200.         -37200.
   14000.          13600.          13400.        ]
 [-40200.         -40200.         -40200.         -40200.
  -40200.         -40200.         -40200.         -40200.
  -40200.          16499.99998474  15899.99998474]
 [-37400.         -37400.         -37400.         -37400.
  -37400.         -37400.         -37400.         -37400.
  -37400.         -37400.          13499.99999237]]
tmp [[  6900.           3500.           6200.           -500.
    5200.            300.           2000.           3100.
    3100.           -100.        ]
 [-45300.           1400.           1000.             -0.
     100.            100.           -500.           1600.
    -300.           -300.        ]
 [    -0.         -53800.           1300.            100.00007629
     200.            100.             99.99992371   -100.
    -100.           -399.99992371]
 [    -0.             -0.         -56200.            300.
    1700.            300.            800.             -0.
     700.            100.        ]
 [    -0.             -0.             -0.         -53199.99997711
      -0.           1000.            699.99998474   -900.
    1300.            200.        ]
 [    -0.             -0.             -0.             -0.
  -44900.            200.           1200.           -400.
    -100.            800.        ]
 [    -0.             -0.             -0.             -0.
      -0.         -53099.99993134   1000.            400.
    1100.           -300.        ]
 [    -0.             -0.             -0.             -0.
      -0.             -0.         -56500.           1500.
     200.           1000.        ]
 [    -0.             -0.             -0.             -0.
      -0.             -0.             -0.         -51200.
     400.            200.        ]
 [    -0.             -0.             -0.             -0.
      -0.             -0.             -0.             -0.
  -56699.99998474    600.        ]]
tmp [[6900.         3500.         6200.         -500.         5200.
   300.         2000.         3100.         3100.         -100.        ]
 [   0.         1400.         1000.           -0.          100.
   100.         -500.         1600.         -300.         -300.        ]
 [   0.            0.         1300.          100.00007629  200.
   100.           99.99992371 -100.         -100.         -399.99992371]
 [   0.            0.            0.          300.         1700.
   300.          800.           -0.          700.          100.        ]
 [   0.            0.            0.            0.           -0.
  1000.          699.99998474 -900.         1300.          200.        ]
 [   0.            0.            0.            0.            0.
   200.         1200.         -400.         -100.          800.        ]
 [   0.            0.            0.            0.            0.
     0.         1000.          400.         1100.         -300.        ]
 [   0.            0.            0.            0.            0.
     0.            0.         1500.          200.         1000.        ]
 [   0.            0.            0.            0.            0.
     0.            0.            0.          400.          200.        ]
 [   0.            0.            0.            0.            0.
     0.            0.            0.            0.          600.        ]]
tmp [6900.         4900.         8500.          -99.99992371 7200.
 2000.         5299.99990845 5200.         6300.         1800.00007629]
cumsum_n_vids [1909 2071 2262 2475 2664 2826 3015 3209 3395 3596]
fgt [ 3.61445783  2.36600676  3.75773652 -0.04040401  2.7027027   0.70771408
  1.75787725  1.62044251  1.8556701   0.50055619]
fgt 1.8842759937524842
fgt [1.88427599]