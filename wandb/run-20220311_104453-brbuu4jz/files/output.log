ucf101: 101 classes
Method : OURS
----AGE 0----
current_task  [37, 97, 56, 55, 33, 84, 3, 4, 72, 59, 66, 48, 65, 91, 99, 39, 34, 22, 67, 74, 19, 35, 9, 86, 88, 63, 85, 38, 54, 25, 57, 62, 83, 76, 6, 13, 2, 53, 8, 24, 44, 12, 100, 29, 5, 17, 15, 73, 47, 27, 46]
current_head  51
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
CosineLinear(input_features=512, output_features=153, sigma=tensor([1.]), eta=tensor([1.]))
video number : 4793
video number + exemplar : 4793
DataLoader Constructed : Train 149
Optimizer Constructed
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-11 10:45:16.234447
Epoch: [0][0/149], lr: 0.00100	Time 13.456 (13.456)	Data 2.869 (2.869)	Loss 3.9903 (3.9903)	Loss CE 3.9284 (3.9284)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6193 (0.6193)	Loss REG 0.0000 (0.0000)	Prec@1 3.125 (3.125)
2022-03-11 10:46:11.497714
Epoch: [0][100/149], lr: 0.00100	Time 0.549 (0.680)	Data 0.000 (0.029)	Loss 3.9829 (3.9906)	Loss CE 3.9226 (3.9284)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6026 (0.6220)	Loss REG 0.0000 (0.0000)	Prec@1 0.000 (2.847)
Sigma : Parameter containing:
tensor([1.0671], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.0317], device='cuda:0', requires_grad=True)
2022-03-11 10:46:37.854608
Epoch: [1][0/149], lr: 0.00100	Time 3.175 (3.175)	Data 1.788 (1.788)	Loss 3.9822 (3.9822)	Loss CE 3.9199 (3.9199)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6230 (0.6230)	Loss REG 0.0000 (0.0000)	Prec@1 9.375 (9.375)
2022-03-11 10:47:52.254164
Epoch: [1][100/149], lr: 0.00100	Time 0.739 (0.768)	Data 0.000 (0.018)	Loss 3.9678 (3.9694)	Loss CE 3.9096 (3.9089)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5813 (0.6049)	Loss REG 0.0000 (0.0000)	Prec@1 9.375 (7.240)
Sigma : Parameter containing:
tensor([1.4107], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.2164], device='cuda:0', requires_grad=True)
2022-03-11 10:48:26.723447
Epoch: [2][0/149], lr: 0.00100	Time 2.822 (2.822)	Data 1.790 (1.790)	Loss 3.9156 (3.9156)	Loss CE 3.8553 (3.8553)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6026 (0.6026)	Loss REG 0.0000 (0.0000)	Prec@1 21.875 (21.875)
2022-03-11 10:49:18.811909
Epoch: [2][100/149], lr: 0.00100	Time 0.427 (0.544)	Data 0.000 (0.018)	Loss 3.4322 (3.7730)	Loss CE 3.3687 (3.7108)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6348 (0.6223)	Loss REG 0.0000 (0.0000)	Prec@1 18.750 (20.142)
Sigma : Parameter containing:
tensor([3.3025], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.4167], device='cuda:0', requires_grad=True)
2022-03-11 10:49:45.328344
Epoch: [3][0/149], lr: 0.00100	Time 3.012 (3.012)	Data 1.915 (1.915)	Loss 2.0281 (2.0281)	Loss CE 1.9637 (1.9637)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6437 (0.6437)	Loss REG 0.0000 (0.0000)	Prec@1 53.125 (53.125)
2022-03-11 10:51:00.312634
Epoch: [3][100/149], lr: 0.00100	Time 0.733 (0.772)	Data 0.000 (0.019)	Loss 1.8448 (1.8402)	Loss CE 1.7763 (1.7741)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6851 (0.6609)	Loss REG 0.0000 (0.0000)	Prec@1 50.000 (53.527)
Sigma : Parameter containing:
tensor([3.6799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.7708], device='cuda:0', requires_grad=True)
2022-03-11 10:51:32.648363
Epoch: [4][0/149], lr: 0.00100	Time 2.881 (2.881)	Data 2.113 (2.113)	Loss 1.3241 (1.3241)	Loss CE 1.2556 (1.2556)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6845 (0.6845)	Loss REG 0.0000 (0.0000)	Prec@1 59.375 (59.375)
Traceback (most recent call last):
  File "main.py", line 101, in <module>
    main()
  File "main.py", line 71, in main
    train_i_cl.train_task(args, i, current_task, current_head, class_indexer, model_flow=model_flow, prefix=prefix)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 461, in train_task
    _train(args, train_loader, model, criterion, optimizer, epoch, age, regularizer=regularizer, lambda_0=lambda_0, model_old=model_old, importance_list=importance_list)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 167, in _train
    if loss_reg != 0:
KeyboardInterrupt