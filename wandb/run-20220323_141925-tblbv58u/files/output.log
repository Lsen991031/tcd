ucf101: 101 classes
creating folder log/ucf101/51/2/006
creating folder checkpoint/ucf101/51/2/006
Method : OURS
----AGE 0----
current_task  [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
current_head  51
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
CosineLinear(input_features=512, output_features=153, sigma=tensor([1.]), eta=tensor([1.]))
video number : 4880
video number + exemplar : 4880
DataLoader Constructed : Train 152
Optimizer Constructed
2022-03-23 14:19:46.436020
Epoch: [0][0/152], lr: 0.00100	Time 13.403 (13.403)	Data 1.904 (1.904)	Loss 3.9944 (3.9944)	Loss CE 3.9328 (3.9328)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6161 (0.6161)	Loss REG 0.0000 (0.0000)	Prec@1 9.375 (9.375)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 14:20:31.464220
Epoch: [0][100/152], lr: 0.00100	Time 0.396 (0.579)	Data 0.000 (0.019)	Loss 3.9860 (3.9924)	Loss CE 3.9240 (3.9302)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6197 (0.6226)	Loss REG 0.0000 (0.0000)	Prec@1 6.250 (2.847)
Sigma : Parameter containing:
tensor([1.0366], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.0169], device='cuda:0', requires_grad=True)
2022-03-23 14:20:56.953423
Epoch: [1][0/152], lr: 0.00100	Time 2.830 (2.830)	Data 2.046 (2.046)	Loss 3.9831 (3.9831)	Loss CE 3.9211 (3.9211)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6195 (0.6195)	Loss REG 0.0000 (0.0000)	Prec@1 3.125 (3.125)
2022-03-23 14:21:41.761623
Epoch: [1][100/152], lr: 0.00100	Time 0.499 (0.472)	Data 0.000 (0.021)	Loss 3.9617 (3.9760)	Loss CE 3.9013 (3.9156)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6038 (0.6035)	Loss REG 0.0000 (0.0000)	Prec@1 15.625 (5.631)
Sigma : Parameter containing:
tensor([1.2854], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.1470], device='cuda:0', requires_grad=True)
2022-03-23 14:22:08.191202
Epoch: [2][0/152], lr: 0.00100	Time 2.706 (2.706)	Data 1.808 (1.808)	Loss 3.9471 (3.9471)	Loss CE 3.8881 (3.8881)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5904 (0.5904)	Loss REG 0.0000 (0.0000)	Prec@1 3.125 (3.125)
2022-03-23 14:22:54.410282
Epoch: [2][100/152], lr: 0.00100	Time 0.551 (0.484)	Data 0.000 (0.018)	Loss 3.8025 (3.9029)	Loss CE 3.7425 (3.8423)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6000 (0.6057)	Loss REG 0.0000 (0.0000)	Prec@1 21.875 (16.615)
Sigma : Parameter containing:
tensor([2.5162], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.9000], device='cuda:0', requires_grad=True)
2022-03-23 14:23:21.173079
Epoch: [3][0/152], lr: 0.00100	Time 2.834 (2.834)	Data 2.184 (2.184)	Loss 3.0882 (3.0882)	Loss CE 3.0253 (3.0253)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6286 (0.6286)	Loss REG 0.0000 (0.0000)	Prec@1 31.250 (31.250)
2022-03-23 14:24:07.291095
Epoch: [3][100/152], lr: 0.00100	Time 0.607 (0.485)	Data 0.000 (0.022)	Loss 1.4232 (2.2712)	Loss CE 1.3545 (2.2062)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6873 (0.6497)	Loss REG 0.0000 (0.0000)	Prec@1 62.500 (44.276)
Sigma : Parameter containing:
tensor([3.6417], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.7269], device='cuda:0', requires_grad=True)
2022-03-23 14:24:34.471006
Epoch: [4][0/152], lr: 0.00100	Time 2.970 (2.970)	Data 2.211 (2.211)	Loss 1.5875 (1.5875)	Loss CE 1.5209 (1.5209)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6659 (0.6659)	Loss REG 0.0000 (0.0000)	Prec@1 56.250 (56.250)
2022-03-23 14:25:19.042802
Epoch: [4][100/152], lr: 0.00100	Time 0.434 (0.471)	Data 0.000 (0.022)	Loss 0.9211 (1.1933)	Loss CE 0.8547 (1.1271)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6641 (0.6623)	Loss REG 0.0000 (0.0000)	Prec@1 75.000 (69.616)
Sigma : Parameter containing:
tensor([3.6534], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.7915], device='cuda:0', requires_grad=True)
2022-03-23 14:25:47.460587
Epoch: [5][0/152], lr: 0.00100	Time 2.720 (2.720)	Data 1.993 (1.993)	Loss 0.6805 (0.6805)	Loss CE 0.6122 (0.6122)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6830 (0.6830)	Loss REG 0.0000 (0.0000)	Prec@1 75.000 (75.000)
2022-03-23 14:26:38.953378
Epoch: [5][100/152], lr: 0.00100	Time 0.438 (0.537)	Data 0.003 (0.020)	Loss 0.7889 (0.8213)	Loss CE 0.7259 (0.7555)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6299 (0.6575)	Loss REG 0.0000 (0.0000)	Prec@1 81.250 (79.084)
Sigma : Parameter containing:
tensor([3.6721], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.8359], device='cuda:0', requires_grad=True)
2022-03-23 14:27:08.734042
Epoch: [6][0/152], lr: 0.00100	Time 2.886 (2.886)	Data 2.251 (2.251)	Loss 0.5099 (0.5099)	Loss CE 0.4451 (0.4451)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6479 (0.6479)	Loss REG 0.0000 (0.0000)	Prec@1 84.375 (84.375)
2022-03-23 14:28:01.036387
Epoch: [6][100/152], lr: 0.00100	Time 0.514 (0.546)	Data 0.000 (0.023)	Loss 0.4738 (0.6058)	Loss CE 0.4119 (0.5403)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6197 (0.6556)	Loss REG 0.0000 (0.0000)	Prec@1 87.500 (85.241)
Sigma : Parameter containing:
tensor([3.7273], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.8944], device='cuda:0', requires_grad=True)
2022-03-23 14:28:30.914421
Epoch: [7][0/152], lr: 0.00100	Time 2.727 (2.727)	Data 1.908 (1.908)	Loss 0.2398 (0.2398)	Loss CE 0.1739 (0.1739)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6591 (0.6591)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-23 14:29:23.293170
Epoch: [7][100/152], lr: 0.00100	Time 0.686 (0.546)	Data 0.000 (0.019)	Loss 0.4792 (0.5315)	Loss CE 0.4147 (0.4660)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6449 (0.6547)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (87.345)
Sigma : Parameter containing:
tensor([3.6878], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.8937], device='cuda:0', requires_grad=True)
2022-03-23 14:29:53.332384
Epoch: [8][0/152], lr: 0.00100	Time 2.890 (2.890)	Data 2.305 (2.305)	Loss 0.3784 (0.3784)	Loss CE 0.3124 (0.3124)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6600 (0.6600)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-23 14:30:45.039714
Epoch: [8][100/152], lr: 0.00100	Time 0.492 (0.541)	Data 0.000 (0.023)	Loss 0.1794 (0.4458)	Loss CE 0.1173 (0.3803)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6211 (0.6551)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (89.325)
Sigma : Parameter containing:
tensor([3.7076], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9237], device='cuda:0', requires_grad=True)
2022-03-23 14:31:14.960101
Epoch: [9][0/152], lr: 0.00100	Time 2.741 (2.741)	Data 1.830 (1.830)	Loss 0.3080 (0.3080)	Loss CE 0.2414 (0.2414)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6661 (0.6661)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-23 14:32:06.620163
Epoch: [9][100/152], lr: 0.00100	Time 0.482 (0.539)	Data 0.000 (0.018)	Loss 0.4086 (0.3812)	Loss CE 0.3431 (0.3160)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6551 (0.6521)	Loss REG 0.0000 (0.0000)	Prec@1 87.500 (90.996)
Sigma : Parameter containing:
tensor([3.7206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9401], device='cuda:0', requires_grad=True)
2022-03-23 14:32:37.069276
Epoch: [10][0/152], lr: 0.00100	Time 3.148 (3.148)	Data 2.402 (2.402)	Loss 0.2402 (0.2402)	Loss CE 0.1748 (0.1748)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6539 (0.6539)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-23 14:33:28.893503
Epoch: [10][100/152], lr: 0.00100	Time 0.486 (0.544)	Data 0.000 (0.024)	Loss 0.1952 (0.3059)	Loss CE 0.1328 (0.2409)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6241 (0.6504)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (93.502)
Sigma : Parameter containing:
tensor([3.7733], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9825], device='cuda:0', requires_grad=True)
2022-03-23 14:33:58.909739
Epoch: [11][0/152], lr: 0.00100	Time 2.778 (2.778)	Data 2.108 (2.108)	Loss 0.3022 (0.3022)	Loss CE 0.2383 (0.2383)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6383 (0.6383)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-23 14:34:50.669195
Epoch: [11][100/152], lr: 0.00100	Time 0.465 (0.540)	Data 0.000 (0.021)	Loss 0.5340 (0.3247)	Loss CE 0.4697 (0.2596)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6434 (0.6503)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (93.224)
Sigma : Parameter containing:
tensor([3.7540], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9750], device='cuda:0', requires_grad=True)
2022-03-23 14:35:21.026564
Epoch: [12][0/152], lr: 0.00100	Time 2.974 (2.974)	Data 1.820 (1.820)	Loss 0.3083 (0.3083)	Loss CE 0.2451 (0.2451)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6318 (0.6318)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-23 14:36:12.853355
Epoch: [12][100/152], lr: 0.00100	Time 0.641 (0.543)	Data 0.000 (0.018)	Loss 0.5834 (0.2673)	Loss CE 0.5201 (0.2029)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6329 (0.6441)	Loss REG 0.0000 (0.0000)	Prec@1 84.375 (94.338)
Sigma : Parameter containing:
tensor([3.7571], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9826], device='cuda:0', requires_grad=True)
2022-03-23 14:36:42.531131
Epoch: [13][0/152], lr: 0.00100	Time 2.756 (2.756)	Data 1.934 (1.934)	Loss 0.4375 (0.4375)	Loss CE 0.3736 (0.3736)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6392 (0.6392)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-23 14:37:34.225749
Epoch: [13][100/152], lr: 0.00100	Time 0.433 (0.539)	Data 0.000 (0.019)	Loss 0.2563 (0.2620)	Loss CE 0.1898 (0.1976)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6658 (0.6437)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (94.245)
Sigma : Parameter containing:
tensor([3.7452], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9837], device='cuda:0', requires_grad=True)
2022-03-23 14:38:03.950600
Epoch: [14][0/152], lr: 0.00100	Time 2.860 (2.860)	Data 2.059 (2.059)	Loss 0.1607 (0.1607)	Loss CE 0.1007 (0.1007)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6002 (0.6002)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-23 14:38:55.236878
Epoch: [14][100/152], lr: 0.00100	Time 0.460 (0.536)	Data 0.000 (0.021)	Loss 0.1225 (0.2244)	Loss CE 0.0583 (0.1598)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6427 (0.6457)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (95.575)
Sigma : Parameter containing:
tensor([3.7294], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9792], device='cuda:0', requires_grad=True)
2022-03-23 14:39:25.802404
Epoch: [15][0/152], lr: 0.00100	Time 3.128 (3.128)	Data 2.398 (2.398)	Loss 0.2050 (0.2050)	Loss CE 0.1423 (0.1423)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6267 (0.6267)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-23 14:40:17.454708
Epoch: [15][100/152], lr: 0.00100	Time 0.674 (0.542)	Data 0.000 (0.024)	Loss 0.2902 (0.2051)	Loss CE 0.2240 (0.1407)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6619 (0.6444)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (96.380)
Sigma : Parameter containing:
tensor([3.7349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9856], device='cuda:0', requires_grad=True)
2022-03-23 14:40:47.797474
Epoch: [16][0/152], lr: 0.00100	Time 2.991 (2.991)	Data 1.982 (1.982)	Loss 0.3338 (0.3338)	Loss CE 0.2707 (0.2707)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6309 (0.6309)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-23 14:41:36.561779
Epoch: [16][100/152], lr: 0.00100	Time 0.440 (0.512)	Data 0.000 (0.020)	Loss 0.0823 (0.1471)	Loss CE 0.0168 (0.0830)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6552 (0.6410)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (97.679)
Sigma : Parameter containing:
tensor([3.8177], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0371], device='cuda:0', requires_grad=True)
2022-03-23 14:42:04.091747
Epoch: [17][0/152], lr: 0.00100	Time 2.859 (2.859)	Data 1.893 (1.893)	Loss 0.3179 (0.3179)	Loss CE 0.2550 (0.2550)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6297 (0.6297)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-23 14:42:50.761521
Epoch: [17][100/152], lr: 0.00100	Time 0.455 (0.490)	Data 0.000 (0.019)	Loss 0.1640 (0.2112)	Loss CE 0.1013 (0.1470)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6262 (0.6414)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (95.761)
Sigma : Parameter containing:
tensor([3.7736], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0130], device='cuda:0', requires_grad=True)
2022-03-23 14:43:18.455570
Epoch: [18][0/152], lr: 0.00100	Time 2.774 (2.774)	Data 2.126 (2.126)	Loss 0.1985 (0.1985)	Loss CE 0.1338 (0.1338)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6469 (0.6469)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:44:06.207157
Epoch: [18][100/152], lr: 0.00100	Time 0.471 (0.500)	Data 0.000 (0.021)	Loss 0.0811 (0.1699)	Loss CE 0.0206 (0.1057)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6049 (0.6416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (97.030)
Sigma : Parameter containing:
tensor([3.7999], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0312], device='cuda:0', requires_grad=True)
2022-03-23 14:44:34.062471
Epoch: [19][0/152], lr: 0.00100	Time 2.749 (2.749)	Data 2.256 (2.256)	Loss 0.1776 (0.1776)	Loss CE 0.1134 (0.1134)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6418 (0.6418)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-23 14:45:21.930197
Epoch: [19][100/152], lr: 0.00100	Time 0.462 (0.501)	Data 0.000 (0.023)	Loss 0.0771 (0.1655)	Loss CE 0.0106 (0.1013)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6647 (0.6417)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (97.246)
Sigma : Parameter containing:
tensor([3.8273], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0483], device='cuda:0', requires_grad=True)
2022-03-23 14:45:49.389582
Epoch: [20][0/152], lr: 0.00010	Time 2.805 (2.805)	Data 2.035 (2.035)	Loss 0.0987 (0.0987)	Loss CE 0.0335 (0.0335)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6519 (0.6519)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:46:35.052228
Epoch: [20][100/152], lr: 0.00010	Time 0.430 (0.480)	Data 0.000 (0.020)	Loss 0.1162 (0.1226)	Loss CE 0.0530 (0.0588)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6323 (0.6383)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (98.453)
Sigma : Parameter containing:
tensor([3.8313], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0509], device='cuda:0', requires_grad=True)
2022-03-23 14:47:01.498462
Epoch: [21][0/152], lr: 0.00010	Time 2.707 (2.707)	Data 1.719 (1.719)	Loss 0.0664 (0.0664)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6376 (0.6376)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:47:46.966800
Epoch: [21][100/152], lr: 0.00010	Time 0.480 (0.477)	Data 0.000 (0.017)	Loss 0.0945 (0.1055)	Loss CE 0.0361 (0.0417)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5840 (0.6373)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (98.979)
Sigma : Parameter containing:
tensor([3.8362], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0541], device='cuda:0', requires_grad=True)
2022-03-23 14:48:13.971925
Epoch: [22][0/152], lr: 0.00010	Time 2.894 (2.894)	Data 1.834 (1.834)	Loss 0.0721 (0.0721)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6460 (0.6460)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:48:59.452592
Epoch: [22][100/152], lr: 0.00010	Time 0.439 (0.479)	Data 0.000 (0.018)	Loss 0.0672 (0.0978)	Loss CE 0.0030 (0.0342)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6415 (0.6360)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (98.979)
Sigma : Parameter containing:
tensor([3.8400], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0562], device='cuda:0', requires_grad=True)
2022-03-23 14:49:26.241981
Epoch: [23][0/152], lr: 0.00010	Time 2.771 (2.771)	Data 2.201 (2.201)	Loss 0.0684 (0.0684)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6521 (0.6521)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:50:11.772848
Epoch: [23][100/152], lr: 0.00010	Time 0.439 (0.478)	Data 0.000 (0.022)	Loss 0.0697 (0.0872)	Loss CE 0.0114 (0.0233)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5838 (0.6385)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.443)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0585], device='cuda:0', requires_grad=True)
2022-03-23 14:50:38.469933
Epoch: [24][0/152], lr: 0.00010	Time 2.790 (2.790)	Data 1.941 (1.941)	Loss 0.0674 (0.0674)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6680 (0.6680)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:51:23.757872
Epoch: [24][100/152], lr: 0.00010	Time 0.416 (0.476)	Data 0.000 (0.019)	Loss 0.0754 (0.1022)	Loss CE 0.0121 (0.0384)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6334 (0.6375)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (98.979)
Sigma : Parameter containing:
tensor([3.8454], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0592], device='cuda:0', requires_grad=True)
2022-03-23 14:51:50.550963
Epoch: [25][0/152], lr: 0.00010	Time 2.866 (2.866)	Data 2.117 (2.117)	Loss 0.0649 (0.0649)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6312 (0.6312)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:52:36.673834
Epoch: [25][100/152], lr: 0.00010	Time 0.443 (0.485)	Data 0.000 (0.022)	Loss 0.0698 (0.0900)	Loss CE 0.0024 (0.0265)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6744 (0.6349)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.257)
Sigma : Parameter containing:
tensor([3.8491], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0615], device='cuda:0', requires_grad=True)
2022-03-23 14:53:06.598400
Epoch: [26][0/152], lr: 0.00010	Time 2.707 (2.707)	Data 1.681 (1.681)	Loss 0.0679 (0.0679)	Loss CE 0.0054 (0.0054)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6248 (0.6248)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:53:58.425808
Epoch: [26][100/152], lr: 0.00010	Time 0.437 (0.540)	Data 0.000 (0.017)	Loss 0.0738 (0.0840)	Loss CE 0.0119 (0.0205)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6184 (0.6354)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.474)
Sigma : Parameter containing:
tensor([3.8533], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0642], device='cuda:0', requires_grad=True)
2022-03-23 14:54:28.817627
Epoch: [27][0/152], lr: 0.00010	Time 2.787 (2.787)	Data 1.873 (1.873)	Loss 0.1032 (0.1032)	Loss CE 0.0378 (0.0378)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6540 (0.6540)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-23 14:55:20.857872
Epoch: [27][100/152], lr: 0.00010	Time 0.470 (0.543)	Data 0.000 (0.019)	Loss 0.0669 (0.0822)	Loss CE 0.0025 (0.0186)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6440 (0.6352)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.536)
Sigma : Parameter containing:
tensor([3.8578], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0670], device='cuda:0', requires_grad=True)
2022-03-23 14:55:51.334656
Epoch: [28][0/152], lr: 0.00010	Time 3.029 (3.029)	Data 2.170 (2.170)	Loss 0.0624 (0.0624)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6156 (0.6156)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:56:43.494453
Epoch: [28][100/152], lr: 0.00010	Time 0.609 (0.546)	Data 0.000 (0.022)	Loss 0.0667 (0.0829)	Loss CE 0.0059 (0.0191)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6077 (0.6371)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.567)
Sigma : Parameter containing:
tensor([3.8608], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0686], device='cuda:0', requires_grad=True)
2022-03-23 14:57:12.966955
Epoch: [29][0/152], lr: 0.00010	Time 2.703 (2.703)	Data 2.122 (2.122)	Loss 0.0715 (0.0715)	Loss CE 0.0080 (0.0080)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6351 (0.6351)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:58:05.099204
Epoch: [29][100/152], lr: 0.00010	Time 0.660 (0.543)	Data 0.000 (0.022)	Loss 0.0765 (0.0843)	Loss CE 0.0158 (0.0210)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6068 (0.6336)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.536)
Sigma : Parameter containing:
tensor([3.8634], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0701], device='cuda:0', requires_grad=True)
2022-03-23 14:58:35.118373
Epoch: [30][0/152], lr: 0.00001	Time 2.748 (2.748)	Data 2.054 (2.054)	Loss 0.0622 (0.0622)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5997 (0.5997)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 14:59:27.387558
Epoch: [30][100/152], lr: 0.00001	Time 0.482 (0.545)	Data 0.000 (0.021)	Loss 0.0955 (0.0852)	Loss CE 0.0329 (0.0215)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6256 (0.6368)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.412)
Sigma : Parameter containing:
tensor([3.8638], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0703], device='cuda:0', requires_grad=True)
2022-03-23 14:59:57.326510
Epoch: [31][0/152], lr: 0.00001	Time 2.832 (2.832)	Data 2.323 (2.323)	Loss 0.0654 (0.0654)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6348 (0.6348)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:00:49.385052
Epoch: [31][100/152], lr: 0.00001	Time 0.425 (0.543)	Data 0.000 (0.023)	Loss 0.1208 (0.0804)	Loss CE 0.0577 (0.0169)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6308 (0.6351)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.474)
Sigma : Parameter containing:
tensor([3.8642], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0706], device='cuda:0', requires_grad=True)
2022-03-23 15:01:19.864685
Epoch: [32][0/152], lr: 0.00001	Time 2.906 (2.906)	Data 1.944 (1.944)	Loss 0.0647 (0.0647)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6198 (0.6198)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:02:12.441208
Epoch: [32][100/152], lr: 0.00001	Time 0.429 (0.549)	Data 0.000 (0.019)	Loss 0.1765 (0.0926)	Loss CE 0.1115 (0.0292)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6497 (0.6335)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.257)
Sigma : Parameter containing:
tensor([3.8644], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0707], device='cuda:0', requires_grad=True)
2022-03-23 15:02:42.762192
Epoch: [33][0/152], lr: 0.00001	Time 2.770 (2.770)	Data 1.898 (1.898)	Loss 0.0904 (0.0904)	Loss CE 0.0276 (0.0276)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6282 (0.6282)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:03:34.397456
Epoch: [33][100/152], lr: 0.00001	Time 0.439 (0.539)	Data 0.000 (0.019)	Loss 0.1462 (0.0858)	Loss CE 0.0851 (0.0227)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6108 (0.6312)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.412)
Sigma : Parameter containing:
tensor([3.8648], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0709], device='cuda:0', requires_grad=True)
2022-03-23 15:04:04.934249
Epoch: [34][0/152], lr: 0.00001	Time 3.057 (3.057)	Data 1.778 (1.778)	Loss 0.0643 (0.0643)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6049 (0.6049)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:04:56.905207
Epoch: [34][100/152], lr: 0.00001	Time 0.509 (0.545)	Data 0.000 (0.018)	Loss 0.0654 (0.0866)	Loss CE 0.0019 (0.0230)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6354 (0.6359)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.505)
Sigma : Parameter containing:
tensor([3.8650], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0710], device='cuda:0', requires_grad=True)
2022-03-23 15:05:27.065165
Epoch: [35][0/152], lr: 0.00001	Time 2.857 (2.857)	Data 2.011 (2.011)	Loss 0.0656 (0.0656)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6209 (0.6209)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:06:18.720398
Epoch: [35][100/152], lr: 0.00001	Time 0.465 (0.540)	Data 0.000 (0.020)	Loss 0.1438 (0.0843)	Loss CE 0.0761 (0.0208)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6775 (0.6351)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.505)
Sigma : Parameter containing:
tensor([3.8654], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0713], device='cuda:0', requires_grad=True)
2022-03-23 15:06:48.698452
Epoch: [36][0/152], lr: 0.00001	Time 2.739 (2.739)	Data 1.936 (1.936)	Loss 0.0647 (0.0647)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6283 (0.6283)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:07:40.526072
Epoch: [36][100/152], lr: 0.00001	Time 0.501 (0.540)	Data 0.000 (0.020)	Loss 0.0701 (0.0847)	Loss CE 0.0044 (0.0213)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6565 (0.6341)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.381)
Sigma : Parameter containing:
tensor([3.8657], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0714], device='cuda:0', requires_grad=True)
2022-03-23 15:08:09.166914
Epoch: [37][0/152], lr: 0.00001	Time 2.796 (2.796)	Data 1.861 (1.861)	Loss 0.1025 (0.1025)	Loss CE 0.0389 (0.0389)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6361 (0.6361)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:08:57.231347
Epoch: [37][100/152], lr: 0.00001	Time 0.513 (0.504)	Data 0.000 (0.019)	Loss 0.0667 (0.0764)	Loss CE 0.0024 (0.0129)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6433 (0.6354)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.691)
Sigma : Parameter containing:
tensor([3.8661], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0716], device='cuda:0', requires_grad=True)
2022-03-23 15:09:24.598391
Epoch: [38][0/152], lr: 0.00001	Time 2.791 (2.791)	Data 1.887 (1.887)	Loss 0.0860 (0.0860)	Loss CE 0.0230 (0.0230)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6303 (0.6303)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:10:12.988559
Epoch: [38][100/152], lr: 0.00001	Time 0.463 (0.507)	Data 0.000 (0.019)	Loss 0.1799 (0.0899)	Loss CE 0.1184 (0.0265)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6154 (0.6349)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (99.226)
Sigma : Parameter containing:
tensor([3.8664], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0718], device='cuda:0', requires_grad=True)
2022-03-23 15:10:41.146273
Epoch: [39][0/152], lr: 0.00001	Time 3.017 (3.017)	Data 2.431 (2.431)	Loss 0.0628 (0.0628)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6181 (0.6181)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:11:29.415994
Epoch: [39][100/152], lr: 0.00001	Time 0.483 (0.508)	Data 0.000 (0.024)	Loss 0.0663 (0.0858)	Loss CE 0.0051 (0.0225)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6129 (0.6335)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.443)
Sigma : Parameter containing:
tensor([3.8667], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 15:11:57.351153
Epoch: [40][0/152], lr: 0.00001	Time 2.653 (2.653)	Data 1.916 (1.916)	Loss 0.1045 (0.1045)	Loss CE 0.0381 (0.0381)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6642 (0.6642)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-23 15:12:44.625562
Epoch: [40][100/152], lr: 0.00001	Time 0.404 (0.494)	Data 0.000 (0.019)	Loss 0.0699 (0.0850)	Loss CE 0.0065 (0.0215)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6340 (0.6345)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.412)
Sigma : Parameter containing:
tensor([3.8670], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0722], device='cuda:0', requires_grad=True)
2022-03-23 15:13:11.855124
Epoch: [41][0/152], lr: 0.00001	Time 2.794 (2.794)	Data 1.871 (1.871)	Loss 0.0715 (0.0715)	Loss CE 0.0112 (0.0112)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6040 (0.6040)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:13:58.171434
Epoch: [41][100/152], lr: 0.00001	Time 0.432 (0.486)	Data 0.000 (0.019)	Loss 0.0718 (0.0832)	Loss CE 0.0034 (0.0195)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6837 (0.6367)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.474)
Sigma : Parameter containing:
tensor([3.8673], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0724], device='cuda:0', requires_grad=True)
2022-03-23 15:14:25.248070
Epoch: [42][0/152], lr: 0.00001	Time 2.931 (2.931)	Data 2.012 (2.012)	Loss 0.0863 (0.0863)	Loss CE 0.0213 (0.0213)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6505 (0.6505)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:15:11.180164
Epoch: [42][100/152], lr: 0.00001	Time 0.475 (0.484)	Data 0.000 (0.020)	Loss 0.0693 (0.0821)	Loss CE 0.0035 (0.0187)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6582 (0.6335)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.412)
Sigma : Parameter containing:
tensor([3.8677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0726], device='cuda:0', requires_grad=True)
2022-03-23 15:15:38.205867
Epoch: [43][0/152], lr: 0.00001	Time 3.110 (3.110)	Data 2.203 (2.203)	Loss 0.0631 (0.0631)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6256 (0.6256)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:16:24.506740
Epoch: [43][100/152], lr: 0.00001	Time 0.469 (0.489)	Data 0.000 (0.022)	Loss 0.0669 (0.0811)	Loss CE 0.0036 (0.0176)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6331 (0.6352)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.505)
Sigma : Parameter containing:
tensor([3.8680], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0728], device='cuda:0', requires_grad=True)
2022-03-23 15:16:51.677126
Epoch: [44][0/152], lr: 0.00001	Time 2.893 (2.893)	Data 2.016 (2.016)	Loss 0.0678 (0.0678)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6348 (0.6348)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:17:37.691533
Epoch: [44][100/152], lr: 0.00001	Time 0.487 (0.484)	Data 0.000 (0.020)	Loss 0.0724 (0.0777)	Loss CE 0.0033 (0.0144)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6901 (0.6330)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.691)
Sigma : Parameter containing:
tensor([3.8686], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0731], device='cuda:0', requires_grad=True)
2022-03-23 15:18:04.568292
Epoch: [45][0/152], lr: 0.00001	Time 3.059 (3.059)	Data 2.322 (2.322)	Loss 0.1608 (0.1608)	Loss CE 0.0936 (0.0936)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6718 (0.6718)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-23 15:18:48.865145
Epoch: [45][100/152], lr: 0.00001	Time 0.398 (0.469)	Data 0.000 (0.023)	Loss 0.1514 (0.0887)	Loss CE 0.0887 (0.0252)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6264 (0.6343)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.196)
Sigma : Parameter containing:
tensor([3.8689], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0733], device='cuda:0', requires_grad=True)
2022-03-23 15:19:16.563029
Epoch: [46][0/152], lr: 0.00001	Time 2.889 (2.889)	Data 2.158 (2.158)	Loss 0.0671 (0.0671)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6350 (0.6350)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:20:08.035336
Epoch: [46][100/152], lr: 0.00001	Time 0.436 (0.538)	Data 0.000 (0.022)	Loss 0.0620 (0.0795)	Loss CE 0.0022 (0.0162)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5980 (0.6334)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.629)
Sigma : Parameter containing:
tensor([3.8691], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0734], device='cuda:0', requires_grad=True)
2022-03-23 15:20:37.688635
Epoch: [47][0/152], lr: 0.00001	Time 2.648 (2.648)	Data 2.079 (2.079)	Loss 0.0708 (0.0708)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6671 (0.6671)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:21:29.765077
Epoch: [47][100/152], lr: 0.00001	Time 0.658 (0.542)	Data 0.000 (0.021)	Loss 0.0670 (0.0822)	Loss CE 0.0004 (0.0186)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6653 (0.6354)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.629)
Sigma : Parameter containing:
tensor([3.8693], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0736], device='cuda:0', requires_grad=True)
2022-03-23 15:21:59.612298
Epoch: [48][0/152], lr: 0.00001	Time 2.823 (2.823)	Data 1.955 (1.955)	Loss 0.0698 (0.0698)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6561 (0.6561)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-23 15:22:51.200786
Epoch: [48][100/152], lr: 0.00001	Time 0.436 (0.539)	Data 0.000 (0.020)	Loss 0.0655 (0.0841)	Loss CE 0.0031 (0.0207)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6243 (0.6341)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.474)
Sigma : Parameter containing:
tensor([3.8697], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0737], device='cuda:0', requires_grad=True)
2022-03-23 15:23:20.823762
Epoch: [49][0/152], lr: 0.00001	Time 2.634 (2.634)	Data 1.724 (1.724)	Loss 0.0977 (0.0977)	Loss CE 0.0355 (0.0355)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6229 (0.6229)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-23 15:24:12.786346
Epoch: [49][100/152], lr: 0.00001	Time 0.543 (0.541)	Data 0.000 (0.017)	Loss 0.0759 (0.0883)	Loss CE 0.0117 (0.0249)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6417 (0.6339)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.196)
Sigma : Parameter containing:
tensor([3.8698], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0738], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
CosineLinear(input_features=512, output_features=153, sigma=tensor([3.8698]), eta=tensor([3.0738]))
Exemplar per class : 5
video number : 4880
video number + exemplar : 4880
Phase 4 : Class-balanced Fine-Tuning : SKIP
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_000.pth.tar
exemplar : 255
Computing the class mean vectors...
Eval Task 0 for Age 0
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 6.419 (6.419)	Prec@1 81.250 (81.250)
Test: [100/123]	Time 0.416 (0.543)	Prec@1 87.500 (87.809)
Testing Results: Prec@1 87.475
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 87.500 (87.252)
Testing Results (NME): Prec@1 87.016
num_test_videos [1964]
Method : OURS
----AGE 1----
current_task  [95, 14]
current_head  53
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05049752469181039]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=159, sigma=tensor([3.8698]), eta=tensor([3.0738])
  (fc1): CosineLinear(input_features=512, output_features=153, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 158
video number + exemplar : 413
DataLoader Constructed : Train 12
Optimizer Constructed
video number : 158
video number + exemplar : 158
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 15:29:10.308825
Epoch: [0][0/12], lr: 0.00100	Time 3.605 (3.605)	Data 2.490 (2.490)	Loss 0.6184 (0.6184)	Loss CE 0.4904 (0.4904)	Loss KD (Logit) 1.0831 (1.0831)	Loss KD (GCAM) 0.0480 (0.0480)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5881 (0.5881)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
Sigma : Parameter containing:
tensor([3.8446], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0581], device='cuda:0', requires_grad=True)
2022-03-23 15:29:22.997464
Epoch: [1][0/12], lr: 0.00100	Time 3.090 (3.090)	Data 1.860 (1.860)	Loss 0.1924 (0.1924)	Loss CE 0.0523 (0.0523)	Loss KD (Logit) 1.1352 (1.1352)	Loss KD (GCAM) 0.0701 (0.0701)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6180 (0.6180)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8230], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0449], device='cuda:0', requires_grad=True)
2022-03-23 15:29:35.910154
Epoch: [2][0/12], lr: 0.00100	Time 3.166 (3.166)	Data 2.311 (2.311)	Loss 0.1556 (0.1556)	Loss CE 0.0056 (0.0056)	Loss KD (Logit) 1.1588 (1.1588)	Loss KD (GCAM) 0.0929 (0.0929)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6361 (0.6361)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7996], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0306], device='cuda:0', requires_grad=True)
2022-03-23 15:29:49.231587
Epoch: [3][0/12], lr: 0.00100	Time 3.369 (3.369)	Data 2.073 (2.073)	Loss 0.1665 (0.1665)	Loss CE 0.0193 (0.0193)	Loss KD (Logit) 1.1361 (1.1361)	Loss KD (GCAM) 0.0939 (0.0939)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6162 (0.6162)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7828], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 15:30:02.075748
Epoch: [4][0/12], lr: 0.00100	Time 3.101 (3.101)	Data 2.244 (2.244)	Loss 0.1774 (0.1774)	Loss CE 0.0242 (0.0242)	Loss KD (Logit) 1.1861 (1.1861)	Loss KD (GCAM) 0.0961 (0.0961)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6454 (0.6454)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7762], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0159], device='cuda:0', requires_grad=True)
2022-03-23 15:30:15.469361
Epoch: [5][0/12], lr: 0.00100	Time 3.625 (3.625)	Data 2.435 (2.435)	Loss 0.1628 (0.1628)	Loss CE 0.0128 (0.0128)	Loss KD (Logit) 1.1574 (1.1574)	Loss KD (GCAM) 0.0872 (0.0872)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6549 (0.6549)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7674], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0110], device='cuda:0', requires_grad=True)
2022-03-23 15:30:28.520871
Epoch: [6][0/12], lr: 0.00100	Time 3.174 (3.174)	Data 2.260 (2.260)	Loss 0.1700 (0.1700)	Loss CE 0.0242 (0.0242)	Loss KD (Logit) 1.1433 (1.1433)	Loss KD (GCAM) 0.0861 (0.0861)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6230 (0.6230)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7675], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0114], device='cuda:0', requires_grad=True)
2022-03-23 15:30:41.936105
Epoch: [7][0/12], lr: 0.00100	Time 3.235 (3.235)	Data 2.167 (2.167)	Loss 0.1507 (0.1507)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 1.1250 (1.1250)	Loss KD (GCAM) 0.0971 (0.0971)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6043 (0.6043)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7708], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0133], device='cuda:0', requires_grad=True)
2022-03-23 15:30:54.742146
Epoch: [8][0/12], lr: 0.00100	Time 2.974 (2.974)	Data 1.835 (1.835)	Loss 0.2149 (0.2149)	Loss CE 0.0624 (0.0624)	Loss KD (Logit) 1.1676 (1.1676)	Loss KD (GCAM) 0.0949 (0.0949)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6506 (0.6506)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.7766], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0167], device='cuda:0', requires_grad=True)
2022-03-23 15:31:07.861789
Epoch: [9][0/12], lr: 0.00100	Time 3.367 (3.367)	Data 2.434 (2.434)	Loss 0.1605 (0.1605)	Loss CE 0.0177 (0.0177)	Loss KD (Logit) 1.1285 (1.1285)	Loss KD (GCAM) 0.0930 (0.0930)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5787 (0.5787)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7822], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 15:31:21.042098
Epoch: [10][0/12], lr: 0.00100	Time 3.374 (3.374)	Data 2.451 (2.451)	Loss 0.1930 (0.1930)	Loss CE 0.0484 (0.0484)	Loss KD (Logit) 1.1334 (1.1334)	Loss KD (GCAM) 0.0870 (0.0870)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6131 (0.6131)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.7847], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0208], device='cuda:0', requires_grad=True)
2022-03-23 15:31:34.061980
Epoch: [11][0/12], lr: 0.00100	Time 3.124 (3.124)	Data 2.270 (2.270)	Loss 0.1502 (0.1502)	Loss CE 0.0050 (0.0050)	Loss KD (Logit) 1.1335 (1.1335)	Loss KD (GCAM) 0.0824 (0.0824)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6323 (0.6323)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0236], device='cuda:0', requires_grad=True)
2022-03-23 15:31:46.978756
Epoch: [12][0/12], lr: 0.00100	Time 3.137 (3.137)	Data 2.062 (2.062)	Loss 0.1537 (0.1537)	Loss CE 0.0100 (0.0100)	Loss KD (Logit) 1.1319 (1.1319)	Loss KD (GCAM) 0.0772 (0.0772)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6338 (0.6338)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7926], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0255], device='cuda:0', requires_grad=True)
2022-03-23 15:31:59.850553
Epoch: [13][0/12], lr: 0.00100	Time 3.067 (3.067)	Data 1.873 (1.873)	Loss 0.1412 (0.1412)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 1.1244 (1.1244)	Loss KD (GCAM) 0.0771 (0.0771)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6019 (0.6019)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7949], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0268], device='cuda:0', requires_grad=True)
2022-03-23 15:32:12.704353
Epoch: [14][0/12], lr: 0.00100	Time 3.049 (3.049)	Data 2.129 (2.129)	Loss 0.1613 (0.1613)	Loss CE 0.0222 (0.0222)	Loss KD (Logit) 1.1302 (1.1302)	Loss KD (GCAM) 0.0828 (0.0828)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5713 (0.5713)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0281], device='cuda:0', requires_grad=True)
2022-03-23 15:32:25.691855
Epoch: [15][0/12], lr: 0.00100	Time 3.093 (3.093)	Data 2.220 (2.220)	Loss 0.1583 (0.1583)	Loss CE 0.0205 (0.0205)	Loss KD (Logit) 1.1282 (1.1282)	Loss KD (GCAM) 0.0697 (0.0697)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5985 (0.5985)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7993], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0292], device='cuda:0', requires_grad=True)
2022-03-23 15:32:38.512095
Epoch: [16][0/12], lr: 0.00100	Time 2.978 (2.978)	Data 1.988 (1.988)	Loss 0.1411 (0.1411)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 1.1150 (1.1150)	Loss KD (GCAM) 0.0706 (0.0706)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6027 (0.6027)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8012], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0303], device='cuda:0', requires_grad=True)
2022-03-23 15:32:51.184190
Epoch: [17][0/12], lr: 0.00100	Time 3.255 (3.255)	Data 2.191 (2.191)	Loss 0.2483 (0.2483)	Loss CE 0.1090 (0.1090)	Loss KD (Logit) 1.1192 (1.1192)	Loss KD (GCAM) 0.0737 (0.0737)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6065 (0.6065)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8011], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0299], device='cuda:0', requires_grad=True)
2022-03-23 15:33:02.895425
Epoch: [18][0/12], lr: 0.00100	Time 3.031 (3.031)	Data 1.922 (1.922)	Loss 0.1409 (0.1409)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 1.1122 (1.1122)	Loss KD (GCAM) 0.0728 (0.0728)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6228 (0.6228)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8009], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:33:14.677859
Epoch: [19][0/12], lr: 0.00100	Time 3.092 (3.092)	Data 1.991 (1.991)	Loss 0.2962 (0.2962)	Loss CE 0.1563 (0.1563)	Loss KD (Logit) 1.1264 (1.1264)	Loss KD (GCAM) 0.0774 (0.0774)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5982 (0.5982)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.7995], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0284], device='cuda:0', requires_grad=True)
2022-03-23 15:33:26.424686
Epoch: [20][0/12], lr: 0.00010	Time 3.293 (3.293)	Data 2.031 (2.031)	Loss 0.1441 (0.1441)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 1.1206 (1.1206)	Loss KD (GCAM) 0.0735 (0.0735)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6500 (0.6500)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7996], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0285], device='cuda:0', requires_grad=True)
2022-03-23 15:33:38.423911
Epoch: [21][0/12], lr: 0.00010	Time 3.068 (3.068)	Data 1.845 (1.845)	Loss 0.1432 (0.1432)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 1.1385 (1.1385)	Loss KD (GCAM) 0.0739 (0.0739)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6220 (0.6220)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7998], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0286], device='cuda:0', requires_grad=True)
2022-03-23 15:33:50.044203
Epoch: [22][0/12], lr: 0.00010	Time 3.128 (3.128)	Data 1.840 (1.840)	Loss 0.1391 (0.1391)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1072 (1.1072)	Loss KD (GCAM) 0.0703 (0.0703)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6181 (0.6181)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8000], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0287], device='cuda:0', requires_grad=True)
2022-03-23 15:34:01.849614
Epoch: [23][0/12], lr: 0.00010	Time 3.149 (3.149)	Data 1.980 (1.980)	Loss 0.1459 (0.1459)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 1.1312 (1.1312)	Loss KD (GCAM) 0.0764 (0.0764)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6543 (0.6543)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8002], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0288], device='cuda:0', requires_grad=True)
2022-03-23 15:34:13.913741
Epoch: [24][0/12], lr: 0.00010	Time 3.198 (3.198)	Data 2.477 (2.477)	Loss 0.1400 (0.1400)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 1.1244 (1.1244)	Loss KD (GCAM) 0.0735 (0.0735)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6044 (0.6044)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8004], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0290], device='cuda:0', requires_grad=True)
2022-03-23 15:34:26.076710
Epoch: [25][0/12], lr: 0.00010	Time 3.085 (3.085)	Data 2.235 (2.235)	Loss 0.1387 (0.1387)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 1.1213 (1.1213)	Loss KD (GCAM) 0.0707 (0.0707)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5971 (0.5971)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8005], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0290], device='cuda:0', requires_grad=True)
2022-03-23 15:34:38.613922
Epoch: [26][0/12], lr: 0.00010	Time 3.547 (3.547)	Data 2.452 (2.452)	Loss 0.1426 (0.1426)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 1.0995 (1.0995)	Loss KD (GCAM) 0.0765 (0.0765)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5669 (0.5669)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8008], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0292], device='cuda:0', requires_grad=True)
2022-03-23 15:34:50.724212
Epoch: [27][0/12], lr: 0.00010	Time 3.044 (3.044)	Data 1.950 (1.950)	Loss 0.1407 (0.1407)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 1.1221 (1.1221)	Loss KD (GCAM) 0.0670 (0.0670)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6079 (0.6079)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8010], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0293], device='cuda:0', requires_grad=True)
2022-03-23 15:35:03.121525
Epoch: [28][0/12], lr: 0.00010	Time 3.289 (3.289)	Data 2.319 (2.319)	Loss 0.1434 (0.1434)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 1.1381 (1.1381)	Loss KD (GCAM) 0.0739 (0.0739)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6258 (0.6258)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8012], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0294], device='cuda:0', requires_grad=True)
2022-03-23 15:35:15.338836
Epoch: [29][0/12], lr: 0.00010	Time 3.164 (3.164)	Data 2.353 (2.353)	Loss 0.1396 (0.1396)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 1.1141 (1.1141)	Loss KD (GCAM) 0.0685 (0.0685)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6235 (0.6235)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:35:27.395364
Epoch: [30][0/12], lr: 0.00001	Time 3.235 (3.235)	Data 2.423 (2.423)	Loss 0.1415 (0.1415)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 1.0999 (1.0999)	Loss KD (GCAM) 0.0716 (0.0716)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6121 (0.6121)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:35:39.465170
Epoch: [31][0/12], lr: 0.00001	Time 3.075 (3.075)	Data 1.983 (1.983)	Loss 0.1390 (0.1390)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 1.0888 (1.0888)	Loss KD (GCAM) 0.0705 (0.0705)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6107 (0.6107)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:35:51.870844
Epoch: [32][0/12], lr: 0.00001	Time 3.361 (3.361)	Data 2.386 (2.386)	Loss 0.1508 (0.1508)	Loss CE 0.0103 (0.0103)	Loss KD (Logit) 1.1097 (1.1097)	Loss KD (GCAM) 0.0756 (0.0756)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6169 (0.6169)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:36:04.256007
Epoch: [33][0/12], lr: 0.00001	Time 3.433 (3.433)	Data 2.452 (2.452)	Loss 0.1388 (0.1388)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 1.1144 (1.1144)	Loss KD (GCAM) 0.0678 (0.0678)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5960 (0.5960)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:36:16.023609
Epoch: [34][0/12], lr: 0.00001	Time 3.080 (3.080)	Data 2.161 (2.161)	Loss 0.1417 (0.1417)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 1.1189 (1.1189)	Loss KD (GCAM) 0.0762 (0.0762)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6094 (0.6094)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:36:28.027052
Epoch: [35][0/12], lr: 0.00001	Time 3.403 (3.403)	Data 2.522 (2.522)	Loss 0.1533 (0.1533)	Loss CE 0.0115 (0.0115)	Loss KD (Logit) 1.1239 (1.1239)	Loss KD (GCAM) 0.0741 (0.0741)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6274 (0.6274)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:36:39.936110
Epoch: [36][0/12], lr: 0.00001	Time 3.252 (3.252)	Data 2.244 (2.244)	Loss 0.1407 (0.1407)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 1.0998 (1.0998)	Loss KD (GCAM) 0.0659 (0.0659)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6487 (0.6487)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:36:52.118988
Epoch: [37][0/12], lr: 0.00001	Time 3.357 (3.357)	Data 2.554 (2.554)	Loss 0.1399 (0.1399)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 1.0985 (1.0985)	Loss KD (GCAM) 0.0727 (0.0727)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6188 (0.6188)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:37:04.042592
Epoch: [38][0/12], lr: 0.00001	Time 3.183 (3.183)	Data 1.890 (1.890)	Loss 0.1388 (0.1388)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 1.1060 (1.1060)	Loss KD (GCAM) 0.0655 (0.0655)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6218 (0.6218)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:37:16.222703
Epoch: [39][0/12], lr: 0.00001	Time 3.347 (3.347)	Data 2.444 (2.444)	Loss 0.1396 (0.1396)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 1.1026 (1.1026)	Loss KD (GCAM) 0.0663 (0.0663)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6230 (0.6230)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:37:28.126090
Epoch: [40][0/12], lr: 0.00001	Time 3.194 (3.194)	Data 2.328 (2.328)	Loss 0.1382 (0.1382)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 1.1057 (1.1057)	Loss KD (GCAM) 0.0653 (0.0653)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6199 (0.6199)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:37:40.024133
Epoch: [41][0/12], lr: 0.00001	Time 3.300 (3.300)	Data 2.275 (2.275)	Loss 0.1459 (0.1459)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 1.1009 (1.1009)	Loss KD (GCAM) 0.0666 (0.0666)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6682 (0.6682)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:37:52.388999
Epoch: [42][0/12], lr: 0.00001	Time 3.556 (3.556)	Data 2.315 (2.315)	Loss 0.3042 (0.3042)	Loss CE 0.1632 (0.1632)	Loss KD (Logit) 1.0975 (1.0975)	Loss KD (GCAM) 0.0681 (0.0681)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6518 (0.6518)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:38:04.185003
Epoch: [43][0/12], lr: 0.00001	Time 3.061 (3.061)	Data 1.791 (1.791)	Loss 0.1383 (0.1383)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 1.0836 (1.0836)	Loss KD (GCAM) 0.0672 (0.0672)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6084 (0.6084)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:38:15.911272
Epoch: [44][0/12], lr: 0.00001	Time 3.045 (3.045)	Data 1.992 (1.992)	Loss 0.1421 (0.1421)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 1.1173 (1.1173)	Loss KD (GCAM) 0.0690 (0.0690)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6175 (0.6175)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:38:27.702830
Epoch: [45][0/12], lr: 0.00001	Time 3.117 (3.117)	Data 1.910 (1.910)	Loss 0.1344 (0.1344)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1184 (1.1184)	Loss KD (GCAM) 0.0629 (0.0629)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5874 (0.5874)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:38:39.757330
Epoch: [46][0/12], lr: 0.00001	Time 3.433 (3.433)	Data 2.605 (2.605)	Loss 0.1368 (0.1368)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 1.1118 (1.1118)	Loss KD (GCAM) 0.0683 (0.0683)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5922 (0.5922)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 15:38:51.799870
Epoch: [47][0/12], lr: 0.00001	Time 3.278 (3.278)	Data 2.019 (2.019)	Loss 0.1435 (0.1435)	Loss CE 0.0081 (0.0081)	Loss KD (Logit) 1.1084 (1.1084)	Loss KD (GCAM) 0.0663 (0.0663)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5955 (0.5955)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:39:03.531148
Epoch: [48][0/12], lr: 0.00001	Time 3.051 (3.051)	Data 2.023 (2.023)	Loss 0.1419 (0.1419)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 1.0985 (1.0985)	Loss KD (GCAM) 0.0668 (0.0668)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6356 (0.6356)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:39:15.179806
Epoch: [49][0/12], lr: 0.00001	Time 3.086 (3.086)	Data 2.145 (2.145)	Loss 0.1444 (0.1444)	Loss CE 0.0093 (0.0093)	Loss KD (Logit) 1.1059 (1.1059)	Loss KD (GCAM) 0.0683 (0.0683)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5877 (0.5877)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=159, sigma=tensor([3.8014]), eta=tensor([3.0296])
  (fc1): CosineLinear(input_features=512, output_features=153, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 158
video number + exemplar : 158
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=159, sigma=tensor([3.8014]), eta=tensor([3.0296])
  (fc1): CosineLinear(input_features=512, output_features=153, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 265
DataLoader CBF Constructed : Train 8
Optimizer Constructed
2022-03-23 15:39:38.991944
Epoch: [0][0/8], lr: 0.00050	Time 2.749 (2.749)	Data 2.255 (2.255)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8016], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:39:45.441214
Epoch: [1][0/8], lr: 0.00050	Time 2.789 (2.789)	Data 2.270 (2.270)	Loss 0.0251 (0.0251)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8028], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0303], device='cuda:0', requires_grad=True)
2022-03-23 15:39:51.952364
Epoch: [2][0/8], lr: 0.00050	Time 2.864 (2.864)	Data 2.281 (2.281)	Loss 0.1317 (0.1317)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8024], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0298], device='cuda:0', requires_grad=True)
2022-03-23 15:39:58.592642
Epoch: [3][0/8], lr: 0.00050	Time 2.997 (2.997)	Data 2.457 (2.457)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8024], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 15:40:05.047108
Epoch: [4][0/8], lr: 0.00050	Time 2.824 (2.824)	Data 2.149 (2.149)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0298], device='cuda:0', requires_grad=True)
2022-03-23 15:40:11.277397
Epoch: [5][0/8], lr: 0.00050	Time 2.648 (2.648)	Data 1.876 (1.876)	Loss 0.0038 (0.0038)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8040], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0303], device='cuda:0', requires_grad=True)
2022-03-23 15:40:17.759321
Epoch: [6][0/8], lr: 0.00050	Time 2.824 (2.824)	Data 2.143 (2.143)	Loss 0.0035 (0.0035)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8047], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0307], device='cuda:0', requires_grad=True)
2022-03-23 15:40:24.134702
Epoch: [7][0/8], lr: 0.00050	Time 2.765 (2.765)	Data 2.179 (2.179)	Loss 0.0042 (0.0042)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8055], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0311], device='cuda:0', requires_grad=True)
2022-03-23 15:40:30.542784
Epoch: [8][0/8], lr: 0.00050	Time 2.779 (2.779)	Data 1.899 (1.899)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8060], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0313], device='cuda:0', requires_grad=True)
2022-03-23 15:40:36.823326
Epoch: [9][0/8], lr: 0.00050	Time 2.899 (2.899)	Data 1.897 (1.897)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8063], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0313], device='cuda:0', requires_grad=True)
2022-03-23 15:40:43.389179
Epoch: [10][0/8], lr: 0.00050	Time 2.901 (2.901)	Data 2.068 (2.068)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8068], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0316], device='cuda:0', requires_grad=True)
2022-03-23 15:40:50.242696
Epoch: [11][0/8], lr: 0.00050	Time 2.892 (2.892)	Data 2.033 (2.033)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8078], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0321], device='cuda:0', requires_grad=True)
2022-03-23 15:40:57.274612
Epoch: [12][0/8], lr: 0.00050	Time 3.012 (3.012)	Data 2.617 (2.617)	Loss 0.0086 (0.0086)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8090], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0328], device='cuda:0', requires_grad=True)
2022-03-23 15:41:04.381688
Epoch: [13][0/8], lr: 0.00050	Time 3.171 (3.171)	Data 2.451 (2.451)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8099], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0332], device='cuda:0', requires_grad=True)
2022-03-23 15:41:11.216269
Epoch: [14][0/8], lr: 0.00050	Time 2.928 (2.928)	Data 2.293 (2.293)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8108], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0336], device='cuda:0', requires_grad=True)
2022-03-23 15:41:18.115593
Epoch: [15][0/8], lr: 0.00050	Time 2.881 (2.881)	Data 2.470 (2.470)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8113], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0338], device='cuda:0', requires_grad=True)
2022-03-23 15:41:25.048212
Epoch: [16][0/8], lr: 0.00050	Time 2.957 (2.957)	Data 2.320 (2.320)	Loss 0.0064 (0.0064)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8124], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0343], device='cuda:0', requires_grad=True)
2022-03-23 15:41:31.943686
Epoch: [17][0/8], lr: 0.00050	Time 2.907 (2.907)	Data 2.132 (2.132)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0349], device='cuda:0', requires_grad=True)
2022-03-23 15:41:38.945997
Epoch: [18][0/8], lr: 0.00050	Time 2.979 (2.979)	Data 2.478 (2.478)	Loss 0.0094 (0.0094)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8146], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0354], device='cuda:0', requires_grad=True)
2022-03-23 15:41:45.947285
Epoch: [19][0/8], lr: 0.00050	Time 2.890 (2.890)	Data 2.279 (2.279)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8154], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0358], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_001.pth.tar
exemplar : 265
Computing the class mean vectors...
Eval Task 0 for Age 1
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.553 (4.553)	Prec@1 75.000 (75.000)
Test: [100/123]	Time 0.409 (0.531)	Prec@1 87.500 (79.332)
Testing Results: Prec@1 79.175
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 81.250 (83.416)
Testing Results (NME): Prec@1 83.096
Eval Task 1 for Age 1
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.799 (3.799)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.552
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 86.207
num_test_videos [1964, 58]
Method : OURS
----AGE 2----
current_task  [71, 96]
current_head  55
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.051478150704935006]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=165, sigma=tensor([3.8154]), eta=tensor([3.0358])
  (fc1): CosineLinear(input_features=512, output_features=159, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 153
video number + exemplar : 418
DataLoader Constructed : Train 13
Optimizer Constructed
video number : 153
video number + exemplar : 153
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 15:44:23.875831
Epoch: [0][0/13], lr: 0.00100	Time 3.828 (3.828)	Data 2.071 (2.071)	Loss 0.0743 (0.0743)	Loss CE 0.0110 (0.0110)	Loss KD (Logit) 0.0024 (0.0024)	Loss KD (GCAM) 0.0011 (0.0011)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6284 (0.6284)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8156], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0361], device='cuda:0', requires_grad=True)
2022-03-23 15:44:37.308966
Epoch: [1][0/13], lr: 0.00100	Time 3.097 (3.097)	Data 1.932 (1.932)	Loss 0.0746 (0.0746)	Loss CE 0.0137 (0.0137)	Loss KD (Logit) 0.0024 (0.0024)	Loss KD (GCAM) 0.0011 (0.0011)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6042 (0.6042)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8164], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0366], device='cuda:0', requires_grad=True)
2022-03-23 15:44:51.338310
Epoch: [2][0/13], lr: 0.00100	Time 3.471 (3.471)	Data 2.097 (2.097)	Loss 0.0683 (0.0683)	Loss CE 0.0050 (0.0050)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6272 (0.6272)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0390], device='cuda:0', requires_grad=True)
2022-03-23 15:45:05.018557
Epoch: [3][0/13], lr: 0.00100	Time 3.137 (3.137)	Data 2.220 (2.220)	Loss 0.0618 (0.0618)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6001 (0.6001)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8246], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0410], device='cuda:0', requires_grad=True)
2022-03-23 15:45:19.005948
Epoch: [4][0/13], lr: 0.00100	Time 3.312 (3.312)	Data 2.014 (2.014)	Loss 0.0617 (0.0617)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5952 (0.5952)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8271], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0425], device='cuda:0', requires_grad=True)
2022-03-23 15:45:33.015724
Epoch: [5][0/13], lr: 0.00100	Time 3.327 (3.327)	Data 2.168 (2.168)	Loss 0.0623 (0.0623)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5891 (0.5891)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8294], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0439], device='cuda:0', requires_grad=True)
2022-03-23 15:45:47.198904
Epoch: [6][0/13], lr: 0.00100	Time 3.125 (3.125)	Data 2.344 (2.344)	Loss 0.0791 (0.0791)	Loss CE 0.0206 (0.0206)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5781 (0.5781)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8277], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0431], device='cuda:0', requires_grad=True)
2022-03-23 15:46:00.782027
Epoch: [7][0/13], lr: 0.00100	Time 3.130 (3.130)	Data 2.174 (2.174)	Loss 0.0953 (0.0953)	Loss CE 0.0338 (0.0338)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6091 (0.6091)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8296], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0445], device='cuda:0', requires_grad=True)
2022-03-23 15:46:14.747801
Epoch: [8][0/13], lr: 0.00100	Time 3.098 (3.098)	Data 1.928 (1.928)	Loss 0.1481 (0.1481)	Loss CE 0.0889 (0.0889)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5861 (0.5861)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8300], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0447], device='cuda:0', requires_grad=True)
2022-03-23 15:46:28.682085
Epoch: [9][0/13], lr: 0.00100	Time 3.384 (3.384)	Data 2.326 (2.326)	Loss 0.0653 (0.0653)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6281 (0.6281)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8320], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0459], device='cuda:0', requires_grad=True)
2022-03-23 15:46:42.737385
Epoch: [10][0/13], lr: 0.00100	Time 3.328 (3.328)	Data 2.262 (2.262)	Loss 0.0642 (0.0642)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5948 (0.5948)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8339], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0471], device='cuda:0', requires_grad=True)
2022-03-23 15:46:56.744507
Epoch: [11][0/13], lr: 0.00100	Time 3.123 (3.123)	Data 1.803 (1.803)	Loss 0.0670 (0.0670)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5947 (0.5947)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8375], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0495], device='cuda:0', requires_grad=True)
2022-03-23 15:47:10.319319
Epoch: [12][0/13], lr: 0.00100	Time 3.106 (3.106)	Data 2.327 (2.327)	Loss 0.0630 (0.0630)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0027 (0.0027)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6168 (0.6168)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8400], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
2022-03-23 15:47:24.403182
Epoch: [13][0/13], lr: 0.00100	Time 3.182 (3.182)	Data 2.455 (2.455)	Loss 0.0791 (0.0791)	Loss CE 0.0184 (0.0184)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6009 (0.6009)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8430], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0529], device='cuda:0', requires_grad=True)
2022-03-23 15:47:38.614883
Epoch: [14][0/13], lr: 0.00100	Time 3.164 (3.164)	Data 2.434 (2.434)	Loss 0.1031 (0.1031)	Loss CE 0.0411 (0.0411)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6142 (0.6142)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8440], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0536], device='cuda:0', requires_grad=True)
2022-03-23 15:47:52.216730
Epoch: [15][0/13], lr: 0.00100	Time 3.157 (3.157)	Data 2.387 (2.387)	Loss 0.0594 (0.0594)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5784 (0.5784)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8446], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0541], device='cuda:0', requires_grad=True)
2022-03-23 15:48:06.110260
Epoch: [16][0/13], lr: 0.00100	Time 3.144 (3.144)	Data 2.185 (2.185)	Loss 0.0653 (0.0653)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6029 (0.6029)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8409], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0521], device='cuda:0', requires_grad=True)
2022-03-23 15:48:20.315869
Epoch: [17][0/13], lr: 0.00100	Time 3.223 (3.223)	Data 2.494 (2.494)	Loss 0.0714 (0.0714)	Loss CE 0.0136 (0.0136)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5712 (0.5712)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8374], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0505], device='cuda:0', requires_grad=True)
2022-03-23 15:48:34.095378
Epoch: [18][0/13], lr: 0.00100	Time 3.185 (3.185)	Data 2.250 (2.250)	Loss 0.0641 (0.0641)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0021 (0.0021)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6161 (0.6161)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8360], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0494], device='cuda:0', requires_grad=True)
2022-03-23 15:48:48.132530
Epoch: [19][0/13], lr: 0.00100	Time 3.265 (3.265)	Data 2.225 (2.225)	Loss 0.1189 (0.1189)	Loss CE 0.0564 (0.0564)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0020 (0.0020)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6170 (0.6170)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0488], device='cuda:0', requires_grad=True)
2022-03-23 15:49:02.339830
Epoch: [20][0/13], lr: 0.00010	Time 3.259 (3.259)	Data 2.189 (2.189)	Loss 0.0629 (0.0629)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6107 (0.6107)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8350], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:49:16.239752
Epoch: [21][0/13], lr: 0.00010	Time 3.218 (3.218)	Data 2.211 (2.211)	Loss 0.0618 (0.0618)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5964 (0.5964)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8345], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 15:49:30.542634
Epoch: [22][0/13], lr: 0.00010	Time 3.276 (3.276)	Data 2.424 (2.424)	Loss 0.0605 (0.0605)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5874 (0.5874)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8342], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 15:49:44.535298
Epoch: [23][0/13], lr: 0.00010	Time 3.553 (3.553)	Data 1.999 (1.999)	Loss 0.0652 (0.0652)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6419 (0.6419)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8342], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 15:49:58.323840
Epoch: [24][0/13], lr: 0.00010	Time 3.076 (3.076)	Data 1.910 (1.910)	Loss 0.0616 (0.0616)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0027 (0.0027)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6035 (0.6035)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8344], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 15:50:12.456954
Epoch: [25][0/13], lr: 0.00010	Time 3.241 (3.241)	Data 2.313 (2.313)	Loss 0.0641 (0.0641)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0027 (0.0027)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6322 (0.6322)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8344], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 15:50:26.159454
Epoch: [26][0/13], lr: 0.00010	Time 3.149 (3.149)	Data 2.110 (2.110)	Loss 0.0633 (0.0633)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6142 (0.6142)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8346], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 15:50:40.024626
Epoch: [27][0/13], lr: 0.00010	Time 3.137 (3.137)	Data 2.300 (2.300)	Loss 0.0699 (0.0699)	Loss CE 0.0081 (0.0081)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6114 (0.6114)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8348], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 15:50:54.136108
Epoch: [28][0/13], lr: 0.00010	Time 3.124 (3.124)	Data 1.979 (1.979)	Loss 0.0659 (0.0659)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6441 (0.6441)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0487], device='cuda:0', requires_grad=True)
2022-03-23 15:51:08.360570
Epoch: [29][0/13], lr: 0.00010	Time 3.439 (3.439)	Data 2.546 (2.546)	Loss 0.0631 (0.0631)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6147 (0.6147)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8351], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:51:22.761409
Epoch: [30][0/13], lr: 0.00001	Time 3.757 (3.757)	Data 2.398 (2.398)	Loss 0.0650 (0.0650)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5881 (0.5881)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:51:36.542490
Epoch: [31][0/13], lr: 0.00001	Time 3.135 (3.135)	Data 2.256 (2.256)	Loss 0.0666 (0.0666)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0027 (0.0027)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6246 (0.6246)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:51:50.500771
Epoch: [32][0/13], lr: 0.00001	Time 3.104 (3.104)	Data 2.199 (2.199)	Loss 0.0601 (0.0601)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5868 (0.5868)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:52:04.193444
Epoch: [33][0/13], lr: 0.00001	Time 3.158 (3.158)	Data 1.985 (1.985)	Loss 0.0684 (0.0684)	Loss CE 0.0097 (0.0097)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5809 (0.5809)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:52:18.123163
Epoch: [34][0/13], lr: 0.00001	Time 3.424 (3.424)	Data 2.336 (2.336)	Loss 0.0628 (0.0628)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6170 (0.6170)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:52:32.155663
Epoch: [35][0/13], lr: 0.00001	Time 3.305 (3.305)	Data 1.947 (1.947)	Loss 0.0624 (0.0624)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5886 (0.5886)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:52:44.607897
Epoch: [36][0/13], lr: 0.00001	Time 3.179 (3.179)	Data 2.035 (2.035)	Loss 0.0674 (0.0674)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0027 (0.0027)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6532 (0.6532)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:52:57.127111
Epoch: [37][0/13], lr: 0.00001	Time 3.110 (3.110)	Data 2.185 (2.185)	Loss 0.0662 (0.0662)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6401 (0.6401)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:53:09.217684
Epoch: [38][0/13], lr: 0.00001	Time 3.053 (3.053)	Data 2.269 (2.269)	Loss 0.0634 (0.0634)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6180 (0.6180)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:53:21.773882
Epoch: [39][0/13], lr: 0.00001	Time 3.281 (3.281)	Data 2.407 (2.407)	Loss 0.0591 (0.0591)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5687 (0.5687)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:53:34.779380
Epoch: [40][0/13], lr: 0.00001	Time 3.467 (3.467)	Data 2.743 (2.743)	Loss 0.0676 (0.0676)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6619 (0.6619)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:53:47.607301
Epoch: [41][0/13], lr: 0.00001	Time 3.380 (3.380)	Data 2.354 (2.354)	Loss 0.0625 (0.0625)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0027 (0.0027)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6061 (0.6061)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:54:00.685321
Epoch: [42][0/13], lr: 0.00001	Time 3.409 (3.409)	Data 2.249 (2.249)	Loss 0.0623 (0.0623)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6127 (0.6127)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:54:14.091684
Epoch: [43][0/13], lr: 0.00001	Time 3.437 (3.437)	Data 2.494 (2.494)	Loss 0.0609 (0.0609)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0025 (0.0025)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5925 (0.5925)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:54:27.383078
Epoch: [44][0/13], lr: 0.00001	Time 3.511 (3.511)	Data 2.725 (2.725)	Loss 0.0605 (0.0605)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5911 (0.5911)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:54:41.000313
Epoch: [45][0/13], lr: 0.00001	Time 3.804 (3.804)	Data 2.455 (2.455)	Loss 0.0615 (0.0615)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:54:54.440110
Epoch: [46][0/13], lr: 0.00001	Time 3.587 (3.587)	Data 2.763 (2.763)	Loss 0.0644 (0.0644)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6319 (0.6319)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:55:07.591034
Epoch: [47][0/13], lr: 0.00001	Time 3.405 (3.405)	Data 2.618 (2.618)	Loss 0.0612 (0.0612)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5976 (0.5976)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:55:20.618786
Epoch: [48][0/13], lr: 0.00001	Time 3.129 (3.129)	Data 1.851 (1.851)	Loss 0.0631 (0.0631)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6207 (0.6207)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8354], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 15:55:33.819599
Epoch: [49][0/13], lr: 0.00001	Time 3.522 (3.522)	Data 2.516 (2.516)	Loss 0.0610 (0.0610)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0026 (0.0026)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6003 (0.6003)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8354], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=165, sigma=tensor([3.8354]), eta=tensor([3.0489])
  (fc1): CosineLinear(input_features=512, output_features=159, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 153
video number + exemplar : 153
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=165, sigma=tensor([3.8354]), eta=tensor([3.0489])
  (fc1): CosineLinear(input_features=512, output_features=159, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 275
DataLoader CBF Constructed : Train 8
Optimizer Constructed
2022-03-23 15:56:00.098025
Epoch: [0][0/8], lr: 0.00050	Time 2.857 (2.857)	Data 2.005 (2.005)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8357], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0492], device='cuda:0', requires_grad=True)
2022-03-23 15:56:06.663079
Epoch: [1][0/8], lr: 0.00050	Time 2.883 (2.883)	Data 2.121 (2.121)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0491], device='cuda:0', requires_grad=True)
2022-03-23 15:56:13.286460
Epoch: [2][0/8], lr: 0.00050	Time 3.028 (3.028)	Data 2.260 (2.260)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0491], device='cuda:0', requires_grad=True)
2022-03-23 15:56:20.028081
Epoch: [3][0/8], lr: 0.00050	Time 3.057 (3.057)	Data 2.293 (2.293)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8348], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0485], device='cuda:0', requires_grad=True)
2022-03-23 15:56:26.539198
Epoch: [4][0/8], lr: 0.00050	Time 2.930 (2.930)	Data 2.254 (2.254)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8336], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0476], device='cuda:0', requires_grad=True)
2022-03-23 15:56:32.938499
Epoch: [5][0/8], lr: 0.00050	Time 2.862 (2.862)	Data 2.119 (2.119)	Loss 0.0060 (0.0060)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8330], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0471], device='cuda:0', requires_grad=True)
2022-03-23 15:56:39.571621
Epoch: [6][0/8], lr: 0.00050	Time 3.027 (3.027)	Data 2.411 (2.411)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8322], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0465], device='cuda:0', requires_grad=True)
2022-03-23 15:56:46.201943
Epoch: [7][0/8], lr: 0.00050	Time 3.025 (3.025)	Data 2.382 (2.382)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0458], device='cuda:0', requires_grad=True)
2022-03-23 15:56:52.802645
Epoch: [8][0/8], lr: 0.00050	Time 3.017 (3.017)	Data 2.491 (2.491)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8305], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0453], device='cuda:0', requires_grad=True)
2022-03-23 15:56:59.311784
Epoch: [9][0/8], lr: 0.00050	Time 2.913 (2.913)	Data 2.247 (2.247)	Loss 0.0081 (0.0081)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8313], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0456], device='cuda:0', requires_grad=True)
2022-03-23 15:57:05.779327
Epoch: [10][0/8], lr: 0.00050	Time 2.804 (2.804)	Data 2.091 (2.091)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8320], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0459], device='cuda:0', requires_grad=True)
2022-03-23 15:57:12.286673
Epoch: [11][0/8], lr: 0.00050	Time 2.881 (2.881)	Data 2.341 (2.341)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8327], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0463], device='cuda:0', requires_grad=True)
2022-03-23 15:57:18.608353
Epoch: [12][0/8], lr: 0.00050	Time 2.932 (2.932)	Data 2.361 (2.361)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8334], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0466], device='cuda:0', requires_grad=True)
2022-03-23 15:57:25.104221
Epoch: [13][0/8], lr: 0.00050	Time 2.889 (2.889)	Data 2.071 (2.071)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8344], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0471], device='cuda:0', requires_grad=True)
2022-03-23 15:57:31.556293
Epoch: [14][0/8], lr: 0.00050	Time 2.850 (2.850)	Data 2.191 (2.191)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0476], device='cuda:0', requires_grad=True)
2022-03-23 15:57:38.083752
Epoch: [15][0/8], lr: 0.00050	Time 2.915 (2.915)	Data 2.148 (2.148)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8361], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0479], device='cuda:0', requires_grad=True)
2022-03-23 15:57:44.508827
Epoch: [16][0/8], lr: 0.00050	Time 2.963 (2.963)	Data 2.245 (2.245)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8367], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0482], device='cuda:0', requires_grad=True)
2022-03-23 15:57:51.015792
Epoch: [17][0/8], lr: 0.00050	Time 2.922 (2.922)	Data 2.454 (2.454)	Loss 0.0064 (0.0064)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8373], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 15:57:57.517632
Epoch: [18][0/8], lr: 0.00050	Time 2.823 (2.823)	Data 1.793 (1.793)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8376], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0485], device='cuda:0', requires_grad=True)
2022-03-23 15:58:04.090003
Epoch: [19][0/8], lr: 0.00050	Time 2.850 (2.850)	Data 2.201 (2.201)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8379], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0487], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_002.pth.tar
exemplar : 275
Computing the class mean vectors...
Eval Task 0 for Age 2
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.560 (4.560)	Prec@1 56.250 (56.250)
Test: [100/123]	Time 0.378 (0.492)	Prec@1 87.500 (81.064)
Testing Results: Prec@1 80.906
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 93.750 (83.849)
Testing Results (NME): Prec@1 83.554
Eval Task 1 for Age 2
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 4.042 (4.042)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 86.207
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 82.759
Eval Task 2 for Age 2
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 4.006 (4.006)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 58.462
num_test_videos [1964, 58, 65]
Method : OURS
----AGE 3----
current_task  [99, 98]
current_head  57
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05244044240850758]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=171, sigma=tensor([3.8379]), eta=tensor([3.0487])
  (fc1): CosineLinear(input_features=512, output_features=165, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 202
video number + exemplar : 477
DataLoader Constructed : Train 14
Optimizer Constructed
video number : 202
video number + exemplar : 202
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 16:00:43.478479
Epoch: [0][0/14], lr: 0.00100	Time 3.504 (3.504)	Data 2.230 (2.230)	Loss 0.1555 (0.1555)	Loss CE 0.0414 (0.0414)	Loss KD (Logit) 0.6203 (0.6203)	Loss KD (GCAM) 0.0389 (0.0389)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6986 (0.6986)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8326], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0454], device='cuda:0', requires_grad=True)
2022-03-23 16:00:56.960534
Epoch: [1][0/14], lr: 0.00100	Time 3.859 (3.859)	Data 2.946 (2.946)	Loss 0.2410 (0.2410)	Loss CE 0.1291 (0.1291)	Loss KD (Logit) 0.6442 (0.6442)	Loss KD (GCAM) 0.0435 (0.0435)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6511 (0.6511)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8292], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0439], device='cuda:0', requires_grad=True)
2022-03-23 16:01:11.525768
Epoch: [2][0/14], lr: 0.00100	Time 3.158 (3.158)	Data 2.154 (2.154)	Loss 0.2272 (0.2272)	Loss CE 0.1092 (0.1092)	Loss KD (Logit) 0.6958 (0.6958)	Loss KD (GCAM) 0.0564 (0.0564)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6466 (0.6466)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8265], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0425], device='cuda:0', requires_grad=True)
2022-03-23 16:01:25.986338
Epoch: [3][0/14], lr: 0.00100	Time 3.090 (3.090)	Data 2.362 (2.362)	Loss 0.1285 (0.1285)	Loss CE 0.0128 (0.0128)	Loss KD (Logit) 0.6643 (0.6643)	Loss KD (GCAM) 0.0540 (0.0540)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6466 (0.6466)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0389], device='cuda:0', requires_grad=True)
2022-03-23 16:01:40.521799
Epoch: [4][0/14], lr: 0.00100	Time 3.090 (3.090)	Data 1.887 (1.887)	Loss 0.1301 (0.1301)	Loss CE 0.0119 (0.0119)	Loss KD (Logit) 0.6898 (0.6898)	Loss KD (GCAM) 0.0570 (0.0570)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6489 (0.6489)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8122], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0340], device='cuda:0', requires_grad=True)
2022-03-23 16:01:55.217864
Epoch: [5][0/14], lr: 0.00100	Time 3.134 (3.134)	Data 2.170 (2.170)	Loss 0.1584 (0.1584)	Loss CE 0.0351 (0.0351)	Loss KD (Logit) 0.6790 (0.6790)	Loss KD (GCAM) 0.0622 (0.0622)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6895 (0.6895)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8095], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0326], device='cuda:0', requires_grad=True)
2022-03-23 16:02:09.853655
Epoch: [6][0/14], lr: 0.00100	Time 3.145 (3.145)	Data 2.171 (2.171)	Loss 0.1785 (0.1785)	Loss CE 0.0564 (0.0564)	Loss KD (Logit) 0.7083 (0.7083)	Loss KD (GCAM) 0.0630 (0.0630)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6612 (0.6612)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8096], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0324], device='cuda:0', requires_grad=True)
2022-03-23 16:02:24.475232
Epoch: [7][0/14], lr: 0.00100	Time 3.262 (3.262)	Data 2.231 (2.231)	Loss 0.1403 (0.1403)	Loss CE 0.0162 (0.0162)	Loss KD (Logit) 0.7062 (0.7062)	Loss KD (GCAM) 0.0648 (0.0648)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6764 (0.6764)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8099], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0323], device='cuda:0', requires_grad=True)
2022-03-23 16:02:39.434041
Epoch: [8][0/14], lr: 0.00100	Time 3.280 (3.280)	Data 2.460 (2.460)	Loss 0.1222 (0.1222)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.6950 (0.6950)	Loss KD (GCAM) 0.0637 (0.0637)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6537 (0.6537)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8118], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0331], device='cuda:0', requires_grad=True)
2022-03-23 16:02:54.117632
Epoch: [9][0/14], lr: 0.00100	Time 3.077 (3.077)	Data 1.826 (1.826)	Loss 0.1335 (0.1335)	Loss CE 0.0159 (0.0159)	Loss KD (Logit) 0.7039 (0.7039)	Loss KD (GCAM) 0.0601 (0.0601)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6268 (0.6268)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8110], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0325], device='cuda:0', requires_grad=True)
2022-03-23 16:03:08.737618
Epoch: [10][0/14], lr: 0.00100	Time 3.194 (3.194)	Data 2.498 (2.498)	Loss 0.1207 (0.1207)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.6759 (0.6759)	Loss KD (GCAM) 0.0623 (0.0623)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6378 (0.6378)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8063], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 16:03:23.356996
Epoch: [11][0/14], lr: 0.00100	Time 3.158 (3.158)	Data 2.187 (2.187)	Loss 0.1215 (0.1215)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6887 (0.6887)	Loss KD (GCAM) 0.0590 (0.0590)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6737 (0.6737)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8044], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0287], device='cuda:0', requires_grad=True)
2022-03-23 16:03:38.158397
Epoch: [12][0/14], lr: 0.00100	Time 3.117 (3.117)	Data 2.040 (2.040)	Loss 0.1250 (0.1250)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.7071 (0.7071)	Loss KD (GCAM) 0.0645 (0.0645)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6686 (0.6686)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0284], device='cuda:0', requires_grad=True)
2022-03-23 16:03:52.982775
Epoch: [13][0/14], lr: 0.00100	Time 3.286 (3.286)	Data 2.095 (2.095)	Loss 0.1239 (0.1239)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.7196 (0.7196)	Loss KD (GCAM) 0.0604 (0.0604)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6430 (0.6430)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8064], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0305], device='cuda:0', requires_grad=True)
2022-03-23 16:04:07.794236
Epoch: [14][0/14], lr: 0.00100	Time 3.339 (3.339)	Data 2.280 (2.280)	Loss 0.1211 (0.1211)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.6566 (0.6566)	Loss KD (GCAM) 0.0600 (0.0600)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6590 (0.6590)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8100], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0324], device='cuda:0', requires_grad=True)
2022-03-23 16:04:22.538688
Epoch: [15][0/14], lr: 0.00100	Time 3.286 (3.286)	Data 2.063 (2.063)	Loss 0.1231 (0.1231)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.6941 (0.6941)	Loss KD (GCAM) 0.0637 (0.0637)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6598 (0.6598)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8124], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0337], device='cuda:0', requires_grad=True)
2022-03-23 16:04:37.085458
Epoch: [16][0/14], lr: 0.00100	Time 3.165 (3.165)	Data 2.128 (2.128)	Loss 0.1194 (0.1194)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.7130 (0.7130)	Loss KD (GCAM) 0.0601 (0.0601)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6366 (0.6366)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8131], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0339], device='cuda:0', requires_grad=True)
2022-03-23 16:04:51.797352
Epoch: [17][0/14], lr: 0.00100	Time 3.166 (3.166)	Data 1.976 (1.976)	Loss 0.1313 (0.1313)	Loss CE 0.0088 (0.0088)	Loss KD (Logit) 0.6749 (0.6749)	Loss KD (GCAM) 0.0561 (0.0561)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7038 (0.7038)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8159], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0355], device='cuda:0', requires_grad=True)
2022-03-23 16:05:06.686083
Epoch: [18][0/14], lr: 0.00100	Time 3.324 (3.324)	Data 2.363 (2.363)	Loss 0.1465 (0.1465)	Loss CE 0.0294 (0.0294)	Loss KD (Logit) 0.6671 (0.6671)	Loss KD (GCAM) 0.0574 (0.0574)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6494 (0.6494)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8169], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0363], device='cuda:0', requires_grad=True)
2022-03-23 16:05:21.264364
Epoch: [19][0/14], lr: 0.00100	Time 3.227 (3.227)	Data 2.481 (2.481)	Loss 0.1204 (0.1204)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.6899 (0.6899)	Loss KD (GCAM) 0.0556 (0.0556)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6693 (0.6693)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8179], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0368], device='cuda:0', requires_grad=True)
2022-03-23 16:05:35.863969
Epoch: [20][0/14], lr: 0.00010	Time 3.053 (3.053)	Data 2.311 (2.311)	Loss 0.1175 (0.1175)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.6621 (0.6621)	Loss KD (GCAM) 0.0558 (0.0558)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6428 (0.6428)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8180], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0368], device='cuda:0', requires_grad=True)
2022-03-23 16:05:50.683342
Epoch: [21][0/14], lr: 0.00010	Time 3.178 (3.178)	Data 2.190 (2.190)	Loss 0.1150 (0.1150)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.6579 (0.6579)	Loss KD (GCAM) 0.0510 (0.0510)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6471 (0.6471)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8178], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0367], device='cuda:0', requires_grad=True)
2022-03-23 16:06:05.686228
Epoch: [22][0/14], lr: 0.00010	Time 3.313 (3.313)	Data 2.536 (2.536)	Loss 0.1159 (0.1159)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.6778 (0.6778)	Loss KD (GCAM) 0.0511 (0.0511)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6399 (0.6399)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8178], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0367], device='cuda:0', requires_grad=True)
2022-03-23 16:06:20.252661
Epoch: [23][0/14], lr: 0.00010	Time 3.212 (3.212)	Data 2.223 (2.223)	Loss 0.1152 (0.1152)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.6663 (0.6663)	Loss KD (GCAM) 0.0532 (0.0532)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6368 (0.6368)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8179], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0367], device='cuda:0', requires_grad=True)
2022-03-23 16:06:35.293183
Epoch: [24][0/14], lr: 0.00010	Time 3.509 (3.509)	Data 2.529 (2.529)	Loss 0.1204 (0.1204)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.6643 (0.6643)	Loss KD (GCAM) 0.0589 (0.0589)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6591 (0.6591)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8179], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0367], device='cuda:0', requires_grad=True)
2022-03-23 16:06:50.116274
Epoch: [25][0/14], lr: 0.00010	Time 3.232 (3.232)	Data 2.395 (2.395)	Loss 0.1156 (0.1156)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.6731 (0.6731)	Loss KD (GCAM) 0.0558 (0.0558)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6262 (0.6262)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8180], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0367], device='cuda:0', requires_grad=True)
2022-03-23 16:07:04.669361
Epoch: [26][0/14], lr: 0.00010	Time 3.093 (3.093)	Data 2.147 (2.147)	Loss 0.1171 (0.1171)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.6584 (0.6584)	Loss KD (GCAM) 0.0521 (0.0521)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6598 (0.6598)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8181], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0368], device='cuda:0', requires_grad=True)
2022-03-23 16:07:19.607943
Epoch: [27][0/14], lr: 0.00010	Time 3.210 (3.210)	Data 1.883 (1.883)	Loss 0.1138 (0.1138)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.6631 (0.6631)	Loss KD (GCAM) 0.0547 (0.0547)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6173 (0.6173)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8183], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:07:34.333781
Epoch: [28][0/14], lr: 0.00010	Time 3.068 (3.068)	Data 1.970 (1.970)	Loss 0.1147 (0.1147)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.6551 (0.6551)	Loss KD (GCAM) 0.0560 (0.0560)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6312 (0.6312)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8184], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:07:49.037267
Epoch: [29][0/14], lr: 0.00010	Time 3.109 (3.109)	Data 2.233 (2.233)	Loss 0.1134 (0.1134)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6356 (0.6356)	Loss KD (GCAM) 0.0504 (0.0504)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6406 (0.6406)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8184], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:08:03.712330
Epoch: [30][0/14], lr: 0.00001	Time 3.044 (3.044)	Data 1.919 (1.919)	Loss 0.1172 (0.1172)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.6712 (0.6712)	Loss KD (GCAM) 0.0532 (0.0532)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6554 (0.6554)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8184], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:08:18.446784
Epoch: [31][0/14], lr: 0.00001	Time 3.102 (3.102)	Data 1.985 (1.985)	Loss 0.1201 (0.1201)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.6490 (0.6490)	Loss KD (GCAM) 0.0537 (0.0537)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6561 (0.6561)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8184], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:08:33.259930
Epoch: [32][0/14], lr: 0.00001	Time 3.340 (3.340)	Data 1.971 (1.971)	Loss 0.1139 (0.1139)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.6734 (0.6734)	Loss KD (GCAM) 0.0534 (0.0534)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6190 (0.6190)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:08:47.871043
Epoch: [33][0/14], lr: 0.00001	Time 3.193 (3.193)	Data 2.020 (2.020)	Loss 0.1206 (0.1206)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.6796 (0.6796)	Loss KD (GCAM) 0.0535 (0.0535)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6845 (0.6845)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:09:02.546364
Epoch: [34][0/14], lr: 0.00001	Time 3.037 (3.037)	Data 1.912 (1.912)	Loss 0.1134 (0.1134)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.6365 (0.6365)	Loss KD (GCAM) 0.0503 (0.0503)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6443 (0.6443)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:09:17.269010
Epoch: [35][0/14], lr: 0.00001	Time 3.183 (3.183)	Data 2.307 (2.307)	Loss 0.1175 (0.1175)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.6851 (0.6851)	Loss KD (GCAM) 0.0525 (0.0525)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6456 (0.6456)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:09:31.770345
Epoch: [36][0/14], lr: 0.00001	Time 3.104 (3.104)	Data 2.249 (2.249)	Loss 0.1221 (0.1221)	Loss CE 0.0090 (0.0090)	Loss KD (Logit) 0.6430 (0.6430)	Loss KD (GCAM) 0.0539 (0.0539)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6325 (0.6325)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:09:46.368883
Epoch: [37][0/14], lr: 0.00001	Time 3.093 (3.093)	Data 1.963 (1.963)	Loss 0.1159 (0.1159)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.7009 (0.7009)	Loss KD (GCAM) 0.0565 (0.0565)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6196 (0.6196)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:10:01.325830
Epoch: [38][0/14], lr: 0.00001	Time 3.401 (3.401)	Data 2.537 (2.537)	Loss 0.1217 (0.1217)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.6720 (0.6720)	Loss KD (GCAM) 0.0529 (0.0529)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6678 (0.6678)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0369], device='cuda:0', requires_grad=True)
2022-03-23 16:10:16.067313
Epoch: [39][0/14], lr: 0.00001	Time 3.218 (3.218)	Data 2.418 (2.418)	Loss 0.1131 (0.1131)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.6568 (0.6568)	Loss KD (GCAM) 0.0482 (0.0482)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6343 (0.6343)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:10:30.569521
Epoch: [40][0/14], lr: 0.00001	Time 3.115 (3.115)	Data 2.313 (2.313)	Loss 0.1150 (0.1150)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6602 (0.6602)	Loss KD (GCAM) 0.0541 (0.0541)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6329 (0.6329)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:10:45.302363
Epoch: [41][0/14], lr: 0.00001	Time 3.182 (3.182)	Data 1.939 (1.939)	Loss 0.1194 (0.1194)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.6738 (0.6738)	Loss KD (GCAM) 0.0489 (0.0489)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6629 (0.6629)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:11:00.303239
Epoch: [42][0/14], lr: 0.00001	Time 3.275 (3.275)	Data 2.448 (2.448)	Loss 0.1175 (0.1175)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6661 (0.6661)	Loss KD (GCAM) 0.0526 (0.0526)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6650 (0.6650)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:11:14.930846
Epoch: [43][0/14], lr: 0.00001	Time 3.269 (3.269)	Data 2.374 (2.374)	Loss 0.1164 (0.1164)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6476 (0.6476)	Loss KD (GCAM) 0.0504 (0.0504)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6708 (0.6708)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:11:29.686284
Epoch: [44][0/14], lr: 0.00001	Time 3.090 (3.090)	Data 2.258 (2.258)	Loss 0.1179 (0.1179)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.6746 (0.6746)	Loss KD (GCAM) 0.0551 (0.0551)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6499 (0.6499)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:11:44.183170
Epoch: [45][0/14], lr: 0.00001	Time 3.159 (3.159)	Data 2.271 (2.271)	Loss 0.1131 (0.1131)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.6573 (0.6573)	Loss KD (GCAM) 0.0526 (0.0526)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6143 (0.6143)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:11:58.879541
Epoch: [46][0/14], lr: 0.00001	Time 3.188 (3.188)	Data 2.087 (2.087)	Loss 0.1196 (0.1196)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.6670 (0.6670)	Loss KD (GCAM) 0.0554 (0.0554)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6473 (0.6473)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:12:13.413859
Epoch: [47][0/14], lr: 0.00001	Time 3.062 (3.062)	Data 1.949 (1.949)	Loss 0.1170 (0.1170)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6605 (0.6605)	Loss KD (GCAM) 0.0512 (0.0512)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6664 (0.6664)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:12:28.294382
Epoch: [48][0/14], lr: 0.00001	Time 3.272 (3.272)	Data 2.278 (2.278)	Loss 0.1178 (0.1178)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6938 (0.6938)	Loss KD (GCAM) 0.0547 (0.0547)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6416 (0.6416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:12:42.701296
Epoch: [49][0/14], lr: 0.00001	Time 3.003 (3.003)	Data 2.077 (2.077)	Loss 0.1187 (0.1187)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.6924 (0.6924)	Loss KD (GCAM) 0.0566 (0.0566)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6265 (0.6265)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=171, sigma=tensor([3.8187]), eta=tensor([3.0370])
  (fc1): CosineLinear(input_features=512, output_features=165, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 202
video number + exemplar : 202
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=171, sigma=tensor([3.8187]), eta=tensor([3.0370])
  (fc1): CosineLinear(input_features=512, output_features=165, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 285
DataLoader CBF Constructed : Train 8
Optimizer Constructed
2022-03-23 16:13:10.219528
Epoch: [0][0/8], lr: 0.00050	Time 2.709 (2.709)	Data 1.914 (1.914)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 16:13:16.775679
Epoch: [1][0/8], lr: 0.00050	Time 2.900 (2.900)	Data 2.378 (2.378)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8184], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0367], device='cuda:0', requires_grad=True)
2022-03-23 16:13:23.282843
Epoch: [2][0/8], lr: 0.00050	Time 2.885 (2.885)	Data 2.220 (2.220)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8184], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0366], device='cuda:0', requires_grad=True)
2022-03-23 16:13:29.756301
Epoch: [3][0/8], lr: 0.00050	Time 2.874 (2.874)	Data 2.165 (2.165)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8188], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0367], device='cuda:0', requires_grad=True)
2022-03-23 16:13:36.187417
Epoch: [4][0/8], lr: 0.00050	Time 2.860 (2.860)	Data 2.093 (2.093)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8192], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0368], device='cuda:0', requires_grad=True)
2022-03-23 16:13:42.660204
Epoch: [5][0/8], lr: 0.00050	Time 2.872 (2.872)	Data 2.311 (2.311)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8188], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0365], device='cuda:0', requires_grad=True)
2022-03-23 16:13:49.297372
Epoch: [6][0/8], lr: 0.00050	Time 2.887 (2.887)	Data 2.247 (2.247)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8181], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0360], device='cuda:0', requires_grad=True)
2022-03-23 16:13:55.833836
Epoch: [7][0/8], lr: 0.00050	Time 2.843 (2.843)	Data 2.210 (2.210)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8177], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0357], device='cuda:0', requires_grad=True)
2022-03-23 16:14:02.243312
Epoch: [8][0/8], lr: 0.00050	Time 2.713 (2.713)	Data 1.829 (1.829)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8179], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0357], device='cuda:0', requires_grad=True)
2022-03-23 16:14:08.700032
Epoch: [9][0/8], lr: 0.00050	Time 2.801 (2.801)	Data 1.839 (1.839)	Loss 0.0047 (0.0047)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8183], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0358], device='cuda:0', requires_grad=True)
2022-03-23 16:14:15.543636
Epoch: [10][0/8], lr: 0.00050	Time 3.146 (3.146)	Data 2.698 (2.698)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8189], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0361], device='cuda:0', requires_grad=True)
2022-03-23 16:14:22.047480
Epoch: [11][0/8], lr: 0.00050	Time 2.767 (2.767)	Data 2.131 (2.131)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8192], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0362], device='cuda:0', requires_grad=True)
2022-03-23 16:14:28.488472
Epoch: [12][0/8], lr: 0.00050	Time 2.714 (2.714)	Data 1.811 (1.811)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8194], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0362], device='cuda:0', requires_grad=True)
2022-03-23 16:14:35.111685
Epoch: [13][0/8], lr: 0.00050	Time 2.894 (2.894)	Data 1.916 (1.916)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8194], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0360], device='cuda:0', requires_grad=True)
2022-03-23 16:14:41.792374
Epoch: [14][0/8], lr: 0.00050	Time 2.904 (2.904)	Data 2.205 (2.205)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8197], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0361], device='cuda:0', requires_grad=True)
2022-03-23 16:14:48.237150
Epoch: [15][0/8], lr: 0.00050	Time 2.666 (2.666)	Data 1.887 (1.887)	Loss 0.0038 (0.0038)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0354], device='cuda:0', requires_grad=True)
2022-03-23 16:14:55.285247
Epoch: [16][0/8], lr: 0.00050	Time 3.260 (3.260)	Data 2.452 (2.452)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0345], device='cuda:0', requires_grad=True)
2022-03-23 16:15:02.053671
Epoch: [17][0/8], lr: 0.00050	Time 3.044 (3.044)	Data 2.579 (2.579)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8165], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0341], device='cuda:0', requires_grad=True)
2022-03-23 16:15:09.024418
Epoch: [18][0/8], lr: 0.00050	Time 3.262 (3.262)	Data 2.706 (2.706)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8161], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0338], device='cuda:0', requires_grad=True)
2022-03-23 16:15:16.037280
Epoch: [19][0/8], lr: 0.00050	Time 3.297 (3.297)	Data 2.563 (2.563)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8163], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0338], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_003.pth.tar
exemplar : 285
Computing the class mean vectors...
Eval Task 0 for Age 3
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.943 (4.943)	Prec@1 68.750 (68.750)
Test: [100/123]	Time 0.390 (0.512)	Prec@1 87.500 (78.280)
Testing Results: Prec@1 78.360
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 93.750 (81.374)
Testing Results (NME): Prec@1 81.110
Eval Task 1 for Age 3
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.806 (3.806)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 62.069
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 62.069
Eval Task 2 for Age 3
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.961 (3.961)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 61.538
Eval Task 3 for Age 3
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.546 (4.546)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 95.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 81.250
num_test_videos [1964, 58, 65, 80]
Method : OURS
----AGE 4----
current_task  [2, 64]
current_head  59
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05338539126015656]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=177, sigma=tensor([3.8163]), eta=tensor([3.0338])
  (fc1): CosineLinear(input_features=512, output_features=171, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 217
video number + exemplar : 502
DataLoader Constructed : Train 15
Optimizer Constructed
video number : 217
video number + exemplar : 217
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 16:18:12.260853
Epoch: [0][0/15], lr: 0.00100	Time 3.800 (3.800)	Data 2.451 (2.451)	Loss 0.0916 (0.0916)	Loss CE 0.0179 (0.0179)	Loss KD (Logit) 0.0987 (0.0987)	Loss KD (GCAM) 0.0144 (0.0144)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6415 (0.6415)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8164], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0338], device='cuda:0', requires_grad=True)
2022-03-23 16:18:25.895521
Epoch: [1][0/15], lr: 0.00100	Time 3.305 (3.305)	Data 2.185 (2.185)	Loss 0.0827 (0.0827)	Loss CE 0.0080 (0.0080)	Loss KD (Logit) 0.1056 (0.1056)	Loss KD (GCAM) 0.0132 (0.0132)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6513 (0.6513)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8197], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0358], device='cuda:0', requires_grad=True)
2022-03-23 16:18:40.488450
Epoch: [2][0/15], lr: 0.00100	Time 3.584 (3.584)	Data 2.704 (2.704)	Loss 0.1353 (0.1353)	Loss CE 0.0545 (0.0545)	Loss KD (Logit) 0.1039 (0.1039)	Loss KD (GCAM) 0.0148 (0.0148)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7077 (0.7077)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8258], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0387], device='cuda:0', requires_grad=True)
2022-03-23 16:18:54.970490
Epoch: [3][0/15], lr: 0.00100	Time 3.723 (3.723)	Data 2.742 (2.742)	Loss 0.1005 (0.1005)	Loss CE 0.0217 (0.0217)	Loss KD (Logit) 0.0991 (0.0991)	Loss KD (GCAM) 0.0157 (0.0157)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6882 (0.6882)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0411], device='cuda:0', requires_grad=True)
2022-03-23 16:19:09.769369
Epoch: [4][0/15], lr: 0.00100	Time 3.605 (3.605)	Data 2.806 (2.806)	Loss 0.0746 (0.0746)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0986 (0.0986)	Loss KD (GCAM) 0.0158 (0.0158)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6309 (0.6309)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8308], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0409], device='cuda:0', requires_grad=True)
2022-03-23 16:19:24.470041
Epoch: [5][0/15], lr: 0.00100	Time 3.813 (3.813)	Data 2.623 (2.623)	Loss 0.0818 (0.0818)	Loss CE 0.0040 (0.0040)	Loss KD (Logit) 0.1016 (0.1016)	Loss KD (GCAM) 0.0170 (0.0170)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6721 (0.6721)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8335], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0425], device='cuda:0', requires_grad=True)
2022-03-23 16:19:38.690913
Epoch: [6][0/15], lr: 0.00100	Time 3.392 (3.392)	Data 2.300 (2.300)	Loss 0.0824 (0.0824)	Loss CE 0.0040 (0.0040)	Loss KD (Logit) 0.0990 (0.0990)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6770 (0.6770)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0437], device='cuda:0', requires_grad=True)
2022-03-23 16:19:53.405018
Epoch: [7][0/15], lr: 0.00100	Time 3.711 (3.711)	Data 2.790 (2.790)	Loss 0.0763 (0.0763)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.1010 (0.1010)	Loss KD (GCAM) 0.0188 (0.0188)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6346 (0.6346)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8364], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0439], device='cuda:0', requires_grad=True)
2022-03-23 16:20:07.897486
Epoch: [8][0/15], lr: 0.00100	Time 3.529 (3.529)	Data 2.409 (2.409)	Loss 0.0757 (0.0757)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.1006 (0.1006)	Loss KD (GCAM) 0.0177 (0.0177)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6390 (0.6390)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8380], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0448], device='cuda:0', requires_grad=True)
2022-03-23 16:20:22.444068
Epoch: [9][0/15], lr: 0.00100	Time 3.715 (3.715)	Data 2.635 (2.635)	Loss 0.0796 (0.0796)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.1023 (0.1023)	Loss KD (GCAM) 0.0196 (0.0196)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6550 (0.6550)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8375], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0445], device='cuda:0', requires_grad=True)
2022-03-23 16:20:36.955098
Epoch: [10][0/15], lr: 0.00100	Time 3.601 (3.601)	Data 2.312 (2.312)	Loss 0.0801 (0.0801)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.1038 (0.1038)	Loss KD (GCAM) 0.0178 (0.0178)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6846 (0.6846)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8401], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0458], device='cuda:0', requires_grad=True)
2022-03-23 16:20:51.467994
Epoch: [11][0/15], lr: 0.00100	Time 3.521 (3.521)	Data 2.280 (2.280)	Loss 0.0974 (0.0974)	Loss CE 0.0212 (0.0212)	Loss KD (Logit) 0.1042 (0.1042)	Loss KD (GCAM) 0.0187 (0.0187)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6502 (0.6502)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8435], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 16:21:05.851870
Epoch: [12][0/15], lr: 0.00100	Time 4.082 (4.082)	Data 2.652 (2.652)	Loss 0.0787 (0.0787)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0984 (0.0984)	Loss KD (GCAM) 0.0178 (0.0178)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6737 (0.6737)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8454], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 16:21:21.363387
Epoch: [13][0/15], lr: 0.00100	Time 3.376 (3.376)	Data 2.556 (2.556)	Loss 0.0816 (0.0816)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.1025 (0.1025)	Loss KD (GCAM) 0.0193 (0.0193)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6925 (0.6925)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8466], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0493], device='cuda:0', requires_grad=True)
2022-03-23 16:21:37.230663
Epoch: [14][0/15], lr: 0.00100	Time 3.764 (3.764)	Data 2.789 (2.789)	Loss 0.0797 (0.0797)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.1037 (0.1037)	Loss KD (GCAM) 0.0181 (0.0181)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6715 (0.6715)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8488], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0506], device='cuda:0', requires_grad=True)
2022-03-23 16:21:52.364551
Epoch: [15][0/15], lr: 0.00100	Time 2.908 (2.908)	Data 1.988 (1.988)	Loss 0.0827 (0.0827)	Loss CE 0.0044 (0.0044)	Loss KD (Logit) 0.1032 (0.1032)	Loss KD (GCAM) 0.0183 (0.0183)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6729 (0.6729)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0523], device='cuda:0', requires_grad=True)
2022-03-23 16:22:07.825656
Epoch: [16][0/15], lr: 0.00100	Time 3.388 (3.388)	Data 2.290 (2.290)	Loss 0.0849 (0.0849)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.1083 (0.1083)	Loss KD (GCAM) 0.0177 (0.0177)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7074 (0.7074)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8539], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0533], device='cuda:0', requires_grad=True)
2022-03-23 16:22:23.625394
Epoch: [17][0/15], lr: 0.00100	Time 3.695 (3.695)	Data 2.308 (2.308)	Loss 0.0769 (0.0769)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1066 (0.1066)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6491 (0.6491)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8550], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0537], device='cuda:0', requires_grad=True)
2022-03-23 16:22:39.186035
Epoch: [18][0/15], lr: 0.00100	Time 3.532 (3.532)	Data 2.221 (2.221)	Loss 0.0759 (0.0759)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.1039 (0.1039)	Loss KD (GCAM) 0.0187 (0.0187)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6462 (0.6462)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8558], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0541], device='cuda:0', requires_grad=True)
2022-03-23 16:22:54.957208
Epoch: [19][0/15], lr: 0.00100	Time 3.515 (3.515)	Data 2.434 (2.434)	Loss 0.1345 (0.1345)	Loss CE 0.0581 (0.0581)	Loss KD (Logit) 0.1072 (0.1072)	Loss KD (GCAM) 0.0182 (0.0182)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6528 (0.6528)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0543], device='cuda:0', requires_grad=True)
2022-03-23 16:23:10.746957
Epoch: [20][0/15], lr: 0.00010	Time 3.535 (3.535)	Data 2.575 (2.575)	Loss 0.0917 (0.0917)	Loss CE 0.0104 (0.0104)	Loss KD (Logit) 0.1018 (0.1018)	Loss KD (GCAM) 0.0226 (0.0226)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6906 (0.6906)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8564], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0544], device='cuda:0', requires_grad=True)
2022-03-23 16:23:26.573219
Epoch: [21][0/15], lr: 0.00010	Time 3.623 (3.623)	Data 2.699 (2.699)	Loss 0.0779 (0.0779)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1068 (0.1068)	Loss KD (GCAM) 0.0208 (0.0208)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6543 (0.6543)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8565], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0545], device='cuda:0', requires_grad=True)
2022-03-23 16:23:42.223983
Epoch: [22][0/15], lr: 0.00010	Time 3.475 (3.475)	Data 2.569 (2.569)	Loss 0.0801 (0.0801)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.1036 (0.1036)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6706 (0.6706)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8563], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0544], device='cuda:0', requires_grad=True)
2022-03-23 16:23:57.678453
Epoch: [23][0/15], lr: 0.00010	Time 3.326 (3.326)	Data 1.938 (1.938)	Loss 0.0780 (0.0780)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.1058 (0.1058)	Loss KD (GCAM) 0.0213 (0.0213)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6479 (0.6479)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8563], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0544], device='cuda:0', requires_grad=True)
2022-03-23 16:24:13.574993
Epoch: [24][0/15], lr: 0.00010	Time 3.340 (3.340)	Data 2.106 (2.106)	Loss 0.0832 (0.0832)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1037 (0.1037)	Loss KD (GCAM) 0.0193 (0.0193)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7148 (0.7148)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0543], device='cuda:0', requires_grad=True)
2022-03-23 16:24:29.553932
Epoch: [25][0/15], lr: 0.00010	Time 3.722 (3.722)	Data 2.616 (2.616)	Loss 0.0846 (0.0846)	Loss CE 0.0102 (0.0102)	Loss KD (Logit) 0.1014 (0.1014)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6300 (0.6300)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8563], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0544], device='cuda:0', requires_grad=True)
2022-03-23 16:24:45.229254
Epoch: [26][0/15], lr: 0.00010	Time 3.310 (3.310)	Data 2.269 (2.269)	Loss 0.0776 (0.0776)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0987 (0.0987)	Loss KD (GCAM) 0.0200 (0.0200)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6301 (0.6301)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8564], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0544], device='cuda:0', requires_grad=True)
2022-03-23 16:25:00.753093
Epoch: [27][0/15], lr: 0.00010	Time 3.379 (3.379)	Data 1.975 (1.975)	Loss 0.0807 (0.0807)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.1003 (0.1003)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6631 (0.6631)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8566], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0545], device='cuda:0', requires_grad=True)
2022-03-23 16:25:16.594857
Epoch: [28][0/15], lr: 0.00010	Time 3.549 (3.549)	Data 2.417 (2.417)	Loss 0.0791 (0.0791)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0999 (0.0999)	Loss KD (GCAM) 0.0205 (0.0205)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6657 (0.6657)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8567], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:25:31.841187
Epoch: [29][0/15], lr: 0.00010	Time 3.352 (3.352)	Data 2.603 (2.603)	Loss 0.0782 (0.0782)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.1051 (0.1051)	Loss KD (GCAM) 0.0188 (0.0188)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6619 (0.6619)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:25:47.442794
Epoch: [30][0/15], lr: 0.00001	Time 3.497 (3.497)	Data 2.161 (2.161)	Loss 0.0821 (0.0821)	Loss CE 0.0040 (0.0040)	Loss KD (Logit) 0.0999 (0.0999)	Loss KD (GCAM) 0.0202 (0.0202)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6672 (0.6672)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:26:03.245114
Epoch: [31][0/15], lr: 0.00001	Time 3.374 (3.374)	Data 2.549 (2.549)	Loss 0.0789 (0.0789)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.1050 (0.1050)	Loss KD (GCAM) 0.0191 (0.0191)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6627 (0.6627)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:26:18.848656
Epoch: [32][0/15], lr: 0.00001	Time 3.496 (3.496)	Data 2.277 (2.277)	Loss 0.0753 (0.0753)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0968 (0.0968)	Loss KD (GCAM) 0.0178 (0.0178)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6408 (0.6408)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:26:34.255801
Epoch: [33][0/15], lr: 0.00001	Time 3.244 (3.244)	Data 2.073 (2.073)	Loss 0.0782 (0.0782)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1085 (0.1085)	Loss KD (GCAM) 0.0197 (0.0197)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6607 (0.6607)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:26:49.860738
Epoch: [34][0/15], lr: 0.00001	Time 3.404 (3.404)	Data 2.372 (2.372)	Loss 0.0852 (0.0852)	Loss CE 0.0084 (0.0084)	Loss KD (Logit) 0.1036 (0.1036)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6517 (0.6517)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:27:05.861965
Epoch: [35][0/15], lr: 0.00001	Time 3.427 (3.427)	Data 2.677 (2.677)	Loss 0.0814 (0.0814)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1007 (0.1007)	Loss KD (GCAM) 0.0195 (0.0195)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6985 (0.6985)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:27:21.632477
Epoch: [36][0/15], lr: 0.00001	Time 3.311 (3.311)	Data 2.291 (2.291)	Loss 0.0819 (0.0819)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.1032 (0.1032)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6711 (0.6711)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:27:37.201335
Epoch: [37][0/15], lr: 0.00001	Time 3.329 (3.329)	Data 2.156 (2.156)	Loss 0.0749 (0.0749)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1019 (0.1019)	Loss KD (GCAM) 0.0183 (0.0183)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6364 (0.6364)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:27:52.598871
Epoch: [38][0/15], lr: 0.00001	Time 3.380 (3.380)	Data 2.290 (2.290)	Loss 0.0874 (0.0874)	Loss CE 0.0123 (0.0123)	Loss KD (Logit) 0.1015 (0.1015)	Loss KD (GCAM) 0.0197 (0.0197)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6376 (0.6376)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:28:08.153031
Epoch: [39][0/15], lr: 0.00001	Time 3.041 (3.041)	Data 1.902 (1.902)	Loss 0.0799 (0.0799)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.1049 (0.1049)	Loss KD (GCAM) 0.0195 (0.0195)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6386 (0.6386)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:28:23.528346
Epoch: [40][0/15], lr: 0.00001	Time 3.304 (3.304)	Data 2.101 (2.101)	Loss 0.0821 (0.0821)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.1012 (0.1012)	Loss KD (GCAM) 0.0193 (0.0193)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6970 (0.6970)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:28:39.255331
Epoch: [41][0/15], lr: 0.00001	Time 3.428 (3.428)	Data 2.099 (2.099)	Loss 0.0754 (0.0754)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1000 (0.1000)	Loss KD (GCAM) 0.0194 (0.0194)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6407 (0.6407)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:28:54.911466
Epoch: [42][0/15], lr: 0.00001	Time 3.286 (3.286)	Data 2.363 (2.363)	Loss 0.0804 (0.0804)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.1027 (0.1027)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6790 (0.6790)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:29:10.494080
Epoch: [43][0/15], lr: 0.00001	Time 3.296 (3.296)	Data 2.422 (2.422)	Loss 0.0826 (0.0826)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.1017 (0.1017)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6885 (0.6885)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:29:25.958350
Epoch: [44][0/15], lr: 0.00001	Time 3.461 (3.461)	Data 2.166 (2.166)	Loss 0.0834 (0.0834)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.1044 (0.1044)	Loss KD (GCAM) 0.0188 (0.0188)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7110 (0.7110)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:29:41.577088
Epoch: [45][0/15], lr: 0.00001	Time 3.618 (3.618)	Data 2.449 (2.449)	Loss 0.1080 (0.1080)	Loss CE 0.0305 (0.0305)	Loss KD (Logit) 0.1005 (0.1005)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6606 (0.6606)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:29:57.241117
Epoch: [46][0/15], lr: 0.00001	Time 3.262 (3.262)	Data 2.462 (2.462)	Loss 0.0793 (0.0793)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.1054 (0.1054)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6608 (0.6608)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:30:13.327007
Epoch: [47][0/15], lr: 0.00001	Time 3.776 (3.776)	Data 2.716 (2.716)	Loss 0.0810 (0.0810)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.1027 (0.1027)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6907 (0.6907)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8570], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:30:29.305588
Epoch: [48][0/15], lr: 0.00001	Time 3.424 (3.424)	Data 2.536 (2.536)	Loss 0.0839 (0.0839)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.1042 (0.1042)	Loss KD (GCAM) 0.0191 (0.0191)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6914 (0.6914)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8570], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
2022-03-23 16:30:44.465974
Epoch: [49][0/15], lr: 0.00001	Time 3.215 (3.215)	Data 1.891 (1.891)	Loss 0.0840 (0.0840)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.1024 (0.1024)	Loss KD (GCAM) 0.0184 (0.0184)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6935 (0.6935)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8570], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0547], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=177, sigma=tensor([3.8570]), eta=tensor([3.0547])
  (fc1): CosineLinear(input_features=512, output_features=171, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 217
video number + exemplar : 217
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=177, sigma=tensor([3.8570]), eta=tensor([3.0547])
  (fc1): CosineLinear(input_features=512, output_features=171, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 295
DataLoader CBF Constructed : Train 9
Optimizer Constructed
2022-03-23 16:31:14.582620
Epoch: [0][0/9], lr: 0.00050	Time 2.731 (2.731)	Data 2.004 (2.004)	Loss 0.0893 (0.0893)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8565], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0544], device='cuda:0', requires_grad=True)
2022-03-23 16:31:21.955844
Epoch: [1][0/9], lr: 0.00050	Time 2.937 (2.937)	Data 2.365 (2.365)	Loss 0.0033 (0.0033)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 16:31:29.404336
Epoch: [2][0/9], lr: 0.00050	Time 2.812 (2.812)	Data 1.992 (1.992)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0548], device='cuda:0', requires_grad=True)
2022-03-23 16:31:36.773974
Epoch: [3][0/9], lr: 0.00050	Time 2.791 (2.791)	Data 2.032 (2.032)	Loss 0.0074 (0.0074)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8579], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0551], device='cuda:0', requires_grad=True)
2022-03-23 16:31:44.270955
Epoch: [4][0/9], lr: 0.00050	Time 2.898 (2.898)	Data 1.979 (1.979)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8587], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0555], device='cuda:0', requires_grad=True)
2022-03-23 16:31:52.068257
Epoch: [5][0/9], lr: 0.00050	Time 2.926 (2.926)	Data 2.194 (2.194)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8595], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0558], device='cuda:0', requires_grad=True)
2022-03-23 16:31:59.903814
Epoch: [6][0/9], lr: 0.00050	Time 3.192 (3.192)	Data 2.320 (2.320)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8608], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0565], device='cuda:0', requires_grad=True)
2022-03-23 16:32:07.225716
Epoch: [7][0/9], lr: 0.00050	Time 2.830 (2.830)	Data 1.942 (1.942)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8616], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0567], device='cuda:0', requires_grad=True)
2022-03-23 16:32:14.436703
Epoch: [8][0/9], lr: 0.00050	Time 2.824 (2.824)	Data 1.866 (1.866)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8616], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0566], device='cuda:0', requires_grad=True)
2022-03-23 16:32:21.519083
Epoch: [9][0/9], lr: 0.00050	Time 2.674 (2.674)	Data 1.901 (1.901)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8620], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0567], device='cuda:0', requires_grad=True)
2022-03-23 16:32:29.166733
Epoch: [10][0/9], lr: 0.00050	Time 2.884 (2.884)	Data 2.273 (2.273)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8624], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0568], device='cuda:0', requires_grad=True)
2022-03-23 16:32:36.438074
Epoch: [11][0/9], lr: 0.00050	Time 2.663 (2.663)	Data 1.888 (1.888)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8628], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0569], device='cuda:0', requires_grad=True)
2022-03-23 16:32:43.588749
Epoch: [12][0/9], lr: 0.00050	Time 2.741 (2.741)	Data 1.819 (1.819)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8634], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0571], device='cuda:0', requires_grad=True)
2022-03-23 16:32:50.875368
Epoch: [13][0/9], lr: 0.00050	Time 2.926 (2.926)	Data 2.472 (2.472)	Loss 0.0106 (0.0106)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8639], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0573], device='cuda:0', requires_grad=True)
2022-03-23 16:32:58.067760
Epoch: [14][0/9], lr: 0.00050	Time 2.789 (2.789)	Data 1.941 (1.941)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8644], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0574], device='cuda:0', requires_grad=True)
2022-03-23 16:33:05.242644
Epoch: [15][0/9], lr: 0.00050	Time 2.733 (2.733)	Data 1.922 (1.922)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8646], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0574], device='cuda:0', requires_grad=True)
2022-03-23 16:33:12.624436
Epoch: [16][0/9], lr: 0.00050	Time 2.990 (2.990)	Data 2.165 (2.165)	Loss 0.0046 (0.0046)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8650], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0575], device='cuda:0', requires_grad=True)
2022-03-23 16:33:19.484246
Epoch: [17][0/9], lr: 0.00050	Time 2.863 (2.863)	Data 1.989 (1.989)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8655], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0577], device='cuda:0', requires_grad=True)
2022-03-23 16:33:26.322887
Epoch: [18][0/9], lr: 0.00050	Time 2.887 (2.887)	Data 2.301 (2.301)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8657], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0577], device='cuda:0', requires_grad=True)
2022-03-23 16:33:32.773454
Epoch: [19][0/9], lr: 0.00050	Time 2.378 (2.378)	Data 1.863 (1.863)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8659], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0577], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_004.pth.tar
exemplar : 295
Computing the class mean vectors...
Eval Task 0 for Age 4
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 5.112 (5.112)	Prec@1 62.500 (62.500)
Test: [100/123]	Time 0.532 (0.513)	Prec@1 68.750 (73.020)
Testing Results: Prec@1 73.320
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 81.250 (80.817)
Testing Results (NME): Prec@1 80.550
Eval Task 1 for Age 4
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.994 (3.994)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 68.966
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 63.793
Eval Task 2 for Age 4
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.784 (3.784)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 75.385
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 53.846
Eval Task 3 for Age 4
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.656 (3.656)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 73.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 78.750
Eval Task 4 for Age 4
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.382 (4.382)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 97.647
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 78.824
num_test_videos [1964, 58, 65, 80, 85]
Method : OURS
----AGE 5----
current_task  [66, 42]
current_head  61
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05431390245600108]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=183, sigma=tensor([3.8659]), eta=tensor([3.0577])
  (fc1): CosineLinear(input_features=512, output_features=177, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 163
video number + exemplar : 458
DataLoader Constructed : Train 14
Optimizer Constructed
video number : 163
video number + exemplar : 163
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 16:36:43.299609
Epoch: [0][0/14], lr: 0.00100	Time 3.702 (3.702)	Data 2.570 (2.570)	Loss 0.1521 (0.1521)	Loss CE 0.0862 (0.0862)	Loss KD (Logit) 0.0090 (0.0090)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6311 (0.6311)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8580], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0545], device='cuda:0', requires_grad=True)
2022-03-23 16:36:56.297121
Epoch: [1][0/14], lr: 0.00100	Time 3.206 (3.206)	Data 2.524 (2.524)	Loss 0.0963 (0.0963)	Loss CE 0.0333 (0.0333)	Loss KD (Logit) 0.0094 (0.0094)	Loss KD (GCAM) 0.0095 (0.0095)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5964 (0.5964)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0528], device='cuda:0', requires_grad=True)
2022-03-23 16:37:09.675007
Epoch: [2][0/14], lr: 0.00100	Time 3.294 (3.294)	Data 2.466 (2.466)	Loss 0.0721 (0.0721)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0116 (0.0116)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6057 (0.6057)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8516], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0533], device='cuda:0', requires_grad=True)
2022-03-23 16:37:22.664092
Epoch: [3][0/14], lr: 0.00100	Time 3.069 (3.069)	Data 2.155 (2.155)	Loss 0.1474 (0.1474)	Loss CE 0.0802 (0.0802)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0115 (0.0115)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6320 (0.6320)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8566], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0565], device='cuda:0', requires_grad=True)
2022-03-23 16:37:35.664696
Epoch: [4][0/14], lr: 0.00100	Time 3.032 (3.032)	Data 1.854 (1.854)	Loss 0.1508 (0.1508)	Loss CE 0.0811 (0.0811)	Loss KD (Logit) 0.0094 (0.0094)	Loss KD (GCAM) 0.0107 (0.0107)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6602 (0.6602)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8611], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0592], device='cuda:0', requires_grad=True)
2022-03-23 16:37:49.268019
Epoch: [5][0/14], lr: 0.00100	Time 3.415 (3.415)	Data 2.671 (2.671)	Loss 0.0725 (0.0725)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0117 (0.0117)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6101 (0.6101)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8656], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0620], device='cuda:0', requires_grad=True)
2022-03-23 16:38:02.455211
Epoch: [6][0/14], lr: 0.00100	Time 3.163 (3.163)	Data 2.227 (2.227)	Loss 0.0958 (0.0958)	Loss CE 0.0281 (0.0281)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0118 (0.0118)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6364 (0.6364)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8693], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0643], device='cuda:0', requires_grad=True)
2022-03-23 16:38:15.816378
Epoch: [7][0/14], lr: 0.00100	Time 3.397 (3.397)	Data 2.023 (2.023)	Loss 0.0655 (0.0655)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0128 (0.0128)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5897 (0.5897)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8755], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0680], device='cuda:0', requires_grad=True)
2022-03-23 16:38:29.436887
Epoch: [8][0/14], lr: 0.00100	Time 3.357 (3.357)	Data 2.133 (2.133)	Loss 0.0679 (0.0679)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0119 (0.0119)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6295 (0.6295)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8796], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0703], device='cuda:0', requires_grad=True)
2022-03-23 16:38:43.133763
Epoch: [9][0/14], lr: 0.00100	Time 3.451 (3.451)	Data 2.688 (2.688)	Loss 0.1005 (0.1005)	Loss CE 0.0338 (0.0338)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0115 (0.0115)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6271 (0.6271)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8812], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0712], device='cuda:0', requires_grad=True)
2022-03-23 16:38:56.652410
Epoch: [10][0/14], lr: 0.00100	Time 3.316 (3.316)	Data 2.421 (2.421)	Loss 0.0655 (0.0655)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0121 (0.0121)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5941 (0.5941)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8819], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0714], device='cuda:0', requires_grad=True)
2022-03-23 16:39:10.265998
Epoch: [11][0/14], lr: 0.00100	Time 3.297 (3.297)	Data 2.127 (2.127)	Loss 0.1788 (0.1788)	Loss CE 0.1147 (0.1147)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0120 (0.0120)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5997 (0.5997)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8791], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0697], device='cuda:0', requires_grad=True)
2022-03-23 16:39:23.399910
Epoch: [12][0/14], lr: 0.00100	Time 3.272 (3.272)	Data 2.273 (2.273)	Loss 0.1204 (0.1204)	Loss CE 0.0574 (0.0574)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0113 (0.0113)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5910 (0.5910)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0711], device='cuda:0', requires_grad=True)
2022-03-23 16:39:37.085300
Epoch: [13][0/14], lr: 0.00100	Time 3.447 (3.447)	Data 2.293 (2.293)	Loss 0.0678 (0.0678)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0094 (0.0094)	Loss KD (GCAM) 0.0117 (0.0117)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6070 (0.6070)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8831], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0721], device='cuda:0', requires_grad=True)
2022-03-23 16:39:50.413799
Epoch: [14][0/14], lr: 0.00100	Time 3.363 (3.363)	Data 2.206 (2.206)	Loss 0.0755 (0.0755)	Loss CE 0.0087 (0.0087)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0125 (0.0125)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6247 (0.6247)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8843], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0732], device='cuda:0', requires_grad=True)
2022-03-23 16:40:04.322616
Epoch: [15][0/14], lr: 0.00100	Time 3.654 (3.654)	Data 2.803 (2.803)	Loss 0.0689 (0.0689)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0114 (0.0114)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6290 (0.6290)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8857], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 16:40:17.334488
Epoch: [16][0/14], lr: 0.00100	Time 3.093 (3.093)	Data 2.030 (2.030)	Loss 0.0712 (0.0712)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0114 (0.0114)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6505 (0.6505)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8871], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0750], device='cuda:0', requires_grad=True)
2022-03-23 16:40:30.617915
Epoch: [17][0/14], lr: 0.00100	Time 3.320 (3.320)	Data 2.550 (2.550)	Loss 0.0680 (0.0680)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0110 (0.0110)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6255 (0.6255)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8877], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0755], device='cuda:0', requires_grad=True)
2022-03-23 16:40:43.788380
Epoch: [18][0/14], lr: 0.00100	Time 3.152 (3.152)	Data 2.343 (2.343)	Loss 0.0654 (0.0654)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0113 (0.0113)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6104 (0.6104)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8889], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0763], device='cuda:0', requires_grad=True)
2022-03-23 16:40:57.346585
Epoch: [19][0/14], lr: 0.00100	Time 3.280 (3.280)	Data 2.365 (2.365)	Loss 0.0679 (0.0679)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0102 (0.0102)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5998 (0.5998)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0763], device='cuda:0', requires_grad=True)
2022-03-23 16:41:10.581111
Epoch: [20][0/14], lr: 0.00010	Time 3.166 (3.166)	Data 2.069 (2.069)	Loss 0.0633 (0.0633)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0112 (0.0112)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5882 (0.5882)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8893], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0763], device='cuda:0', requires_grad=True)
2022-03-23 16:41:25.168746
Epoch: [21][0/14], lr: 0.00010	Time 4.126 (4.126)	Data 3.374 (3.374)	Loss 0.0679 (0.0679)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0112 (0.0112)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6372 (0.6372)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8894], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0764], device='cuda:0', requires_grad=True)
2022-03-23 16:41:39.812203
Epoch: [22][0/14], lr: 0.00010	Time 3.215 (3.215)	Data 2.112 (2.112)	Loss 0.0656 (0.0656)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0122 (0.0122)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6085 (0.6085)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8895], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0764], device='cuda:0', requires_grad=True)
2022-03-23 16:41:54.568726
Epoch: [23][0/14], lr: 0.00010	Time 3.118 (3.118)	Data 2.397 (2.397)	Loss 0.0692 (0.0692)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0102 (0.0102)	Loss KD (GCAM) 0.0122 (0.0122)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6421 (0.6421)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8896], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0765], device='cuda:0', requires_grad=True)
2022-03-23 16:42:09.225722
Epoch: [24][0/14], lr: 0.00010	Time 3.009 (3.009)	Data 1.823 (1.823)	Loss 0.0665 (0.0665)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0104 (0.0104)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6161 (0.6161)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8897], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0765], device='cuda:0', requires_grad=True)
2022-03-23 16:42:23.921846
Epoch: [25][0/14], lr: 0.00010	Time 3.172 (3.172)	Data 1.800 (1.800)	Loss 0.1613 (0.1613)	Loss CE 0.0960 (0.0960)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0106 (0.0106)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6156 (0.6156)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8898], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0765], device='cuda:0', requires_grad=True)
2022-03-23 16:42:38.699619
Epoch: [26][0/14], lr: 0.00010	Time 3.363 (3.363)	Data 2.415 (2.415)	Loss 0.0671 (0.0671)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0109 (0.0109)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5953 (0.5953)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8899], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0766], device='cuda:0', requires_grad=True)
2022-03-23 16:42:53.374178
Epoch: [27][0/14], lr: 0.00010	Time 3.190 (3.190)	Data 2.420 (2.420)	Loss 0.0657 (0.0657)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0109 (0.0109)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6014 (0.6014)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8900], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0766], device='cuda:0', requires_grad=True)
2022-03-23 16:43:08.294751
Epoch: [28][0/14], lr: 0.00010	Time 3.302 (3.302)	Data 2.351 (2.351)	Loss 0.0704 (0.0704)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0108 (0.0108)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6584 (0.6584)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8901], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:43:23.021687
Epoch: [29][0/14], lr: 0.00010	Time 3.209 (3.209)	Data 2.032 (2.032)	Loss 0.0710 (0.0710)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0109 (0.0109)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6240 (0.6240)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:43:37.606796
Epoch: [30][0/14], lr: 0.00001	Time 3.240 (3.240)	Data 2.047 (2.047)	Loss 0.0681 (0.0681)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0119 (0.0119)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5915 (0.5915)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:43:52.178467
Epoch: [31][0/14], lr: 0.00001	Time 3.049 (3.049)	Data 1.786 (1.786)	Loss 0.0678 (0.0678)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0094 (0.0094)	Loss KD (GCAM) 0.0108 (0.0108)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6355 (0.6355)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:44:06.969648
Epoch: [32][0/14], lr: 0.00001	Time 3.250 (3.250)	Data 2.452 (2.452)	Loss 0.0660 (0.0660)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0113 (0.0113)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6132 (0.6132)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:44:21.487521
Epoch: [33][0/14], lr: 0.00001	Time 3.067 (3.067)	Data 1.993 (1.993)	Loss 0.0703 (0.0703)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.0101 (0.0101)	Loss KD (GCAM) 0.0120 (0.0120)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6164 (0.6164)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:44:36.171466
Epoch: [34][0/14], lr: 0.00001	Time 3.241 (3.241)	Data 2.217 (2.217)	Loss 0.0648 (0.0648)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0124 (0.0124)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5987 (0.5987)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:44:51.068465
Epoch: [35][0/14], lr: 0.00001	Time 3.324 (3.324)	Data 1.911 (1.911)	Loss 0.0628 (0.0628)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0111 (0.0111)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5875 (0.5875)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:45:05.830136
Epoch: [36][0/14], lr: 0.00001	Time 3.142 (3.142)	Data 2.095 (2.095)	Loss 0.0684 (0.0684)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0112 (0.0112)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6273 (0.6273)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:45:20.630567
Epoch: [37][0/14], lr: 0.00001	Time 3.264 (3.264)	Data 2.218 (2.218)	Loss 0.0637 (0.0637)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0113 (0.0113)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5963 (0.5963)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 16:45:35.436916
Epoch: [38][0/14], lr: 0.00001	Time 3.285 (3.285)	Data 1.857 (1.857)	Loss 0.0687 (0.0687)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0109 (0.0109)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6174 (0.6174)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:45:50.140724
Epoch: [39][0/14], lr: 0.00001	Time 3.029 (3.029)	Data 2.018 (2.018)	Loss 0.0649 (0.0649)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0114 (0.0114)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6013 (0.6013)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:46:04.779099
Epoch: [40][0/14], lr: 0.00001	Time 3.078 (3.078)	Data 2.333 (2.333)	Loss 0.0653 (0.0653)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0111 (0.0111)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6090 (0.6090)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:46:19.636501
Epoch: [41][0/14], lr: 0.00001	Time 3.289 (3.289)	Data 2.477 (2.477)	Loss 0.0657 (0.0657)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0108 (0.0108)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5987 (0.5987)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:46:34.541846
Epoch: [42][0/14], lr: 0.00001	Time 3.495 (3.495)	Data 2.317 (2.317)	Loss 0.0666 (0.0666)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0116 (0.0116)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6140 (0.6140)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:46:49.110477
Epoch: [43][0/14], lr: 0.00001	Time 3.076 (3.076)	Data 2.273 (2.273)	Loss 0.0691 (0.0691)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0117 (0.0117)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6371 (0.6371)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:47:04.147705
Epoch: [44][0/14], lr: 0.00001	Time 3.364 (3.364)	Data 2.475 (2.475)	Loss 0.0675 (0.0675)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0101 (0.0101)	Loss KD (GCAM) 0.0115 (0.0115)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6288 (0.6288)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:47:19.498503
Epoch: [45][0/14], lr: 0.00001	Time 3.664 (3.664)	Data 2.638 (2.638)	Loss 0.0635 (0.0635)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0116 (0.0116)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5811 (0.5811)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:47:33.836188
Epoch: [46][0/14], lr: 0.00001	Time 3.164 (3.164)	Data 2.084 (2.084)	Loss 0.0650 (0.0650)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0108 (0.0108)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6073 (0.6073)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:47:49.016072
Epoch: [47][0/14], lr: 0.00001	Time 3.389 (3.389)	Data 2.217 (2.217)	Loss 0.0679 (0.0679)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0105 (0.0105)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6294 (0.6294)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:48:03.549797
Epoch: [48][0/14], lr: 0.00001	Time 3.022 (3.022)	Data 1.952 (1.952)	Loss 0.0709 (0.0709)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0120 (0.0120)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6635 (0.6635)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
2022-03-23 16:48:18.110386
Epoch: [49][0/14], lr: 0.00001	Time 3.102 (3.102)	Data 1.931 (1.931)	Loss 0.0668 (0.0668)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0100 (0.0100)	Loss KD (GCAM) 0.0111 (0.0111)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6132 (0.6132)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0768], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=183, sigma=tensor([3.8904]), eta=tensor([3.0768])
  (fc1): CosineLinear(input_features=512, output_features=177, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 163
video number + exemplar : 163
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=183, sigma=tensor([3.8904]), eta=tensor([3.0768])
  (fc1): CosineLinear(input_features=512, output_features=177, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 305
DataLoader CBF Constructed : Train 9
Optimizer Constructed
2022-03-23 16:48:46.040982
Epoch: [0][0/9], lr: 0.00050	Time 2.665 (2.665)	Data 1.867 (1.867)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8908], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0770], device='cuda:0', requires_grad=True)
2022-03-23 16:48:53.157421
Epoch: [1][0/9], lr: 0.00050	Time 2.664 (2.664)	Data 2.083 (2.083)	Loss 0.0052 (0.0052)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8914], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0773], device='cuda:0', requires_grad=True)
2022-03-23 16:49:00.397096
Epoch: [2][0/9], lr: 0.00050	Time 2.851 (2.851)	Data 2.354 (2.354)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8919], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0775], device='cuda:0', requires_grad=True)
2022-03-23 16:49:07.994951
Epoch: [3][0/9], lr: 0.00050	Time 2.924 (2.924)	Data 2.261 (2.261)	Loss 0.0177 (0.0177)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8923], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0778], device='cuda:0', requires_grad=True)
2022-03-23 16:49:15.323132
Epoch: [4][0/9], lr: 0.00050	Time 2.658 (2.658)	Data 1.815 (1.815)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8931], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0782], device='cuda:0', requires_grad=True)
2022-03-23 16:49:22.486064
Epoch: [5][0/9], lr: 0.00050	Time 2.716 (2.716)	Data 1.935 (1.935)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8937], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0785], device='cuda:0', requires_grad=True)
2022-03-23 16:49:29.698393
Epoch: [6][0/9], lr: 0.00050	Time 2.820 (2.820)	Data 2.007 (2.007)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8942], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0787], device='cuda:0', requires_grad=True)
2022-03-23 16:49:36.934665
Epoch: [7][0/9], lr: 0.00050	Time 2.826 (2.826)	Data 2.359 (2.359)	Loss 0.0242 (0.0242)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8947], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0789], device='cuda:0', requires_grad=True)
2022-03-23 16:49:44.154670
Epoch: [8][0/9], lr: 0.00050	Time 2.847 (2.847)	Data 2.161 (2.161)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8951], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0790], device='cuda:0', requires_grad=True)
2022-03-23 16:49:51.360986
Epoch: [9][0/9], lr: 0.00050	Time 2.698 (2.698)	Data 1.958 (1.958)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8951], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0789], device='cuda:0', requires_grad=True)
2022-03-23 16:49:58.585200
Epoch: [10][0/9], lr: 0.00050	Time 2.820 (2.820)	Data 2.381 (2.381)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8951], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0788], device='cuda:0', requires_grad=True)
2022-03-23 16:50:05.745268
Epoch: [11][0/9], lr: 0.00050	Time 2.817 (2.817)	Data 2.126 (2.126)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8953], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0787], device='cuda:0', requires_grad=True)
2022-03-23 16:50:13.032806
Epoch: [12][0/9], lr: 0.00050	Time 2.894 (2.894)	Data 2.220 (2.220)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8954], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0787], device='cuda:0', requires_grad=True)
2022-03-23 16:50:20.375806
Epoch: [13][0/9], lr: 0.00050	Time 2.963 (2.963)	Data 2.411 (2.411)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8953], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0785], device='cuda:0', requires_grad=True)
2022-03-23 16:50:27.765803
Epoch: [14][0/9], lr: 0.00050	Time 2.699 (2.699)	Data 2.002 (2.002)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8953], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0784], device='cuda:0', requires_grad=True)
2022-03-23 16:50:35.320221
Epoch: [15][0/9], lr: 0.00050	Time 2.978 (2.978)	Data 2.068 (2.068)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8953], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0783], device='cuda:0', requires_grad=True)
2022-03-23 16:50:42.867795
Epoch: [16][0/9], lr: 0.00050	Time 2.899 (2.899)	Data 2.243 (2.243)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8957], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0784], device='cuda:0', requires_grad=True)
2022-03-23 16:50:50.477193
Epoch: [17][0/9], lr: 0.00050	Time 2.918 (2.918)	Data 1.945 (1.945)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8962], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0785], device='cuda:0', requires_grad=True)
2022-03-23 16:50:58.006620
Epoch: [18][0/9], lr: 0.00050	Time 2.877 (2.877)	Data 2.150 (2.150)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8963], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0785], device='cuda:0', requires_grad=True)
2022-03-23 16:51:05.515649
Epoch: [19][0/9], lr: 0.00050	Time 2.874 (2.874)	Data 2.373 (2.373)	Loss 0.0023 (0.0023)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8967], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0786], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_005.pth.tar
exemplar : 305
Computing the class mean vectors...
Eval Task 0 for Age 5
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.879 (4.879)	Prec@1 62.500 (62.500)
Test: [100/123]	Time 0.509 (0.518)	Prec@1 68.750 (73.948)
Testing Results: Prec@1 74.033
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (78.713)
Testing Results (NME): Prec@1 79.022
Eval Task 1 for Age 5
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.527 (3.527)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 56.897
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 67.241
Eval Task 2 for Age 5
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.795 (3.795)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 61.538
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 52.308
Eval Task 3 for Age 5
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.727 (3.727)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 62.500
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 68.750
Eval Task 4 for Age 5
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.010 (4.010)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 62.353
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 71.765
Eval Task 5 for Age 5
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.684 (3.684)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.774
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 80.645
num_test_videos [1964, 58, 65, 80, 85, 62]
Method : OURS
----AGE 6----
current_task  [22, 35]
current_head  63
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.055226805085936304]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=189, sigma=tensor([3.8967]), eta=tensor([3.0786])
  (fc1): CosineLinear(input_features=512, output_features=183, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 208
video number + exemplar : 513
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 208
video number + exemplar : 208
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 16:54:25.369888
Epoch: [0][0/16], lr: 0.00100	Time 3.868 (3.868)	Data 2.818 (2.818)	Loss 0.4462 (0.4462)	Loss CE 0.3723 (0.3723)	Loss KD (Logit) 0.0822 (0.0822)	Loss KD (GCAM) 0.0217 (0.0217)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6281 (0.6281)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8641], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0575], device='cuda:0', requires_grad=True)
2022-03-23 16:54:40.322038
Epoch: [1][0/16], lr: 0.00100	Time 3.174 (3.174)	Data 2.054 (2.054)	Loss 0.0887 (0.0887)	Loss CE 0.0121 (0.0121)	Loss KD (Logit) 0.0923 (0.0923)	Loss KD (GCAM) 0.0307 (0.0307)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6237 (0.6237)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8384], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 16:54:56.382071
Epoch: [2][0/16], lr: 0.00100	Time 4.046 (4.046)	Data 3.277 (3.277)	Loss 0.4740 (0.4740)	Loss CE 0.3997 (0.3997)	Loss KD (Logit) 0.0927 (0.0927)	Loss KD (GCAM) 0.0312 (0.0312)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5979 (0.5979)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8015], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0161], device='cuda:0', requires_grad=True)
2022-03-23 16:55:12.094150
Epoch: [3][0/16], lr: 0.00100	Time 3.682 (3.682)	Data 2.816 (2.816)	Loss 0.0936 (0.0936)	Loss CE 0.0141 (0.0141)	Loss KD (Logit) 0.0916 (0.0916)	Loss KD (GCAM) 0.0322 (0.0322)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6481 (0.6481)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0069], device='cuda:0', requires_grad=True)
2022-03-23 16:55:27.547479
Epoch: [4][0/16], lr: 0.00100	Time 3.439 (3.439)	Data 2.336 (2.336)	Loss 0.0972 (0.0972)	Loss CE 0.0205 (0.0205)	Loss KD (Logit) 0.0927 (0.0927)	Loss KD (GCAM) 0.0352 (0.0352)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6100 (0.6100)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7889], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0085], device='cuda:0', requires_grad=True)
2022-03-23 16:55:43.025246
Epoch: [5][0/16], lr: 0.00100	Time 3.534 (3.534)	Data 2.692 (2.692)	Loss 0.0915 (0.0915)	Loss CE 0.0120 (0.0120)	Loss KD (Logit) 0.0929 (0.0929)	Loss KD (GCAM) 0.0341 (0.0341)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6423 (0.6423)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7863], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0067], device='cuda:0', requires_grad=True)
2022-03-23 16:55:58.839213
Epoch: [6][0/16], lr: 0.00100	Time 3.691 (3.691)	Data 2.249 (2.249)	Loss 0.1352 (0.1352)	Loss CE 0.0577 (0.0577)	Loss KD (Logit) 0.0917 (0.0917)	Loss KD (GCAM) 0.0350 (0.0350)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6196 (0.6196)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.7805], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0027], device='cuda:0', requires_grad=True)
2022-03-23 16:56:14.031749
Epoch: [7][0/16], lr: 0.00100	Time 3.232 (3.232)	Data 2.171 (2.171)	Loss 0.0940 (0.0940)	Loss CE 0.0139 (0.0139)	Loss KD (Logit) 0.0932 (0.0932)	Loss KD (GCAM) 0.0388 (0.0388)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6332 (0.6332)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7805], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0024], device='cuda:0', requires_grad=True)
2022-03-23 16:56:29.869620
Epoch: [8][0/16], lr: 0.00100	Time 3.699 (3.699)	Data 2.389 (2.389)	Loss 0.0876 (0.0876)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0904 (0.0904)	Loss KD (GCAM) 0.0345 (0.0345)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6891 (0.6891)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7833], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0043], device='cuda:0', requires_grad=True)
2022-03-23 16:56:44.805737
Epoch: [9][0/16], lr: 0.00100	Time 3.376 (3.376)	Data 2.322 (2.322)	Loss 0.0974 (0.0974)	Loss CE 0.0177 (0.0177)	Loss KD (Logit) 0.0923 (0.0923)	Loss KD (GCAM) 0.0338 (0.0338)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6446 (0.6446)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7803], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0025], device='cuda:0', requires_grad=True)
2022-03-23 16:56:59.791500
Epoch: [10][0/16], lr: 0.00100	Time 3.330 (3.330)	Data 2.161 (2.161)	Loss 0.0928 (0.0928)	Loss CE 0.0137 (0.0137)	Loss KD (Logit) 0.0918 (0.0918)	Loss KD (GCAM) 0.0329 (0.0329)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6417 (0.6417)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7816], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0034], device='cuda:0', requires_grad=True)
2022-03-23 16:57:14.302730
Epoch: [11][0/16], lr: 0.00100	Time 2.901 (2.901)	Data 1.766 (1.766)	Loss 0.0902 (0.0902)	Loss CE 0.0127 (0.0127)	Loss KD (Logit) 0.0906 (0.0906)	Loss KD (GCAM) 0.0312 (0.0312)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6311 (0.6311)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7835], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0043], device='cuda:0', requires_grad=True)
2022-03-23 16:57:28.996116
Epoch: [12][0/16], lr: 0.00100	Time 3.163 (3.163)	Data 2.018 (2.018)	Loss 0.0989 (0.0989)	Loss CE 0.0229 (0.0229)	Loss KD (Logit) 0.0912 (0.0912)	Loss KD (GCAM) 0.0319 (0.0319)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6136 (0.6136)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7883], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0075], device='cuda:0', requires_grad=True)
2022-03-23 16:57:43.449799
Epoch: [13][0/16], lr: 0.00100	Time 3.127 (3.127)	Data 2.015 (2.015)	Loss 0.0928 (0.0928)	Loss CE 0.0127 (0.0127)	Loss KD (Logit) 0.0944 (0.0944)	Loss KD (GCAM) 0.0355 (0.0355)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6430 (0.6430)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7947], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0116], device='cuda:0', requires_grad=True)
2022-03-23 16:57:58.420378
Epoch: [14][0/16], lr: 0.00100	Time 3.132 (3.132)	Data 1.924 (1.924)	Loss 0.0808 (0.0808)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0919 (0.0919)	Loss KD (GCAM) 0.0313 (0.0313)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6410 (0.6410)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7976], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0135], device='cuda:0', requires_grad=True)
2022-03-23 16:58:13.140882
Epoch: [15][0/16], lr: 0.00100	Time 3.026 (3.026)	Data 1.872 (1.872)	Loss 0.0794 (0.0794)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0911 (0.0911)	Loss KD (GCAM) 0.0326 (0.0326)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6379 (0.6379)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7985], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0139], device='cuda:0', requires_grad=True)
2022-03-23 16:58:28.022475
Epoch: [16][0/16], lr: 0.00100	Time 3.211 (3.211)	Data 2.088 (2.088)	Loss 0.0752 (0.0752)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0915 (0.0915)	Loss KD (GCAM) 0.0299 (0.0299)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6022 (0.6022)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8000], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0147], device='cuda:0', requires_grad=True)
2022-03-23 16:58:42.767349
Epoch: [17][0/16], lr: 0.00100	Time 3.138 (3.138)	Data 1.954 (1.954)	Loss 0.0803 (0.0803)	Loss CE 0.0066 (0.0066)	Loss KD (Logit) 0.0916 (0.0916)	Loss KD (GCAM) 0.0316 (0.0316)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5917 (0.5917)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8000], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0152], device='cuda:0', requires_grad=True)
2022-03-23 16:58:57.958913
Epoch: [18][0/16], lr: 0.00100	Time 3.247 (3.247)	Data 2.501 (2.501)	Loss 0.0816 (0.0816)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0913 (0.0913)	Loss KD (GCAM) 0.0314 (0.0314)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6271 (0.6271)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8021], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0164], device='cuda:0', requires_grad=True)
2022-03-23 16:59:12.879970
Epoch: [19][0/16], lr: 0.00100	Time 3.443 (3.443)	Data 2.074 (2.074)	Loss 0.1075 (0.1075)	Loss CE 0.0271 (0.0271)	Loss KD (Logit) 0.0919 (0.0919)	Loss KD (GCAM) 0.0319 (0.0319)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6574 (0.6574)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8055], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0184], device='cuda:0', requires_grad=True)
2022-03-23 16:59:28.059186
Epoch: [20][0/16], lr: 0.00010	Time 3.515 (3.515)	Data 2.209 (2.209)	Loss 0.0831 (0.0831)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0924 (0.0924)	Loss KD (GCAM) 0.0324 (0.0324)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6803 (0.6803)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8058], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0185], device='cuda:0', requires_grad=True)
2022-03-23 16:59:43.091557
Epoch: [21][0/16], lr: 0.00010	Time 3.488 (3.488)	Data 2.709 (2.709)	Loss 0.0773 (0.0773)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0923 (0.0923)	Loss KD (GCAM) 0.0319 (0.0319)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6194 (0.6194)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8059], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0186], device='cuda:0', requires_grad=True)
2022-03-23 16:59:57.693474
Epoch: [22][0/16], lr: 0.00010	Time 2.924 (2.924)	Data 1.892 (1.892)	Loss 0.0769 (0.0769)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0929 (0.0929)	Loss KD (GCAM) 0.0302 (0.0302)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6203 (0.6203)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8061], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0187], device='cuda:0', requires_grad=True)
2022-03-23 17:00:12.720040
Epoch: [23][0/16], lr: 0.00010	Time 3.316 (3.316)	Data 2.157 (2.157)	Loss 0.0823 (0.0823)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0918 (0.0918)	Loss KD (GCAM) 0.0299 (0.0299)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6806 (0.6806)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8062], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0188], device='cuda:0', requires_grad=True)
2022-03-23 17:00:27.730317
Epoch: [24][0/16], lr: 0.00010	Time 3.271 (3.271)	Data 2.240 (2.240)	Loss 0.0760 (0.0760)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0934 (0.0934)	Loss KD (GCAM) 0.0291 (0.0291)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6183 (0.6183)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8064], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0189], device='cuda:0', requires_grad=True)
2022-03-23 17:00:42.354488
Epoch: [25][0/16], lr: 0.00010	Time 3.281 (3.281)	Data 2.370 (2.370)	Loss 0.0782 (0.0782)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0925 (0.0925)	Loss KD (GCAM) 0.0336 (0.0336)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6200 (0.6200)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8066], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0190], device='cuda:0', requires_grad=True)
2022-03-23 17:00:57.484682
Epoch: [26][0/16], lr: 0.00010	Time 3.352 (3.352)	Data 2.339 (2.339)	Loss 0.0813 (0.0813)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0916 (0.0916)	Loss KD (GCAM) 0.0315 (0.0315)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6614 (0.6614)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8069], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0191], device='cuda:0', requires_grad=True)
2022-03-23 17:01:11.963899
Epoch: [27][0/16], lr: 0.00010	Time 3.521 (3.521)	Data 2.446 (2.446)	Loss 0.0726 (0.0726)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0913 (0.0913)	Loss KD (GCAM) 0.0307 (0.0307)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5665 (0.5665)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8071], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0193], device='cuda:0', requires_grad=True)
2022-03-23 17:01:27.675520
Epoch: [28][0/16], lr: 0.00010	Time 3.441 (3.441)	Data 2.290 (2.290)	Loss 0.0749 (0.0749)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0910 (0.0910)	Loss KD (GCAM) 0.0307 (0.0307)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5938 (0.5938)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8075], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0195], device='cuda:0', requires_grad=True)
2022-03-23 17:01:43.393176
Epoch: [29][0/16], lr: 0.00010	Time 2.817 (2.817)	Data 1.894 (1.894)	Loss 0.0779 (0.0779)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0918 (0.0918)	Loss KD (GCAM) 0.0307 (0.0307)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6267 (0.6267)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8078], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:02:00.155076
Epoch: [30][0/16], lr: 0.00001	Time 3.323 (3.323)	Data 2.606 (2.606)	Loss 0.0803 (0.0803)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0912 (0.0912)	Loss KD (GCAM) 0.0309 (0.0309)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6432 (0.6432)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8078], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:02:16.780246
Epoch: [31][0/16], lr: 0.00001	Time 3.176 (3.176)	Data 2.055 (2.055)	Loss 0.0744 (0.0744)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0915 (0.0915)	Loss KD (GCAM) 0.0323 (0.0323)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5928 (0.5928)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8078], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:02:33.055395
Epoch: [32][0/16], lr: 0.00001	Time 3.182 (3.182)	Data 2.119 (2.119)	Loss 0.0943 (0.0943)	Loss CE 0.0174 (0.0174)	Loss KD (Logit) 0.0912 (0.0912)	Loss KD (GCAM) 0.0293 (0.0293)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6304 (0.6304)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8078], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:02:49.701033
Epoch: [33][0/16], lr: 0.00001	Time 3.377 (3.377)	Data 2.248 (2.248)	Loss 0.1041 (0.1041)	Loss CE 0.0286 (0.0286)	Loss KD (Logit) 0.0923 (0.0923)	Loss KD (GCAM) 0.0308 (0.0308)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6115 (0.6115)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8078], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:03:06.291795
Epoch: [34][0/16], lr: 0.00001	Time 3.243 (3.243)	Data 2.159 (2.159)	Loss 0.0756 (0.0756)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0898 (0.0898)	Loss KD (GCAM) 0.0287 (0.0287)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6067 (0.6067)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8079], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:03:22.702533
Epoch: [35][0/16], lr: 0.00001	Time 3.515 (3.515)	Data 2.476 (2.476)	Loss 0.0795 (0.0795)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0909 (0.0909)	Loss KD (GCAM) 0.0312 (0.0312)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6232 (0.6232)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8079], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:03:39.542595
Epoch: [36][0/16], lr: 0.00001	Time 3.606 (3.606)	Data 2.200 (2.200)	Loss 0.0866 (0.0866)	Loss CE 0.0079 (0.0079)	Loss KD (Logit) 0.0927 (0.0927)	Loss KD (GCAM) 0.0291 (0.0291)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6484 (0.6484)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8079], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:03:56.040076
Epoch: [37][0/16], lr: 0.00001	Time 3.207 (3.207)	Data 1.938 (1.938)	Loss 0.0780 (0.0780)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0929 (0.0929)	Loss KD (GCAM) 0.0291 (0.0291)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6399 (0.6399)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8079], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:04:12.739521
Epoch: [38][0/16], lr: 0.00001	Time 3.250 (3.250)	Data 2.458 (2.458)	Loss 0.0805 (0.0805)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0940 (0.0940)	Loss KD (GCAM) 0.0286 (0.0286)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6641 (0.6641)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8079], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0197], device='cuda:0', requires_grad=True)
2022-03-23 17:04:28.973206
Epoch: [39][0/16], lr: 0.00001	Time 3.384 (3.384)	Data 2.307 (2.307)	Loss 0.0816 (0.0816)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0917 (0.0917)	Loss KD (GCAM) 0.0277 (0.0277)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6472 (0.6472)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8079], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:04:45.453181
Epoch: [40][0/16], lr: 0.00001	Time 3.297 (3.297)	Data 2.248 (2.248)	Loss 0.0828 (0.0828)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0932 (0.0932)	Loss KD (GCAM) 0.0304 (0.0304)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6679 (0.6679)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8080], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:05:02.005372
Epoch: [41][0/16], lr: 0.00001	Time 3.664 (3.664)	Data 2.407 (2.407)	Loss 0.0905 (0.0905)	Loss CE 0.0132 (0.0132)	Loss KD (Logit) 0.0936 (0.0936)	Loss KD (GCAM) 0.0303 (0.0303)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6305 (0.6305)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8080], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:05:18.979075
Epoch: [42][0/16], lr: 0.00001	Time 3.725 (3.725)	Data 2.657 (2.657)	Loss 0.0779 (0.0779)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0919 (0.0919)	Loss KD (GCAM) 0.0300 (0.0300)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6173 (0.6173)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8080], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:05:35.420225
Epoch: [43][0/16], lr: 0.00001	Time 3.251 (3.251)	Data 2.118 (2.118)	Loss 0.0751 (0.0751)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0921 (0.0921)	Loss KD (GCAM) 0.0295 (0.0295)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5928 (0.5928)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8080], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:05:51.928636
Epoch: [44][0/16], lr: 0.00001	Time 3.155 (3.155)	Data 2.073 (2.073)	Loss 0.0748 (0.0748)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0915 (0.0915)	Loss KD (GCAM) 0.0300 (0.0300)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5985 (0.5985)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8080], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:06:08.557990
Epoch: [45][0/16], lr: 0.00001	Time 3.319 (3.319)	Data 2.383 (2.383)	Loss 0.0780 (0.0780)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0913 (0.0913)	Loss KD (GCAM) 0.0283 (0.0283)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6260 (0.6260)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8081], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:06:24.877125
Epoch: [46][0/16], lr: 0.00001	Time 3.309 (3.309)	Data 2.230 (2.230)	Loss 0.0776 (0.0776)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0925 (0.0925)	Loss KD (GCAM) 0.0276 (0.0276)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6388 (0.6388)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8081], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:06:41.720835
Epoch: [47][0/16], lr: 0.00001	Time 3.375 (3.375)	Data 2.222 (2.222)	Loss 0.0833 (0.0833)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0916 (0.0916)	Loss KD (GCAM) 0.0285 (0.0285)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6674 (0.6674)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8081], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:06:58.420378
Epoch: [48][0/16], lr: 0.00001	Time 3.183 (3.183)	Data 2.493 (2.493)	Loss 0.0801 (0.0801)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0937 (0.0937)	Loss KD (GCAM) 0.0330 (0.0330)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6432 (0.6432)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8081], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
2022-03-23 17:07:14.991545
Epoch: [49][0/16], lr: 0.00001	Time 3.205 (3.205)	Data 1.978 (1.978)	Loss 0.0796 (0.0796)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0907 (0.0907)	Loss KD (GCAM) 0.0315 (0.0315)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6485 (0.6485)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8081], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0198], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=189, sigma=tensor([3.8081]), eta=tensor([3.0198])
  (fc1): CosineLinear(input_features=512, output_features=183, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 208
video number + exemplar : 208
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=189, sigma=tensor([3.8081]), eta=tensor([3.0198])
  (fc1): CosineLinear(input_features=512, output_features=183, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 315
DataLoader CBF Constructed : Train 9
Optimizer Constructed
2022-03-23 17:07:47.016469
Epoch: [0][0/9], lr: 0.00050	Time 2.828 (2.828)	Data 1.924 (1.924)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8087], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0202], device='cuda:0', requires_grad=True)
2022-03-23 17:07:54.478273
Epoch: [1][0/9], lr: 0.00050	Time 3.012 (3.012)	Data 2.567 (2.567)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8095], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0206], device='cuda:0', requires_grad=True)
2022-03-23 17:08:01.899737
Epoch: [2][0/9], lr: 0.00050	Time 2.891 (2.891)	Data 2.326 (2.326)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8102], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0210], device='cuda:0', requires_grad=True)
2022-03-23 17:08:09.313823
Epoch: [3][0/9], lr: 0.00050	Time 2.670 (2.670)	Data 1.900 (1.900)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8109], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0213], device='cuda:0', requires_grad=True)
2022-03-23 17:08:16.792277
Epoch: [4][0/9], lr: 0.00050	Time 3.008 (3.008)	Data 2.443 (2.443)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8110], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0213], device='cuda:0', requires_grad=True)
2022-03-23 17:08:24.255502
Epoch: [5][0/9], lr: 0.00050	Time 2.950 (2.950)	Data 2.103 (2.103)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8109], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0211], device='cuda:0', requires_grad=True)
2022-03-23 17:08:31.840286
Epoch: [6][0/9], lr: 0.00050	Time 2.881 (2.881)	Data 2.198 (2.198)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8114], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0213], device='cuda:0', requires_grad=True)
2022-03-23 17:08:39.376023
Epoch: [7][0/9], lr: 0.00050	Time 2.841 (2.841)	Data 1.956 (1.956)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8121], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0216], device='cuda:0', requires_grad=True)
2022-03-23 17:08:47.142638
Epoch: [8][0/9], lr: 0.00050	Time 3.030 (3.030)	Data 2.199 (2.199)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8127], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0219], device='cuda:0', requires_grad=True)
2022-03-23 17:08:54.710828
Epoch: [9][0/9], lr: 0.00050	Time 2.911 (2.911)	Data 2.240 (2.240)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8133], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0221], device='cuda:0', requires_grad=True)
2022-03-23 17:09:02.284892
Epoch: [10][0/9], lr: 0.00050	Time 2.924 (2.924)	Data 1.955 (1.955)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8139], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0225], device='cuda:0', requires_grad=True)
2022-03-23 17:09:09.734583
Epoch: [11][0/9], lr: 0.00050	Time 2.814 (2.814)	Data 1.945 (1.945)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8146], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0228], device='cuda:0', requires_grad=True)
2022-03-23 17:09:17.139113
Epoch: [12][0/9], lr: 0.00050	Time 2.976 (2.976)	Data 2.297 (2.297)	Loss 0.0082 (0.0082)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8158], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0234], device='cuda:0', requires_grad=True)
2022-03-23 17:09:24.692959
Epoch: [13][0/9], lr: 0.00050	Time 2.638 (2.638)	Data 1.913 (1.913)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8164], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0237], device='cuda:0', requires_grad=True)
2022-03-23 17:09:32.197300
Epoch: [14][0/9], lr: 0.00050	Time 2.888 (2.888)	Data 2.137 (2.137)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8169], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0239], device='cuda:0', requires_grad=True)
2022-03-23 17:09:39.785634
Epoch: [15][0/9], lr: 0.00050	Time 2.917 (2.917)	Data 2.419 (2.419)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8176], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0243], device='cuda:0', requires_grad=True)
2022-03-23 17:09:47.371943
Epoch: [16][0/9], lr: 0.00050	Time 2.959 (2.959)	Data 2.301 (2.301)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8181], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0245], device='cuda:0', requires_grad=True)
2022-03-23 17:09:55.057417
Epoch: [17][0/9], lr: 0.00050	Time 3.059 (3.059)	Data 2.347 (2.347)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8188], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0248], device='cuda:0', requires_grad=True)
2022-03-23 17:10:02.524865
Epoch: [18][0/9], lr: 0.00050	Time 2.846 (2.846)	Data 2.081 (2.081)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8198], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0253], device='cuda:0', requires_grad=True)
2022-03-23 17:10:10.098927
Epoch: [19][0/9], lr: 0.00050	Time 2.941 (2.941)	Data 2.271 (2.271)	Loss 0.0047 (0.0047)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0257], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_006.pth.tar
exemplar : 315
Computing the class mean vectors...
Eval Task 0 for Age 6
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.953 (4.953)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.393 (0.516)	Prec@1 75.000 (71.597)
Testing Results: Prec@1 71.894
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (78.218)
Testing Results (NME): Prec@1 78.157
Eval Task 1 for Age 6
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 4.220 (4.220)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 62.069
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 67.241
Eval Task 2 for Age 6
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.972 (3.972)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 64.615
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 52.308
Eval Task 3 for Age 6
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.075 (4.075)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 70.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 63.750
Eval Task 4 for Age 6
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.962 (3.962)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 74.118
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 67.059
Eval Task 5 for Age 6
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.676 (3.676)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 75.806
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 67.742
Eval Task 6 for Age 6
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.736 (3.736)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 93.827
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 56.790
num_test_videos [1964, 58, 65, 80, 85, 62, 81]
Method : OURS
----AGE 7----
current_task  [86, 24]
current_head  65
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.056124860801609125]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=195, sigma=tensor([3.8205]), eta=tensor([3.0257])
  (fc1): CosineLinear(input_features=512, output_features=189, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 159
video number + exemplar : 474
DataLoader Constructed : Train 14
Optimizer Constructed
video number : 159
video number + exemplar : 159
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 17:13:44.578759
Epoch: [0][0/14], lr: 0.00100	Time 3.569 (3.569)	Data 2.434 (2.434)	Loss 0.0724 (0.0724)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0325 (0.0325)	Loss KD (GCAM) 0.0125 (0.0125)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6298 (0.6298)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8133], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0215], device='cuda:0', requires_grad=True)
2022-03-23 17:13:57.477440
Epoch: [1][0/14], lr: 0.00100	Time 3.411 (3.411)	Data 2.595 (2.595)	Loss 0.0656 (0.0656)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0324 (0.0324)	Loss KD (GCAM) 0.0134 (0.0134)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5879 (0.5879)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8139], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0219], device='cuda:0', requires_grad=True)
2022-03-23 17:14:11.031603
Epoch: [2][0/14], lr: 0.00100	Time 3.334 (3.334)	Data 2.361 (2.361)	Loss 0.0768 (0.0768)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0343 (0.0343)	Loss KD (GCAM) 0.0163 (0.0163)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6294 (0.6294)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8148], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0226], device='cuda:0', requires_grad=True)
2022-03-23 17:14:24.545644
Epoch: [3][0/14], lr: 0.00100	Time 3.350 (3.350)	Data 2.302 (2.302)	Loss 0.1379 (0.1379)	Loss CE 0.0731 (0.0731)	Loss KD (Logit) 0.0340 (0.0340)	Loss KD (GCAM) 0.0173 (0.0173)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5767 (0.5767)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8178], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0239], device='cuda:0', requires_grad=True)
2022-03-23 17:14:38.134038
Epoch: [4][0/14], lr: 0.00100	Time 3.259 (3.259)	Data 2.253 (2.253)	Loss 0.0733 (0.0733)	Loss CE 0.0098 (0.0098)	Loss KD (Logit) 0.0340 (0.0340)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5622 (0.5622)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8193], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0246], device='cuda:0', requires_grad=True)
2022-03-23 17:14:51.537390
Epoch: [5][0/14], lr: 0.00100	Time 3.262 (3.262)	Data 2.368 (2.368)	Loss 0.1376 (0.1376)	Loss CE 0.0676 (0.0676)	Loss KD (Logit) 0.0347 (0.0347)	Loss KD (GCAM) 0.0189 (0.0189)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6245 (0.6245)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8184], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0240], device='cuda:0', requires_grad=True)
2022-03-23 17:15:05.333728
Epoch: [6][0/14], lr: 0.00100	Time 3.123 (3.123)	Data 1.868 (1.868)	Loss 0.0698 (0.0698)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0345 (0.0345)	Loss KD (GCAM) 0.0221 (0.0221)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6093 (0.6093)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8194], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0247], device='cuda:0', requires_grad=True)
2022-03-23 17:15:19.564875
Epoch: [7][0/14], lr: 0.00100	Time 3.556 (3.556)	Data 2.574 (2.574)	Loss 0.1292 (0.1292)	Loss CE 0.0656 (0.0656)	Loss KD (Logit) 0.0336 (0.0336)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5633 (0.5633)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8203], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0251], device='cuda:0', requires_grad=True)
2022-03-23 17:15:33.234585
Epoch: [8][0/14], lr: 0.00100	Time 3.117 (3.117)	Data 1.911 (1.911)	Loss 0.0883 (0.0883)	Loss CE 0.0196 (0.0196)	Loss KD (Logit) 0.0342 (0.0342)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6142 (0.6142)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0255], device='cuda:0', requires_grad=True)
2022-03-23 17:15:46.741149
Epoch: [9][0/14], lr: 0.00100	Time 3.092 (3.092)	Data 2.278 (2.278)	Loss 0.0694 (0.0694)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 0.0351 (0.0351)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5544 (0.5544)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8211], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0255], device='cuda:0', requires_grad=True)
2022-03-23 17:16:00.943859
Epoch: [10][0/14], lr: 0.00100	Time 3.524 (3.524)	Data 2.683 (2.683)	Loss 0.0743 (0.0743)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0355 (0.0355)	Loss KD (GCAM) 0.0221 (0.0221)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6345 (0.6345)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0253], device='cuda:0', requires_grad=True)
2022-03-23 17:16:14.483856
Epoch: [11][0/14], lr: 0.00100	Time 3.149 (3.149)	Data 1.974 (1.974)	Loss 0.0709 (0.0709)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0350 (0.0350)	Loss KD (GCAM) 0.0183 (0.0183)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5929 (0.5929)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0265], device='cuda:0', requires_grad=True)
2022-03-23 17:16:28.234719
Epoch: [12][0/14], lr: 0.00100	Time 3.245 (3.245)	Data 2.081 (2.081)	Loss 0.0826 (0.0826)	Loss CE 0.0158 (0.0158)	Loss KD (Logit) 0.0352 (0.0352)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5874 (0.5874)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8245], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0281], device='cuda:0', requires_grad=True)
2022-03-23 17:16:42.315899
Epoch: [13][0/14], lr: 0.00100	Time 3.442 (3.442)	Data 2.613 (2.613)	Loss 0.0691 (0.0691)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0345 (0.0345)	Loss KD (GCAM) 0.0206 (0.0206)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5943 (0.5943)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8249], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0284], device='cuda:0', requires_grad=True)
2022-03-23 17:16:56.120438
Epoch: [14][0/14], lr: 0.00100	Time 3.322 (3.322)	Data 2.232 (2.232)	Loss 0.0669 (0.0669)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0344 (0.0344)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5818 (0.5818)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8269], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0295], device='cuda:0', requires_grad=True)
2022-03-23 17:17:09.616325
Epoch: [15][0/14], lr: 0.00100	Time 3.306 (3.306)	Data 1.986 (1.986)	Loss 0.0682 (0.0682)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0350 (0.0350)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5957 (0.5957)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8281], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0300], device='cuda:0', requires_grad=True)
2022-03-23 17:17:22.937677
Epoch: [16][0/14], lr: 0.00100	Time 3.308 (3.308)	Data 2.307 (2.307)	Loss 0.0686 (0.0686)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0344 (0.0344)	Loss KD (GCAM) 0.0205 (0.0205)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5988 (0.5988)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8283], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0299], device='cuda:0', requires_grad=True)
2022-03-23 17:17:36.470239
Epoch: [17][0/14], lr: 0.00100	Time 3.380 (3.380)	Data 2.126 (2.126)	Loss 0.0688 (0.0688)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0340 (0.0340)	Loss KD (GCAM) 0.0171 (0.0171)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6160 (0.6160)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0301], device='cuda:0', requires_grad=True)
2022-03-23 17:17:50.044434
Epoch: [18][0/14], lr: 0.00100	Time 3.345 (3.345)	Data 2.195 (2.195)	Loss 0.0667 (0.0667)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0338 (0.0338)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5659 (0.5659)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8291], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0301], device='cuda:0', requires_grad=True)
2022-03-23 17:18:03.534450
Epoch: [19][0/14], lr: 0.00100	Time 3.394 (3.394)	Data 2.156 (2.156)	Loss 0.0690 (0.0690)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0345 (0.0345)	Loss KD (GCAM) 0.0205 (0.0205)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6056 (0.6056)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8304], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0307], device='cuda:0', requires_grad=True)
2022-03-23 17:18:17.016253
Epoch: [20][0/14], lr: 0.00010	Time 3.389 (3.389)	Data 2.451 (2.451)	Loss 0.0677 (0.0677)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0341 (0.0341)	Loss KD (GCAM) 0.0158 (0.0158)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5903 (0.5903)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0308], device='cuda:0', requires_grad=True)
2022-03-23 17:18:30.228895
Epoch: [21][0/14], lr: 0.00010	Time 3.188 (3.188)	Data 1.982 (1.982)	Loss 0.0665 (0.0665)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0347 (0.0347)	Loss KD (GCAM) 0.0191 (0.0191)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5844 (0.5844)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8308], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0309], device='cuda:0', requires_grad=True)
2022-03-23 17:18:43.805917
Epoch: [22][0/14], lr: 0.00010	Time 3.198 (3.198)	Data 2.088 (2.088)	Loss 0.0795 (0.0795)	Loss CE 0.0095 (0.0095)	Loss KD (Logit) 0.0342 (0.0342)	Loss KD (GCAM) 0.0175 (0.0175)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6288 (0.6288)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8309], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0310], device='cuda:0', requires_grad=True)
2022-03-23 17:18:57.449869
Epoch: [23][0/14], lr: 0.00010	Time 3.503 (3.503)	Data 1.957 (1.957)	Loss 0.0664 (0.0664)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0342 (0.0342)	Loss KD (GCAM) 0.0166 (0.0166)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5935 (0.5935)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0310], device='cuda:0', requires_grad=True)
2022-03-23 17:19:10.998545
Epoch: [24][0/14], lr: 0.00010	Time 3.453 (3.453)	Data 2.544 (2.544)	Loss 0.0698 (0.0698)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0348 (0.0348)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6025 (0.6025)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0311], device='cuda:0', requires_grad=True)
2022-03-23 17:19:24.527497
Epoch: [25][0/14], lr: 0.00010	Time 3.265 (3.265)	Data 2.235 (2.235)	Loss 0.0671 (0.0671)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0346 (0.0346)	Loss KD (GCAM) 0.0181 (0.0181)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5940 (0.5940)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8313], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0312], device='cuda:0', requires_grad=True)
2022-03-23 17:19:38.428932
Epoch: [26][0/14], lr: 0.00010	Time 3.435 (3.435)	Data 2.454 (2.454)	Loss 0.0672 (0.0672)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0340 (0.0340)	Loss KD (GCAM) 0.0197 (0.0197)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5851 (0.5851)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8313], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0312], device='cuda:0', requires_grad=True)
2022-03-23 17:19:52.026971
Epoch: [27][0/14], lr: 0.00010	Time 3.286 (3.286)	Data 2.154 (2.154)	Loss 0.0688 (0.0688)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.0340 (0.0340)	Loss KD (GCAM) 0.0169 (0.0169)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5868 (0.5868)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8315], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0313], device='cuda:0', requires_grad=True)
2022-03-23 17:20:05.460600
Epoch: [28][0/14], lr: 0.00010	Time 3.248 (3.248)	Data 2.212 (2.212)	Loss 0.0703 (0.0703)	Loss CE 0.0053 (0.0053)	Loss KD (Logit) 0.0343 (0.0343)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5711 (0.5711)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8316], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:20:18.705541
Epoch: [29][0/14], lr: 0.00010	Time 3.290 (3.290)	Data 2.449 (2.449)	Loss 0.0665 (0.0665)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0336 (0.0336)	Loss KD (GCAM) 0.0172 (0.0172)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5733 (0.5733)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:20:32.065430
Epoch: [30][0/14], lr: 0.00001	Time 3.300 (3.300)	Data 2.063 (2.063)	Loss 0.0642 (0.0642)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0332 (0.0332)	Loss KD (GCAM) 0.0170 (0.0170)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5702 (0.5702)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:20:45.780400
Epoch: [31][0/14], lr: 0.00001	Time 3.560 (3.560)	Data 2.786 (2.786)	Loss 0.1297 (0.1297)	Loss CE 0.0634 (0.0634)	Loss KD (Logit) 0.0351 (0.0351)	Loss KD (GCAM) 0.0181 (0.0181)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5888 (0.5888)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:20:59.368539
Epoch: [32][0/14], lr: 0.00001	Time 3.370 (3.370)	Data 2.153 (2.153)	Loss 0.0642 (0.0642)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0334 (0.0334)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5674 (0.5674)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:21:12.788866
Epoch: [33][0/14], lr: 0.00001	Time 3.294 (3.294)	Data 1.945 (1.945)	Loss 0.0725 (0.0725)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0344 (0.0344)	Loss KD (GCAM) 0.0183 (0.0183)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6369 (0.6369)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:21:26.120657
Epoch: [34][0/14], lr: 0.00001	Time 3.950 (3.950)	Data 2.880 (2.880)	Loss 0.0722 (0.0722)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0349 (0.0349)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6158 (0.6158)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:21:40.747871
Epoch: [35][0/14], lr: 0.00001	Time 3.258 (3.258)	Data 2.466 (2.466)	Loss 0.0667 (0.0667)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0345 (0.0345)	Loss KD (GCAM) 0.0154 (0.0154)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5906 (0.5906)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:21:55.401659
Epoch: [36][0/14], lr: 0.00001	Time 3.194 (3.194)	Data 2.038 (2.038)	Loss 0.0677 (0.0677)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0347 (0.0347)	Loss KD (GCAM) 0.0160 (0.0160)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6056 (0.6056)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:22:10.491428
Epoch: [37][0/14], lr: 0.00001	Time 3.335 (3.335)	Data 1.927 (1.927)	Loss 0.0695 (0.0695)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0340 (0.0340)	Loss KD (GCAM) 0.0172 (0.0172)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6201 (0.6201)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:22:25.013088
Epoch: [38][0/14], lr: 0.00001	Time 3.295 (3.295)	Data 2.333 (2.333)	Loss 0.0672 (0.0672)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0347 (0.0347)	Loss KD (GCAM) 0.0174 (0.0174)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5999 (0.5999)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:22:39.730133
Epoch: [39][0/14], lr: 0.00001	Time 3.267 (3.267)	Data 2.225 (2.225)	Loss 0.0658 (0.0658)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0337 (0.0337)	Loss KD (GCAM) 0.0165 (0.0165)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5845 (0.5845)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:22:54.524725
Epoch: [40][0/14], lr: 0.00001	Time 3.388 (3.388)	Data 2.521 (2.521)	Loss 0.0660 (0.0660)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0346 (0.0346)	Loss KD (GCAM) 0.0194 (0.0194)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5610 (0.5610)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:23:09.245255
Epoch: [41][0/14], lr: 0.00001	Time 3.378 (3.378)	Data 2.673 (2.673)	Loss 0.0693 (0.0693)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0351 (0.0351)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6183 (0.6183)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:23:23.922751
Epoch: [42][0/14], lr: 0.00001	Time 3.163 (3.163)	Data 1.982 (1.982)	Loss 0.0664 (0.0664)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0345 (0.0345)	Loss KD (GCAM) 0.0172 (0.0172)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5918 (0.5918)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:23:38.741944
Epoch: [43][0/14], lr: 0.00001	Time 3.349 (3.349)	Data 2.247 (2.247)	Loss 0.0670 (0.0670)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0346 (0.0346)	Loss KD (GCAM) 0.0171 (0.0171)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5955 (0.5955)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:23:53.569652
Epoch: [44][0/14], lr: 0.00001	Time 3.374 (3.374)	Data 2.432 (2.432)	Loss 0.0702 (0.0702)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0345 (0.0345)	Loss KD (GCAM) 0.0173 (0.0173)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6203 (0.6203)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:24:08.261462
Epoch: [45][0/14], lr: 0.00001	Time 3.343 (3.343)	Data 2.466 (2.466)	Loss 0.0643 (0.0643)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0332 (0.0332)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5667 (0.5667)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:24:23.732272
Epoch: [46][0/14], lr: 0.00001	Time 3.709 (3.709)	Data 2.341 (2.341)	Loss 0.0649 (0.0649)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0340 (0.0340)	Loss KD (GCAM) 0.0172 (0.0172)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5752 (0.5752)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:24:38.551652
Epoch: [47][0/14], lr: 0.00001	Time 3.481 (3.481)	Data 2.427 (2.427)	Loss 0.0663 (0.0663)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0341 (0.0341)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5871 (0.5871)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:24:53.568842
Epoch: [48][0/14], lr: 0.00001	Time 3.141 (3.141)	Data 2.044 (2.044)	Loss 0.0663 (0.0663)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0339 (0.0339)	Loss KD (GCAM) 0.0185 (0.0185)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5855 (0.5855)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0314], device='cuda:0', requires_grad=True)
2022-03-23 17:25:07.957575
Epoch: [49][0/14], lr: 0.00001	Time 3.058 (3.058)	Data 1.855 (1.855)	Loss 0.0701 (0.0701)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0339 (0.0339)	Loss KD (GCAM) 0.0166 (0.0166)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6264 (0.6264)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0315], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=195, sigma=tensor([3.8318]), eta=tensor([3.0315])
  (fc1): CosineLinear(input_features=512, output_features=189, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 159
video number + exemplar : 159
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=195, sigma=tensor([3.8318]), eta=tensor([3.0315])
  (fc1): CosineLinear(input_features=512, output_features=189, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 325
DataLoader CBF Constructed : Train 10
Optimizer Constructed
2022-03-23 17:25:36.682416
Epoch: [0][0/10], lr: 0.00050	Time 2.813 (2.813)	Data 1.796 (1.796)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8322], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0317], device='cuda:0', requires_grad=True)
2022-03-23 17:25:44.747503
Epoch: [1][0/10], lr: 0.00050	Time 2.873 (2.873)	Data 1.943 (1.943)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8326], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0319], device='cuda:0', requires_grad=True)
2022-03-23 17:25:52.693339
Epoch: [2][0/10], lr: 0.00050	Time 2.783 (2.783)	Data 1.938 (1.938)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8330], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0321], device='cuda:0', requires_grad=True)
2022-03-23 17:26:00.740164
Epoch: [3][0/10], lr: 0.00050	Time 2.780 (2.780)	Data 1.949 (1.949)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8331], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0321], device='cuda:0', requires_grad=True)
2022-03-23 17:26:08.770230
Epoch: [4][0/10], lr: 0.00050	Time 2.810 (2.810)	Data 2.219 (2.219)	Loss 0.0032 (0.0032)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8335], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0321], device='cuda:0', requires_grad=True)
2022-03-23 17:26:16.867239
Epoch: [5][0/10], lr: 0.00050	Time 2.903 (2.903)	Data 2.408 (2.408)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8340], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0323], device='cuda:0', requires_grad=True)
2022-03-23 17:26:24.840462
Epoch: [6][0/10], lr: 0.00050	Time 2.924 (2.924)	Data 1.947 (1.947)	Loss 0.0069 (0.0069)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8345], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0325], device='cuda:0', requires_grad=True)
2022-03-23 17:26:33.100335
Epoch: [7][0/10], lr: 0.00050	Time 3.136 (3.136)	Data 2.017 (2.017)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8350], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0327], device='cuda:0', requires_grad=True)
2022-03-23 17:26:40.786696
Epoch: [8][0/10], lr: 0.00050	Time 2.814 (2.814)	Data 1.942 (1.942)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0329], device='cuda:0', requires_grad=True)
2022-03-23 17:26:48.820336
Epoch: [9][0/10], lr: 0.00050	Time 2.963 (2.963)	Data 2.464 (2.464)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8360], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0331], device='cuda:0', requires_grad=True)
2022-03-23 17:26:57.012272
Epoch: [10][0/10], lr: 0.00050	Time 2.925 (2.925)	Data 1.898 (1.898)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8367], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0334], device='cuda:0', requires_grad=True)
2022-03-23 17:27:04.850522
Epoch: [11][0/10], lr: 0.00050	Time 2.979 (2.979)	Data 2.148 (2.148)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8364], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0331], device='cuda:0', requires_grad=True)
2022-03-23 17:27:13.049875
Epoch: [12][0/10], lr: 0.00050	Time 2.940 (2.940)	Data 2.433 (2.433)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0325], device='cuda:0', requires_grad=True)
2022-03-23 17:27:21.075987
Epoch: [13][0/10], lr: 0.00050	Time 2.832 (2.832)	Data 1.878 (1.878)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0322], device='cuda:0', requires_grad=True)
2022-03-23 17:27:29.083347
Epoch: [14][0/10], lr: 0.00050	Time 2.969 (2.969)	Data 2.206 (2.206)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0320], device='cuda:0', requires_grad=True)
2022-03-23 17:27:36.901278
Epoch: [15][0/10], lr: 0.00050	Time 2.697 (2.697)	Data 1.882 (1.882)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0320], device='cuda:0', requires_grad=True)
2022-03-23 17:27:44.929674
Epoch: [16][0/10], lr: 0.00050	Time 2.960 (2.960)	Data 2.263 (2.263)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8357], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0321], device='cuda:0', requires_grad=True)
2022-03-23 17:27:52.900690
Epoch: [17][0/10], lr: 0.00050	Time 2.731 (2.731)	Data 2.014 (2.014)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8358], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0321], device='cuda:0', requires_grad=True)
2022-03-23 17:28:00.730214
Epoch: [18][0/10], lr: 0.00050	Time 2.562 (2.562)	Data 2.139 (2.139)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0320], device='cuda:0', requires_grad=True)
2022-03-23 17:28:08.990595
Epoch: [19][0/10], lr: 0.00050	Time 2.778 (2.778)	Data 2.120 (2.120)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0319], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_007.pth.tar
exemplar : 325
Computing the class mean vectors...
Eval Task 0 for Age 7
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.291 (4.291)	Prec@1 56.250 (56.250)
Test: [100/123]	Time 0.499 (0.510)	Prec@1 75.000 (71.040)
Testing Results: Prec@1 71.181
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 68.750 (76.980)
Testing Results (NME): Prec@1 77.037
Eval Task 1 for Age 7
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.617 (3.617)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 58.621
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 67.241
Eval Task 2 for Age 7
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.288 (3.288)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 53.846
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 60.000
Eval Task 3 for Age 7
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.792 (3.792)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 68.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 62.500
Eval Task 4 for Age 7
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.392 (4.392)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 72.941
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 64.706
Eval Task 5 for Age 7
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.653 (3.653)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.935
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 70.968
Eval Task 6 for Age 7
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.081 (4.081)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 88.889
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 50.617
Eval Task 7 for Age 7
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.823 (3.823)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.507
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 85.075
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67]
Method : OURS
----AGE 8----
current_task  [34, 87]
current_head  67
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.057008771254956896]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=201, sigma=tensor([3.8356]), eta=tensor([3.0319])
  (fc1): CosineLinear(input_features=512, output_features=195, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 200
video number + exemplar : 525
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 200
video number + exemplar : 200
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 17:31:52.649921
Epoch: [0][0/16], lr: 0.00100	Time 3.480 (3.480)	Data 2.257 (2.257)	Loss 0.0885 (0.0885)	Loss CE 0.0242 (0.0242)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0002 (0.0002)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6416 (0.6416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8236], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0248], device='cuda:0', requires_grad=True)
2022-03-23 17:32:08.900756
Epoch: [1][0/16], lr: 0.00100	Time 3.448 (3.448)	Data 2.215 (2.215)	Loss 0.2188 (0.2188)	Loss CE 0.1592 (0.1592)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5951 (0.5951)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8140], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0193], device='cuda:0', requires_grad=True)
2022-03-23 17:32:25.303684
Epoch: [2][0/16], lr: 0.00100	Time 3.391 (3.391)	Data 2.435 (2.435)	Loss 0.0731 (0.0731)	Loss CE 0.0096 (0.0096)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6346 (0.6346)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8174], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0222], device='cuda:0', requires_grad=True)
2022-03-23 17:32:41.883365
Epoch: [3][0/16], lr: 0.00100	Time 3.265 (3.265)	Data 2.144 (2.144)	Loss 0.0638 (0.0638)	Loss CE 0.0065 (0.0065)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5714 (0.5714)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0229], device='cuda:0', requires_grad=True)
2022-03-23 17:32:58.955267
Epoch: [4][0/16], lr: 0.00100	Time 3.717 (3.717)	Data 2.732 (2.732)	Loss 0.0786 (0.0786)	Loss CE 0.0185 (0.0185)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5998 (0.5998)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8177], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0236], device='cuda:0', requires_grad=True)
2022-03-23 17:33:15.621181
Epoch: [5][0/16], lr: 0.00100	Time 3.373 (3.373)	Data 2.243 (2.243)	Loss 0.0631 (0.0631)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6052 (0.6052)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8168], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0226], device='cuda:0', requires_grad=True)
2022-03-23 17:33:30.415770
Epoch: [6][0/16], lr: 0.00100	Time 3.238 (3.238)	Data 2.054 (2.054)	Loss 0.0734 (0.0734)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6822 (0.6822)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8161], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0221], device='cuda:0', requires_grad=True)
2022-03-23 17:33:45.006771
Epoch: [7][0/16], lr: 0.00100	Time 3.201 (3.201)	Data 1.908 (1.908)	Loss 0.0720 (0.0720)	Loss CE 0.0111 (0.0111)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6076 (0.6076)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8200], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0239], device='cuda:0', requires_grad=True)
2022-03-23 17:33:59.983717
Epoch: [8][0/16], lr: 0.00100	Time 3.402 (3.402)	Data 2.588 (2.588)	Loss 0.0647 (0.0647)	Loss CE 0.0068 (0.0068)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5777 (0.5777)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8241], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0260], device='cuda:0', requires_grad=True)
2022-03-23 17:34:14.768315
Epoch: [9][0/16], lr: 0.00100	Time 3.336 (3.336)	Data 2.151 (2.151)	Loss 0.0634 (0.0634)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5902 (0.5902)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8272], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0278], device='cuda:0', requires_grad=True)
2022-03-23 17:34:29.277177
Epoch: [10][0/16], lr: 0.00100	Time 2.847 (2.847)	Data 1.854 (1.854)	Loss 0.0627 (0.0627)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6162 (0.6162)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8285], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0285], device='cuda:0', requires_grad=True)
2022-03-23 17:34:44.752967
Epoch: [11][0/16], lr: 0.00100	Time 3.419 (3.419)	Data 2.493 (2.493)	Loss 0.1099 (0.1099)	Loss CE 0.0472 (0.0472)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6255 (0.6255)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8309], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0299], device='cuda:0', requires_grad=True)
2022-03-23 17:35:00.432878
Epoch: [12][0/16], lr: 0.00100	Time 3.406 (3.406)	Data 2.668 (2.668)	Loss 0.0950 (0.0950)	Loss CE 0.0375 (0.0375)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5736 (0.5736)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8324], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0306], device='cuda:0', requires_grad=True)
2022-03-23 17:35:15.831473
Epoch: [13][0/16], lr: 0.00100	Time 3.336 (3.336)	Data 2.320 (2.320)	Loss 0.0797 (0.0797)	Loss CE 0.0224 (0.0224)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5723 (0.5723)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8322], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0304], device='cuda:0', requires_grad=True)
2022-03-23 17:35:31.230598
Epoch: [14][0/16], lr: 0.00100	Time 3.437 (3.437)	Data 2.372 (2.372)	Loss 0.0592 (0.0592)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5836 (0.5836)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0297], device='cuda:0', requires_grad=True)
2022-03-23 17:35:46.856150
Epoch: [15][0/16], lr: 0.00100	Time 3.618 (3.618)	Data 2.718 (2.718)	Loss 0.0732 (0.0732)	Loss CE 0.0120 (0.0120)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6103 (0.6103)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 17:36:02.259978
Epoch: [16][0/16], lr: 0.00100	Time 3.348 (3.348)	Data 2.401 (2.401)	Loss 0.0612 (0.0612)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6061 (0.6061)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8329], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0308], device='cuda:0', requires_grad=True)
2022-03-23 17:36:17.637203
Epoch: [17][0/16], lr: 0.00100	Time 3.518 (3.518)	Data 2.208 (2.208)	Loss 0.0626 (0.0626)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6044 (0.6044)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0324], device='cuda:0', requires_grad=True)
2022-03-23 17:36:33.367714
Epoch: [18][0/16], lr: 0.00100	Time 3.644 (3.644)	Data 2.802 (2.802)	Loss 0.0668 (0.0668)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6190 (0.6190)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8390], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0341], device='cuda:0', requires_grad=True)
2022-03-23 17:36:48.562743
Epoch: [19][0/16], lr: 0.00100	Time 3.327 (3.327)	Data 2.426 (2.426)	Loss 0.0636 (0.0636)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6283 (0.6283)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8417], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0354], device='cuda:0', requires_grad=True)
2022-03-23 17:37:03.455008
Epoch: [20][0/16], lr: 0.00010	Time 3.447 (3.447)	Data 2.129 (2.129)	Loss 0.0653 (0.0653)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6247 (0.6247)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0354], device='cuda:0', requires_grad=True)
2022-03-23 17:37:18.625679
Epoch: [21][0/16], lr: 0.00010	Time 3.585 (3.585)	Data 2.078 (2.078)	Loss 0.0711 (0.0711)	Loss CE 0.0098 (0.0098)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6116 (0.6116)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8415], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0353], device='cuda:0', requires_grad=True)
2022-03-23 17:37:33.346735
Epoch: [22][0/16], lr: 0.00010	Time 3.407 (3.407)	Data 2.424 (2.424)	Loss 0.0635 (0.0635)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6002 (0.6002)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:37:48.238684
Epoch: [23][0/16], lr: 0.00010	Time 3.281 (3.281)	Data 2.470 (2.470)	Loss 0.0634 (0.0634)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6170 (0.6170)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:38:03.109213
Epoch: [24][0/16], lr: 0.00010	Time 3.333 (3.333)	Data 2.513 (2.513)	Loss 0.0624 (0.0624)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6113 (0.6113)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:38:17.723260
Epoch: [25][0/16], lr: 0.00010	Time 3.127 (3.127)	Data 1.925 (1.925)	Loss 0.0713 (0.0713)	Loss CE 0.0106 (0.0106)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6063 (0.6063)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:38:32.622898
Epoch: [26][0/16], lr: 0.00010	Time 3.269 (3.269)	Data 2.281 (2.281)	Loss 0.0609 (0.0609)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6046 (0.6046)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8415], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0352], device='cuda:0', requires_grad=True)
2022-03-23 17:38:47.288144
Epoch: [27][0/16], lr: 0.00010	Time 3.312 (3.312)	Data 2.397 (2.397)	Loss 0.0578 (0.0578)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5730 (0.5730)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0352], device='cuda:0', requires_grad=True)
2022-03-23 17:39:02.265889
Epoch: [28][0/16], lr: 0.00010	Time 3.410 (3.410)	Data 2.292 (2.292)	Loss 0.0714 (0.0714)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6436 (0.6436)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0353], device='cuda:0', requires_grad=True)
2022-03-23 17:39:17.168264
Epoch: [29][0/16], lr: 0.00010	Time 3.421 (3.421)	Data 2.555 (2.555)	Loss 0.0641 (0.0641)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6327 (0.6327)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:39:32.115490
Epoch: [30][0/16], lr: 0.00001	Time 3.585 (3.585)	Data 2.689 (2.689)	Loss 0.0685 (0.0685)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6374 (0.6374)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:39:46.976921
Epoch: [31][0/16], lr: 0.00001	Time 3.504 (3.504)	Data 2.718 (2.718)	Loss 0.0634 (0.0634)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6184 (0.6184)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:40:01.956047
Epoch: [32][0/16], lr: 0.00001	Time 3.270 (3.270)	Data 2.117 (2.117)	Loss 0.0617 (0.0617)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6101 (0.6101)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:40:16.853085
Epoch: [33][0/16], lr: 0.00001	Time 3.375 (3.375)	Data 2.040 (2.040)	Loss 0.0651 (0.0651)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6400 (0.6400)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:40:31.795295
Epoch: [34][0/16], lr: 0.00001	Time 3.464 (3.464)	Data 2.321 (2.321)	Loss 0.0928 (0.0928)	Loss CE 0.0308 (0.0308)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6195 (0.6195)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:40:46.556375
Epoch: [35][0/16], lr: 0.00001	Time 3.382 (3.382)	Data 2.637 (2.637)	Loss 0.0623 (0.0623)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5768 (0.5768)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:41:01.252088
Epoch: [36][0/16], lr: 0.00001	Time 3.333 (3.333)	Data 2.233 (2.233)	Loss 0.0643 (0.0643)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6003 (0.6003)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:41:16.202888
Epoch: [37][0/16], lr: 0.00001	Time 3.759 (3.759)	Data 2.672 (2.672)	Loss 0.0661 (0.0661)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6243 (0.6243)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:41:32.451968
Epoch: [38][0/16], lr: 0.00001	Time 3.529 (3.529)	Data 2.180 (2.180)	Loss 0.0597 (0.0597)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5955 (0.5955)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:41:49.357508
Epoch: [39][0/16], lr: 0.00001	Time 3.603 (3.603)	Data 2.817 (2.817)	Loss 0.0644 (0.0644)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6404 (0.6404)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:42:05.804159
Epoch: [40][0/16], lr: 0.00001	Time 3.315 (3.315)	Data 2.545 (2.545)	Loss 0.0625 (0.0625)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6165 (0.6165)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:42:22.325459
Epoch: [41][0/16], lr: 0.00001	Time 3.147 (3.147)	Data 2.193 (2.193)	Loss 0.0650 (0.0650)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6280 (0.6280)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:42:38.192556
Epoch: [42][0/16], lr: 0.00001	Time 3.025 (3.025)	Data 1.856 (1.856)	Loss 0.0606 (0.0606)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5936 (0.5936)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:42:54.789236
Epoch: [43][0/16], lr: 0.00001	Time 3.165 (3.165)	Data 1.985 (1.985)	Loss 0.0639 (0.0639)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6271 (0.6271)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:43:11.042793
Epoch: [44][0/16], lr: 0.00001	Time 3.670 (3.670)	Data 2.099 (2.099)	Loss 0.0594 (0.0594)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5848 (0.5848)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:43:27.632820
Epoch: [45][0/16], lr: 0.00001	Time 3.552 (3.552)	Data 2.676 (2.676)	Loss 0.0668 (0.0668)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6304 (0.6304)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:43:44.060715
Epoch: [46][0/16], lr: 0.00001	Time 3.254 (3.254)	Data 2.328 (2.328)	Loss 0.0585 (0.0585)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5799 (0.5799)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:44:00.535578
Epoch: [47][0/16], lr: 0.00001	Time 3.185 (3.185)	Data 2.019 (2.019)	Loss 0.0632 (0.0632)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6246 (0.6246)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:44:16.953674
Epoch: [48][0/16], lr: 0.00001	Time 3.204 (3.204)	Data 2.307 (2.307)	Loss 0.0667 (0.0667)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6299 (0.6299)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
2022-03-23 17:44:33.293071
Epoch: [49][0/16], lr: 0.00001	Time 3.570 (3.570)	Data 2.039 (2.039)	Loss 0.0611 (0.0611)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6000 (0.6000)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0351], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=201, sigma=tensor([3.8414]), eta=tensor([3.0351])
  (fc1): CosineLinear(input_features=512, output_features=195, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 200
video number + exemplar : 200
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=201, sigma=tensor([3.8414]), eta=tensor([3.0351])
  (fc1): CosineLinear(input_features=512, output_features=195, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 335
DataLoader CBF Constructed : Train 10
Optimizer Constructed
2022-03-23 17:45:05.602654
Epoch: [0][0/10], lr: 0.00050	Time 3.284 (3.284)	Data 2.223 (2.223)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8417], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0352], device='cuda:0', requires_grad=True)
2022-03-23 17:45:13.493492
Epoch: [1][0/10], lr: 0.00050	Time 2.809 (2.809)	Data 2.134 (2.134)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8420], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0353], device='cuda:0', requires_grad=True)
2022-03-23 17:45:21.744650
Epoch: [2][0/10], lr: 0.00050	Time 3.130 (3.130)	Data 2.405 (2.405)	Loss 0.0044 (0.0044)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8424], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0354], device='cuda:0', requires_grad=True)
2022-03-23 17:45:29.438704
Epoch: [3][0/10], lr: 0.00050	Time 2.804 (2.804)	Data 2.122 (2.122)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8432], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0357], device='cuda:0', requires_grad=True)
2022-03-23 17:45:37.351720
Epoch: [4][0/10], lr: 0.00050	Time 2.894 (2.894)	Data 2.317 (2.317)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8437], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0359], device='cuda:0', requires_grad=True)
2022-03-23 17:45:45.576688
Epoch: [5][0/10], lr: 0.00050	Time 3.025 (3.025)	Data 2.328 (2.328)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8434], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0356], device='cuda:0', requires_grad=True)
2022-03-23 17:45:53.310690
Epoch: [6][0/10], lr: 0.00050	Time 2.876 (2.876)	Data 2.061 (2.061)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8425], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0349], device='cuda:0', requires_grad=True)
2022-03-23 17:46:01.544800
Epoch: [7][0/10], lr: 0.00050	Time 3.065 (3.065)	Data 2.069 (2.069)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8419], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0344], device='cuda:0', requires_grad=True)
2022-03-23 17:46:09.179004
Epoch: [8][0/10], lr: 0.00050	Time 2.708 (2.708)	Data 1.891 (1.891)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8423], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0344], device='cuda:0', requires_grad=True)
2022-03-23 17:46:17.240823
Epoch: [9][0/10], lr: 0.00050	Time 3.052 (3.052)	Data 2.207 (2.207)	Loss 0.0064 (0.0064)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8428], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0346], device='cuda:0', requires_grad=True)
2022-03-23 17:46:25.495375
Epoch: [10][0/10], lr: 0.00050	Time 3.112 (3.112)	Data 2.176 (2.176)	Loss 0.0033 (0.0033)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8434], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0348], device='cuda:0', requires_grad=True)
2022-03-23 17:46:33.459437
Epoch: [11][0/10], lr: 0.00050	Time 2.956 (2.956)	Data 2.192 (2.192)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8439], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0350], device='cuda:0', requires_grad=True)
2022-03-23 17:46:41.701644
Epoch: [12][0/10], lr: 0.00050	Time 2.952 (2.952)	Data 2.074 (2.074)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8448], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0354], device='cuda:0', requires_grad=True)
2022-03-23 17:46:49.357929
Epoch: [13][0/10], lr: 0.00050	Time 2.628 (2.628)	Data 1.841 (1.841)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8457], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0357], device='cuda:0', requires_grad=True)
2022-03-23 17:46:57.289895
Epoch: [14][0/10], lr: 0.00050	Time 2.879 (2.879)	Data 1.873 (1.873)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8462], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0359], device='cuda:0', requires_grad=True)
2022-03-23 17:47:05.246016
Epoch: [15][0/10], lr: 0.00050	Time 2.833 (2.833)	Data 1.814 (1.814)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8464], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0359], device='cuda:0', requires_grad=True)
2022-03-23 17:47:13.270232
Epoch: [16][0/10], lr: 0.00050	Time 2.919 (2.919)	Data 2.357 (2.357)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8465], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0358], device='cuda:0', requires_grad=True)
2022-03-23 17:47:21.154362
Epoch: [17][0/10], lr: 0.00050	Time 2.843 (2.843)	Data 2.074 (2.074)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8469], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0359], device='cuda:0', requires_grad=True)
2022-03-23 17:47:29.196233
Epoch: [18][0/10], lr: 0.00050	Time 2.873 (2.873)	Data 2.247 (2.247)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8472], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0359], device='cuda:0', requires_grad=True)
2022-03-23 17:47:37.274036
Epoch: [19][0/10], lr: 0.00050	Time 2.974 (2.974)	Data 2.241 (2.241)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8473], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0359], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_008.pth.tar
exemplar : 335
Computing the class mean vectors...
Eval Task 0 for Age 8
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.847 (4.847)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.353 (0.524)	Prec@1 75.000 (71.782)
Testing Results: Prec@1 71.589
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (78.465)
Testing Results (NME): Prec@1 78.310
Eval Task 1 for Age 8
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.742 (3.742)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 75.862
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 70.690
Eval Task 2 for Age 8
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.808 (3.808)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 64.615
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 58.462
Eval Task 3 for Age 8
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.669 (3.669)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 61.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 60.000
Eval Task 4 for Age 8
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.939 (3.939)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 72.941
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 62.353
Eval Task 5 for Age 8
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.713 (3.713)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 85.484
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 82.258
Eval Task 6 for Age 8
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.181 (4.181)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 82.716
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 49.383
Eval Task 7 for Age 8
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.723 (3.723)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.522
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 85.075
Eval Task 8 for Age 8
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.267 (3.267)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 87.879
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 69.697
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66]
Method : OURS
----AGE 9----
current_task  [21, 100]
current_head  69
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05787918451395113]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=207, sigma=tensor([3.8473]), eta=tensor([3.0359])
  (fc1): CosineLinear(input_features=512, output_features=201, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 191
video number + exemplar : 526
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 191
video number + exemplar : 191
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 17:51:34.064241
Epoch: [0][0/16], lr: 0.00100	Time 3.466 (3.466)	Data 1.989 (1.989)	Loss 0.0721 (0.0721)	Loss CE 0.0138 (0.0138)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5803 (0.5803)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8357], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0296], device='cuda:0', requires_grad=True)
2022-03-23 17:51:50.232110
Epoch: [1][0/16], lr: 0.00100	Time 3.416 (3.416)	Data 2.622 (2.622)	Loss 0.1150 (0.1150)	Loss CE 0.0533 (0.0533)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6129 (0.6129)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8250], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0226], device='cuda:0', requires_grad=True)
2022-03-23 17:52:06.954447
Epoch: [2][0/16], lr: 0.00100	Time 3.621 (3.621)	Data 2.557 (2.557)	Loss 0.0758 (0.0758)	Loss CE 0.0173 (0.0173)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5799 (0.5799)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8138], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0156], device='cuda:0', requires_grad=True)
2022-03-23 17:52:23.204659
Epoch: [3][0/16], lr: 0.00100	Time 3.135 (3.135)	Data 2.078 (2.078)	Loss 0.0817 (0.0817)	Loss CE 0.0240 (0.0240)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5702 (0.5702)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8191], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0193], device='cuda:0', requires_grad=True)
2022-03-23 17:52:39.205780
Epoch: [4][0/16], lr: 0.00100	Time 3.293 (3.293)	Data 1.864 (1.864)	Loss 0.0758 (0.0758)	Loss CE 0.0189 (0.0189)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5624 (0.5624)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8266], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0241], device='cuda:0', requires_grad=True)
2022-03-23 17:52:56.075256
Epoch: [5][0/16], lr: 0.00100	Time 3.838 (3.838)	Data 2.505 (2.505)	Loss 0.0570 (0.0570)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5375 (0.5375)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8340], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0291], device='cuda:0', requires_grad=True)
2022-03-23 17:53:11.329203
Epoch: [6][0/16], lr: 0.00100	Time 3.457 (3.457)	Data 2.523 (2.523)	Loss 0.1384 (0.1384)	Loss CE 0.0832 (0.0832)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5451 (0.5451)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8397], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0326], device='cuda:0', requires_grad=True)
2022-03-23 17:53:26.258265
Epoch: [7][0/16], lr: 0.00100	Time 3.490 (3.490)	Data 2.318 (2.318)	Loss 0.0590 (0.0590)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5744 (0.5744)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8449], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0360], device='cuda:0', requires_grad=True)
2022-03-23 17:53:40.865748
Epoch: [8][0/16], lr: 0.00100	Time 3.316 (3.316)	Data 2.318 (2.318)	Loss 0.0624 (0.0624)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5815 (0.5815)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8490], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0388], device='cuda:0', requires_grad=True)
2022-03-23 17:53:55.693939
Epoch: [9][0/16], lr: 0.00100	Time 3.520 (3.520)	Data 2.602 (2.602)	Loss 0.1028 (0.1028)	Loss CE 0.0397 (0.0397)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6244 (0.6244)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8506], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0394], device='cuda:0', requires_grad=True)
2022-03-23 17:54:10.591629
Epoch: [10][0/16], lr: 0.00100	Time 3.372 (3.372)	Data 2.543 (2.543)	Loss 0.0598 (0.0598)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5776 (0.5776)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8546], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0418], device='cuda:0', requires_grad=True)
2022-03-23 17:54:26.121023
Epoch: [11][0/16], lr: 0.00100	Time 3.400 (3.400)	Data 2.391 (2.391)	Loss 0.0637 (0.0637)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5861 (0.5861)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8577], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0437], device='cuda:0', requires_grad=True)
2022-03-23 17:54:41.177642
Epoch: [12][0/16], lr: 0.00100	Time 3.273 (3.273)	Data 2.298 (2.298)	Loss 0.0712 (0.0712)	Loss CE 0.0100 (0.0100)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6056 (0.6056)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8614], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0461], device='cuda:0', requires_grad=True)
2022-03-23 17:54:56.481041
Epoch: [13][0/16], lr: 0.00100	Time 3.377 (3.377)	Data 2.048 (2.048)	Loss 0.0699 (0.0699)	Loss CE 0.0082 (0.0082)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6106 (0.6106)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8649], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 17:55:12.169193
Epoch: [14][0/16], lr: 0.00100	Time 3.488 (3.488)	Data 1.972 (1.972)	Loss 0.0586 (0.0586)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5727 (0.5727)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0491], device='cuda:0', requires_grad=True)
2022-03-23 17:55:27.293799
Epoch: [15][0/16], lr: 0.00100	Time 3.245 (3.245)	Data 2.480 (2.480)	Loss 0.0871 (0.0871)	Loss CE 0.0249 (0.0249)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6152 (0.6152)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8710], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0519], device='cuda:0', requires_grad=True)
2022-03-23 17:55:42.985400
Epoch: [16][0/16], lr: 0.00100	Time 3.624 (3.624)	Data 2.859 (2.859)	Loss 0.0596 (0.0596)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5788 (0.5788)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8752], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0544], device='cuda:0', requires_grad=True)
2022-03-23 17:55:58.482140
Epoch: [17][0/16], lr: 0.00100	Time 3.459 (3.459)	Data 2.348 (2.348)	Loss 0.0578 (0.0578)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5506 (0.5506)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8784], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0565], device='cuda:0', requires_grad=True)
2022-03-23 17:56:14.101503
Epoch: [18][0/16], lr: 0.00100	Time 3.585 (3.585)	Data 2.279 (2.279)	Loss 0.0591 (0.0591)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5637 (0.5637)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8825], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0591], device='cuda:0', requires_grad=True)
2022-03-23 17:56:29.628099
Epoch: [19][0/16], lr: 0.00100	Time 3.714 (3.714)	Data 2.497 (2.497)	Loss 0.0825 (0.0825)	Loss CE 0.0239 (0.0239)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5798 (0.5798)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8839], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0602], device='cuda:0', requires_grad=True)
2022-03-23 17:56:44.501008
Epoch: [20][0/16], lr: 0.00010	Time 3.153 (3.153)	Data 1.933 (1.933)	Loss 0.0595 (0.0595)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5724 (0.5724)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8842], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0603], device='cuda:0', requires_grad=True)
2022-03-23 17:56:59.568170
Epoch: [21][0/16], lr: 0.00010	Time 3.299 (3.299)	Data 2.196 (2.196)	Loss 0.0721 (0.0721)	Loss CE 0.0120 (0.0120)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5950 (0.5950)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8843], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0604], device='cuda:0', requires_grad=True)
2022-03-23 17:57:14.358753
Epoch: [22][0/16], lr: 0.00010	Time 3.302 (3.302)	Data 1.957 (1.957)	Loss 0.0567 (0.0567)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5512 (0.5512)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8845], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0605], device='cuda:0', requires_grad=True)
2022-03-23 17:57:29.030738
Epoch: [23][0/16], lr: 0.00010	Time 3.344 (3.344)	Data 2.407 (2.407)	Loss 0.0594 (0.0594)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5746 (0.5746)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8848], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0607], device='cuda:0', requires_grad=True)
2022-03-23 17:57:43.941893
Epoch: [24][0/16], lr: 0.00010	Time 3.414 (3.414)	Data 2.671 (2.671)	Loss 0.0604 (0.0604)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5810 (0.5810)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8848], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0607], device='cuda:0', requires_grad=True)
2022-03-23 17:57:59.009196
Epoch: [25][0/16], lr: 0.00010	Time 3.405 (3.405)	Data 2.154 (2.154)	Loss 0.0584 (0.0584)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5621 (0.5621)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8849], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0606], device='cuda:0', requires_grad=True)
2022-03-23 17:58:13.986017
Epoch: [26][0/16], lr: 0.00010	Time 3.452 (3.452)	Data 2.313 (2.313)	Loss 0.0847 (0.0847)	Loss CE 0.0276 (0.0276)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5644 (0.5644)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8849], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0607], device='cuda:0', requires_grad=True)
2022-03-23 17:58:28.331220
Epoch: [27][0/16], lr: 0.00010	Time 2.781 (2.781)	Data 1.841 (1.841)	Loss 0.0637 (0.0637)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5860 (0.5860)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8853], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0608], device='cuda:0', requires_grad=True)
2022-03-23 17:58:43.364116
Epoch: [28][0/16], lr: 0.00010	Time 3.386 (3.386)	Data 2.346 (2.346)	Loss 0.0617 (0.0617)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5908 (0.5908)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8855], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0610], device='cuda:0', requires_grad=True)
2022-03-23 17:58:58.131642
Epoch: [29][0/16], lr: 0.00010	Time 3.385 (3.385)	Data 2.516 (2.516)	Loss 0.0659 (0.0659)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6284 (0.6284)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8857], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0611], device='cuda:0', requires_grad=True)
2022-03-23 17:59:13.416524
Epoch: [30][0/16], lr: 0.00001	Time 3.692 (3.692)	Data 2.135 (2.135)	Loss 0.0647 (0.0647)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6194 (0.6194)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8857], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0611], device='cuda:0', requires_grad=True)
2022-03-23 17:59:28.163108
Epoch: [31][0/16], lr: 0.00001	Time 3.416 (3.416)	Data 2.309 (2.309)	Loss 0.0638 (0.0638)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5908 (0.5908)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8858], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0611], device='cuda:0', requires_grad=True)
2022-03-23 17:59:43.125806
Epoch: [32][0/16], lr: 0.00001	Time 3.446 (3.446)	Data 2.677 (2.677)	Loss 0.0574 (0.0574)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5577 (0.5577)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8858], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0611], device='cuda:0', requires_grad=True)
2022-03-23 17:59:57.980363
Epoch: [33][0/16], lr: 0.00001	Time 3.321 (3.321)	Data 2.037 (2.037)	Loss 0.0587 (0.0587)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5738 (0.5738)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8858], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0612], device='cuda:0', requires_grad=True)
2022-03-23 18:00:13.012797
Epoch: [34][0/16], lr: 0.00001	Time 3.470 (3.470)	Data 2.611 (2.611)	Loss 0.0648 (0.0648)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6292 (0.6292)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8858], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0612], device='cuda:0', requires_grad=True)
2022-03-23 18:00:27.857790
Epoch: [35][0/16], lr: 0.00001	Time 3.309 (3.309)	Data 2.047 (2.047)	Loss 0.0533 (0.0533)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5195 (0.5195)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8859], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0612], device='cuda:0', requires_grad=True)
2022-03-23 18:00:42.720480
Epoch: [36][0/16], lr: 0.00001	Time 3.373 (3.373)	Data 2.332 (2.332)	Loss 0.0698 (0.0698)	Loss CE 0.0144 (0.0144)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5479 (0.5479)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8859], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0612], device='cuda:0', requires_grad=True)
2022-03-23 18:00:57.631955
Epoch: [37][0/16], lr: 0.00001	Time 3.797 (3.797)	Data 2.825 (2.825)	Loss 0.0640 (0.0640)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6019 (0.6019)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8859], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0612], device='cuda:0', requires_grad=True)
2022-03-23 18:01:14.058993
Epoch: [38][0/16], lr: 0.00001	Time 3.239 (3.239)	Data 1.997 (1.997)	Loss 0.0601 (0.0601)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5786 (0.5786)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8859], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0612], device='cuda:0', requires_grad=True)
2022-03-23 18:01:30.693525
Epoch: [39][0/16], lr: 0.00001	Time 3.306 (3.306)	Data 2.403 (2.403)	Loss 0.0591 (0.0591)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5800 (0.5800)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8860], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0612], device='cuda:0', requires_grad=True)
2022-03-23 18:01:46.986149
Epoch: [40][0/16], lr: 0.00001	Time 3.271 (3.271)	Data 1.838 (1.838)	Loss 0.0580 (0.0580)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5597 (0.5597)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8860], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:02:03.255849
Epoch: [41][0/16], lr: 0.00001	Time 3.312 (3.312)	Data 2.173 (2.173)	Loss 0.0603 (0.0603)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5842 (0.5842)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8860], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:02:19.812242
Epoch: [42][0/16], lr: 0.00001	Time 3.369 (3.369)	Data 2.009 (2.009)	Loss 0.0615 (0.0615)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6001 (0.6001)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8860], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:02:36.199686
Epoch: [43][0/16], lr: 0.00001	Time 3.191 (3.191)	Data 2.224 (2.224)	Loss 0.0767 (0.0767)	Loss CE 0.0162 (0.0162)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5991 (0.5991)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:02:52.724070
Epoch: [44][0/16], lr: 0.00001	Time 3.186 (3.186)	Data 2.082 (2.082)	Loss 0.0621 (0.0621)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5738 (0.5738)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:03:09.225452
Epoch: [45][0/16], lr: 0.00001	Time 3.361 (3.361)	Data 2.395 (2.395)	Loss 0.0609 (0.0609)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5739 (0.5739)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:03:25.512463
Epoch: [46][0/16], lr: 0.00001	Time 3.475 (3.475)	Data 1.886 (1.886)	Loss 0.0571 (0.0571)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5548 (0.5548)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:03:42.487622
Epoch: [47][0/16], lr: 0.00001	Time 3.720 (3.720)	Data 2.488 (2.488)	Loss 0.0591 (0.0591)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5776 (0.5776)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:03:58.746511
Epoch: [48][0/16], lr: 0.00001	Time 3.202 (3.202)	Data 2.314 (2.314)	Loss 0.0584 (0.0584)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5708 (0.5708)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
2022-03-23 18:04:14.799086
Epoch: [49][0/16], lr: 0.00001	Time 3.208 (3.208)	Data 1.811 (1.811)	Loss 0.0625 (0.0625)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5879 (0.5879)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8862], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0613], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=207, sigma=tensor([3.8862]), eta=tensor([3.0613])
  (fc1): CosineLinear(input_features=512, output_features=201, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 191
video number + exemplar : 191
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=207, sigma=tensor([3.8862]), eta=tensor([3.0613])
  (fc1): CosineLinear(input_features=512, output_features=201, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 345
DataLoader CBF Constructed : Train 10
Optimizer Constructed
2022-03-23 18:04:46.237420
Epoch: [0][0/10], lr: 0.00050	Time 2.842 (2.842)	Data 1.981 (1.981)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8867], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0616], device='cuda:0', requires_grad=True)
2022-03-23 18:04:54.127202
Epoch: [1][0/10], lr: 0.00050	Time 2.847 (2.847)	Data 2.012 (2.012)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8877], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0621], device='cuda:0', requires_grad=True)
2022-03-23 18:05:01.936030
Epoch: [2][0/10], lr: 0.00050	Time 2.678 (2.678)	Data 1.869 (1.869)	Loss 0.0038 (0.0038)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8885], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 18:05:09.989506
Epoch: [3][0/10], lr: 0.00050	Time 2.979 (2.979)	Data 2.267 (2.267)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8893], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0629], device='cuda:0', requires_grad=True)
2022-03-23 18:05:17.474408
Epoch: [4][0/10], lr: 0.00050	Time 2.683 (2.683)	Data 1.794 (1.794)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8901], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0633], device='cuda:0', requires_grad=True)
2022-03-23 18:05:25.096184
Epoch: [5][0/10], lr: 0.00050	Time 2.798 (2.798)	Data 1.916 (1.916)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8906], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0635], device='cuda:0', requires_grad=True)
2022-03-23 18:05:33.129963
Epoch: [6][0/10], lr: 0.00050	Time 2.951 (2.951)	Data 2.101 (2.101)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8910], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0637], device='cuda:0', requires_grad=True)
2022-03-23 18:05:41.267845
Epoch: [7][0/10], lr: 0.00050	Time 2.871 (2.871)	Data 1.946 (1.946)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0640], device='cuda:0', requires_grad=True)
2022-03-23 18:05:48.993594
Epoch: [8][0/10], lr: 0.00050	Time 2.782 (2.782)	Data 2.306 (2.306)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8926], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0644], device='cuda:0', requires_grad=True)
2022-03-23 18:05:56.964850
Epoch: [9][0/10], lr: 0.00050	Time 2.839 (2.839)	Data 1.942 (1.942)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8931], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0645], device='cuda:0', requires_grad=True)
2022-03-23 18:06:04.894805
Epoch: [10][0/10], lr: 0.00050	Time 2.750 (2.750)	Data 2.005 (2.005)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8935], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0645], device='cuda:0', requires_grad=True)
2022-03-23 18:06:12.972162
Epoch: [11][0/10], lr: 0.00050	Time 2.942 (2.942)	Data 2.169 (2.169)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8936], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0645], device='cuda:0', requires_grad=True)
2022-03-23 18:06:21.691906
Epoch: [12][0/10], lr: 0.00050	Time 3.510 (3.510)	Data 2.781 (2.781)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8939], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0645], device='cuda:0', requires_grad=True)
2022-03-23 18:06:29.356869
Epoch: [13][0/10], lr: 0.00050	Time 2.766 (2.766)	Data 2.099 (2.099)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8940], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0645], device='cuda:0', requires_grad=True)
2022-03-23 18:06:37.209444
Epoch: [14][0/10], lr: 0.00050	Time 2.801 (2.801)	Data 2.249 (2.249)	Loss 0.0028 (0.0028)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8942], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0645], device='cuda:0', requires_grad=True)
2022-03-23 18:06:45.452448
Epoch: [15][0/10], lr: 0.00050	Time 2.930 (2.930)	Data 2.273 (2.273)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8945], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0645], device='cuda:0', requires_grad=True)
2022-03-23 18:06:53.727542
Epoch: [16][0/10], lr: 0.00050	Time 3.228 (3.228)	Data 2.655 (2.655)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8946], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0644], device='cuda:0', requires_grad=True)
2022-03-23 18:07:01.822960
Epoch: [17][0/10], lr: 0.00050	Time 3.012 (3.012)	Data 2.124 (2.124)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8945], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0643], device='cuda:0', requires_grad=True)
2022-03-23 18:07:09.691470
Epoch: [18][0/10], lr: 0.00050	Time 2.770 (2.770)	Data 1.889 (1.889)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8941], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0641], device='cuda:0', requires_grad=True)
2022-03-23 18:07:17.584758
Epoch: [19][0/10], lr: 0.00050	Time 2.710 (2.710)	Data 1.937 (1.937)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8940], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0640], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_009.pth.tar
exemplar : 345
Computing the class mean vectors...
Eval Task 0 for Age 9
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.394 (4.394)	Prec@1 56.250 (56.250)
Test: [100/123]	Time 0.364 (0.518)	Prec@1 75.000 (68.936)
Testing Results: Prec@1 68.839
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.557)
Testing Results (NME): Prec@1 75.458
Eval Task 1 for Age 9
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.740 (3.740)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 55.172
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 63.793
Eval Task 2 for Age 9
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.697 (3.697)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 60.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 50.769
Eval Task 3 for Age 9
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.703 (3.703)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 72.500
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 72.500
Eval Task 4 for Age 9
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.852 (3.852)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 74.118
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 69.412
Eval Task 5 for Age 9
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.714 (3.714)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 66.129
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 79.032
Eval Task 6 for Age 9
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.760 (3.760)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 81.481
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 56.790
Eval Task 7 for Age 9
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.494 (3.494)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 94.030
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 80.597
Eval Task 8 for Age 9
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.083 (4.083)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 68.182
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 57.576
Eval Task 9 for Age 9
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.838 (3.838)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 96.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 66.667
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75]
Method : OURS
----AGE 10----
current_task  [0, 88]
current_head  71
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05873670062235365]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=213, sigma=tensor([3.8940]), eta=tensor([3.0640])
  (fc1): CosineLinear(input_features=512, output_features=207, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 190
video number + exemplar : 535
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 190
video number + exemplar : 190
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 18:11:23.971321
Epoch: [0][0/16], lr: 0.00100	Time 3.772 (3.772)	Data 2.605 (2.605)	Loss 0.0994 (0.0994)	Loss CE 0.0345 (0.0345)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6457 (0.6457)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8708], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0508], device='cuda:0', requires_grad=True)
2022-03-23 18:11:40.346556
Epoch: [1][0/16], lr: 0.00100	Time 3.470 (3.470)	Data 1.931 (1.931)	Loss 0.0657 (0.0657)	Loss CE 0.0084 (0.0084)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5692 (0.5692)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8648], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 18:11:56.979858
Epoch: [2][0/16], lr: 0.00100	Time 3.398 (3.398)	Data 2.117 (2.117)	Loss 0.0642 (0.0642)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6098 (0.6098)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8601], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0446], device='cuda:0', requires_grad=True)
2022-03-23 18:12:13.459518
Epoch: [3][0/16], lr: 0.00100	Time 3.311 (3.311)	Data 2.071 (2.071)	Loss 0.0690 (0.0690)	Loss CE 0.0044 (0.0044)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6407 (0.6407)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8623], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0463], device='cuda:0', requires_grad=True)
2022-03-23 18:12:29.884045
Epoch: [4][0/16], lr: 0.00100	Time 3.409 (3.409)	Data 2.547 (2.547)	Loss 0.0719 (0.0719)	Loss CE 0.0103 (0.0103)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6106 (0.6106)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8592], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0448], device='cuda:0', requires_grad=True)
2022-03-23 18:12:45.703523
Epoch: [5][0/16], lr: 0.00100	Time 3.092 (3.092)	Data 2.146 (2.146)	Loss 0.0674 (0.0674)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6580 (0.6580)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8585], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0444], device='cuda:0', requires_grad=True)
2022-03-23 18:13:00.514036
Epoch: [6][0/16], lr: 0.00100	Time 3.462 (3.462)	Data 2.403 (2.403)	Loss 0.0626 (0.0626)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6021 (0.6021)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0434], device='cuda:0', requires_grad=True)
2022-03-23 18:13:15.342033
Epoch: [7][0/16], lr: 0.00100	Time 3.676 (3.676)	Data 2.780 (2.780)	Loss 0.0679 (0.0679)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6218 (0.6218)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8528], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0411], device='cuda:0', requires_grad=True)
2022-03-23 18:13:29.981978
Epoch: [8][0/16], lr: 0.00100	Time 3.470 (3.470)	Data 2.574 (2.574)	Loss 0.0681 (0.0681)	Loss CE 0.0082 (0.0082)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5930 (0.5930)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8500], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0393], device='cuda:0', requires_grad=True)
2022-03-23 18:13:44.594721
Epoch: [9][0/16], lr: 0.00100	Time 3.266 (3.266)	Data 2.375 (2.375)	Loss 0.0563 (0.0563)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5497 (0.5497)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8488], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0381], device='cuda:0', requires_grad=True)
2022-03-23 18:13:59.406932
Epoch: [10][0/16], lr: 0.00100	Time 3.364 (3.364)	Data 2.449 (2.449)	Loss 0.0858 (0.0858)	Loss CE 0.0265 (0.0265)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5881 (0.5881)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8480], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0376], device='cuda:0', requires_grad=True)
2022-03-23 18:14:14.490835
Epoch: [11][0/16], lr: 0.00100	Time 3.397 (3.397)	Data 2.450 (2.450)	Loss 0.0636 (0.0636)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6037 (0.6037)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8490], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0385], device='cuda:0', requires_grad=True)
2022-03-23 18:14:29.999107
Epoch: [12][0/16], lr: 0.00100	Time 3.447 (3.447)	Data 2.425 (2.425)	Loss 0.0624 (0.0624)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6099 (0.6099)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8503], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0393], device='cuda:0', requires_grad=True)
2022-03-23 18:14:45.182768
Epoch: [13][0/16], lr: 0.00100	Time 3.257 (3.257)	Data 2.052 (2.052)	Loss 0.0631 (0.0631)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5899 (0.5899)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:15:00.448796
Epoch: [14][0/16], lr: 0.00100	Time 3.238 (3.238)	Data 2.097 (2.097)	Loss 0.0638 (0.0638)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6199 (0.6199)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8548], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0423], device='cuda:0', requires_grad=True)
2022-03-23 18:15:16.283306
Epoch: [15][0/16], lr: 0.00100	Time 3.689 (3.689)	Data 2.777 (2.777)	Loss 0.0622 (0.0622)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6107 (0.6107)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0439], device='cuda:0', requires_grad=True)
2022-03-23 18:15:32.029645
Epoch: [16][0/16], lr: 0.00100	Time 3.898 (3.898)	Data 2.787 (2.787)	Loss 0.0836 (0.0836)	Loss CE 0.0185 (0.0185)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6448 (0.6448)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8594], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0449], device='cuda:0', requires_grad=True)
2022-03-23 18:15:47.328653
Epoch: [17][0/16], lr: 0.00100	Time 3.497 (3.497)	Data 2.549 (2.549)	Loss 0.0649 (0.0649)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6227 (0.6227)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8619], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0463], device='cuda:0', requires_grad=True)
2022-03-23 18:16:03.218223
Epoch: [18][0/16], lr: 0.00100	Time 3.811 (3.811)	Data 2.984 (2.984)	Loss 0.0644 (0.0644)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6310 (0.6310)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8628], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0463], device='cuda:0', requires_grad=True)
2022-03-23 18:16:17.912879
Epoch: [19][0/16], lr: 0.00100	Time 3.213 (3.213)	Data 2.030 (2.030)	Loss 0.0633 (0.0633)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6073 (0.6073)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8655], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0476], device='cuda:0', requires_grad=True)
2022-03-23 18:16:32.773421
Epoch: [20][0/16], lr: 0.00010	Time 3.344 (3.344)	Data 2.560 (2.560)	Loss 0.0550 (0.0550)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5425 (0.5425)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8657], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 18:16:47.771870
Epoch: [21][0/16], lr: 0.00010	Time 3.494 (3.494)	Data 2.595 (2.595)	Loss 0.0639 (0.0639)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6089 (0.6089)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8658], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:17:02.371347
Epoch: [22][0/16], lr: 0.00010	Time 3.259 (3.259)	Data 2.347 (2.347)	Loss 0.0611 (0.0611)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6030 (0.6030)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8659], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:17:17.053425
Epoch: [23][0/16], lr: 0.00010	Time 3.123 (3.123)	Data 2.259 (2.259)	Loss 0.0625 (0.0625)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6180 (0.6180)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8658], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:17:32.207382
Epoch: [24][0/16], lr: 0.00010	Time 3.646 (3.646)	Data 2.750 (2.750)	Loss 0.0645 (0.0645)	Loss CE 0.0057 (0.0057)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5818 (0.5818)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8659], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 18:17:47.317053
Epoch: [25][0/16], lr: 0.00010	Time 3.643 (3.643)	Data 2.274 (2.274)	Loss 0.0613 (0.0613)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5648 (0.5648)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8660], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:18:01.916326
Epoch: [26][0/16], lr: 0.00010	Time 3.108 (3.108)	Data 2.398 (2.398)	Loss 0.0610 (0.0610)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5999 (0.5999)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8659], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 18:18:16.737540
Epoch: [27][0/16], lr: 0.00010	Time 3.515 (3.515)	Data 2.694 (2.694)	Loss 0.0640 (0.0640)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6219 (0.6219)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8659], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 18:18:31.586363
Epoch: [28][0/16], lr: 0.00010	Time 3.187 (3.187)	Data 1.992 (1.992)	Loss 0.0651 (0.0651)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6088 (0.6088)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8660], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:18:46.722795
Epoch: [29][0/16], lr: 0.00010	Time 3.524 (3.524)	Data 2.661 (2.661)	Loss 0.0587 (0.0587)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5721 (0.5721)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8661], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:19:01.829019
Epoch: [30][0/16], lr: 0.00001	Time 3.417 (3.417)	Data 2.273 (2.273)	Loss 0.0625 (0.0625)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6051 (0.6051)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8661], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:19:16.856811
Epoch: [31][0/16], lr: 0.00001	Time 3.491 (3.491)	Data 2.682 (2.682)	Loss 0.0727 (0.0727)	Loss CE 0.0105 (0.0105)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6173 (0.6173)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8661], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:19:32.062950
Epoch: [32][0/16], lr: 0.00001	Time 3.352 (3.352)	Data 2.215 (2.215)	Loss 0.0618 (0.0618)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5992 (0.5992)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8661], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:19:47.300906
Epoch: [33][0/16], lr: 0.00001	Time 3.403 (3.403)	Data 2.313 (2.313)	Loss 0.0626 (0.0626)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6097 (0.6097)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:20:02.274398
Epoch: [34][0/16], lr: 0.00001	Time 3.430 (3.430)	Data 2.391 (2.391)	Loss 0.0634 (0.0634)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6255 (0.6255)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:20:17.141686
Epoch: [35][0/16], lr: 0.00001	Time 3.449 (3.449)	Data 2.400 (2.400)	Loss 0.0605 (0.0605)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5884 (0.5884)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:20:31.662723
Epoch: [36][0/16], lr: 0.00001	Time 3.116 (3.116)	Data 2.208 (2.208)	Loss 0.0585 (0.0585)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5698 (0.5698)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:20:46.013879
Epoch: [37][0/16], lr: 0.00001	Time 3.536 (3.536)	Data 2.295 (2.295)	Loss 0.1167 (0.1167)	Loss CE 0.0521 (0.0521)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6398 (0.6398)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:21:02.621407
Epoch: [38][0/16], lr: 0.00001	Time 3.403 (3.403)	Data 2.592 (2.592)	Loss 0.0616 (0.0616)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5715 (0.5715)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:21:19.386796
Epoch: [39][0/16], lr: 0.00001	Time 3.439 (3.439)	Data 2.489 (2.489)	Loss 0.0735 (0.0735)	Loss CE 0.0074 (0.0074)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6559 (0.6559)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:21:35.768410
Epoch: [40][0/16], lr: 0.00001	Time 3.287 (3.287)	Data 2.355 (2.355)	Loss 0.0655 (0.0655)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6410 (0.6410)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:21:52.419909
Epoch: [41][0/16], lr: 0.00001	Time 3.263 (3.263)	Data 2.176 (2.176)	Loss 0.0662 (0.0662)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6437 (0.6437)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:22:08.727390
Epoch: [42][0/16], lr: 0.00001	Time 3.121 (3.121)	Data 1.875 (1.875)	Loss 0.0646 (0.0646)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6322 (0.6322)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:22:25.073317
Epoch: [43][0/16], lr: 0.00001	Time 3.302 (3.302)	Data 1.993 (1.993)	Loss 0.0616 (0.0616)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6082 (0.6082)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:22:41.454912
Epoch: [44][0/16], lr: 0.00001	Time 3.542 (3.542)	Data 2.281 (2.281)	Loss 0.0612 (0.0612)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6000 (0.6000)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:22:57.685592
Epoch: [45][0/16], lr: 0.00001	Time 3.183 (3.183)	Data 2.406 (2.406)	Loss 0.0649 (0.0649)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6208 (0.6208)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:23:14.260689
Epoch: [46][0/16], lr: 0.00001	Time 3.273 (3.273)	Data 2.091 (2.091)	Loss 0.0601 (0.0601)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5885 (0.5885)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 18:23:30.762515
Epoch: [47][0/16], lr: 0.00001	Time 3.165 (3.165)	Data 1.930 (1.930)	Loss 0.0757 (0.0757)	Loss CE 0.0121 (0.0121)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6304 (0.6304)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8663], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0479], device='cuda:0', requires_grad=True)
2022-03-23 18:23:47.094309
Epoch: [48][0/16], lr: 0.00001	Time 3.191 (3.191)	Data 2.412 (2.412)	Loss 0.0594 (0.0594)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5843 (0.5843)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8663], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0479], device='cuda:0', requires_grad=True)
2022-03-23 18:24:03.392619
Epoch: [49][0/16], lr: 0.00001	Time 3.277 (3.277)	Data 2.369 (2.369)	Loss 0.0660 (0.0660)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6517 (0.6517)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8663], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0479], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=213, sigma=tensor([3.8663]), eta=tensor([3.0479])
  (fc1): CosineLinear(input_features=512, output_features=207, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 190
video number + exemplar : 190
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=213, sigma=tensor([3.8663]), eta=tensor([3.0479])
  (fc1): CosineLinear(input_features=512, output_features=207, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 355
DataLoader CBF Constructed : Train 11
Optimizer Constructed
2022-03-23 18:24:35.140804
Epoch: [0][0/11], lr: 0.00050	Time 2.654 (2.654)	Data 1.717 (1.717)	Loss 0.0172 (0.0172)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8668], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0481], device='cuda:0', requires_grad=True)
2022-03-23 18:24:43.289119
Epoch: [1][0/11], lr: 0.00050	Time 2.613 (2.613)	Data 1.823 (1.823)	Loss 0.0041 (0.0041)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8676], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 18:24:51.895277
Epoch: [2][0/11], lr: 0.00050	Time 2.984 (2.984)	Data 2.071 (2.071)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8685], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0487], device='cuda:0', requires_grad=True)
2022-03-23 18:25:00.560870
Epoch: [3][0/11], lr: 0.00050	Time 3.069 (3.069)	Data 2.298 (2.298)	Loss 0.0085 (0.0085)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8695], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0492], device='cuda:0', requires_grad=True)
2022-03-23 18:25:09.267485
Epoch: [4][0/11], lr: 0.00050	Time 2.855 (2.855)	Data 2.065 (2.065)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8704], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0495], device='cuda:0', requires_grad=True)
2022-03-23 18:25:17.755272
Epoch: [5][0/11], lr: 0.00050	Time 2.897 (2.897)	Data 2.246 (2.246)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8708], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0496], device='cuda:0', requires_grad=True)
2022-03-23 18:25:26.441921
Epoch: [6][0/11], lr: 0.00050	Time 3.116 (3.116)	Data 1.970 (1.970)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8710], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0496], device='cuda:0', requires_grad=True)
2022-03-23 18:25:35.240721
Epoch: [7][0/11], lr: 0.00050	Time 3.156 (3.156)	Data 2.224 (2.224)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8715], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0497], device='cuda:0', requires_grad=True)
2022-03-23 18:25:43.401532
Epoch: [8][0/11], lr: 0.00050	Time 2.854 (2.854)	Data 1.927 (1.927)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8720], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0501], device='cuda:0', requires_grad=True)
2022-03-23 18:25:52.077844
Epoch: [9][0/11], lr: 0.00050	Time 2.909 (2.909)	Data 1.830 (1.830)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8727], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0505], device='cuda:0', requires_grad=True)
2022-03-23 18:26:00.433248
Epoch: [10][0/11], lr: 0.00050	Time 2.813 (2.813)	Data 1.992 (1.992)	Loss 0.0036 (0.0036)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8731], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0507], device='cuda:0', requires_grad=True)
2022-03-23 18:26:08.945817
Epoch: [11][0/11], lr: 0.00050	Time 2.952 (2.952)	Data 1.944 (1.944)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8730], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0505], device='cuda:0', requires_grad=True)
2022-03-23 18:26:17.558812
Epoch: [12][0/11], lr: 0.00050	Time 3.013 (3.013)	Data 2.110 (2.110)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8729], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0502], device='cuda:0', requires_grad=True)
2022-03-23 18:26:26.057966
Epoch: [13][0/11], lr: 0.00050	Time 3.086 (3.086)	Data 2.268 (2.268)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8730], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0502], device='cuda:0', requires_grad=True)
2022-03-23 18:26:34.508671
Epoch: [14][0/11], lr: 0.00050	Time 2.917 (2.917)	Data 1.932 (1.932)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8730], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0501], device='cuda:0', requires_grad=True)
2022-03-23 18:26:42.676826
Epoch: [15][0/11], lr: 0.00050	Time 2.612 (2.612)	Data 1.816 (1.816)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8726], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0498], device='cuda:0', requires_grad=True)
2022-03-23 18:26:51.490182
Epoch: [16][0/11], lr: 0.00050	Time 3.024 (3.024)	Data 2.192 (2.192)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8721], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0495], device='cuda:0', requires_grad=True)
2022-03-23 18:26:59.944701
Epoch: [17][0/11], lr: 0.00050	Time 3.029 (3.029)	Data 2.530 (2.530)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8719], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0493], device='cuda:0', requires_grad=True)
2022-03-23 18:27:08.596674
Epoch: [18][0/11], lr: 0.00050	Time 2.837 (2.837)	Data 2.335 (2.335)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8722], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0493], device='cuda:0', requires_grad=True)
2022-03-23 18:27:17.188528
Epoch: [19][0/11], lr: 0.00050	Time 2.950 (2.950)	Data 2.091 (2.091)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8728], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0495], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_010.pth.tar
exemplar : 355
Computing the class mean vectors...
Eval Task 0 for Age 10
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.915 (4.915)	Prec@1 68.750 (68.750)
Test: [100/123]	Time 0.401 (0.524)	Prec@1 62.500 (69.183)
Testing Results: Prec@1 69.552
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 68.750 (75.371)
Testing Results (NME): Prec@1 74.949
Eval Task 1 for Age 10
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.796 (3.796)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 60.345
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 70.690
Eval Task 2 for Age 10
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.745 (3.745)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 61.538
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 49.231
Eval Task 3 for Age 10
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.705 (3.705)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 76.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 75.000
Eval Task 4 for Age 10
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.766 (3.766)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 72.941
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 71.765
Eval Task 5 for Age 10
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.669 (3.669)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 79.032
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 70.968
Eval Task 6 for Age 10
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.048 (4.048)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 80.247
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 50.617
Eval Task 7 for Age 10
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.852 (3.852)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.537
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 80.597
Eval Task 8 for Age 10
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.505 (3.505)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 59.091
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 59.091
Eval Task 9 for Age 10
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.852 (3.852)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 77.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 50.667
Eval Task 10 for Age 10
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.969 (3.969)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.837
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 94.186
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86]
Method : OURS
----AGE 11----
current_task  [27, 18]
current_head  73
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05958187643906492]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=219, sigma=tensor([3.8728]), eta=tensor([3.0495])
  (fc1): CosineLinear(input_features=512, output_features=213, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 150
video number + exemplar : 505
DataLoader Constructed : Train 15
Optimizer Constructed
video number : 150
video number + exemplar : 150
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-23 18:31:36.959399
Epoch: [0][0/15], lr: 0.00100	Time 3.601 (3.601)	Data 2.481 (2.481)	Loss 0.0710 (0.0710)	Loss CE 0.0121 (0.0121)	Loss KD (Logit) 0.0365 (0.0365)	Loss KD (GCAM) 0.0086 (0.0086)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5418 (0.5418)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.8635], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0442], device='cuda:0', requires_grad=True)
2022-03-23 18:31:52.295636
Epoch: [1][0/15], lr: 0.00100	Time 3.192 (3.192)	Data 2.302 (2.302)	Loss 0.0701 (0.0701)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.0363 (0.0363)	Loss KD (GCAM) 0.0136 (0.0136)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5929 (0.5929)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0403], device='cuda:0', requires_grad=True)
2022-03-23 18:32:07.866217
Epoch: [2][0/15], lr: 0.00100	Time 3.466 (3.466)	Data 2.351 (2.351)	Loss 0.0699 (0.0699)	Loss CE 0.0100 (0.0100)	Loss KD (Logit) 0.0382 (0.0382)	Loss KD (GCAM) 0.0114 (0.0114)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5419 (0.5419)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8544], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0390], device='cuda:0', requires_grad=True)
2022-03-23 18:32:22.878923
Epoch: [3][0/15], lr: 0.00100	Time 3.071 (3.071)	Data 2.272 (2.272)	Loss 0.0708 (0.0708)	Loss CE 0.0085 (0.0085)	Loss KD (Logit) 0.0378 (0.0378)	Loss KD (GCAM) 0.0115 (0.0115)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5661 (0.5661)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8505], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0363], device='cuda:0', requires_grad=True)
2022-03-23 18:32:36.979375
Epoch: [4][0/15], lr: 0.00100	Time 3.388 (3.388)	Data 2.480 (2.480)	Loss 0.0705 (0.0705)	Loss CE 0.0052 (0.0052)	Loss KD (Logit) 0.0370 (0.0370)	Loss KD (GCAM) 0.0149 (0.0149)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5863 (0.5863)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8491], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0356], device='cuda:0', requires_grad=True)
2022-03-23 18:32:51.303227
Epoch: [5][0/15], lr: 0.00100	Time 3.492 (3.492)	Data 2.743 (2.743)	Loss 0.0769 (0.0769)	Loss CE 0.0126 (0.0126)	Loss KD (Logit) 0.0379 (0.0379)	Loss KD (GCAM) 0.0166 (0.0166)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5704 (0.5704)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8468], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0341], device='cuda:0', requires_grad=True)
2022-03-23 18:33:04.917234
Epoch: [6][0/15], lr: 0.00100	Time 3.093 (3.093)	Data 1.933 (1.933)	Loss 0.0738 (0.0738)	Loss CE 0.0089 (0.0089)	Loss KD (Logit) 0.0371 (0.0371)	Loss KD (GCAM) 0.0151 (0.0151)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5813 (0.5813)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0335], device='cuda:0', requires_grad=True)
2022-03-23 18:33:18.879887
Epoch: [7][0/15], lr: 0.00100	Time 3.206 (3.206)	Data 1.919 (1.919)	Loss 0.1019 (0.1019)	Loss CE 0.0383 (0.0383)	Loss KD (Logit) 0.0371 (0.0371)	Loss KD (GCAM) 0.0147 (0.0147)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5702 (0.5702)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8465], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0341], device='cuda:0', requires_grad=True)
2022-03-23 18:33:33.012442
Epoch: [8][0/15], lr: 0.00100	Time 3.215 (3.215)	Data 2.268 (2.268)	Loss 0.0661 (0.0661)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0386 (0.0386)	Loss KD (GCAM) 0.0138 (0.0138)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5688 (0.5688)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8472], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0348], device='cuda:0', requires_grad=True)
2022-03-23 18:33:47.591654
Epoch: [9][0/15], lr: 0.00100	Time 3.325 (3.325)	Data 2.326 (2.326)	Loss 0.0706 (0.0706)	Loss CE 0.0071 (0.0071)	Loss KD (Logit) 0.0374 (0.0374)	Loss KD (GCAM) 0.0151 (0.0151)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5673 (0.5673)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8492], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0363], device='cuda:0', requires_grad=True)
2022-03-23 18:34:02.204343
Epoch: [10][0/15], lr: 0.00100	Time 3.242 (3.242)	Data 2.544 (2.544)	Loss 0.1091 (0.1091)	Loss CE 0.0447 (0.0447)	Loss KD (Logit) 0.0385 (0.0385)	Loss KD (GCAM) 0.0150 (0.0150)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5765 (0.5765)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0373], device='cuda:0', requires_grad=True)
2022-03-23 18:34:17.114330
Epoch: [11][0/15], lr: 0.00100	Time 3.440 (3.440)	Data 2.547 (2.547)	Loss 0.0670 (0.0670)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0392 (0.0392)	Loss KD (GCAM) 0.0142 (0.0142)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5909 (0.5909)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8525], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0383], device='cuda:0', requires_grad=True)
2022-03-23 18:34:31.504603
Epoch: [12][0/15], lr: 0.00100	Time 3.144 (3.144)	Data 2.099 (2.099)	Loss 0.0676 (0.0676)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0392 (0.0392)	Loss KD (GCAM) 0.0130 (0.0130)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5832 (0.5832)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8520], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0376], device='cuda:0', requires_grad=True)
2022-03-23 18:34:46.078204
Epoch: [13][0/15], lr: 0.00100	Time 3.314 (3.314)	Data 2.425 (2.425)	Loss 0.0686 (0.0686)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0385 (0.0385)	Loss KD (GCAM) 0.0140 (0.0140)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5821 (0.5821)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 18:35:00.523622
Epoch: [14][0/15], lr: 0.00100	Time 3.252 (3.252)	Data 2.186 (2.186)	Loss 0.0647 (0.0647)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0380 (0.0380)	Loss KD (GCAM) 0.0143 (0.0143)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5689 (0.5689)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8499], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0365], device='cuda:0', requires_grad=True)
2022-03-23 18:35:15.333972
Epoch: [15][0/15], lr: 0.00100	Time 3.500 (3.500)	Data 2.446 (2.446)	Loss 0.0710 (0.0710)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0400 (0.0400)	Loss KD (GCAM) 0.0152 (0.0152)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5899 (0.5899)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8510], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0372], device='cuda:0', requires_grad=True)
2022-03-23 18:35:30.250259
Epoch: [16][0/15], lr: 0.00100	Time 3.631 (3.631)	Data 2.355 (2.355)	Loss 0.0787 (0.0787)	Loss CE 0.0161 (0.0161)	Loss KD (Logit) 0.0395 (0.0395)	Loss KD (GCAM) 0.0147 (0.0147)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5581 (0.5581)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8526], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0381], device='cuda:0', requires_grad=True)
2022-03-23 18:35:44.796518
Epoch: [17][0/15], lr: 0.00100	Time 3.202 (3.202)	Data 2.191 (2.191)	Loss 0.0650 (0.0650)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0385 (0.0385)	Loss KD (GCAM) 0.0134 (0.0134)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5584 (0.5584)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8541], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0389], device='cuda:0', requires_grad=True)
2022-03-23 18:35:59.203820
Epoch: [18][0/15], lr: 0.00100	Time 3.403 (3.403)	Data 2.168 (2.168)	Loss 0.0780 (0.0780)	Loss CE 0.0127 (0.0127)	Loss KD (Logit) 0.0387 (0.0387)	Loss KD (GCAM) 0.0141 (0.0141)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5878 (0.5878)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0395], device='cuda:0', requires_grad=True)
2022-03-23 18:36:13.609870
Epoch: [19][0/15], lr: 0.00100	Time 3.508 (3.508)	Data 2.318 (2.318)	Loss 0.0746 (0.0746)	Loss CE 0.0106 (0.0106)	Loss KD (Logit) 0.0389 (0.0389)	Loss KD (GCAM) 0.0153 (0.0153)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5711 (0.5711)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8560], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 18:36:27.727323
Epoch: [20][0/15], lr: 0.00010	Time 3.038 (3.038)	Data 1.900 (1.900)	Loss 0.0646 (0.0646)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0397 (0.0397)	Loss KD (GCAM) 0.0150 (0.0150)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5635 (0.5635)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0401], device='cuda:0', requires_grad=True)
2022-03-23 18:36:41.721985
Epoch: [21][0/15], lr: 0.00010	Time 3.214 (3.214)	Data 2.292 (2.292)	Loss 0.0656 (0.0656)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0386 (0.0386)	Loss KD (GCAM) 0.0151 (0.0151)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5799 (0.5799)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8565], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0402], device='cuda:0', requires_grad=True)
2022-03-23 18:36:55.707158
Epoch: [22][0/15], lr: 0.00010	Time 3.268 (3.268)	Data 2.150 (2.150)	Loss 0.0681 (0.0681)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0378 (0.0378)	Loss KD (GCAM) 0.0160 (0.0160)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5609 (0.5609)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8567], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0404], device='cuda:0', requires_grad=True)
2022-03-23 18:37:09.883561
Epoch: [23][0/15], lr: 0.00010	Time 3.442 (3.442)	Data 2.348 (2.348)	Loss 0.1254 (0.1254)	Loss CE 0.0600 (0.0600)	Loss KD (Logit) 0.0388 (0.0388)	Loss KD (GCAM) 0.0148 (0.0148)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5864 (0.5864)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8566], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0403], device='cuda:0', requires_grad=True)
2022-03-23 18:37:24.128873
Epoch: [24][0/15], lr: 0.00010	Time 3.452 (3.452)	Data 2.454 (2.454)	Loss 0.0680 (0.0680)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 0.0388 (0.0388)	Loss KD (GCAM) 0.0133 (0.0133)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5497 (0.5497)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8567], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0403], device='cuda:0', requires_grad=True)
2022-03-23 18:37:38.432679
Epoch: [25][0/15], lr: 0.00010	Time 3.364 (3.364)	Data 2.107 (2.107)	Loss 0.0636 (0.0636)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0400 (0.0400)	Loss KD (GCAM) 0.0136 (0.0136)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5672 (0.5672)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0404], device='cuda:0', requires_grad=True)
2022-03-23 18:37:52.641774
Epoch: [26][0/15], lr: 0.00010	Time 3.308 (3.308)	Data 2.209 (2.209)	Loss 0.1391 (0.1391)	Loss CE 0.0777 (0.0777)	Loss KD (Logit) 0.0372 (0.0372)	Loss KD (GCAM) 0.0129 (0.0129)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5530 (0.5530)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0404], device='cuda:0', requires_grad=True)
2022-03-23 18:38:06.985892
Epoch: [27][0/15], lr: 0.00010	Time 3.355 (3.355)	Data 2.205 (2.205)	Loss 0.0666 (0.0666)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0380 (0.0380)	Loss KD (GCAM) 0.0143 (0.0143)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5988 (0.5988)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8571], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:38:21.581697
Epoch: [28][0/15], lr: 0.00010	Time 3.331 (3.331)	Data 2.573 (2.573)	Loss 0.0682 (0.0682)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0375 (0.0375)	Loss KD (GCAM) 0.0126 (0.0126)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6113 (0.6113)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:38:35.645787
Epoch: [29][0/15], lr: 0.00010	Time 3.377 (3.377)	Data 2.556 (2.556)	Loss 0.0664 (0.0664)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0398 (0.0398)	Loss KD (GCAM) 0.0132 (0.0132)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5921 (0.5921)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:38:49.715102
Epoch: [30][0/15], lr: 0.00001	Time 3.388 (3.388)	Data 2.239 (2.239)	Loss 0.0671 (0.0671)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0390 (0.0390)	Loss KD (GCAM) 0.0135 (0.0135)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5979 (0.5979)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:39:03.944439
Epoch: [31][0/15], lr: 0.00001	Time 3.377 (3.377)	Data 2.296 (2.296)	Loss 0.0659 (0.0659)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0372 (0.0372)	Loss KD (GCAM) 0.0133 (0.0133)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5896 (0.5896)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:39:18.202913
Epoch: [32][0/15], lr: 0.00001	Time 3.425 (3.425)	Data 2.215 (2.215)	Loss 0.0724 (0.0724)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0373 (0.0373)	Loss KD (GCAM) 0.0133 (0.0133)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6070 (0.6070)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:39:32.370782
Epoch: [33][0/15], lr: 0.00001	Time 3.382 (3.382)	Data 2.542 (2.542)	Loss 0.0674 (0.0674)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0392 (0.0392)	Loss KD (GCAM) 0.0136 (0.0136)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5718 (0.5718)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:39:46.447419
Epoch: [34][0/15], lr: 0.00001	Time 3.494 (3.494)	Data 2.485 (2.485)	Loss 0.0619 (0.0619)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0379 (0.0379)	Loss KD (GCAM) 0.0154 (0.0154)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5403 (0.5403)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:40:00.357231
Epoch: [35][0/15], lr: 0.00001	Time 3.285 (3.285)	Data 2.348 (2.348)	Loss 0.0673 (0.0673)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0397 (0.0397)	Loss KD (GCAM) 0.0149 (0.0149)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6015 (0.6015)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:40:13.996612
Epoch: [36][0/15], lr: 0.00001	Time 3.128 (3.128)	Data 2.175 (2.175)	Loss 0.0659 (0.0659)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0380 (0.0380)	Loss KD (GCAM) 0.0138 (0.0138)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5904 (0.5904)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:40:29.435923
Epoch: [37][0/15], lr: 0.00001	Time 4.020 (4.020)	Data 3.192 (3.192)	Loss 0.0636 (0.0636)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0385 (0.0385)	Loss KD (GCAM) 0.0133 (0.0133)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5720 (0.5720)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:40:44.934871
Epoch: [38][0/15], lr: 0.00001	Time 3.290 (3.290)	Data 2.335 (2.335)	Loss 0.0630 (0.0630)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0387 (0.0387)	Loss KD (GCAM) 0.0147 (0.0147)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5422 (0.5422)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 18:41:01.002161
Epoch: [39][0/15], lr: 0.00001	Time 3.263 (3.263)	Data 2.189 (2.189)	Loss 0.0685 (0.0685)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0390 (0.0390)	Loss KD (GCAM) 0.0144 (0.0144)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6119 (0.6119)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:41:16.302828
Epoch: [40][0/15], lr: 0.00001	Time 3.267 (3.267)	Data 1.929 (1.929)	Loss 0.0634 (0.0634)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0385 (0.0385)	Loss KD (GCAM) 0.0130 (0.0130)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5634 (0.5634)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:41:31.529050
Epoch: [41][0/15], lr: 0.00001	Time 3.307 (3.307)	Data 2.206 (2.206)	Loss 0.0630 (0.0630)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0380 (0.0380)	Loss KD (GCAM) 0.0133 (0.0133)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5589 (0.5589)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:41:46.873403
Epoch: [42][0/15], lr: 0.00001	Time 3.309 (3.309)	Data 2.155 (2.155)	Loss 0.0669 (0.0669)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0394 (0.0394)	Loss KD (GCAM) 0.0132 (0.0132)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5707 (0.5707)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:42:03.020639
Epoch: [43][0/15], lr: 0.00001	Time 3.196 (3.196)	Data 2.450 (2.450)	Loss 0.0666 (0.0666)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0369 (0.0369)	Loss KD (GCAM) 0.0123 (0.0123)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6029 (0.6029)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:42:19.050744
Epoch: [44][0/15], lr: 0.00001	Time 3.430 (3.430)	Data 2.199 (2.199)	Loss 0.0634 (0.0634)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0381 (0.0381)	Loss KD (GCAM) 0.0136 (0.0136)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5661 (0.5661)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:42:34.388798
Epoch: [45][0/15], lr: 0.00001	Time 3.287 (3.287)	Data 2.262 (2.262)	Loss 0.0659 (0.0659)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0383 (0.0383)	Loss KD (GCAM) 0.0148 (0.0148)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5690 (0.5690)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:42:50.496391
Epoch: [46][0/15], lr: 0.00001	Time 3.343 (3.343)	Data 2.507 (2.507)	Loss 0.0645 (0.0645)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0387 (0.0387)	Loss KD (GCAM) 0.0141 (0.0141)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5745 (0.5745)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:43:06.040632
Epoch: [47][0/15], lr: 0.00001	Time 3.311 (3.311)	Data 2.278 (2.278)	Loss 0.0748 (0.0748)	Loss CE 0.0076 (0.0076)	Loss KD (Logit) 0.0382 (0.0382)	Loss KD (GCAM) 0.0134 (0.0134)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6099 (0.6099)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:43:21.794318
Epoch: [48][0/15], lr: 0.00001	Time 3.250 (3.250)	Data 1.960 (1.960)	Loss 0.0787 (0.0787)	Loss CE 0.0148 (0.0148)	Loss KD (Logit) 0.0392 (0.0392)	Loss KD (GCAM) 0.0153 (0.0153)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5699 (0.5699)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
2022-03-23 18:43:37.690313
Epoch: [49][0/15], lr: 0.00001	Time 3.569 (3.569)	Data 2.179 (2.179)	Loss 0.0635 (0.0635)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0369 (0.0369)	Loss KD (GCAM) 0.0132 (0.0132)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5710 (0.5710)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0406], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=219, sigma=tensor([3.8574]), eta=tensor([3.0406])
  (fc1): CosineLinear(input_features=512, output_features=213, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 150
video number + exemplar : 150
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=219, sigma=tensor([3.8574]), eta=tensor([3.0406])
  (fc1): CosineLinear(input_features=512, output_features=213, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 365
DataLoader CBF Constructed : Train 11
Optimizer Constructed
2022-03-23 18:44:07.779534
Epoch: [0][0/11], lr: 0.00050	Time 2.807 (2.807)	Data 1.997 (1.997)	Loss 0.0593 (0.0593)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8567], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0402], device='cuda:0', requires_grad=True)
2022-03-23 18:44:16.684414
Epoch: [1][0/11], lr: 0.00050	Time 3.096 (3.096)	Data 1.963 (1.963)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8565], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 18:44:25.442428
Epoch: [2][0/11], lr: 0.00050	Time 2.991 (2.991)	Data 2.036 (2.036)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0404], device='cuda:0', requires_grad=True)
2022-03-23 18:44:33.896869
Epoch: [3][0/11], lr: 0.00050	Time 2.951 (2.951)	Data 2.418 (2.418)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0409], device='cuda:0', requires_grad=True)
2022-03-23 18:44:42.282125
Epoch: [4][0/11], lr: 0.00050	Time 2.850 (2.850)	Data 2.361 (2.361)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8589], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0412], device='cuda:0', requires_grad=True)
2022-03-23 18:44:50.895784
Epoch: [5][0/11], lr: 0.00050	Time 3.030 (3.030)	Data 2.395 (2.395)	Loss 0.0038 (0.0038)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0416], device='cuda:0', requires_grad=True)
2022-03-23 18:44:59.632333
Epoch: [6][0/11], lr: 0.00050	Time 3.147 (3.147)	Data 2.049 (2.049)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8604], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0418], device='cuda:0', requires_grad=True)
2022-03-23 18:45:07.937455
Epoch: [7][0/11], lr: 0.00050	Time 2.738 (2.738)	Data 1.858 (1.858)	Loss 0.0035 (0.0035)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8607], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0417], device='cuda:0', requires_grad=True)
2022-03-23 18:45:16.658006
Epoch: [8][0/11], lr: 0.00050	Time 2.979 (2.979)	Data 2.328 (2.328)	Loss 0.0063 (0.0063)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8613], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0420], device='cuda:0', requires_grad=True)
2022-03-23 18:45:25.351167
Epoch: [9][0/11], lr: 0.00050	Time 3.045 (3.045)	Data 1.937 (1.937)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8618], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0421], device='cuda:0', requires_grad=True)
2022-03-23 18:45:33.743274
Epoch: [10][0/11], lr: 0.00050	Time 2.772 (2.772)	Data 1.895 (1.895)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8623], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0423], device='cuda:0', requires_grad=True)
2022-03-23 18:45:42.273235
Epoch: [11][0/11], lr: 0.00050	Time 2.949 (2.949)	Data 1.955 (1.955)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8628], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0424], device='cuda:0', requires_grad=True)
2022-03-23 18:45:50.970233
Epoch: [12][0/11], lr: 0.00050	Time 3.117 (3.117)	Data 2.047 (2.047)	Loss 0.0298 (0.0298)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8635], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0426], device='cuda:0', requires_grad=True)
2022-03-23 18:45:59.731065
Epoch: [13][0/11], lr: 0.00050	Time 3.254 (3.254)	Data 2.059 (2.059)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8641], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0428], device='cuda:0', requires_grad=True)
2022-03-23 18:46:08.388120
Epoch: [14][0/11], lr: 0.00050	Time 3.028 (3.028)	Data 2.547 (2.547)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8645], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0429], device='cuda:0', requires_grad=True)
2022-03-23 18:46:16.870288
Epoch: [15][0/11], lr: 0.00050	Time 2.795 (2.795)	Data 2.186 (2.186)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8648], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0430], device='cuda:0', requires_grad=True)
2022-03-23 18:46:25.206770
Epoch: [16][0/11], lr: 0.00050	Time 2.876 (2.876)	Data 2.197 (2.197)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8651], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0431], device='cuda:0', requires_grad=True)
2022-03-23 18:46:33.682118
Epoch: [17][0/11], lr: 0.00050	Time 2.899 (2.899)	Data 2.313 (2.313)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8656], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0433], device='cuda:0', requires_grad=True)
2022-03-23 18:46:42.398216
Epoch: [18][0/11], lr: 0.00050	Time 3.090 (3.090)	Data 2.199 (2.199)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8659], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0435], device='cuda:0', requires_grad=True)
2022-03-23 18:46:51.171168
Epoch: [19][0/11], lr: 0.00050	Time 2.993 (2.993)	Data 1.840 (1.840)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8648], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0427], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_011.pth.tar
exemplar : 365
Computing the class mean vectors...
Eval Task 0 for Age 11
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.532 (4.532)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.575 (0.521)	Prec@1 68.750 (69.802)
Testing Results: Prec@1 69.348
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 81.250 (76.238)
Testing Results (NME): Prec@1 75.560
Eval Task 1 for Age 11
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.506 (3.506)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 65.517
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 72.414
Eval Task 2 for Age 11
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.701 (3.701)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 47.692
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 53.846
Eval Task 3 for Age 11
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.175 (4.175)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 78.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 77.500
Eval Task 4 for Age 11
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.086 (4.086)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 76.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 68.235
Eval Task 5 for Age 11
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.584 (3.584)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 69.355
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 62.903
Eval Task 6 for Age 11
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.959 (3.959)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 77.778
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 50.617
Eval Task 7 for Age 11
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.610 (3.610)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 94.030
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 80.597
Eval Task 8 for Age 11
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.876 (3.876)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 53.030
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 56.061
Eval Task 9 for Age 11
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.817 (3.817)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 76.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 56.000
Eval Task 10 for Age 11
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.068 (4.068)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 93.023
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 95.349
Eval Task 11 for Age 11
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.681 (3.681)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 79.032
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62]
Method : OURS
----AGE 12----
current_task  [94, 11]
current_head  75
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06041522986797286]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=225, sigma=tensor([3.8648]), eta=tensor([3.0427])
  (fc1): CosineLinear(input_features=512, output_features=219, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 203
video number + exemplar : 568
DataLoader Constructed : Train 17
Optimizer Constructed
video number : 203
video number + exemplar : 203
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 18:51:21.383760
Epoch: [0][0/17], lr: 0.00100	Time 3.587 (3.587)	Data 2.577 (2.577)	Loss 0.1892 (0.1892)	Loss CE 0.1218 (0.1218)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6694 (0.6694)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8635], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0422], device='cuda:0', requires_grad=True)
2022-03-23 18:51:38.275811
Epoch: [1][0/17], lr: 0.00100	Time 3.251 (3.251)	Data 2.108 (2.108)	Loss 0.0678 (0.0678)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6452 (0.6452)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8654], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0432], device='cuda:0', requires_grad=True)
2022-03-23 18:51:56.005360
Epoch: [2][0/17], lr: 0.00100	Time 3.748 (3.748)	Data 2.799 (2.799)	Loss 0.0657 (0.0657)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6435 (0.6435)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8672], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0442], device='cuda:0', requires_grad=True)
2022-03-23 18:52:12.561044
Epoch: [3][0/17], lr: 0.00100	Time 3.544 (3.544)	Data 2.671 (2.671)	Loss 0.0734 (0.0734)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7091 (0.7091)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8711], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0462], device='cuda:0', requires_grad=True)
2022-03-23 18:52:27.969293
Epoch: [4][0/17], lr: 0.00100	Time 3.343 (3.343)	Data 2.530 (2.530)	Loss 0.0685 (0.0685)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6283 (0.6283)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8735], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0473], device='cuda:0', requires_grad=True)
2022-03-23 18:52:43.145582
Epoch: [5][0/17], lr: 0.00100	Time 3.254 (3.254)	Data 2.013 (2.013)	Loss 0.0665 (0.0665)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6507 (0.6507)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8751], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0480], device='cuda:0', requires_grad=True)
2022-03-23 18:52:58.635792
Epoch: [6][0/17], lr: 0.00100	Time 3.199 (3.199)	Data 1.885 (1.885)	Loss 0.0617 (0.0617)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6059 (0.6059)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8751], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0480], device='cuda:0', requires_grad=True)
2022-03-23 18:53:14.278582
Epoch: [7][0/17], lr: 0.00100	Time 3.337 (3.337)	Data 2.321 (2.321)	Loss 0.0604 (0.0604)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5971 (0.5971)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8759], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0483], device='cuda:0', requires_grad=True)
2022-03-23 18:53:30.362977
Epoch: [8][0/17], lr: 0.00100	Time 3.492 (3.492)	Data 2.586 (2.586)	Loss 0.0724 (0.0724)	Loss CE 0.0099 (0.0099)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6185 (0.6185)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8767], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 18:53:46.901085
Epoch: [9][0/17], lr: 0.00100	Time 3.730 (3.730)	Data 2.533 (2.533)	Loss 0.1897 (0.1897)	Loss CE 0.1257 (0.1257)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6341 (0.6341)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8746], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0467], device='cuda:0', requires_grad=True)
2022-03-23 18:54:03.290089
Epoch: [10][0/17], lr: 0.00100	Time 3.718 (3.718)	Data 2.931 (2.931)	Loss 0.0635 (0.0635)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6130 (0.6130)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8723], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0448], device='cuda:0', requires_grad=True)
2022-03-23 18:54:19.670230
Epoch: [11][0/17], lr: 0.00100	Time 3.414 (3.414)	Data 2.539 (2.539)	Loss 0.0734 (0.0734)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6589 (0.6589)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8724], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0448], device='cuda:0', requires_grad=True)
2022-03-23 18:54:35.617065
Epoch: [12][0/17], lr: 0.00100	Time 3.258 (3.258)	Data 2.054 (2.054)	Loss 0.0658 (0.0658)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6463 (0.6463)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8737], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0453], device='cuda:0', requires_grad=True)
2022-03-23 18:54:51.917103
Epoch: [13][0/17], lr: 0.00100	Time 3.577 (3.577)	Data 2.805 (2.805)	Loss 0.1399 (0.1399)	Loss CE 0.0774 (0.0774)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6182 (0.6182)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8742], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 18:55:08.395546
Epoch: [14][0/17], lr: 0.00100	Time 3.676 (3.676)	Data 2.629 (2.629)	Loss 0.0646 (0.0646)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0020 (0.0020)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6273 (0.6273)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8737], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0449], device='cuda:0', requires_grad=True)
2022-03-23 18:55:24.291916
Epoch: [15][0/17], lr: 0.00100	Time 3.081 (3.081)	Data 1.942 (1.942)	Loss 0.0639 (0.0639)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0019 (0.0019)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6300 (0.6300)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8732], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0446], device='cuda:0', requires_grad=True)
2022-03-23 18:55:39.831202
Epoch: [16][0/17], lr: 0.00100	Time 3.304 (3.304)	Data 2.489 (2.489)	Loss 0.0738 (0.0738)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7230 (0.7230)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8745], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0453], device='cuda:0', requires_grad=True)
2022-03-23 18:55:55.589589
Epoch: [17][0/17], lr: 0.00100	Time 3.301 (3.301)	Data 2.119 (2.119)	Loss 0.0672 (0.0672)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6551 (0.6551)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8750], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0453], device='cuda:0', requires_grad=True)
2022-03-23 18:56:11.379095
Epoch: [18][0/17], lr: 0.00100	Time 3.390 (3.390)	Data 2.335 (2.335)	Loss 0.0691 (0.0691)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6716 (0.6716)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8752], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0452], device='cuda:0', requires_grad=True)
2022-03-23 18:56:26.845588
Epoch: [19][0/17], lr: 0.00100	Time 3.375 (3.375)	Data 2.403 (2.403)	Loss 0.0697 (0.0697)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6583 (0.6583)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8747], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0446], device='cuda:0', requires_grad=True)
2022-03-23 18:56:42.614081
Epoch: [20][0/17], lr: 0.00010	Time 3.503 (3.503)	Data 2.532 (2.532)	Loss 0.0656 (0.0656)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0020 (0.0020)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6121 (0.6121)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8747], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0445], device='cuda:0', requires_grad=True)
2022-03-23 18:56:58.135741
Epoch: [21][0/17], lr: 0.00010	Time 3.332 (3.332)	Data 2.240 (2.240)	Loss 0.0819 (0.0819)	Loss CE 0.0155 (0.0155)	Loss KD (Logit) 0.0022 (0.0022)	Loss KD (GCAM) 0.0021 (0.0021)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6563 (0.6563)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8750], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0446], device='cuda:0', requires_grad=True)
2022-03-23 18:57:13.871789
Epoch: [22][0/17], lr: 0.00010	Time 3.516 (3.516)	Data 2.591 (2.591)	Loss 0.0707 (0.0707)	Loss CE 0.0064 (0.0064)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6361 (0.6361)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8750], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0447], device='cuda:0', requires_grad=True)
2022-03-23 18:57:29.058923
Epoch: [23][0/17], lr: 0.00010	Time 3.312 (3.312)	Data 2.392 (2.392)	Loss 0.0660 (0.0660)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0022 (0.0022)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6322 (0.6322)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8751], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0447], device='cuda:0', requires_grad=True)
2022-03-23 18:57:44.748096
Epoch: [24][0/17], lr: 0.00010	Time 3.417 (3.417)	Data 2.014 (2.014)	Loss 0.0650 (0.0650)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6389 (0.6389)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8753], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0448], device='cuda:0', requires_grad=True)
2022-03-23 18:58:00.462715
Epoch: [25][0/17], lr: 0.00010	Time 3.361 (3.361)	Data 2.478 (2.478)	Loss 0.0657 (0.0657)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6481 (0.6481)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8754], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0449], device='cuda:0', requires_grad=True)
2022-03-23 18:58:15.964456
Epoch: [26][0/17], lr: 0.00010	Time 3.315 (3.315)	Data 2.364 (2.364)	Loss 0.0668 (0.0668)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0022 (0.0022)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6540 (0.6540)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8756], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0450], device='cuda:0', requires_grad=True)
2022-03-23 18:58:31.614830
Epoch: [27][0/17], lr: 0.00010	Time 3.432 (3.432)	Data 2.401 (2.401)	Loss 0.0661 (0.0661)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6420 (0.6420)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8757], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0450], device='cuda:0', requires_grad=True)
2022-03-23 18:58:47.535449
Epoch: [28][0/17], lr: 0.00010	Time 3.394 (3.394)	Data 2.446 (2.446)	Loss 0.0617 (0.0617)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0022 (0.0022)	Loss KD (GCAM) 0.0020 (0.0020)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5975 (0.5975)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 18:59:03.054587
Epoch: [29][0/17], lr: 0.00010	Time 3.353 (3.353)	Data 2.240 (2.240)	Loss 0.0653 (0.0653)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6390 (0.6390)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8757], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 18:59:18.418595
Epoch: [30][0/17], lr: 0.00001	Time 3.068 (3.068)	Data 1.916 (1.916)	Loss 0.0631 (0.0631)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6053 (0.6053)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 18:59:34.163033
Epoch: [31][0/17], lr: 0.00001	Time 3.437 (3.437)	Data 2.079 (2.079)	Loss 0.0680 (0.0680)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0022 (0.0022)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6701 (0.6701)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 18:59:50.067711
Epoch: [32][0/17], lr: 0.00001	Time 3.344 (3.344)	Data 2.624 (2.624)	Loss 0.0667 (0.0667)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6301 (0.6301)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:00:05.543248
Epoch: [33][0/17], lr: 0.00001	Time 3.646 (3.646)	Data 2.522 (2.522)	Loss 0.0655 (0.0655)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6470 (0.6470)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:00:22.708757
Epoch: [34][0/17], lr: 0.00001	Time 3.478 (3.478)	Data 2.327 (2.327)	Loss 0.0642 (0.0642)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6233 (0.6233)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:00:40.224305
Epoch: [35][0/17], lr: 0.00001	Time 3.497 (3.497)	Data 1.936 (1.936)	Loss 0.0665 (0.0665)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6529 (0.6529)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:00:57.641160
Epoch: [36][0/17], lr: 0.00001	Time 3.340 (3.340)	Data 1.927 (1.927)	Loss 0.0619 (0.0619)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6054 (0.6054)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:01:14.690305
Epoch: [37][0/17], lr: 0.00001	Time 3.227 (3.227)	Data 2.089 (2.089)	Loss 0.0687 (0.0687)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6732 (0.6732)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:01:32.194788
Epoch: [38][0/17], lr: 0.00001	Time 3.368 (3.368)	Data 2.238 (2.238)	Loss 0.0636 (0.0636)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6144 (0.6144)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:01:49.395159
Epoch: [39][0/17], lr: 0.00001	Time 3.419 (3.419)	Data 2.402 (2.402)	Loss 0.0650 (0.0650)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6398 (0.6398)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:02:06.775014
Epoch: [40][0/17], lr: 0.00001	Time 3.187 (3.187)	Data 2.351 (2.351)	Loss 0.0845 (0.0845)	Loss CE 0.0182 (0.0182)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6555 (0.6555)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:02:23.983526
Epoch: [41][0/17], lr: 0.00001	Time 3.356 (3.356)	Data 2.592 (2.592)	Loss 0.0676 (0.0676)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6606 (0.6606)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:02:40.750195
Epoch: [42][0/17], lr: 0.00001	Time 2.898 (2.898)	Data 1.928 (1.928)	Loss 0.0667 (0.0667)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0022 (0.0022)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6423 (0.6423)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:02:58.023937
Epoch: [43][0/17], lr: 0.00001	Time 3.386 (3.386)	Data 2.144 (2.144)	Loss 0.0659 (0.0659)	Loss CE 0.0000 (0.0000)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6522 (0.6522)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:03:15.459378
Epoch: [44][0/17], lr: 0.00001	Time 3.562 (3.562)	Data 2.289 (2.289)	Loss 0.0641 (0.0641)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0020 (0.0020)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6296 (0.6296)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:03:32.934249
Epoch: [45][0/17], lr: 0.00001	Time 3.273 (3.273)	Data 2.294 (2.294)	Loss 0.0641 (0.0641)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6324 (0.6324)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:03:50.029562
Epoch: [46][0/17], lr: 0.00001	Time 3.345 (3.345)	Data 2.207 (2.207)	Loss 0.0672 (0.0672)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6616 (0.6616)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8759], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:04:07.017844
Epoch: [47][0/17], lr: 0.00001	Time 3.299 (3.299)	Data 1.934 (1.934)	Loss 0.0658 (0.0658)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0019 (0.0019)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6304 (0.6304)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8759], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:04:24.530015
Epoch: [48][0/17], lr: 0.00001	Time 3.484 (3.484)	Data 2.423 (2.423)	Loss 0.0608 (0.0608)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0018 (0.0018)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5989 (0.5989)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8759], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
2022-03-23 19:04:41.630641
Epoch: [49][0/17], lr: 0.00001	Time 3.398 (3.398)	Data 2.219 (2.219)	Loss 0.0662 (0.0662)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0021 (0.0021)	Loss KD (GCAM) 0.0017 (0.0017)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6415 (0.6415)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8759], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0451], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=225, sigma=tensor([3.8759]), eta=tensor([3.0451])
  (fc1): CosineLinear(input_features=512, output_features=219, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 203
video number + exemplar : 203
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=225, sigma=tensor([3.8759]), eta=tensor([3.0451])
  (fc1): CosineLinear(input_features=512, output_features=219, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 375
DataLoader CBF Constructed : Train 11
Optimizer Constructed
2022-03-23 19:05:14.252156
Epoch: [0][0/11], lr: 0.00050	Time 2.970 (2.970)	Data 2.297 (2.297)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0450], device='cuda:0', requires_grad=True)
2022-03-23 19:05:22.878324
Epoch: [1][0/11], lr: 0.00050	Time 3.056 (3.056)	Data 2.097 (2.097)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8765], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0453], device='cuda:0', requires_grad=True)
2022-03-23 19:05:31.589099
Epoch: [2][0/11], lr: 0.00050	Time 3.159 (3.159)	Data 2.426 (2.426)	Loss 0.0395 (0.0395)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8777], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0457], device='cuda:0', requires_grad=True)
2022-03-23 19:05:40.245422
Epoch: [3][0/11], lr: 0.00050	Time 3.083 (3.083)	Data 2.653 (2.653)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8785], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0460], device='cuda:0', requires_grad=True)
2022-03-23 19:05:48.790298
Epoch: [4][0/11], lr: 0.00050	Time 2.949 (2.949)	Data 2.200 (2.200)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8789], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0461], device='cuda:0', requires_grad=True)
2022-03-23 19:05:57.105386
Epoch: [5][0/11], lr: 0.00050	Time 2.782 (2.782)	Data 2.244 (2.244)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8794], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0463], device='cuda:0', requires_grad=True)
2022-03-23 19:06:05.809363
Epoch: [6][0/11], lr: 0.00050	Time 2.924 (2.924)	Data 2.434 (2.434)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8803], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0467], device='cuda:0', requires_grad=True)
2022-03-23 19:06:14.364552
Epoch: [7][0/11], lr: 0.00050	Time 3.061 (3.061)	Data 2.217 (2.217)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8808], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0468], device='cuda:0', requires_grad=True)
2022-03-23 19:06:22.940335
Epoch: [8][0/11], lr: 0.00050	Time 2.880 (2.880)	Data 1.900 (1.900)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8810], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0468], device='cuda:0', requires_grad=True)
2022-03-23 19:06:31.457017
Epoch: [9][0/11], lr: 0.00050	Time 2.960 (2.960)	Data 1.836 (1.836)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8807], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0466], device='cuda:0', requires_grad=True)
2022-03-23 19:06:39.918012
Epoch: [10][0/11], lr: 0.00050	Time 2.903 (2.903)	Data 2.337 (2.337)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8811], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0468], device='cuda:0', requires_grad=True)
2022-03-23 19:06:48.509559
Epoch: [11][0/11], lr: 0.00050	Time 2.896 (2.896)	Data 2.243 (2.243)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8820], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0472], device='cuda:0', requires_grad=True)
2022-03-23 19:06:57.114940
Epoch: [12][0/11], lr: 0.00050	Time 2.948 (2.948)	Data 2.045 (2.045)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8827], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0476], device='cuda:0', requires_grad=True)
2022-03-23 19:07:05.401175
Epoch: [13][0/11], lr: 0.00050	Time 2.862 (2.862)	Data 2.314 (2.314)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8839], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0482], device='cuda:0', requires_grad=True)
2022-03-23 19:07:14.031993
Epoch: [14][0/11], lr: 0.00050	Time 2.918 (2.918)	Data 2.254 (2.254)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8847], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0487], device='cuda:0', requires_grad=True)
2022-03-23 19:07:22.341370
Epoch: [15][0/11], lr: 0.00050	Time 2.832 (2.832)	Data 2.025 (2.025)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8853], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0489], device='cuda:0', requires_grad=True)
2022-03-23 19:07:30.851751
Epoch: [16][0/11], lr: 0.00050	Time 2.990 (2.990)	Data 2.135 (2.135)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8851], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 19:07:39.360880
Epoch: [17][0/11], lr: 0.00050	Time 2.870 (2.870)	Data 2.243 (2.243)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8851], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0485], device='cuda:0', requires_grad=True)
2022-03-23 19:07:47.718941
Epoch: [18][0/11], lr: 0.00050	Time 2.938 (2.938)	Data 2.379 (2.379)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8855], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0487], device='cuda:0', requires_grad=True)
2022-03-23 19:07:56.350119
Epoch: [19][0/11], lr: 0.00050	Time 3.007 (3.007)	Data 1.868 (1.868)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8861], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0490], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_012.pth.tar
exemplar : 375
Computing the class mean vectors...
Eval Task 0 for Age 12
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.706 (4.706)	Prec@1 56.250 (56.250)
Test: [100/123]	Time 0.686 (0.520)	Prec@1 75.000 (69.926)
Testing Results: Prec@1 69.552
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.371)
Testing Results (NME): Prec@1 75.305
Eval Task 1 for Age 12
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.835 (3.835)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 81.034
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 77.586
Eval Task 2 for Age 12
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.416 (3.416)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 46.154
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 53.846
Eval Task 3 for Age 12
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.120 (4.120)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 70.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 62.500
Eval Task 4 for Age 12
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.967 (3.967)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 69.412
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 61.176
Eval Task 5 for Age 12
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.537 (3.537)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 61.290
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 67.742
Eval Task 6 for Age 12
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.959 (3.959)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 77.778
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 54.321
Eval Task 7 for Age 12
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.429 (3.429)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 89.552
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 77.612
Eval Task 8 for Age 12
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.744 (3.744)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 57.576
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 48.485
Eval Task 9 for Age 12
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.815 (3.815)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 78.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 54.667
Eval Task 10 for Age 12
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.950 (3.950)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 86.047
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 90.698
Eval Task 11 for Age 12
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.548 (3.548)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.161
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 67.742
Eval Task 12 for Age 12
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.086 (4.086)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.386
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83]
Method : OURS
----AGE 13----
current_task  [12, 47]
current_head  77
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06123724356957945]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=231, sigma=tensor([3.8861]), eta=tensor([3.0490])
  (fc1): CosineLinear(input_features=512, output_features=225, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 199
video number + exemplar : 574
DataLoader Constructed : Train 17
Optimizer Constructed
video number : 199
video number + exemplar : 199
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-23 19:12:38.855808
Epoch: [0][0/17], lr: 0.00100	Time 3.974 (3.974)	Data 2.934 (2.934)	Loss 0.0876 (0.0876)	Loss CE 0.0252 (0.0252)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6121 (0.6121)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.8738], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0412], device='cuda:0', requires_grad=True)
2022-03-23 19:12:54.803047
Epoch: [1][0/17], lr: 0.00100	Time 4.214 (4.214)	Data 3.159 (3.159)	Loss 0.0819 (0.0819)	Loss CE 0.0170 (0.0170)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6349 (0.6349)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8653], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0368], device='cuda:0', requires_grad=True)
2022-03-23 19:13:11.018191
Epoch: [2][0/17], lr: 0.00100	Time 3.807 (3.807)	Data 3.054 (3.054)	Loss 0.0864 (0.0864)	Loss CE 0.0177 (0.0177)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6715 (0.6715)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8671], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0390], device='cuda:0', requires_grad=True)
2022-03-23 19:13:27.314377
Epoch: [3][0/17], lr: 0.00100	Time 4.496 (4.496)	Data 3.512 (3.512)	Loss 0.0876 (0.0876)	Loss CE 0.0253 (0.0253)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0042 (0.0042)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6056 (0.6056)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8703], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0416], device='cuda:0', requires_grad=True)
2022-03-23 19:13:43.296698
Epoch: [4][0/17], lr: 0.00100	Time 3.993 (3.993)	Data 3.325 (3.325)	Loss 0.0647 (0.0647)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0072 (0.0072)	Loss KD (GCAM) 0.0041 (0.0041)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8747], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0444], device='cuda:0', requires_grad=True)
2022-03-23 19:13:58.578371
Epoch: [5][0/17], lr: 0.00100	Time 3.603 (3.603)	Data 2.712 (2.712)	Loss 0.0719 (0.0719)	Loss CE 0.0089 (0.0089)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0040 (0.0040)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6147 (0.6147)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8797], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0473], device='cuda:0', requires_grad=True)
2022-03-23 19:14:14.009509
Epoch: [6][0/17], lr: 0.00100	Time 3.539 (3.539)	Data 2.677 (2.677)	Loss 0.1274 (0.1274)	Loss CE 0.0631 (0.0631)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0041 (0.0041)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6261 (0.6261)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8827], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0491], device='cuda:0', requires_grad=True)
2022-03-23 19:14:29.113718
Epoch: [7][0/17], lr: 0.00100	Time 3.392 (3.392)	Data 2.566 (2.566)	Loss 0.0633 (0.0633)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0043 (0.0043)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6016 (0.6016)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8830], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 19:14:44.724464
Epoch: [8][0/17], lr: 0.00100	Time 3.586 (3.586)	Data 2.346 (2.346)	Loss 0.1156 (0.1156)	Loss CE 0.0498 (0.0498)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0044 (0.0044)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6409 (0.6409)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8846], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0502], device='cuda:0', requires_grad=True)
2022-03-23 19:15:00.277072
Epoch: [9][0/17], lr: 0.00100	Time 3.413 (3.413)	Data 2.504 (2.504)	Loss 0.0602 (0.0602)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0072 (0.0072)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5746 (0.5746)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8869], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0518], device='cuda:0', requires_grad=True)
2022-03-23 19:15:16.020103
Epoch: [10][0/17], lr: 0.00100	Time 3.739 (3.739)	Data 2.301 (2.301)	Loss 0.0691 (0.0691)	Loss CE 0.0052 (0.0052)	Loss KD (Logit) 0.0072 (0.0072)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6208 (0.6208)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8938], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0561], device='cuda:0', requires_grad=True)
2022-03-23 19:15:32.072474
Epoch: [11][0/17], lr: 0.00100	Time 3.890 (3.890)	Data 2.949 (2.949)	Loss 0.1874 (0.1874)	Loss CE 0.1220 (0.1220)	Loss KD (Logit) 0.0073 (0.0073)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6336 (0.6336)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8909], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0546], device='cuda:0', requires_grad=True)
2022-03-23 19:15:48.347533
Epoch: [12][0/17], lr: 0.00100	Time 3.959 (3.959)	Data 3.126 (3.126)	Loss 0.0851 (0.0851)	Loss CE 0.0187 (0.0187)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6440 (0.6440)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8875], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0526], device='cuda:0', requires_grad=True)
2022-03-23 19:16:04.067324
Epoch: [13][0/17], lr: 0.00100	Time 3.557 (3.557)	Data 2.699 (2.699)	Loss 0.2509 (0.2509)	Loss CE 0.1872 (0.1872)	Loss KD (Logit) 0.0074 (0.0074)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6170 (0.6170)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8863], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0521], device='cuda:0', requires_grad=True)
2022-03-23 19:16:19.807219
Epoch: [14][0/17], lr: 0.00100	Time 3.530 (3.530)	Data 2.197 (2.197)	Loss 0.0711 (0.0711)	Loss CE 0.0076 (0.0076)	Loss KD (Logit) 0.0073 (0.0073)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6154 (0.6154)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8906], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0549], device='cuda:0', requires_grad=True)
2022-03-23 19:16:35.976734
Epoch: [15][0/17], lr: 0.00100	Time 3.544 (3.544)	Data 2.674 (2.674)	Loss 0.0622 (0.0622)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0073 (0.0073)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5674 (0.5674)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8922], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0556], device='cuda:0', requires_grad=True)
2022-03-23 19:16:51.629824
Epoch: [16][0/17], lr: 0.00100	Time 3.534 (3.534)	Data 2.228 (2.228)	Loss 0.1516 (0.1516)	Loss CE 0.0923 (0.0923)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5739 (0.5739)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8926], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0556], device='cuda:0', requires_grad=True)
2022-03-23 19:17:06.939673
Epoch: [17][0/17], lr: 0.00100	Time 3.375 (3.375)	Data 2.241 (2.241)	Loss 0.0723 (0.0723)	Loss CE 0.0087 (0.0087)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6172 (0.6172)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8925], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0553], device='cuda:0', requires_grad=True)
2022-03-23 19:17:22.458229
Epoch: [18][0/17], lr: 0.00100	Time 3.526 (3.526)	Data 2.403 (2.403)	Loss 0.0723 (0.0723)	Loss CE 0.0113 (0.0113)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5911 (0.5911)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8932], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0561], device='cuda:0', requires_grad=True)
2022-03-23 19:17:37.895339
Epoch: [19][0/17], lr: 0.00100	Time 3.440 (3.440)	Data 2.740 (2.740)	Loss 0.0669 (0.0669)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6050 (0.6050)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8955], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0573], device='cuda:0', requires_grad=True)
2022-03-23 19:17:53.446855
Epoch: [20][0/17], lr: 0.00010	Time 3.540 (3.540)	Data 2.136 (2.136)	Loss 0.0728 (0.0728)	Loss CE 0.0057 (0.0057)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6528 (0.6528)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8958], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0574], device='cuda:0', requires_grad=True)
2022-03-23 19:18:08.623569
Epoch: [21][0/17], lr: 0.00010	Time 3.055 (3.055)	Data 2.084 (2.084)	Loss 0.0597 (0.0597)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0072 (0.0072)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5677 (0.5677)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8958], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0574], device='cuda:0', requires_grad=True)
2022-03-23 19:18:24.692664
Epoch: [22][0/17], lr: 0.00010	Time 3.648 (3.648)	Data 2.783 (2.783)	Loss 0.0660 (0.0660)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.0073 (0.0073)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5795 (0.5795)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8960], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0575], device='cuda:0', requires_grad=True)
2022-03-23 19:18:39.942212
Epoch: [23][0/17], lr: 0.00010	Time 3.155 (3.155)	Data 1.994 (1.994)	Loss 0.0679 (0.0679)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6468 (0.6468)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8961], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0576], device='cuda:0', requires_grad=True)
2022-03-23 19:18:55.457529
Epoch: [24][0/17], lr: 0.00010	Time 3.364 (3.364)	Data 2.247 (2.247)	Loss 0.0649 (0.0649)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0074 (0.0074)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6038 (0.6038)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8963], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0577], device='cuda:0', requires_grad=True)
2022-03-23 19:19:10.955592
Epoch: [25][0/17], lr: 0.00010	Time 3.506 (3.506)	Data 2.278 (2.278)	Loss 0.0693 (0.0693)	Loss CE 0.0068 (0.0068)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6061 (0.6061)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8964], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0578], device='cuda:0', requires_grad=True)
2022-03-23 19:19:26.674351
Epoch: [26][0/17], lr: 0.00010	Time 3.652 (3.652)	Data 2.903 (2.903)	Loss 0.0655 (0.0655)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0045 (0.0045)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6279 (0.6279)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8966], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0579], device='cuda:0', requires_grad=True)
2022-03-23 19:19:41.953109
Epoch: [27][0/17], lr: 0.00010	Time 3.349 (3.349)	Data 2.344 (2.344)	Loss 0.0665 (0.0665)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0073 (0.0073)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6092 (0.6092)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8968], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0580], device='cuda:0', requires_grad=True)
2022-03-23 19:19:57.474120
Epoch: [28][0/17], lr: 0.00010	Time 3.451 (3.451)	Data 2.544 (2.544)	Loss 0.0636 (0.0636)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5948 (0.5948)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0581], device='cuda:0', requires_grad=True)
2022-03-23 19:20:12.720968
Epoch: [29][0/17], lr: 0.00010	Time 3.089 (3.089)	Data 2.233 (2.233)	Loss 0.0639 (0.0639)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6135 (0.6135)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8971], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:20:27.246024
Epoch: [30][0/17], lr: 0.00001	Time 3.275 (3.275)	Data 2.130 (2.130)	Loss 0.0618 (0.0618)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5930 (0.5930)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8972], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:20:41.680231
Epoch: [31][0/17], lr: 0.00001	Time 3.134 (3.134)	Data 2.304 (2.304)	Loss 0.0639 (0.0639)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6017 (0.6017)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8972], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:20:56.604416
Epoch: [32][0/17], lr: 0.00001	Time 3.608 (3.608)	Data 2.599 (2.599)	Loss 0.0674 (0.0674)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6440 (0.6440)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8972], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:21:11.213689
Epoch: [33][0/17], lr: 0.00001	Time 3.270 (3.270)	Data 2.065 (2.065)	Loss 0.0706 (0.0706)	Loss CE 0.0044 (0.0044)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6425 (0.6425)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8972], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:21:25.780653
Epoch: [34][0/17], lr: 0.00001	Time 3.191 (3.191)	Data 2.472 (2.472)	Loss 0.0640 (0.0640)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6211 (0.6211)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8972], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:21:40.285165
Epoch: [35][0/17], lr: 0.00001	Time 3.297 (3.297)	Data 2.407 (2.407)	Loss 0.0641 (0.0641)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0072 (0.0072)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6167 (0.6167)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:21:54.918821
Epoch: [36][0/17], lr: 0.00001	Time 3.263 (3.263)	Data 2.531 (2.531)	Loss 0.0744 (0.0744)	Loss CE 0.0125 (0.0125)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0045 (0.0045)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6004 (0.6004)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:22:09.429911
Epoch: [37][0/17], lr: 0.00001	Time 3.268 (3.268)	Data 2.499 (2.499)	Loss 0.0633 (0.0633)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0072 (0.0072)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6099 (0.6099)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:22:23.824807
Epoch: [38][0/17], lr: 0.00001	Time 3.123 (3.123)	Data 2.114 (2.114)	Loss 0.0619 (0.0619)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5862 (0.5862)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0582], device='cuda:0', requires_grad=True)
2022-03-23 19:22:38.777034
Epoch: [39][0/17], lr: 0.00001	Time 3.522 (3.522)	Data 2.585 (2.585)	Loss 0.0649 (0.0649)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0044 (0.0044)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6056 (0.6056)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:22:53.343892
Epoch: [40][0/17], lr: 0.00001	Time 3.214 (3.214)	Data 2.002 (2.002)	Loss 0.0675 (0.0675)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6477 (0.6477)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:23:08.074027
Epoch: [41][0/17], lr: 0.00001	Time 3.143 (3.143)	Data 1.932 (1.932)	Loss 0.0617 (0.0617)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5965 (0.5965)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:23:22.674125
Epoch: [42][0/17], lr: 0.00001	Time 3.180 (3.180)	Data 2.273 (2.273)	Loss 0.0745 (0.0745)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0045 (0.0045)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6598 (0.6598)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:23:37.463554
Epoch: [43][0/17], lr: 0.00001	Time 3.492 (3.492)	Data 2.598 (2.598)	Loss 0.0614 (0.0614)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5934 (0.5934)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:23:52.147292
Epoch: [44][0/17], lr: 0.00001	Time 3.275 (3.275)	Data 2.471 (2.471)	Loss 0.0660 (0.0660)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0072 (0.0072)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6372 (0.6372)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:24:06.524523
Epoch: [45][0/17], lr: 0.00001	Time 3.187 (3.187)	Data 2.149 (2.149)	Loss 0.0777 (0.0777)	Loss CE 0.0083 (0.0083)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0045 (0.0045)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6765 (0.6765)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:24:21.006537
Epoch: [46][0/17], lr: 0.00001	Time 3.299 (3.299)	Data 2.492 (2.492)	Loss 0.0658 (0.0658)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6218 (0.6218)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:24:35.550230
Epoch: [47][0/17], lr: 0.00001	Time 3.347 (3.347)	Data 2.331 (2.331)	Loss 0.0634 (0.0634)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6051 (0.6051)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:24:50.012166
Epoch: [48][0/17], lr: 0.00001	Time 3.217 (3.217)	Data 2.423 (2.423)	Loss 0.0681 (0.0681)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0045 (0.0045)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6250 (0.6250)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
2022-03-23 19:25:04.448195
Epoch: [49][0/17], lr: 0.00001	Time 3.258 (3.258)	Data 2.014 (2.014)	Loss 0.0682 (0.0682)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6564 (0.6564)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8974], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0583], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=231, sigma=tensor([3.8974]), eta=tensor([3.0583])
  (fc1): CosineLinear(input_features=512, output_features=225, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 199
video number + exemplar : 199
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=231, sigma=tensor([3.8974]), eta=tensor([3.0583])
  (fc1): CosineLinear(input_features=512, output_features=225, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 385
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-23 19:25:32.854995
Epoch: [0][0/12], lr: 0.00050	Time 2.935 (2.935)	Data 2.496 (2.496)	Loss 0.0150 (0.0150)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0587], device='cuda:0', requires_grad=True)
2022-03-23 19:25:40.720714
Epoch: [1][0/12], lr: 0.00050	Time 2.788 (2.788)	Data 2.265 (2.265)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8986], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0589], device='cuda:0', requires_grad=True)
2022-03-23 19:25:48.305244
Epoch: [2][0/12], lr: 0.00050	Time 2.819 (2.819)	Data 2.097 (2.097)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8991], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0590], device='cuda:0', requires_grad=True)
2022-03-23 19:25:56.161334
Epoch: [3][0/12], lr: 0.00050	Time 3.041 (3.041)	Data 2.412 (2.412)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9000], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0594], device='cuda:0', requires_grad=True)
2022-03-23 19:26:03.787023
Epoch: [4][0/12], lr: 0.00050	Time 2.810 (2.810)	Data 1.943 (1.943)	Loss 0.0028 (0.0028)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9008], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0598], device='cuda:0', requires_grad=True)
2022-03-23 19:26:11.597604
Epoch: [5][0/12], lr: 0.00050	Time 2.853 (2.853)	Data 2.061 (2.061)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9017], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0601], device='cuda:0', requires_grad=True)
2022-03-23 19:26:19.262606
Epoch: [6][0/12], lr: 0.00050	Time 2.827 (2.827)	Data 2.317 (2.317)	Loss 0.0066 (0.0066)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9026], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0604], device='cuda:0', requires_grad=True)
2022-03-23 19:26:26.815717
Epoch: [7][0/12], lr: 0.00050	Time 2.820 (2.820)	Data 1.826 (1.826)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0604], device='cuda:0', requires_grad=True)
2022-03-23 19:26:34.699144
Epoch: [8][0/12], lr: 0.00050	Time 3.011 (3.011)	Data 2.446 (2.446)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9031], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0603], device='cuda:0', requires_grad=True)
2022-03-23 19:26:42.654169
Epoch: [9][0/12], lr: 0.00050	Time 2.934 (2.934)	Data 2.423 (2.423)	Loss 0.0041 (0.0041)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9035], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0604], device='cuda:0', requires_grad=True)
2022-03-23 19:26:50.392228
Epoch: [10][0/12], lr: 0.00050	Time 2.841 (2.841)	Data 2.025 (2.025)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9035], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0603], device='cuda:0', requires_grad=True)
2022-03-23 19:26:58.189324
Epoch: [11][0/12], lr: 0.00050	Time 2.919 (2.919)	Data 2.044 (2.044)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9040], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0605], device='cuda:0', requires_grad=True)
2022-03-23 19:27:06.060310
Epoch: [12][0/12], lr: 0.00050	Time 2.914 (2.914)	Data 2.222 (2.222)	Loss 0.0622 (0.0622)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9035], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0600], device='cuda:0', requires_grad=True)
2022-03-23 19:27:13.698910
Epoch: [13][0/12], lr: 0.00050	Time 2.712 (2.712)	Data 2.264 (2.264)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9034], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0598], device='cuda:0', requires_grad=True)
2022-03-23 19:27:21.416066
Epoch: [14][0/12], lr: 0.00050	Time 2.932 (2.932)	Data 1.953 (1.953)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9034], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0597], device='cuda:0', requires_grad=True)
2022-03-23 19:27:29.071775
Epoch: [15][0/12], lr: 0.00050	Time 2.896 (2.896)	Data 2.125 (2.125)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9035], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0595], device='cuda:0', requires_grad=True)
2022-03-23 19:27:36.674388
Epoch: [16][0/12], lr: 0.00050	Time 2.789 (2.789)	Data 2.010 (2.010)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9033], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0593], device='cuda:0', requires_grad=True)
2022-03-23 19:27:44.354647
Epoch: [17][0/12], lr: 0.00050	Time 2.724 (2.724)	Data 1.930 (1.930)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9031], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0590], device='cuda:0', requires_grad=True)
2022-03-23 19:27:52.035958
Epoch: [18][0/12], lr: 0.00050	Time 2.803 (2.803)	Data 2.131 (2.131)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0587], device='cuda:0', requires_grad=True)
2022-03-23 19:27:59.812409
Epoch: [19][0/12], lr: 0.00050	Time 2.931 (2.931)	Data 1.912 (1.912)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9032], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0588], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_013.pth.tar
exemplar : 385
Computing the class mean vectors...
Eval Task 0 for Age 13
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.232 (4.232)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.343 (0.463)	Prec@1 75.000 (67.079)
Testing Results: Prec@1 67.159
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 68.750 (74.505)
Testing Results (NME): Prec@1 74.389
Eval Task 1 for Age 13
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.656 (3.656)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 58.621
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 65.517
Eval Task 2 for Age 13
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.781 (3.781)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 61.538
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 55.385
Eval Task 3 for Age 13
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.923 (3.923)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 68.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 62.500
Eval Task 4 for Age 13
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.779 (3.779)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 71.765
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 68.235
Eval Task 5 for Age 13
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.094 (3.094)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 70.968
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 69.355
Eval Task 6 for Age 13
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.963 (3.963)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 67.901
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 50.617
Eval Task 7 for Age 13
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.651 (3.651)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 86.567
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 76.119
Eval Task 8 for Age 13
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.740 (3.740)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 56.061
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 51.515
Eval Task 9 for Age 13
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.780 (3.780)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 70.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 49.333
Eval Task 10 for Age 13
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.892 (3.892)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 83.721
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 82.558
Eval Task 11 for Age 13
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.420 (3.420)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 91.935
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 69.355
Eval Task 12 for Age 13
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.897 (3.897)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 13
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.742 (3.742)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 97.368
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 89.474
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76]
Method : OURS
----AGE 14----
current_task  [25, 30]
current_head  79
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.062048368229954284]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=237, sigma=tensor([3.9032]), eta=tensor([3.0588])
  (fc1): CosineLinear(input_features=512, output_features=231, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 194
video number + exemplar : 579
DataLoader Constructed : Train 18
Optimizer Constructed
video number : 194
video number + exemplar : 194
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 19:32:28.894560
Epoch: [0][0/18], lr: 0.00100	Time 3.593 (3.593)	Data 2.499 (2.499)	Loss 0.2511 (0.2511)	Loss CE 0.1927 (0.1927)	Loss KD (Logit) 0.0102 (0.0102)	Loss KD (GCAM) 0.0043 (0.0043)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5651 (0.5651)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8907], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0516], device='cuda:0', requires_grad=True)
2022-03-23 19:32:43.792078
Epoch: [1][0/18], lr: 0.00100	Time 3.267 (3.267)	Data 2.430 (2.430)	Loss 0.0609 (0.0609)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0107 (0.0107)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5761 (0.5761)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0528], device='cuda:0', requires_grad=True)
2022-03-23 19:32:58.708884
Epoch: [2][0/18], lr: 0.00100	Time 3.065 (3.065)	Data 2.115 (2.115)	Loss 0.1601 (0.1601)	Loss CE 0.0977 (0.0977)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5977 (0.5977)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8919], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0531], device='cuda:0', requires_grad=True)
2022-03-23 19:33:14.361309
Epoch: [3][0/18], lr: 0.00100	Time 3.405 (3.405)	Data 2.109 (2.109)	Loss 0.0749 (0.0749)	Loss CE 0.0141 (0.0141)	Loss KD (Logit) 0.0106 (0.0106)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5797 (0.5797)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8947], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0550], device='cuda:0', requires_grad=True)
2022-03-23 19:33:29.572913
Epoch: [4][0/18], lr: 0.00100	Time 3.304 (3.304)	Data 2.432 (2.432)	Loss 0.1345 (0.1345)	Loss CE 0.0710 (0.0710)	Loss KD (Logit) 0.0105 (0.0105)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6085 (0.6085)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8952], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0552], device='cuda:0', requires_grad=True)
2022-03-23 19:33:44.609594
Epoch: [5][0/18], lr: 0.00100	Time 3.021 (3.021)	Data 1.966 (1.966)	Loss 0.0830 (0.0830)	Loss CE 0.0235 (0.0235)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5680 (0.5680)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8991], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0573], device='cuda:0', requires_grad=True)
2022-03-23 19:34:00.041614
Epoch: [6][0/18], lr: 0.00100	Time 3.454 (3.454)	Data 2.481 (2.481)	Loss 0.0597 (0.0597)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0111 (0.0111)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5403 (0.5403)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9051], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0611], device='cuda:0', requires_grad=True)
2022-03-23 19:34:15.214716
Epoch: [7][0/18], lr: 0.00100	Time 3.238 (3.238)	Data 1.851 (1.851)	Loss 0.0681 (0.0681)	Loss CE 0.0093 (0.0093)	Loss KD (Logit) 0.0105 (0.0105)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5619 (0.5619)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9087], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0634], device='cuda:0', requires_grad=True)
2022-03-23 19:34:30.318107
Epoch: [8][0/18], lr: 0.00100	Time 3.158 (3.158)	Data 2.255 (2.255)	Loss 0.0602 (0.0602)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0103 (0.0103)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5715 (0.5715)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0647], device='cuda:0', requires_grad=True)
2022-03-23 19:34:46.020631
Epoch: [9][0/18], lr: 0.00100	Time 3.545 (3.545)	Data 2.833 (2.833)	Loss 0.0589 (0.0589)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0107 (0.0107)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5502 (0.5502)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9123], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0647], device='cuda:0', requires_grad=True)
2022-03-23 19:35:01.663151
Epoch: [10][0/18], lr: 0.00100	Time 3.382 (3.382)	Data 2.015 (2.015)	Loss 0.0582 (0.0582)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0109 (0.0109)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5451 (0.5451)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9136], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0651], device='cuda:0', requires_grad=True)
2022-03-23 19:35:16.885591
Epoch: [11][0/18], lr: 0.00100	Time 3.227 (3.227)	Data 2.154 (2.154)	Loss 0.0767 (0.0767)	Loss CE 0.0194 (0.0194)	Loss KD (Logit) 0.0112 (0.0112)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5449 (0.5449)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9140], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0655], device='cuda:0', requires_grad=True)
2022-03-23 19:35:32.169537
Epoch: [12][0/18], lr: 0.00100	Time 3.123 (3.123)	Data 2.091 (2.091)	Loss 0.0626 (0.0626)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0104 (0.0104)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5975 (0.5975)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9142], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0656], device='cuda:0', requires_grad=True)
2022-03-23 19:35:47.427294
Epoch: [13][0/18], lr: 0.00100	Time 3.271 (3.271)	Data 2.307 (2.307)	Loss 0.0657 (0.0657)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5883 (0.5883)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9151], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0659], device='cuda:0', requires_grad=True)
2022-03-23 19:36:02.733450
Epoch: [14][0/18], lr: 0.00100	Time 3.267 (3.267)	Data 2.594 (2.594)	Loss 0.0602 (0.0602)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5747 (0.5747)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9155], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0659], device='cuda:0', requires_grad=True)
2022-03-23 19:36:17.883279
Epoch: [15][0/18], lr: 0.00100	Time 3.240 (3.240)	Data 1.959 (1.959)	Loss 0.1504 (0.1504)	Loss CE 0.0909 (0.0909)	Loss KD (Logit) 0.0112 (0.0112)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5652 (0.5652)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9139], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0644], device='cuda:0', requires_grad=True)
2022-03-23 19:36:33.186104
Epoch: [16][0/18], lr: 0.00100	Time 3.230 (3.230)	Data 2.175 (2.175)	Loss 0.1004 (0.1004)	Loss CE 0.0397 (0.0397)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5782 (0.5782)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9158], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0660], device='cuda:0', requires_grad=True)
2022-03-23 19:36:48.405325
Epoch: [17][0/18], lr: 0.00100	Time 3.217 (3.217)	Data 2.231 (2.231)	Loss 0.0632 (0.0632)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5881 (0.5881)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9136], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0646], device='cuda:0', requires_grad=True)
2022-03-23 19:37:03.403079
Epoch: [18][0/18], lr: 0.00100	Time 3.072 (3.072)	Data 1.817 (1.817)	Loss 0.3118 (0.3118)	Loss CE 0.2489 (0.2489)	Loss KD (Logit) 0.0111 (0.0111)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5974 (0.5974)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.9097], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0614], device='cuda:0', requires_grad=True)
2022-03-23 19:37:18.541972
Epoch: [19][0/18], lr: 0.00100	Time 3.054 (3.054)	Data 1.858 (1.858)	Loss 0.0628 (0.0628)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0113 (0.0113)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5954 (0.5954)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9097], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0614], device='cuda:0', requires_grad=True)
2022-03-23 19:37:33.697947
Epoch: [20][0/18], lr: 0.00010	Time 3.226 (3.226)	Data 2.521 (2.521)	Loss 0.0697 (0.0697)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6155 (0.6155)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9098], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0615], device='cuda:0', requires_grad=True)
2022-03-23 19:37:48.779906
Epoch: [21][0/18], lr: 0.00010	Time 3.069 (3.069)	Data 2.127 (2.127)	Loss 0.0589 (0.0589)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5542 (0.5542)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9099], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0616], device='cuda:0', requires_grad=True)
2022-03-23 19:38:04.181861
Epoch: [22][0/18], lr: 0.00010	Time 3.435 (3.435)	Data 2.681 (2.681)	Loss 0.0663 (0.0663)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6103 (0.6103)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9102], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0617], device='cuda:0', requires_grad=True)
2022-03-23 19:38:19.514631
Epoch: [23][0/18], lr: 0.00010	Time 3.265 (3.265)	Data 2.287 (2.287)	Loss 0.0598 (0.0598)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0109 (0.0109)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5589 (0.5589)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9102], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0617], device='cuda:0', requires_grad=True)
2022-03-23 19:38:34.816960
Epoch: [24][0/18], lr: 0.00010	Time 3.377 (3.377)	Data 2.274 (2.274)	Loss 0.0617 (0.0617)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0115 (0.0115)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5818 (0.5818)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9105], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0618], device='cuda:0', requires_grad=True)
2022-03-23 19:38:49.937265
Epoch: [25][0/18], lr: 0.00010	Time 3.133 (3.133)	Data 1.918 (1.918)	Loss 0.0641 (0.0641)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6001 (0.6001)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9107], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0620], device='cuda:0', requires_grad=True)
2022-03-23 19:39:04.904702
Epoch: [26][0/18], lr: 0.00010	Time 3.113 (3.113)	Data 1.925 (1.925)	Loss 0.0623 (0.0623)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5737 (0.5737)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9109], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0621], device='cuda:0', requires_grad=True)
2022-03-23 19:39:20.282787
Epoch: [27][0/18], lr: 0.00010	Time 3.242 (3.242)	Data 2.096 (2.096)	Loss 0.0965 (0.0965)	Loss CE 0.0346 (0.0346)	Loss KD (Logit) 0.0112 (0.0112)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5891 (0.5891)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9112], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0622], device='cuda:0', requires_grad=True)
2022-03-23 19:39:35.356436
Epoch: [28][0/18], lr: 0.00010	Time 3.208 (3.208)	Data 2.118 (2.118)	Loss 0.0625 (0.0625)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5414 (0.5414)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9114], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0623], device='cuda:0', requires_grad=True)
2022-03-23 19:39:50.614192
Epoch: [29][0/18], lr: 0.00010	Time 3.268 (3.268)	Data 2.518 (2.518)	Loss 0.0600 (0.0600)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0107 (0.0107)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5334 (0.5334)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9115], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:40:05.782845
Epoch: [30][0/18], lr: 0.00001	Time 3.150 (3.150)	Data 2.134 (2.134)	Loss 0.0627 (0.0627)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0106 (0.0106)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5695 (0.5695)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9115], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:40:20.961066
Epoch: [31][0/18], lr: 0.00001	Time 3.225 (3.225)	Data 2.018 (2.018)	Loss 0.0607 (0.0607)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5734 (0.5734)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9115], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:40:36.205312
Epoch: [32][0/18], lr: 0.00001	Time 3.194 (3.194)	Data 2.320 (2.320)	Loss 0.0635 (0.0635)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0112 (0.0112)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6004 (0.6004)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9115], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:40:51.515306
Epoch: [33][0/18], lr: 0.00001	Time 3.423 (3.423)	Data 1.992 (1.992)	Loss 0.0607 (0.0607)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5509 (0.5509)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9115], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:41:06.808162
Epoch: [34][0/18], lr: 0.00001	Time 3.210 (3.210)	Data 2.311 (2.311)	Loss 0.0574 (0.0574)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0109 (0.0109)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5417 (0.5417)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:41:21.971063
Epoch: [35][0/18], lr: 0.00001	Time 3.199 (3.199)	Data 2.402 (2.402)	Loss 0.0579 (0.0579)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0107 (0.0107)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5290 (0.5290)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:41:37.026899
Epoch: [36][0/18], lr: 0.00001	Time 3.045 (3.045)	Data 1.858 (1.858)	Loss 0.0616 (0.0616)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0111 (0.0111)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5840 (0.5840)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:41:52.615784
Epoch: [37][0/18], lr: 0.00001	Time 3.269 (3.269)	Data 2.136 (2.136)	Loss 0.0628 (0.0628)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5937 (0.5937)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:42:07.865912
Epoch: [38][0/18], lr: 0.00001	Time 3.259 (3.259)	Data 1.966 (1.966)	Loss 0.0627 (0.0627)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5875 (0.5875)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 19:42:22.957012
Epoch: [39][0/18], lr: 0.00001	Time 3.185 (3.185)	Data 1.923 (1.923)	Loss 0.0577 (0.0577)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5449 (0.5449)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:42:38.306959
Epoch: [40][0/18], lr: 0.00001	Time 3.108 (3.108)	Data 2.005 (2.005)	Loss 0.0617 (0.0617)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0110 (0.0110)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5849 (0.5849)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:42:53.705544
Epoch: [41][0/18], lr: 0.00001	Time 3.258 (3.258)	Data 2.102 (2.102)	Loss 0.0610 (0.0610)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0112 (0.0112)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5594 (0.5594)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:43:08.903241
Epoch: [42][0/18], lr: 0.00001	Time 3.214 (3.214)	Data 1.998 (1.998)	Loss 0.0710 (0.0710)	Loss CE 0.0083 (0.0083)	Loss KD (Logit) 0.0109 (0.0109)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5970 (0.5970)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:43:24.108853
Epoch: [43][0/18], lr: 0.00001	Time 3.248 (3.248)	Data 2.488 (2.488)	Loss 0.0962 (0.0962)	Loss CE 0.0355 (0.0355)	Loss KD (Logit) 0.0109 (0.0109)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5776 (0.5776)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9117], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:43:39.442629
Epoch: [44][0/18], lr: 0.00001	Time 3.274 (3.274)	Data 1.882 (1.882)	Loss 0.0583 (0.0583)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0111 (0.0111)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5520 (0.5520)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9117], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:43:54.677373
Epoch: [45][0/18], lr: 0.00001	Time 3.330 (3.330)	Data 2.158 (2.158)	Loss 0.0574 (0.0574)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0109 (0.0109)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5429 (0.5429)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9117], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:44:09.693152
Epoch: [46][0/18], lr: 0.00001	Time 3.027 (3.027)	Data 2.207 (2.207)	Loss 0.0628 (0.0628)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5858 (0.5858)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9117], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:44:24.742619
Epoch: [47][0/18], lr: 0.00001	Time 3.198 (3.198)	Data 1.997 (1.997)	Loss 0.0642 (0.0642)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0112 (0.0112)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5935 (0.5935)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9117], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:44:40.188751
Epoch: [48][0/18], lr: 0.00001	Time 3.365 (3.365)	Data 2.167 (2.167)	Loss 0.0603 (0.0603)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0107 (0.0107)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5509 (0.5509)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9117], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
2022-03-23 19:44:55.555792
Epoch: [49][0/18], lr: 0.00001	Time 3.367 (3.367)	Data 2.498 (2.498)	Loss 0.0592 (0.0592)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0108 (0.0108)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5598 (0.5598)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9117], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0625], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=237, sigma=tensor([3.9117]), eta=tensor([3.0625])
  (fc1): CosineLinear(input_features=512, output_features=231, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 194
video number + exemplar : 194
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=237, sigma=tensor([3.9117]), eta=tensor([3.0625])
  (fc1): CosineLinear(input_features=512, output_features=231, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 395
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-23 19:45:24.777475
Epoch: [0][0/12], lr: 0.00050	Time 2.870 (2.870)	Data 2.171 (2.171)	Loss 0.0069 (0.0069)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9126], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0630], device='cuda:0', requires_grad=True)
2022-03-23 19:45:32.729038
Epoch: [1][0/12], lr: 0.00050	Time 3.057 (3.057)	Data 2.523 (2.523)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9137], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0637], device='cuda:0', requires_grad=True)
2022-03-23 19:45:40.141237
Epoch: [2][0/12], lr: 0.00050	Time 2.619 (2.619)	Data 1.812 (1.812)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9143], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0639], device='cuda:0', requires_grad=True)
2022-03-23 19:45:48.011862
Epoch: [3][0/12], lr: 0.00050	Time 2.872 (2.872)	Data 1.968 (1.968)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9148], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0641], device='cuda:0', requires_grad=True)
2022-03-23 19:45:55.832688
Epoch: [4][0/12], lr: 0.00050	Time 2.848 (2.848)	Data 1.965 (1.965)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9152], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0641], device='cuda:0', requires_grad=True)
2022-03-23 19:46:03.579891
Epoch: [5][0/12], lr: 0.00050	Time 2.809 (2.809)	Data 1.859 (1.859)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9153], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0639], device='cuda:0', requires_grad=True)
2022-03-23 19:46:11.552533
Epoch: [6][0/12], lr: 0.00050	Time 3.013 (3.013)	Data 2.384 (2.384)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9154], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0638], device='cuda:0', requires_grad=True)
2022-03-23 19:46:19.558625
Epoch: [7][0/12], lr: 0.00050	Time 3.137 (3.137)	Data 2.045 (2.045)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9154], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0636], device='cuda:0', requires_grad=True)
2022-03-23 19:46:27.369886
Epoch: [8][0/12], lr: 0.00050	Time 2.899 (2.899)	Data 2.244 (2.244)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9155], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0635], device='cuda:0', requires_grad=True)
2022-03-23 19:46:35.173784
Epoch: [9][0/12], lr: 0.00050	Time 2.979 (2.979)	Data 2.494 (2.494)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9155], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0633], device='cuda:0', requires_grad=True)
2022-03-23 19:46:42.881476
Epoch: [10][0/12], lr: 0.00050	Time 2.796 (2.796)	Data 2.298 (2.298)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9156], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0633], device='cuda:0', requires_grad=True)
2022-03-23 19:46:50.547513
Epoch: [11][0/12], lr: 0.00050	Time 2.858 (2.858)	Data 2.118 (2.118)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9155], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0630], device='cuda:0', requires_grad=True)
2022-03-23 19:46:58.501856
Epoch: [12][0/12], lr: 0.00050	Time 2.938 (2.938)	Data 1.844 (1.844)	Loss 0.0048 (0.0048)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9158], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0632], device='cuda:0', requires_grad=True)
2022-03-23 19:47:06.099122
Epoch: [13][0/12], lr: 0.00050	Time 2.777 (2.777)	Data 1.862 (1.862)	Loss 0.0033 (0.0033)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9169], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0638], device='cuda:0', requires_grad=True)
2022-03-23 19:47:13.895941
Epoch: [14][0/12], lr: 0.00050	Time 2.865 (2.865)	Data 2.224 (2.224)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9172], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0637], device='cuda:0', requires_grad=True)
2022-03-23 19:47:21.688728
Epoch: [15][0/12], lr: 0.00050	Time 2.877 (2.877)	Data 2.377 (2.377)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9174], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0636], device='cuda:0', requires_grad=True)
2022-03-23 19:47:29.513259
Epoch: [16][0/12], lr: 0.00050	Time 2.895 (2.895)	Data 2.164 (2.164)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0634], device='cuda:0', requires_grad=True)
2022-03-23 19:47:37.153725
Epoch: [17][0/12], lr: 0.00050	Time 2.776 (2.776)	Data 1.900 (1.900)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0633], device='cuda:0', requires_grad=True)
2022-03-23 19:47:45.093024
Epoch: [18][0/12], lr: 0.00050	Time 2.916 (2.916)	Data 2.225 (2.225)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0631], device='cuda:0', requires_grad=True)
2022-03-23 19:47:52.686094
Epoch: [19][0/12], lr: 0.00050	Time 2.907 (2.907)	Data 2.372 (2.372)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0628], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_014.pth.tar
exemplar : 395
Computing the class mean vectors...
Eval Task 0 for Age 14
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.332 (4.332)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.337 (0.459)	Prec@1 75.000 (69.369)
Testing Results: Prec@1 69.297
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 68.750 (75.062)
Testing Results (NME): Prec@1 75.000
Eval Task 1 for Age 14
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.557 (3.557)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 56.897
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.138
Eval Task 2 for Age 14
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.937 (3.937)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 53.846
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 53.846
Eval Task 3 for Age 14
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.981 (3.981)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 75.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 63.750
Eval Task 4 for Age 14
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.820 (3.820)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 78.824
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 68.235
Eval Task 5 for Age 14
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.703 (3.703)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 74.194
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 72.581
Eval Task 6 for Age 14
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.957 (3.957)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 75.309
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 54.321
Eval Task 7 for Age 14
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.869 (3.869)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 91.045
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.627
Eval Task 8 for Age 14
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.720 (3.720)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 50.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 50.000
Eval Task 9 for Age 14
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.746 (3.746)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 68.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 53.333
Eval Task 10 for Age 14
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.941 (3.941)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 73.256
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 77.907
Eval Task 11 for Age 14
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.393 (3.393)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 85.484
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 74.194
Eval Task 12 for Age 14
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.864 (3.864)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 93.976
Eval Task 13 for Age 14
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.909 (3.909)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 92.105
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 89.474
Eval Task 14 for Age 14
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.777 (3.777)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 98.780
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82]
Method : OURS
----AGE 15----
current_task  [46, 62]
current_head  81
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06284902544988268]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=243, sigma=tensor([3.9171]), eta=tensor([3.0628])
  (fc1): CosineLinear(input_features=512, output_features=237, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 203
video number + exemplar : 598
DataLoader Constructed : Train 18
Optimizer Constructed
video number : 203
video number + exemplar : 203
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 19:52:33.279323
Epoch: [0][0/18], lr: 0.00100	Time 3.510 (3.510)	Data 2.524 (2.524)	Loss 0.0738 (0.0738)	Loss CE 0.0063 (0.0063)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6603 (0.6603)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9107], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0585], device='cuda:0', requires_grad=True)
2022-03-23 19:52:48.275788
Epoch: [1][0/18], lr: 0.00100	Time 3.269 (3.269)	Data 2.569 (2.569)	Loss 0.2141 (0.2141)	Loss CE 0.1508 (0.1508)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6136 (0.6136)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9054], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0548], device='cuda:0', requires_grad=True)
2022-03-23 19:53:03.536404
Epoch: [2][0/18], lr: 0.00100	Time 3.220 (3.220)	Data 2.102 (2.102)	Loss 0.0855 (0.0855)	Loss CE 0.0231 (0.0231)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0059 (0.0059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6007 (0.6007)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9045], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0543], device='cuda:0', requires_grad=True)
2022-03-23 19:53:19.086395
Epoch: [3][0/18], lr: 0.00100	Time 3.349 (3.349)	Data 2.489 (2.489)	Loss 0.0805 (0.0805)	Loss CE 0.0132 (0.0132)	Loss KD (Logit) 0.0090 (0.0090)	Loss KD (GCAM) 0.0058 (0.0058)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6499 (0.6499)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9094], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0580], device='cuda:0', requires_grad=True)
2022-03-23 19:53:34.427497
Epoch: [4][0/18], lr: 0.00100	Time 3.432 (3.432)	Data 2.666 (2.666)	Loss 0.0827 (0.0827)	Loss CE 0.0144 (0.0144)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6591 (0.6591)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9095], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0594], device='cuda:0', requires_grad=True)
2022-03-23 19:53:49.534611
Epoch: [5][0/18], lr: 0.00100	Time 3.216 (3.216)	Data 2.528 (2.528)	Loss 0.0645 (0.0645)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5887 (0.5887)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9072], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0585], device='cuda:0', requires_grad=True)
2022-03-23 19:54:05.058743
Epoch: [6][0/18], lr: 0.00100	Time 3.363 (3.363)	Data 2.676 (2.676)	Loss 0.0688 (0.0688)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6287 (0.6287)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9104], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0607], device='cuda:0', requires_grad=True)
2022-03-23 19:54:20.502353
Epoch: [7][0/18], lr: 0.00100	Time 3.330 (3.330)	Data 2.040 (2.040)	Loss 0.0884 (0.0884)	Loss CE 0.0221 (0.0221)	Loss KD (Logit) 0.0094 (0.0094)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6358 (0.6358)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9115], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0615], device='cuda:0', requires_grad=True)
2022-03-23 19:54:35.727801
Epoch: [8][0/18], lr: 0.00100	Time 3.131 (3.131)	Data 1.983 (1.983)	Loss 0.0736 (0.0736)	Loss CE 0.0056 (0.0056)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6541 (0.6541)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9153], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0640], device='cuda:0', requires_grad=True)
2022-03-23 19:54:51.690305
Epoch: [9][0/18], lr: 0.00100	Time 3.744 (3.744)	Data 3.024 (3.024)	Loss 0.0804 (0.0804)	Loss CE 0.0135 (0.0135)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6426 (0.6426)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9185], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0658], device='cuda:0', requires_grad=True)
2022-03-23 19:55:06.914679
Epoch: [10][0/18], lr: 0.00100	Time 3.321 (3.321)	Data 2.489 (2.489)	Loss 0.0789 (0.0789)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6928 (0.6928)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0673], device='cuda:0', requires_grad=True)
2022-03-23 19:55:22.124205
Epoch: [11][0/18], lr: 0.00100	Time 3.219 (3.219)	Data 2.065 (2.065)	Loss 0.1765 (0.1765)	Loss CE 0.1108 (0.1108)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6298 (0.6298)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9228], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0680], device='cuda:0', requires_grad=True)
2022-03-23 19:55:37.545370
Epoch: [12][0/18], lr: 0.00100	Time 3.370 (3.370)	Data 2.315 (2.315)	Loss 0.0751 (0.0751)	Loss CE 0.0127 (0.0127)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5976 (0.5976)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0670], device='cuda:0', requires_grad=True)
2022-03-23 19:55:52.755318
Epoch: [13][0/18], lr: 0.00100	Time 3.209 (3.209)	Data 2.095 (2.095)	Loss 0.0695 (0.0695)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6585 (0.6585)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9229], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0676], device='cuda:0', requires_grad=True)
2022-03-23 19:56:08.184136
Epoch: [14][0/18], lr: 0.00100	Time 3.273 (3.273)	Data 2.485 (2.485)	Loss 0.0680 (0.0680)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6415 (0.6415)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9259], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0692], device='cuda:0', requires_grad=True)
2022-03-23 19:56:23.485781
Epoch: [15][0/18], lr: 0.00100	Time 3.266 (3.266)	Data 2.123 (2.123)	Loss 0.0722 (0.0722)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6687 (0.6687)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9287], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0708], device='cuda:0', requires_grad=True)
2022-03-23 19:56:38.584269
Epoch: [16][0/18], lr: 0.00100	Time 3.119 (3.119)	Data 2.067 (2.067)	Loss 0.0877 (0.0877)	Loss CE 0.0207 (0.0207)	Loss KD (Logit) 0.0094 (0.0094)	Loss KD (GCAM) 0.0063 (0.0063)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6451 (0.6451)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9316], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0723], device='cuda:0', requires_grad=True)
2022-03-23 19:56:53.894878
Epoch: [17][0/18], lr: 0.00100	Time 3.146 (3.146)	Data 1.976 (1.976)	Loss 0.0655 (0.0655)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0098 (0.0098)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6205 (0.6205)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9336], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0733], device='cuda:0', requires_grad=True)
2022-03-23 19:57:09.456140
Epoch: [18][0/18], lr: 0.00100	Time 3.272 (3.272)	Data 2.539 (2.539)	Loss 0.0679 (0.0679)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0063 (0.0063)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6512 (0.6512)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9350], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 19:57:24.706444
Epoch: [19][0/18], lr: 0.00100	Time 3.339 (3.339)	Data 2.674 (2.674)	Loss 0.0647 (0.0647)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0062 (0.0062)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6169 (0.6169)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0740], device='cuda:0', requires_grad=True)
2022-03-23 19:57:39.761912
Epoch: [20][0/18], lr: 0.00010	Time 3.168 (3.168)	Data 1.984 (1.984)	Loss 0.0669 (0.0669)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6300 (0.6300)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9346], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0738], device='cuda:0', requires_grad=True)
2022-03-23 19:57:55.088582
Epoch: [21][0/18], lr: 0.00010	Time 3.155 (3.155)	Data 2.138 (2.138)	Loss 0.0628 (0.0628)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5971 (0.5971)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9345], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0737], device='cuda:0', requires_grad=True)
2022-03-23 19:58:10.403292
Epoch: [22][0/18], lr: 0.00010	Time 3.416 (3.416)	Data 2.714 (2.714)	Loss 0.0677 (0.0677)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6471 (0.6471)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9346], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0738], device='cuda:0', requires_grad=True)
2022-03-23 19:58:25.666448
Epoch: [23][0/18], lr: 0.00010	Time 3.315 (3.315)	Data 2.268 (2.268)	Loss 0.0647 (0.0647)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6088 (0.6088)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9348], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0738], device='cuda:0', requires_grad=True)
2022-03-23 19:58:40.979706
Epoch: [24][0/18], lr: 0.00010	Time 3.322 (3.322)	Data 2.509 (2.509)	Loss 0.0696 (0.0696)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0094 (0.0094)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6684 (0.6684)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0739], device='cuda:0', requires_grad=True)
2022-03-23 19:58:56.407353
Epoch: [25][0/18], lr: 0.00010	Time 3.290 (3.290)	Data 2.441 (2.441)	Loss 0.0734 (0.0734)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0057 (0.0057)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6911 (0.6911)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9350], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0739], device='cuda:0', requires_grad=True)
2022-03-23 19:59:11.831140
Epoch: [26][0/18], lr: 0.00010	Time 3.456 (3.456)	Data 2.071 (2.071)	Loss 0.0656 (0.0656)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6315 (0.6315)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0740], device='cuda:0', requires_grad=True)
2022-03-23 19:59:27.237359
Epoch: [27][0/18], lr: 0.00010	Time 3.413 (3.413)	Data 2.432 (2.432)	Loss 0.0663 (0.0663)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6337 (0.6337)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0741], device='cuda:0', requires_grad=True)
2022-03-23 19:59:42.302953
Epoch: [28][0/18], lr: 0.00010	Time 3.181 (3.181)	Data 2.262 (2.262)	Loss 0.0702 (0.0702)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0059 (0.0059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6707 (0.6707)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9354], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0741], device='cuda:0', requires_grad=True)
2022-03-23 19:59:57.781535
Epoch: [29][0/18], lr: 0.00010	Time 3.183 (3.183)	Data 2.060 (2.060)	Loss 0.0679 (0.0679)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6408 (0.6408)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0741], device='cuda:0', requires_grad=True)
2022-03-23 20:00:13.100427
Epoch: [30][0/18], lr: 0.00001	Time 3.068 (3.068)	Data 2.320 (2.320)	Loss 0.0829 (0.0829)	Loss CE 0.0169 (0.0169)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0059 (0.0059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6365 (0.6365)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:00:28.552242
Epoch: [31][0/18], lr: 0.00001	Time 3.351 (3.351)	Data 2.675 (2.675)	Loss 0.0622 (0.0622)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5944 (0.5944)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:00:43.869151
Epoch: [32][0/18], lr: 0.00001	Time 3.323 (3.323)	Data 1.982 (1.982)	Loss 0.0668 (0.0668)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0063 (0.0063)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6309 (0.6309)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:00:59.071551
Epoch: [33][0/18], lr: 0.00001	Time 3.267 (3.267)	Data 2.208 (2.208)	Loss 0.0675 (0.0675)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6423 (0.6423)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:01:14.397058
Epoch: [34][0/18], lr: 0.00001	Time 3.254 (3.254)	Data 2.173 (2.173)	Loss 0.0695 (0.0695)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0062 (0.0062)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6331 (0.6331)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9355], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:01:29.700282
Epoch: [35][0/18], lr: 0.00001	Time 3.240 (3.240)	Data 2.182 (2.182)	Loss 0.0675 (0.0675)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6454 (0.6454)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:01:45.104195
Epoch: [36][0/18], lr: 0.00001	Time 3.337 (3.337)	Data 2.103 (2.103)	Loss 0.0720 (0.0720)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0063 (0.0063)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6926 (0.6926)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:02:00.525042
Epoch: [37][0/18], lr: 0.00001	Time 3.543 (3.543)	Data 2.265 (2.265)	Loss 0.0710 (0.0710)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0091 (0.0091)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6641 (0.6641)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:02:15.797105
Epoch: [38][0/18], lr: 0.00001	Time 3.162 (3.162)	Data 2.391 (2.391)	Loss 0.0709 (0.0709)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6807 (0.6807)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:02:31.310278
Epoch: [39][0/18], lr: 0.00001	Time 3.396 (3.396)	Data 2.615 (2.615)	Loss 0.0686 (0.0686)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6591 (0.6591)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:02:46.591706
Epoch: [40][0/18], lr: 0.00001	Time 3.305 (3.305)	Data 2.515 (2.515)	Loss 0.0736 (0.0736)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0092 (0.0092)	Loss KD (GCAM) 0.0063 (0.0063)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6844 (0.6844)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:03:02.092564
Epoch: [41][0/18], lr: 0.00001	Time 3.377 (3.377)	Data 2.721 (2.721)	Loss 0.0694 (0.0694)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6482 (0.6482)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:03:17.336392
Epoch: [42][0/18], lr: 0.00001	Time 3.204 (3.204)	Data 1.922 (1.922)	Loss 0.0993 (0.0993)	Loss CE 0.0329 (0.0329)	Loss KD (Logit) 0.0099 (0.0099)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6389 (0.6389)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:03:32.355597
Epoch: [43][0/18], lr: 0.00001	Time 3.092 (3.092)	Data 2.160 (2.160)	Loss 0.0658 (0.0658)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0059 (0.0059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6269 (0.6269)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:03:47.641071
Epoch: [44][0/18], lr: 0.00001	Time 3.204 (3.204)	Data 2.162 (2.162)	Loss 0.0655 (0.0655)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0097 (0.0097)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6106 (0.6106)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:04:03.003279
Epoch: [45][0/18], lr: 0.00001	Time 3.336 (3.336)	Data 1.978 (1.978)	Loss 0.0634 (0.0634)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0096 (0.0096)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5998 (0.5998)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:04:18.057441
Epoch: [46][0/18], lr: 0.00001	Time 3.141 (3.141)	Data 1.892 (1.892)	Loss 0.0694 (0.0694)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0062 (0.0062)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6330 (0.6330)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:04:33.306520
Epoch: [47][0/18], lr: 0.00001	Time 3.220 (3.220)	Data 1.905 (1.905)	Loss 0.0720 (0.0720)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0060 (0.0060)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6916 (0.6916)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:04:48.713817
Epoch: [48][0/18], lr: 0.00001	Time 3.412 (3.412)	Data 2.018 (2.018)	Loss 0.0675 (0.0675)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0095 (0.0095)	Loss KD (GCAM) 0.0059 (0.0059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6357 (0.6357)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:05:03.870294
Epoch: [49][0/18], lr: 0.00001	Time 3.310 (3.310)	Data 2.273 (2.273)	Loss 0.0682 (0.0682)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0093 (0.0093)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6554 (0.6554)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9356], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=243, sigma=tensor([3.9356]), eta=tensor([3.0742])
  (fc1): CosineLinear(input_features=512, output_features=237, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 203
video number + exemplar : 203
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=243, sigma=tensor([3.9356]), eta=tensor([3.0742])
  (fc1): CosineLinear(input_features=512, output_features=237, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 405
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-23 20:05:33.269804
Epoch: [0][0/12], lr: 0.00050	Time 2.871 (2.871)	Data 2.385 (2.385)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9358], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0742], device='cuda:0', requires_grad=True)
2022-03-23 20:05:41.181867
Epoch: [1][0/12], lr: 0.00050	Time 2.909 (2.909)	Data 2.066 (2.066)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9357], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0740], device='cuda:0', requires_grad=True)
2022-03-23 20:05:49.087577
Epoch: [2][0/12], lr: 0.00050	Time 2.774 (2.774)	Data 1.896 (1.896)	Loss 0.0193 (0.0193)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9367], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0745], device='cuda:0', requires_grad=True)
2022-03-23 20:05:56.857899
Epoch: [3][0/12], lr: 0.00050	Time 2.879 (2.879)	Data 1.856 (1.856)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9380], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0752], device='cuda:0', requires_grad=True)
2022-03-23 20:06:05.015182
Epoch: [4][0/12], lr: 0.00050	Time 3.238 (3.238)	Data 2.727 (2.727)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9390], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0757], device='cuda:0', requires_grad=True)
2022-03-23 20:06:12.914861
Epoch: [5][0/12], lr: 0.00050	Time 2.879 (2.879)	Data 2.107 (2.107)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9396], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0760], device='cuda:0', requires_grad=True)
2022-03-23 20:06:20.634013
Epoch: [6][0/12], lr: 0.00050	Time 2.767 (2.767)	Data 1.865 (1.865)	Loss 0.0052 (0.0052)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9407], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0766], device='cuda:0', requires_grad=True)
2022-03-23 20:06:28.655350
Epoch: [7][0/12], lr: 0.00050	Time 3.114 (3.114)	Data 2.589 (2.589)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0772], device='cuda:0', requires_grad=True)
2022-03-23 20:06:36.394961
Epoch: [8][0/12], lr: 0.00050	Time 2.863 (2.863)	Data 1.818 (1.818)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9421], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0775], device='cuda:0', requires_grad=True)
2022-03-23 20:06:44.030055
Epoch: [9][0/12], lr: 0.00050	Time 2.757 (2.757)	Data 2.265 (2.265)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9426], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0777], device='cuda:0', requires_grad=True)
2022-03-23 20:06:51.915530
Epoch: [10][0/12], lr: 0.00050	Time 2.875 (2.875)	Data 2.419 (2.419)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9431], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0778], device='cuda:0', requires_grad=True)
2022-03-23 20:06:59.549189
Epoch: [11][0/12], lr: 0.00050	Time 2.696 (2.696)	Data 1.840 (1.840)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9432], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0778], device='cuda:0', requires_grad=True)
2022-03-23 20:07:07.512601
Epoch: [12][0/12], lr: 0.00050	Time 3.102 (3.102)	Data 2.579 (2.579)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9431], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0776], device='cuda:0', requires_grad=True)
2022-03-23 20:07:15.324587
Epoch: [13][0/12], lr: 0.00050	Time 2.858 (2.858)	Data 1.978 (1.978)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9431], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0775], device='cuda:0', requires_grad=True)
2022-03-23 20:07:23.019179
Epoch: [14][0/12], lr: 0.00050	Time 2.627 (2.627)	Data 1.860 (1.860)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9430], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0772], device='cuda:0', requires_grad=True)
2022-03-23 20:07:30.928098
Epoch: [15][0/12], lr: 0.00050	Time 2.919 (2.919)	Data 2.275 (2.275)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9433], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0773], device='cuda:0', requires_grad=True)
2022-03-23 20:07:38.435872
Epoch: [16][0/12], lr: 0.00050	Time 2.748 (2.748)	Data 1.997 (1.997)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9432], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0772], device='cuda:0', requires_grad=True)
2022-03-23 20:07:45.988264
Epoch: [17][0/12], lr: 0.00050	Time 2.675 (2.675)	Data 1.833 (1.833)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9432], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0770], device='cuda:0', requires_grad=True)
2022-03-23 20:07:53.781353
Epoch: [18][0/12], lr: 0.00050	Time 2.909 (2.909)	Data 1.973 (1.973)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9433], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0769], device='cuda:0', requires_grad=True)
2022-03-23 20:08:01.637948
Epoch: [19][0/12], lr: 0.00050	Time 2.775 (2.775)	Data 1.859 (1.859)	Loss 0.0061 (0.0061)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9432], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_015.pth.tar
exemplar : 405
Computing the class mean vectors...
Eval Task 0 for Age 15
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.325 (4.325)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.339 (0.460)	Prec@1 75.000 (68.441)
Testing Results: Prec@1 68.228
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 81.250 (75.928)
Testing Results (NME): Prec@1 75.611
Eval Task 1 for Age 15
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.556 (3.556)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 50.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 68.966
Eval Task 2 for Age 15
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.629 (3.629)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 52.308
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 49.231
Eval Task 3 for Age 15
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.842 (3.842)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 62.500
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 61.250
Eval Task 4 for Age 15
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.010 (4.010)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 76.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 77.647
Eval Task 5 for Age 15
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.674 (3.674)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 67.742
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 67.742
Eval Task 6 for Age 15
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.911 (3.911)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 53.086
Eval Task 7 for Age 15
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.802 (3.802)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 89.552
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.627
Eval Task 8 for Age 15
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.168 (3.168)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 45.455
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 56.061
Eval Task 9 for Age 15
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.579 (3.579)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 70.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 50.667
Eval Task 10 for Age 15
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.720 (3.720)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 74.419
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 79.070
Eval Task 11 for Age 15
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.487 (3.487)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 87.097
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 77.419
Eval Task 12 for Age 15
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.874 (3.874)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.771
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 15
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.624 (3.624)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 69.737
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 82.895
Eval Task 14 for Age 15
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.959 (3.959)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 97.561
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 95.122
Eval Task 15 for Age 15
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.539 (3.539)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.500
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80]
Method : OURS
----AGE 16----
current_task  [69, 36]
current_head  83
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06363961030678927]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=249, sigma=tensor([3.9432]), eta=tensor([3.0767])
  (fc1): CosineLinear(input_features=512, output_features=243, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 172
video number + exemplar : 577
DataLoader Constructed : Train 18
Optimizer Constructed
video number : 172
video number + exemplar : 172
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 20:12:50.097819
Epoch: [0][0/18], lr: 0.00100	Time 3.442 (3.442)	Data 2.153 (2.153)	Loss 0.1207 (0.1207)	Loss CE 0.0443 (0.0443)	Loss KD (Logit) 0.1013 (0.1013)	Loss KD (GCAM) 0.0232 (0.0232)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6298 (0.6298)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0713], device='cuda:0', requires_grad=True)
2022-03-23 20:13:05.084098
Epoch: [1][0/18], lr: 0.00100	Time 3.343 (3.343)	Data 2.406 (2.406)	Loss 0.1782 (0.1782)	Loss CE 0.0984 (0.0984)	Loss KD (Logit) 0.1047 (0.1047)	Loss KD (GCAM) 0.0281 (0.0281)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6473 (0.6473)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.9351], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0705], device='cuda:0', requires_grad=True)
2022-03-23 20:13:20.392662
Epoch: [2][0/18], lr: 0.00100	Time 3.502 (3.502)	Data 2.714 (2.714)	Loss 0.0870 (0.0870)	Loss CE 0.0072 (0.0072)	Loss KD (Logit) 0.1092 (0.1092)	Loss KD (GCAM) 0.0333 (0.0333)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6278 (0.6278)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9388], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0733], device='cuda:0', requires_grad=True)
2022-03-23 20:13:35.870360
Epoch: [3][0/18], lr: 0.00100	Time 3.357 (3.357)	Data 2.420 (2.420)	Loss 0.0846 (0.0846)	Loss CE 0.0056 (0.0056)	Loss KD (Logit) 0.1056 (0.1056)	Loss KD (GCAM) 0.0358 (0.0358)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6159 (0.6159)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9419], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0754], device='cuda:0', requires_grad=True)
2022-03-23 20:13:51.204563
Epoch: [4][0/18], lr: 0.00100	Time 3.321 (3.321)	Data 2.269 (2.269)	Loss 0.0808 (0.0808)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.1054 (0.1054)	Loss KD (GCAM) 0.0309 (0.0309)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6061 (0.6061)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9440], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0767], device='cuda:0', requires_grad=True)
2022-03-23 20:14:06.293139
Epoch: [5][0/18], lr: 0.00100	Time 3.232 (3.232)	Data 2.518 (2.518)	Loss 0.1483 (0.1483)	Loss CE 0.0631 (0.0631)	Loss KD (Logit) 0.1089 (0.1089)	Loss KD (GCAM) 0.0325 (0.0325)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6857 (0.6857)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.9477], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0784], device='cuda:0', requires_grad=True)
2022-03-23 20:14:21.572701
Epoch: [6][0/18], lr: 0.00100	Time 3.319 (3.319)	Data 2.513 (2.513)	Loss 0.0860 (0.0860)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 0.1087 (0.1087)	Loss KD (GCAM) 0.0356 (0.0356)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6243 (0.6243)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0806], device='cuda:0', requires_grad=True)
2022-03-23 20:14:36.484995
Epoch: [7][0/18], lr: 0.00100	Time 3.063 (3.063)	Data 2.262 (2.262)	Loss 0.1066 (0.1066)	Loss CE 0.0327 (0.0327)	Loss KD (Logit) 0.1066 (0.1066)	Loss KD (GCAM) 0.0308 (0.0308)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5784 (0.5784)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9580], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0849], device='cuda:0', requires_grad=True)
2022-03-23 20:14:51.763869
Epoch: [8][0/18], lr: 0.00100	Time 3.376 (3.376)	Data 2.632 (2.632)	Loss 0.0853 (0.0853)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.1091 (0.1091)	Loss KD (GCAM) 0.0333 (0.0333)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6290 (0.6290)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0837], device='cuda:0', requires_grad=True)
2022-03-23 20:15:07.019561
Epoch: [9][0/18], lr: 0.00100	Time 3.138 (3.138)	Data 1.875 (1.875)	Loss 0.0800 (0.0800)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.1092 (0.1092)	Loss KD (GCAM) 0.0324 (0.0324)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6069 (0.6069)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0856], device='cuda:0', requires_grad=True)
2022-03-23 20:15:22.392719
Epoch: [10][0/18], lr: 0.00100	Time 3.240 (3.240)	Data 2.139 (2.139)	Loss 0.0798 (0.0798)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.1064 (0.1064)	Loss KD (GCAM) 0.0330 (0.0330)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6107 (0.6107)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9606], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0870], device='cuda:0', requires_grad=True)
2022-03-23 20:15:37.837157
Epoch: [11][0/18], lr: 0.00100	Time 3.277 (3.277)	Data 2.357 (2.357)	Loss 0.0866 (0.0866)	Loss CE 0.0087 (0.0087)	Loss KD (Logit) 0.1113 (0.1113)	Loss KD (GCAM) 0.0348 (0.0348)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6044 (0.6044)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9630], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0883], device='cuda:0', requires_grad=True)
2022-03-23 20:15:53.073054
Epoch: [12][0/18], lr: 0.00100	Time 3.304 (3.304)	Data 2.614 (2.614)	Loss 0.1568 (0.1568)	Loss CE 0.0742 (0.0742)	Loss KD (Logit) 0.1116 (0.1116)	Loss KD (GCAM) 0.0333 (0.0333)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6546 (0.6546)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9644], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0885], device='cuda:0', requires_grad=True)
2022-03-23 20:16:08.212495
Epoch: [13][0/18], lr: 0.00100	Time 3.252 (3.252)	Data 2.479 (2.479)	Loss 0.1621 (0.1621)	Loss CE 0.0783 (0.0783)	Loss KD (Logit) 0.1092 (0.1092)	Loss KD (GCAM) 0.0337 (0.0337)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6675 (0.6675)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9660], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0893], device='cuda:0', requires_grad=True)
2022-03-23 20:16:23.383854
Epoch: [14][0/18], lr: 0.00100	Time 3.277 (3.277)	Data 2.565 (2.565)	Loss 0.0869 (0.0869)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.1096 (0.1096)	Loss KD (GCAM) 0.0334 (0.0334)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6374 (0.6374)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9684], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0907], device='cuda:0', requires_grad=True)
2022-03-23 20:16:38.323370
Epoch: [15][0/18], lr: 0.00100	Time 3.116 (3.116)	Data 1.899 (1.899)	Loss 0.0855 (0.0855)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.1095 (0.1095)	Loss KD (GCAM) 0.0337 (0.0337)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6617 (0.6617)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9705], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0918], device='cuda:0', requires_grad=True)
2022-03-23 20:16:53.642417
Epoch: [16][0/18], lr: 0.00100	Time 3.254 (3.254)	Data 2.105 (2.105)	Loss 0.0782 (0.0782)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.1097 (0.1097)	Loss KD (GCAM) 0.0313 (0.0313)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5976 (0.5976)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9689], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0909], device='cuda:0', requires_grad=True)
2022-03-23 20:17:08.840616
Epoch: [17][0/18], lr: 0.00100	Time 3.201 (3.201)	Data 2.036 (2.036)	Loss 0.0827 (0.0827)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.1101 (0.1101)	Loss KD (GCAM) 0.0355 (0.0355)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6435 (0.6435)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0923], device='cuda:0', requires_grad=True)
2022-03-23 20:17:24.105451
Epoch: [18][0/18], lr: 0.00100	Time 3.338 (3.338)	Data 2.608 (2.608)	Loss 0.1028 (0.1028)	Loss CE 0.0227 (0.0227)	Loss KD (Logit) 0.1103 (0.1103)	Loss KD (GCAM) 0.0338 (0.0338)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6293 (0.6293)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9741], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0940], device='cuda:0', requires_grad=True)
2022-03-23 20:17:38.990103
Epoch: [19][0/18], lr: 0.00100	Time 3.090 (3.090)	Data 1.848 (1.848)	Loss 0.0826 (0.0826)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 0.1099 (0.1099)	Loss KD (GCAM) 0.0349 (0.0349)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5845 (0.5845)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9766], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:17:54.347689
Epoch: [20][0/18], lr: 0.00010	Time 3.196 (3.196)	Data 2.105 (2.105)	Loss 0.0805 (0.0805)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1092 (0.1092)	Loss KD (GCAM) 0.0305 (0.0305)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6398 (0.6398)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9767], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0954], device='cuda:0', requires_grad=True)
2022-03-23 20:18:09.424486
Epoch: [21][0/18], lr: 0.00010	Time 3.155 (3.155)	Data 2.331 (2.331)	Loss 0.0834 (0.0834)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.1091 (0.1091)	Loss KD (GCAM) 0.0308 (0.0308)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6623 (0.6623)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9767], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:18:24.530254
Epoch: [22][0/18], lr: 0.00010	Time 3.162 (3.162)	Data 2.033 (2.033)	Loss 0.0760 (0.0760)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.1077 (0.1077)	Loss KD (GCAM) 0.0312 (0.0312)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5882 (0.5882)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9768], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0954], device='cuda:0', requires_grad=True)
2022-03-23 20:18:39.767696
Epoch: [23][0/18], lr: 0.00010	Time 3.163 (3.163)	Data 1.958 (1.958)	Loss 0.0739 (0.0739)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1062 (0.1062)	Loss KD (GCAM) 0.0307 (0.0307)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5774 (0.5774)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9769], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0954], device='cuda:0', requires_grad=True)
2022-03-23 20:18:54.954220
Epoch: [24][0/18], lr: 0.00010	Time 3.321 (3.321)	Data 2.226 (2.226)	Loss 0.0778 (0.0778)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.1079 (0.1079)	Loss KD (GCAM) 0.0306 (0.0306)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6053 (0.6053)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9769], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0954], device='cuda:0', requires_grad=True)
2022-03-23 20:19:09.968051
Epoch: [25][0/18], lr: 0.00010	Time 3.167 (3.167)	Data 2.173 (2.173)	Loss 0.0804 (0.0804)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.1108 (0.1108)	Loss KD (GCAM) 0.0311 (0.0311)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6224 (0.6224)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9771], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0955], device='cuda:0', requires_grad=True)
2022-03-23 20:19:25.282076
Epoch: [26][0/18], lr: 0.00010	Time 3.207 (3.207)	Data 2.249 (2.249)	Loss 0.0864 (0.0864)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.1079 (0.1079)	Loss KD (GCAM) 0.0315 (0.0315)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6658 (0.6658)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9771], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0954], device='cuda:0', requires_grad=True)
2022-03-23 20:19:40.678926
Epoch: [27][0/18], lr: 0.00010	Time 3.434 (3.434)	Data 2.660 (2.660)	Loss 0.0829 (0.0829)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1083 (0.1083)	Loss KD (GCAM) 0.0331 (0.0331)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6588 (0.6588)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9771], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0954], device='cuda:0', requires_grad=True)
2022-03-23 20:19:56.252392
Epoch: [28][0/18], lr: 0.00010	Time 3.370 (3.370)	Data 2.195 (2.195)	Loss 0.0749 (0.0749)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1070 (0.1070)	Loss KD (GCAM) 0.0315 (0.0315)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5829 (0.5829)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9771], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0954], device='cuda:0', requires_grad=True)
2022-03-23 20:20:11.755696
Epoch: [29][0/18], lr: 0.00010	Time 3.533 (3.533)	Data 2.149 (2.149)	Loss 0.0798 (0.0798)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1078 (0.1078)	Loss KD (GCAM) 0.0330 (0.0330)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6252 (0.6252)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9769], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:20:26.780295
Epoch: [30][0/18], lr: 0.00001	Time 3.295 (3.295)	Data 2.044 (2.044)	Loss 0.0788 (0.0788)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.1101 (0.1101)	Loss KD (GCAM) 0.0335 (0.0335)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6026 (0.6026)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9769], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:20:42.051491
Epoch: [31][0/18], lr: 0.00001	Time 3.223 (3.223)	Data 2.551 (2.551)	Loss 0.0813 (0.0813)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1078 (0.1078)	Loss KD (GCAM) 0.0291 (0.0291)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6533 (0.6533)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:20:57.399889
Epoch: [32][0/18], lr: 0.00001	Time 3.196 (3.196)	Data 1.906 (1.906)	Loss 0.0802 (0.0802)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.1099 (0.1099)	Loss KD (GCAM) 0.0302 (0.0302)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6194 (0.6194)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:21:12.559752
Epoch: [33][0/18], lr: 0.00001	Time 3.170 (3.170)	Data 2.006 (2.006)	Loss 0.0797 (0.0797)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.1090 (0.1090)	Loss KD (GCAM) 0.0330 (0.0330)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6180 (0.6180)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:21:28.170472
Epoch: [34][0/18], lr: 0.00001	Time 3.467 (3.467)	Data 1.894 (1.894)	Loss 0.0883 (0.0883)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.1101 (0.1101)	Loss KD (GCAM) 0.0338 (0.0338)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6686 (0.6686)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:21:43.193943
Epoch: [35][0/18], lr: 0.00001	Time 2.948 (2.948)	Data 2.012 (2.012)	Loss 0.0760 (0.0760)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1072 (0.1072)	Loss KD (GCAM) 0.0314 (0.0314)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5929 (0.5929)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:21:58.738786
Epoch: [36][0/18], lr: 0.00001	Time 3.335 (3.335)	Data 2.471 (2.471)	Loss 0.0854 (0.0854)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.1088 (0.1088)	Loss KD (GCAM) 0.0319 (0.0319)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6647 (0.6647)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:22:13.526846
Epoch: [37][0/18], lr: 0.00001	Time 2.986 (2.986)	Data 1.992 (1.992)	Loss 0.0786 (0.0786)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1096 (0.1096)	Loss KD (GCAM) 0.0335 (0.0335)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6109 (0.6109)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:22:28.747546
Epoch: [38][0/18], lr: 0.00001	Time 3.222 (3.222)	Data 2.080 (2.080)	Loss 0.0813 (0.0813)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1107 (0.1107)	Loss KD (GCAM) 0.0298 (0.0298)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6504 (0.6504)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:22:44.124643
Epoch: [39][0/18], lr: 0.00001	Time 3.325 (3.325)	Data 2.120 (2.120)	Loss 0.0788 (0.0788)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.1082 (0.1082)	Loss KD (GCAM) 0.0342 (0.0342)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6016 (0.6016)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:22:59.322588
Epoch: [40][0/18], lr: 0.00001	Time 3.287 (3.287)	Data 2.464 (2.464)	Loss 0.0863 (0.0863)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1123 (0.1123)	Loss KD (GCAM) 0.0353 (0.0353)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6827 (0.6827)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:23:14.453805
Epoch: [41][0/18], lr: 0.00001	Time 3.167 (3.167)	Data 2.037 (2.037)	Loss 0.0753 (0.0753)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1064 (0.1064)	Loss KD (GCAM) 0.0309 (0.0309)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5893 (0.5893)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:23:29.581427
Epoch: [42][0/18], lr: 0.00001	Time 3.138 (3.138)	Data 2.193 (2.193)	Loss 0.0862 (0.0862)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.1084 (0.1084)	Loss KD (GCAM) 0.0313 (0.0313)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6652 (0.6652)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:23:44.609258
Epoch: [43][0/18], lr: 0.00001	Time 3.134 (3.134)	Data 2.108 (2.108)	Loss 0.0756 (0.0756)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.1090 (0.1090)	Loss KD (GCAM) 0.0309 (0.0309)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5928 (0.5928)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:23:59.875572
Epoch: [44][0/18], lr: 0.00001	Time 3.274 (3.274)	Data 2.375 (2.375)	Loss 0.0839 (0.0839)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1079 (0.1079)	Loss KD (GCAM) 0.0319 (0.0319)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6704 (0.6704)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:24:15.021944
Epoch: [45][0/18], lr: 0.00001	Time 3.238 (3.238)	Data 2.123 (2.123)	Loss 0.0851 (0.0851)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.1089 (0.1089)	Loss KD (GCAM) 0.0332 (0.0332)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6273 (0.6273)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:24:30.291610
Epoch: [46][0/18], lr: 0.00001	Time 3.134 (3.134)	Data 1.866 (1.866)	Loss 0.0784 (0.0784)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1080 (0.1080)	Loss KD (GCAM) 0.0312 (0.0312)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6182 (0.6182)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:24:45.596847
Epoch: [47][0/18], lr: 0.00001	Time 3.238 (3.238)	Data 2.224 (2.224)	Loss 0.0827 (0.0827)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.1098 (0.1098)	Loss KD (GCAM) 0.0314 (0.0314)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6613 (0.6613)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:25:00.577972
Epoch: [48][0/18], lr: 0.00001	Time 3.132 (3.132)	Data 1.890 (1.890)	Loss 0.0798 (0.0798)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.1065 (0.1065)	Loss KD (GCAM) 0.0339 (0.0339)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6086 (0.6086)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
2022-03-23 20:25:15.880916
Epoch: [49][0/18], lr: 0.00001	Time 3.212 (3.212)	Data 2.453 (2.453)	Loss 0.0779 (0.0779)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.1081 (0.1081)	Loss KD (GCAM) 0.0355 (0.0355)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5912 (0.5912)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0953], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=249, sigma=tensor([3.9770]), eta=tensor([3.0953])
  (fc1): CosineLinear(input_features=512, output_features=243, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 172
video number + exemplar : 172
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=249, sigma=tensor([3.9770]), eta=tensor([3.0953])
  (fc1): CosineLinear(input_features=512, output_features=243, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 415
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-23 20:25:44.961076
Epoch: [0][0/12], lr: 0.00050	Time 2.804 (2.804)	Data 1.863 (1.863)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9769], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-23 20:25:52.696852
Epoch: [1][0/12], lr: 0.00050	Time 2.894 (2.894)	Data 2.239 (2.239)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9769], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0950], device='cuda:0', requires_grad=True)
2022-03-23 20:26:00.357326
Epoch: [2][0/12], lr: 0.00050	Time 2.786 (2.786)	Data 2.364 (2.364)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9770], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-23 20:26:08.197424
Epoch: [3][0/12], lr: 0.00050	Time 2.907 (2.907)	Data 2.058 (2.058)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9772], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-23 20:26:15.914141
Epoch: [4][0/12], lr: 0.00050	Time 2.919 (2.919)	Data 2.361 (2.361)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9773], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0948], device='cuda:0', requires_grad=True)
2022-03-23 20:26:23.631606
Epoch: [5][0/12], lr: 0.00050	Time 2.679 (2.679)	Data 2.067 (2.067)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9767], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0945], device='cuda:0', requires_grad=True)
2022-03-23 20:26:31.402774
Epoch: [6][0/12], lr: 0.00050	Time 2.930 (2.930)	Data 2.485 (2.485)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9762], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0942], device='cuda:0', requires_grad=True)
2022-03-23 20:26:39.147631
Epoch: [7][0/12], lr: 0.00050	Time 2.913 (2.913)	Data 2.054 (2.054)	Loss 0.0117 (0.0117)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9764], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0942], device='cuda:0', requires_grad=True)
2022-03-23 20:26:47.047412
Epoch: [8][0/12], lr: 0.00050	Time 2.918 (2.918)	Data 2.466 (2.466)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9765], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0941], device='cuda:0', requires_grad=True)
2022-03-23 20:26:54.900143
Epoch: [9][0/12], lr: 0.00050	Time 2.871 (2.871)	Data 2.222 (2.222)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9766], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0941], device='cuda:0', requires_grad=True)
2022-03-23 20:27:02.904145
Epoch: [10][0/12], lr: 0.00050	Time 3.021 (3.021)	Data 2.157 (2.157)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9764], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-23 20:27:10.681331
Epoch: [11][0/12], lr: 0.00050	Time 2.809 (2.809)	Data 2.324 (2.324)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9761], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0935], device='cuda:0', requires_grad=True)
2022-03-23 20:27:18.570526
Epoch: [12][0/12], lr: 0.00050	Time 2.945 (2.945)	Data 2.263 (2.263)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9758], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0932], device='cuda:0', requires_grad=True)
2022-03-23 20:27:26.469442
Epoch: [13][0/12], lr: 0.00050	Time 2.918 (2.918)	Data 2.203 (2.203)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9756], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0929], device='cuda:0', requires_grad=True)
2022-03-23 20:27:34.299133
Epoch: [14][0/12], lr: 0.00050	Time 2.916 (2.916)	Data 2.172 (2.172)	Loss 0.0030 (0.0030)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9754], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0926], device='cuda:0', requires_grad=True)
2022-03-23 20:27:41.860774
Epoch: [15][0/12], lr: 0.00050	Time 2.771 (2.771)	Data 2.136 (2.136)	Loss 0.0086 (0.0086)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9754], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0924], device='cuda:0', requires_grad=True)
2022-03-23 20:27:49.462806
Epoch: [16][0/12], lr: 0.00050	Time 2.803 (2.803)	Data 1.770 (1.770)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9752], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0921], device='cuda:0', requires_grad=True)
2022-03-23 20:27:57.134040
Epoch: [17][0/12], lr: 0.00050	Time 2.830 (2.830)	Data 2.404 (2.404)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9749], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0918], device='cuda:0', requires_grad=True)
2022-03-23 20:28:05.308964
Epoch: [18][0/12], lr: 0.00050	Time 3.094 (3.094)	Data 2.593 (2.593)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9746], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0914], device='cuda:0', requires_grad=True)
2022-03-23 20:28:13.068824
Epoch: [19][0/12], lr: 0.00050	Time 2.958 (2.958)	Data 1.948 (1.948)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9742], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0910], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_016.pth.tar
exemplar : 415
Computing the class mean vectors...
Eval Task 0 for Age 16
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.328 (4.328)	Prec@1 43.750 (43.750)
Test: [100/123]	Time 0.355 (0.458)	Prec@1 68.750 (67.450)
Testing Results: Prec@1 67.057
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (74.691)
Testing Results (NME): Prec@1 74.084
Eval Task 1 for Age 16
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.756 (3.756)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 44.828
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 60.345
Eval Task 2 for Age 16
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.837 (3.837)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 32.308
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 44.615
Eval Task 3 for Age 16
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.883 (3.883)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 61.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 62.500
Eval Task 4 for Age 16
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.947 (3.947)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 76.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 77.647
Eval Task 5 for Age 16
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.854 (3.854)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 66.129
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 70.968
Eval Task 6 for Age 16
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.018 (4.018)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 41.975
Eval Task 7 for Age 16
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.788 (3.788)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.522
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 80.597
Eval Task 8 for Age 16
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.772 (3.772)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 48.485
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 53.030
Eval Task 9 for Age 16
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.439 (3.439)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 69.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 56.000
Eval Task 10 for Age 16
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.591 (3.591)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 82.558
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 79.070
Eval Task 11 for Age 16
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.109 (3.109)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 87.097
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 82.258
Eval Task 12 for Age 16
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.057 (4.057)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 90.361
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 16
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.764 (3.764)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 65.789
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 71.053
Eval Task 14 for Age 16
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.832 (3.832)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.780
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 96.341
Eval Task 15 for Age 16
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.869 (3.869)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 80.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 76.250
Eval Task 16 for Age 16
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.337 (3.337)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.071
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 75.000
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56]
Method : OURS
----AGE 17----
current_task  [61, 7]
current_head  85
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06442049363362563]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=255, sigma=tensor([3.9742]), eta=tensor([3.0910])
  (fc1): CosineLinear(input_features=512, output_features=249, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 206
video number + exemplar : 621
DataLoader Constructed : Train 19
Optimizer Constructed
video number : 206
video number + exemplar : 206
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 20:33:13.506772
Epoch: [0][0/19], lr: 0.00100	Time 3.478 (3.478)	Data 2.398 (2.398)	Loss 0.3995 (0.3995)	Loss CE 0.3362 (0.3362)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0023 (0.0023)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6225 (0.6225)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.9555], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0788], device='cuda:0', requires_grad=True)
2022-03-23 20:33:29.310415
Epoch: [1][0/19], lr: 0.00100	Time 3.365 (3.365)	Data 2.362 (2.362)	Loss 0.0715 (0.0715)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6632 (0.6632)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9503], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0755], device='cuda:0', requires_grad=True)
2022-03-23 20:33:45.458516
Epoch: [2][0/19], lr: 0.00100	Time 3.385 (3.385)	Data 2.436 (2.436)	Loss 0.3611 (0.3611)	Loss CE 0.3004 (0.3004)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5952 (0.5952)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9519], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0758], device='cuda:0', requires_grad=True)
2022-03-23 20:34:01.771109
Epoch: [3][0/19], lr: 0.00100	Time 3.427 (3.427)	Data 2.564 (2.564)	Loss 0.0702 (0.0702)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0034 (0.0034)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6454 (0.6454)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9589], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0802], device='cuda:0', requires_grad=True)
2022-03-23 20:34:17.882516
Epoch: [4][0/19], lr: 0.00100	Time 3.278 (3.278)	Data 2.306 (2.306)	Loss 0.0837 (0.0837)	Loss CE 0.0273 (0.0273)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5499 (0.5499)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9698], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0869], device='cuda:0', requires_grad=True)
2022-03-23 20:34:33.345525
Epoch: [5][0/19], lr: 0.00100	Time 3.017 (3.017)	Data 1.827 (1.827)	Loss 0.1987 (0.1987)	Loss CE 0.1371 (0.1371)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6025 (0.6025)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9746], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0903], device='cuda:0', requires_grad=True)
2022-03-23 20:34:49.146641
Epoch: [6][0/19], lr: 0.00100	Time 3.215 (3.215)	Data 2.177 (2.177)	Loss 0.1063 (0.1063)	Loss CE 0.0443 (0.0443)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6070 (0.6070)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9747], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0911], device='cuda:0', requires_grad=True)
2022-03-23 20:35:05.104498
Epoch: [7][0/19], lr: 0.00100	Time 3.354 (3.354)	Data 2.491 (2.491)	Loss 0.0695 (0.0695)	Loss CE 0.0113 (0.0113)	Loss KD (Logit) 0.0047 (0.0047)	Loss KD (GCAM) 0.0043 (0.0043)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5669 (0.5669)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9695], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0879], device='cuda:0', requires_grad=True)
2022-03-23 20:35:20.985781
Epoch: [8][0/19], lr: 0.00100	Time 3.244 (3.244)	Data 2.272 (2.272)	Loss 0.0709 (0.0709)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6616 (0.6616)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9699], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0883], device='cuda:0', requires_grad=True)
2022-03-23 20:35:36.887100
Epoch: [9][0/19], lr: 0.00100	Time 3.353 (3.353)	Data 2.625 (2.625)	Loss 0.0721 (0.0721)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0041 (0.0041)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6368 (0.6368)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0892], device='cuda:0', requires_grad=True)
2022-03-23 20:35:52.808488
Epoch: [10][0/19], lr: 0.00100	Time 3.375 (3.375)	Data 2.106 (2.106)	Loss 0.0651 (0.0651)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6140 (0.6140)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9746], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0912], device='cuda:0', requires_grad=True)
2022-03-23 20:36:08.614086
Epoch: [11][0/19], lr: 0.00100	Time 3.194 (3.194)	Data 1.978 (1.978)	Loss 0.0654 (0.0654)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6290 (0.6290)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9760], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0917], device='cuda:0', requires_grad=True)
2022-03-23 20:36:24.317300
Epoch: [12][0/19], lr: 0.00100	Time 3.064 (3.064)	Data 2.138 (2.138)	Loss 0.0725 (0.0725)	Loss CE 0.0095 (0.0095)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6162 (0.6162)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9761], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0912], device='cuda:0', requires_grad=True)
2022-03-23 20:36:40.386098
Epoch: [13][0/19], lr: 0.00100	Time 3.458 (3.458)	Data 1.969 (1.969)	Loss 0.1864 (0.1864)	Loss CE 0.1242 (0.1242)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0034 (0.0034)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6096 (0.6096)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0884], device='cuda:0', requires_grad=True)
2022-03-23 20:36:56.327849
Epoch: [14][0/19], lr: 0.00100	Time 3.314 (3.314)	Data 2.176 (2.176)	Loss 0.0770 (0.0770)	Loss CE 0.0135 (0.0135)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0040 (0.0040)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6204 (0.6204)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9723], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0889], device='cuda:0', requires_grad=True)
2022-03-23 20:37:12.371319
Epoch: [15][0/19], lr: 0.00100	Time 3.236 (3.236)	Data 2.525 (2.525)	Loss 0.0670 (0.0670)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6313 (0.6313)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9749], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0904], device='cuda:0', requires_grad=True)
2022-03-23 20:37:28.252932
Epoch: [16][0/19], lr: 0.00100	Time 3.215 (3.215)	Data 2.482 (2.482)	Loss 0.0668 (0.0668)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0041 (0.0041)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6321 (0.6321)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9717], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0889], device='cuda:0', requires_grad=True)
2022-03-23 20:37:43.995069
Epoch: [17][0/19], lr: 0.00100	Time 3.139 (3.139)	Data 2.094 (2.094)	Loss 0.0641 (0.0641)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6223 (0.6223)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9748], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0909], device='cuda:0', requires_grad=True)
2022-03-23 20:37:59.963851
Epoch: [18][0/19], lr: 0.00100	Time 3.269 (3.269)	Data 2.502 (2.502)	Loss 0.0627 (0.0627)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5948 (0.5948)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9773], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0926], device='cuda:0', requires_grad=True)
2022-03-23 20:38:15.805138
Epoch: [19][0/19], lr: 0.00100	Time 3.289 (3.289)	Data 2.436 (2.436)	Loss 0.0628 (0.0628)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6017 (0.6017)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9801], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0944], device='cuda:0', requires_grad=True)
2022-03-23 20:38:31.602915
Epoch: [20][0/19], lr: 0.00010	Time 3.187 (3.187)	Data 1.909 (1.909)	Loss 0.0744 (0.0744)	Loss CE 0.0143 (0.0143)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5859 (0.5859)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9804], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0946], device='cuda:0', requires_grad=True)
2022-03-23 20:38:47.408618
Epoch: [21][0/19], lr: 0.00010	Time 3.159 (3.159)	Data 1.993 (1.993)	Loss 0.0692 (0.0692)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6075 (0.6075)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-23 20:39:03.548810
Epoch: [22][0/19], lr: 0.00010	Time 3.384 (3.384)	Data 2.471 (2.471)	Loss 0.0622 (0.0622)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5994 (0.5994)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9812], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:39:19.434255
Epoch: [23][0/19], lr: 0.00010	Time 3.231 (3.231)	Data 2.281 (2.281)	Loss 0.0644 (0.0644)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6179 (0.6179)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9813], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:39:35.235623
Epoch: [24][0/19], lr: 0.00010	Time 3.221 (3.221)	Data 2.445 (2.445)	Loss 0.0602 (0.0602)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5803 (0.5803)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9813], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:39:51.152189
Epoch: [25][0/19], lr: 0.00010	Time 3.307 (3.307)	Data 2.164 (2.164)	Loss 0.0732 (0.0732)	Loss CE 0.0086 (0.0086)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6313 (0.6313)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-23 20:40:06.955001
Epoch: [26][0/19], lr: 0.00010	Time 3.266 (3.266)	Data 2.213 (2.213)	Loss 0.0670 (0.0670)	Loss CE 0.0053 (0.0053)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6018 (0.6018)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9813], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:40:22.767730
Epoch: [27][0/19], lr: 0.00010	Time 3.128 (3.128)	Data 1.928 (1.928)	Loss 0.0644 (0.0644)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6222 (0.6222)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:40:38.803818
Epoch: [28][0/19], lr: 0.00010	Time 3.219 (3.219)	Data 2.318 (2.318)	Loss 0.0703 (0.0703)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6570 (0.6570)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9813], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0950], device='cuda:0', requires_grad=True)
2022-03-23 20:40:54.557312
Epoch: [29][0/19], lr: 0.00010	Time 3.166 (3.166)	Data 1.951 (1.951)	Loss 0.0648 (0.0648)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6076 (0.6076)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9813], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:41:10.579084
Epoch: [30][0/19], lr: 0.00001	Time 3.173 (3.173)	Data 2.281 (2.281)	Loss 0.0670 (0.0670)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6412 (0.6412)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:41:26.428120
Epoch: [31][0/19], lr: 0.00001	Time 3.138 (3.138)	Data 1.972 (1.972)	Loss 0.0673 (0.0673)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6335 (0.6335)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:41:42.652327
Epoch: [32][0/19], lr: 0.00001	Time 3.607 (3.607)	Data 2.461 (2.461)	Loss 0.0621 (0.0621)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5948 (0.5948)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:41:58.673032
Epoch: [33][0/19], lr: 0.00001	Time 3.269 (3.269)	Data 2.411 (2.411)	Loss 0.0668 (0.0668)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6510 (0.6510)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:42:14.631453
Epoch: [34][0/19], lr: 0.00001	Time 3.144 (3.144)	Data 1.852 (1.852)	Loss 0.0694 (0.0694)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6651 (0.6651)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:42:30.626869
Epoch: [35][0/19], lr: 0.00001	Time 3.270 (3.270)	Data 2.292 (2.292)	Loss 0.0638 (0.0638)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6132 (0.6132)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:42:46.561050
Epoch: [36][0/19], lr: 0.00001	Time 3.200 (3.200)	Data 2.138 (2.138)	Loss 0.0601 (0.0601)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5846 (0.5846)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:43:02.430140
Epoch: [37][0/19], lr: 0.00001	Time 3.168 (3.168)	Data 1.904 (1.904)	Loss 0.0630 (0.0630)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6108 (0.6108)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:43:18.378980
Epoch: [38][0/19], lr: 0.00001	Time 3.148 (3.148)	Data 2.055 (2.055)	Loss 0.0591 (0.0591)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5714 (0.5714)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:43:34.327229
Epoch: [39][0/19], lr: 0.00001	Time 3.540 (3.540)	Data 1.952 (1.952)	Loss 0.0614 (0.0614)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5962 (0.5962)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:43:50.179576
Epoch: [40][0/19], lr: 0.00001	Time 3.267 (3.267)	Data 2.594 (2.594)	Loss 0.0714 (0.0714)	Loss CE 0.0066 (0.0066)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6334 (0.6334)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:44:06.130135
Epoch: [41][0/19], lr: 0.00001	Time 3.239 (3.239)	Data 2.220 (2.220)	Loss 0.0597 (0.0597)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5684 (0.5684)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:44:21.976192
Epoch: [42][0/19], lr: 0.00001	Time 3.160 (3.160)	Data 2.151 (2.151)	Loss 0.0636 (0.0636)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6172 (0.6172)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:44:37.917483
Epoch: [43][0/19], lr: 0.00001	Time 3.257 (3.257)	Data 1.954 (1.954)	Loss 0.0665 (0.0665)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6466 (0.6466)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:44:53.502116
Epoch: [44][0/19], lr: 0.00001	Time 3.158 (3.158)	Data 2.329 (2.329)	Loss 0.0613 (0.0613)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5953 (0.5953)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:45:09.234101
Epoch: [45][0/19], lr: 0.00001	Time 3.202 (3.202)	Data 2.124 (2.124)	Loss 0.0631 (0.0631)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6059 (0.6059)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0951], device='cuda:0', requires_grad=True)
2022-03-23 20:45:25.315384
Epoch: [46][0/19], lr: 0.00001	Time 3.339 (3.339)	Data 2.148 (2.148)	Loss 0.0679 (0.0679)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6490 (0.6490)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-23 20:45:41.102079
Epoch: [47][0/19], lr: 0.00001	Time 3.220 (3.220)	Data 2.154 (2.154)	Loss 0.0598 (0.0598)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5738 (0.5738)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-23 20:45:57.036626
Epoch: [48][0/19], lr: 0.00001	Time 3.265 (3.265)	Data 1.917 (1.917)	Loss 0.0711 (0.0711)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6553 (0.6553)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-23 20:46:13.370277
Epoch: [49][0/19], lr: 0.00001	Time 3.437 (3.437)	Data 2.722 (2.722)	Loss 0.0658 (0.0658)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0046 (0.0046)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6326 (0.6326)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=255, sigma=tensor([3.9815]), eta=tensor([3.0952])
  (fc1): CosineLinear(input_features=512, output_features=249, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 206
video number + exemplar : 206
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=255, sigma=tensor([3.9815]), eta=tensor([3.0952])
  (fc1): CosineLinear(input_features=512, output_features=249, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 425
DataLoader CBF Constructed : Train 13
Optimizer Constructed
2022-03-23 20:46:43.783879
Epoch: [0][0/13], lr: 0.00050	Time 2.893 (2.893)	Data 2.308 (2.308)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9817], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-23 20:46:51.934962
Epoch: [1][0/13], lr: 0.00050	Time 2.929 (2.929)	Data 2.465 (2.465)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-23 20:47:00.115162
Epoch: [2][0/13], lr: 0.00050	Time 2.904 (2.904)	Data 2.133 (2.133)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9818], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-23 20:47:08.641623
Epoch: [3][0/13], lr: 0.00050	Time 3.112 (3.112)	Data 2.238 (2.238)	Loss 0.0082 (0.0082)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9819], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-23 20:47:16.799921
Epoch: [4][0/13], lr: 0.00050	Time 2.806 (2.806)	Data 1.854 (1.854)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9818], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0946], device='cuda:0', requires_grad=True)
2022-03-23 20:47:24.868784
Epoch: [5][0/13], lr: 0.00050	Time 2.789 (2.789)	Data 1.881 (1.881)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9810], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-23 20:47:33.186408
Epoch: [6][0/13], lr: 0.00050	Time 2.954 (2.954)	Data 2.376 (2.376)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9803], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0932], device='cuda:0', requires_grad=True)
2022-03-23 20:47:41.505828
Epoch: [7][0/13], lr: 0.00050	Time 2.840 (2.840)	Data 2.072 (2.072)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
2022-03-23 20:47:49.702591
Epoch: [8][0/13], lr: 0.00050	Time 2.867 (2.867)	Data 1.889 (1.889)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9795], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0923], device='cuda:0', requires_grad=True)
2022-03-23 20:47:57.879865
Epoch: [9][0/13], lr: 0.00050	Time 2.853 (2.853)	Data 2.296 (2.296)	Loss 0.0041 (0.0041)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9793], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0921], device='cuda:0', requires_grad=True)
2022-03-23 20:48:06.158234
Epoch: [10][0/13], lr: 0.00050	Time 3.052 (3.052)	Data 2.579 (2.579)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9795], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0919], device='cuda:0', requires_grad=True)
2022-03-23 20:48:14.661940
Epoch: [11][0/13], lr: 0.00050	Time 3.139 (3.139)	Data 2.038 (2.038)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9793], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0916], device='cuda:0', requires_grad=True)
2022-03-23 20:48:23.055946
Epoch: [12][0/13], lr: 0.00050	Time 3.074 (3.074)	Data 2.253 (2.253)	Loss 0.0035 (0.0035)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9793], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0914], device='cuda:0', requires_grad=True)
2022-03-23 20:48:31.181831
Epoch: [13][0/13], lr: 0.00050	Time 2.768 (2.768)	Data 1.967 (1.967)	Loss 0.0039 (0.0039)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9792], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0912], device='cuda:0', requires_grad=True)
2022-03-23 20:48:39.628771
Epoch: [14][0/13], lr: 0.00050	Time 3.054 (3.054)	Data 2.493 (2.493)	Loss 0.0199 (0.0199)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9790], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0910], device='cuda:0', requires_grad=True)
2022-03-23 20:48:47.964317
Epoch: [15][0/13], lr: 0.00050	Time 3.102 (3.102)	Data 1.994 (1.994)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9789], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0908], device='cuda:0', requires_grad=True)
2022-03-23 20:48:56.142923
Epoch: [16][0/13], lr: 0.00050	Time 2.827 (2.827)	Data 2.186 (2.186)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9787], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0906], device='cuda:0', requires_grad=True)
2022-03-23 20:49:04.618374
Epoch: [17][0/13], lr: 0.00050	Time 3.174 (3.174)	Data 2.523 (2.523)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9786], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0904], device='cuda:0', requires_grad=True)
2022-03-23 20:49:12.717339
Epoch: [18][0/13], lr: 0.00050	Time 2.869 (2.869)	Data 2.340 (2.340)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9785], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0902], device='cuda:0', requires_grad=True)
2022-03-23 20:49:20.943646
Epoch: [19][0/13], lr: 0.00050	Time 2.870 (2.870)	Data 1.955 (1.955)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9781], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0898], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_017.pth.tar
exemplar : 425
Computing the class mean vectors...
Eval Task 0 for Age 17
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.544 (4.544)	Prec@1 68.750 (68.750)
Test: [100/123]	Time 0.341 (0.460)	Prec@1 62.500 (67.574)
Testing Results: Prec@1 67.057
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (72.649)
Testing Results (NME): Prec@1 72.149
Eval Task 1 for Age 17
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.563 (3.563)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 53.448
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 65.517
Eval Task 2 for Age 17
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.322 (3.322)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 38.462
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 53.846
Eval Task 3 for Age 17
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.777 (3.777)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 73.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 55.000
Eval Task 4 for Age 17
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.909 (3.909)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 56.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 67.059
Eval Task 5 for Age 17
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.690 (3.690)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 61.290
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 64.516
Eval Task 6 for Age 17
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.727 (3.727)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 49.383
Eval Task 7 for Age 17
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.874 (3.874)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 94.030
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 82.090
Eval Task 8 for Age 17
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.204 (3.204)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 57.576
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 51.515
Eval Task 9 for Age 17
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.518 (3.518)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 60.000
Eval Task 10 for Age 17
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.972 (3.972)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 77.907
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 79.070
Eval Task 11 for Age 17
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.455 (3.455)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 79.032
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 70.968
Eval Task 12 for Age 17
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.792 (3.792)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 89.157
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 17
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.596 (3.596)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 56.579
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 60.526
Eval Task 14 for Age 17
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.403 (3.403)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 93.902
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 93.902
Eval Task 15 for Age 17
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.668 (3.668)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 67.500
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 72.500
Eval Task 16 for Age 17
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.477 (3.477)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 67.857
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 67.857
Eval Task 17 for Age 17
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.695 (3.695)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 98.795
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 66.265
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83]
Method : OURS
----AGE 18----
current_task  [63, 75]
current_head  87
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.0651920240520265]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=261, sigma=tensor([3.9781]), eta=tensor([3.0898])
  (fc1): CosineLinear(input_features=512, output_features=255, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 178
video number + exemplar : 603
DataLoader Constructed : Train 18
Optimizer Constructed
video number : 178
video number + exemplar : 178
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-23 20:54:31.591413
Epoch: [0][0/18], lr: 0.00100	Time 3.457 (3.457)	Data 2.296 (2.296)	Loss 0.1218 (0.1218)	Loss CE 0.0483 (0.0483)	Loss KD (Logit) 0.0809 (0.0809)	Loss KD (GCAM) 0.0176 (0.0176)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6287 (0.6287)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.9730], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0867], device='cuda:0', requires_grad=True)
2022-03-23 20:54:46.903520
Epoch: [1][0/18], lr: 0.00100	Time 3.795 (3.795)	Data 2.389 (2.389)	Loss 0.0807 (0.0807)	Loss CE 0.0061 (0.0061)	Loss KD (Logit) 0.0863 (0.0863)	Loss KD (GCAM) 0.0269 (0.0269)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6093 (0.6093)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9676], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0833], device='cuda:0', requires_grad=True)
2022-03-23 20:55:02.355286
Epoch: [2][0/18], lr: 0.00100	Time 3.474 (3.474)	Data 2.382 (2.382)	Loss 0.0797 (0.0797)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0826 (0.0826)	Loss KD (GCAM) 0.0314 (0.0314)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6294 (0.6294)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0780], device='cuda:0', requires_grad=True)
2022-03-23 20:55:17.467278
Epoch: [3][0/18], lr: 0.00100	Time 3.089 (3.089)	Data 2.081 (2.081)	Loss 0.0839 (0.0839)	Loss CE 0.0076 (0.0076)	Loss KD (Logit) 0.0808 (0.0808)	Loss KD (GCAM) 0.0329 (0.0329)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6109 (0.6109)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0761], device='cuda:0', requires_grad=True)
2022-03-23 20:55:32.706726
Epoch: [4][0/18], lr: 0.00100	Time 3.260 (3.260)	Data 2.215 (2.215)	Loss 0.0767 (0.0767)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0826 (0.0826)	Loss KD (GCAM) 0.0341 (0.0341)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5871 (0.5871)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9590], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0775], device='cuda:0', requires_grad=True)
2022-03-23 20:55:47.849258
Epoch: [5][0/18], lr: 0.00100	Time 3.209 (3.209)	Data 1.963 (1.963)	Loss 0.0804 (0.0804)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 0.0850 (0.0850)	Loss KD (GCAM) 0.0329 (0.0329)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5822 (0.5822)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9611], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0790], device='cuda:0', requires_grad=True)
2022-03-23 20:56:03.339278
Epoch: [6][0/18], lr: 0.00100	Time 3.333 (3.333)	Data 2.333 (2.333)	Loss 0.0772 (0.0772)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0843 (0.0843)	Loss KD (GCAM) 0.0382 (0.0382)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5735 (0.5735)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0765], device='cuda:0', requires_grad=True)
2022-03-23 20:56:18.541003
Epoch: [7][0/18], lr: 0.00100	Time 3.321 (3.321)	Data 2.077 (2.077)	Loss 0.1219 (0.1219)	Loss CE 0.0460 (0.0460)	Loss KD (Logit) 0.0876 (0.0876)	Loss KD (GCAM) 0.0366 (0.0366)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5923 (0.5923)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0770], device='cuda:0', requires_grad=True)
2022-03-23 20:56:34.101695
Epoch: [8][0/18], lr: 0.00100	Time 3.429 (3.429)	Data 2.697 (2.697)	Loss 0.0750 (0.0750)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0858 (0.0858)	Loss KD (GCAM) 0.0348 (0.0348)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5720 (0.5720)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9606], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0781], device='cuda:0', requires_grad=True)
2022-03-23 20:56:49.345523
Epoch: [9][0/18], lr: 0.00100	Time 3.229 (3.229)	Data 2.252 (2.252)	Loss 0.0793 (0.0793)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0839 (0.0839)	Loss KD (GCAM) 0.0392 (0.0392)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6060 (0.6060)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9643], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0801], device='cuda:0', requires_grad=True)
2022-03-23 20:57:04.830412
Epoch: [10][0/18], lr: 0.00100	Time 3.221 (3.221)	Data 2.326 (2.326)	Loss 0.1199 (0.1199)	Loss CE 0.0423 (0.0423)	Loss KD (Logit) 0.0851 (0.0851)	Loss KD (GCAM) 0.0355 (0.0355)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6136 (0.6136)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9667], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0814], device='cuda:0', requires_grad=True)
2022-03-23 20:57:20.210105
Epoch: [11][0/18], lr: 0.00100	Time 3.292 (3.292)	Data 2.497 (2.497)	Loss 0.0751 (0.0751)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0831 (0.0831)	Loss KD (GCAM) 0.0344 (0.0344)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5912 (0.5912)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9690], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0829], device='cuda:0', requires_grad=True)
2022-03-23 20:57:35.520499
Epoch: [12][0/18], lr: 0.00100	Time 3.288 (3.288)	Data 2.618 (2.618)	Loss 0.0816 (0.0816)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0863 (0.0863)	Loss KD (GCAM) 0.0364 (0.0364)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6324 (0.6324)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9692], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0831], device='cuda:0', requires_grad=True)
2022-03-23 20:57:50.815018
Epoch: [13][0/18], lr: 0.00100	Time 3.350 (3.350)	Data 2.361 (2.361)	Loss 0.0690 (0.0690)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0832 (0.0832)	Loss KD (GCAM) 0.0330 (0.0330)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5062 (0.5062)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9698], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0837], device='cuda:0', requires_grad=True)
2022-03-23 20:58:06.189051
Epoch: [14][0/18], lr: 0.00100	Time 3.333 (3.333)	Data 2.137 (2.137)	Loss 0.0985 (0.0985)	Loss CE 0.0178 (0.0178)	Loss KD (Logit) 0.0846 (0.0846)	Loss KD (GCAM) 0.0388 (0.0388)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6352 (0.6352)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9656], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0812], device='cuda:0', requires_grad=True)
2022-03-23 20:58:21.593477
Epoch: [15][0/18], lr: 0.00100	Time 3.292 (3.292)	Data 2.525 (2.525)	Loss 0.0771 (0.0771)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0881 (0.0881)	Loss KD (GCAM) 0.0409 (0.0409)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5682 (0.5682)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9657], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0815], device='cuda:0', requires_grad=True)
2022-03-23 20:58:37.416553
Epoch: [16][0/18], lr: 0.00100	Time 3.305 (3.305)	Data 2.025 (2.025)	Loss 0.0761 (0.0761)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0877 (0.0877)	Loss KD (GCAM) 0.0381 (0.0381)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5723 (0.5723)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9659], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0815], device='cuda:0', requires_grad=True)
2022-03-23 20:58:53.465221
Epoch: [17][0/18], lr: 0.00100	Time 3.388 (3.388)	Data 2.263 (2.263)	Loss 0.0828 (0.0828)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0830 (0.0830)	Loss KD (GCAM) 0.0358 (0.0358)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6183 (0.6183)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9676], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0822], device='cuda:0', requires_grad=True)
2022-03-23 20:59:09.516779
Epoch: [18][0/18], lr: 0.00100	Time 3.313 (3.313)	Data 2.212 (2.212)	Loss 0.0815 (0.0815)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0866 (0.0866)	Loss KD (GCAM) 0.0355 (0.0355)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6366 (0.6366)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9673], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0819], device='cuda:0', requires_grad=True)
2022-03-23 20:59:26.121727
Epoch: [19][0/18], lr: 0.00100	Time 3.385 (3.385)	Data 2.590 (2.590)	Loss 0.0815 (0.0815)	Loss CE 0.0050 (0.0050)	Loss KD (Logit) 0.0842 (0.0842)	Loss KD (GCAM) 0.0337 (0.0337)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6086 (0.6086)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9673], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0819], device='cuda:0', requires_grad=True)
2022-03-23 20:59:42.294090
Epoch: [20][0/18], lr: 0.00010	Time 3.374 (3.374)	Data 2.339 (2.339)	Loss 0.0739 (0.0739)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0849 (0.0849)	Loss KD (GCAM) 0.0325 (0.0325)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5760 (0.5760)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9672], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0819], device='cuda:0', requires_grad=True)
2022-03-23 20:59:58.634046
Epoch: [21][0/18], lr: 0.00010	Time 3.365 (3.365)	Data 2.521 (2.521)	Loss 0.0732 (0.0732)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0829 (0.0829)	Loss KD (GCAM) 0.0321 (0.0321)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5782 (0.5782)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9672], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0818], device='cuda:0', requires_grad=True)
2022-03-23 21:00:15.008618
Epoch: [22][0/18], lr: 0.00010	Time 3.268 (3.268)	Data 2.012 (2.012)	Loss 0.0812 (0.0812)	Loss CE 0.0068 (0.0068)	Loss KD (Logit) 0.0831 (0.0831)	Loss KD (GCAM) 0.0339 (0.0339)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5883 (0.5883)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9673], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0819], device='cuda:0', requires_grad=True)
2022-03-23 21:00:31.317935
Epoch: [23][0/18], lr: 0.00010	Time 3.270 (3.270)	Data 2.089 (2.089)	Loss 0.0796 (0.0796)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0835 (0.0835)	Loss KD (GCAM) 0.0357 (0.0357)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5799 (0.5799)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9674], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0820], device='cuda:0', requires_grad=True)
2022-03-23 21:00:47.814934
Epoch: [24][0/18], lr: 0.00010	Time 3.208 (3.208)	Data 2.026 (2.026)	Loss 0.0788 (0.0788)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0823 (0.0823)	Loss KD (GCAM) 0.0348 (0.0348)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6155 (0.6155)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9675], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0820], device='cuda:0', requires_grad=True)
2022-03-23 21:01:04.506486
Epoch: [25][0/18], lr: 0.00010	Time 3.346 (3.346)	Data 2.126 (2.126)	Loss 0.0868 (0.0868)	Loss CE 0.0110 (0.0110)	Loss KD (Logit) 0.0872 (0.0872)	Loss KD (GCAM) 0.0329 (0.0329)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6018 (0.6018)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9676], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:01:21.006162
Epoch: [26][0/18], lr: 0.00010	Time 3.440 (3.440)	Data 2.267 (2.267)	Loss 0.0786 (0.0786)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0861 (0.0861)	Loss KD (GCAM) 0.0324 (0.0324)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6302 (0.6302)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9674], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0820], device='cuda:0', requires_grad=True)
2022-03-23 21:01:37.424107
Epoch: [27][0/18], lr: 0.00010	Time 3.374 (3.374)	Data 2.532 (2.532)	Loss 0.0736 (0.0736)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0843 (0.0843)	Loss KD (GCAM) 0.0350 (0.0350)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5474 (0.5474)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9675], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0820], device='cuda:0', requires_grad=True)
2022-03-23 21:01:53.734391
Epoch: [28][0/18], lr: 0.00010	Time 3.238 (3.238)	Data 2.306 (2.306)	Loss 0.0785 (0.0785)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0845 (0.0845)	Loss KD (GCAM) 0.0326 (0.0326)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5968 (0.5968)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9676], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:02:10.149037
Epoch: [29][0/18], lr: 0.00010	Time 3.222 (3.222)	Data 2.087 (2.087)	Loss 0.0875 (0.0875)	Loss CE 0.0093 (0.0093)	Loss KD (Logit) 0.0856 (0.0856)	Loss KD (GCAM) 0.0327 (0.0327)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6283 (0.6283)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:02:26.852693
Epoch: [30][0/18], lr: 0.00001	Time 3.280 (3.280)	Data 2.480 (2.480)	Loss 0.0755 (0.0755)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0840 (0.0840)	Loss KD (GCAM) 0.0312 (0.0312)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6038 (0.6038)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:02:43.585303
Epoch: [31][0/18], lr: 0.00001	Time 3.259 (3.259)	Data 1.979 (1.979)	Loss 0.0812 (0.0812)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0859 (0.0859)	Loss KD (GCAM) 0.0324 (0.0324)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6539 (0.6539)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:02:59.812398
Epoch: [32][0/18], lr: 0.00001	Time 3.256 (3.256)	Data 2.319 (2.319)	Loss 0.0760 (0.0760)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0841 (0.0841)	Loss KD (GCAM) 0.0327 (0.0327)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5998 (0.5998)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:03:15.558846
Epoch: [33][0/18], lr: 0.00001	Time 3.283 (3.283)	Data 2.011 (2.011)	Loss 0.0789 (0.0789)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0836 (0.0836)	Loss KD (GCAM) 0.0326 (0.0326)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6222 (0.6222)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:03:33.967783
Epoch: [34][0/18], lr: 0.00001	Time 3.487 (3.487)	Data 2.390 (2.390)	Loss 0.0781 (0.0781)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0885 (0.0885)	Loss KD (GCAM) 0.0342 (0.0342)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6124 (0.6124)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:03:53.419673
Epoch: [35][0/18], lr: 0.00001	Time 3.571 (3.571)	Data 2.073 (2.073)	Loss 0.0780 (0.0780)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0858 (0.0858)	Loss KD (GCAM) 0.0328 (0.0328)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6202 (0.6202)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:04:13.007128
Epoch: [36][0/18], lr: 0.00001	Time 3.708 (3.708)	Data 2.194 (2.194)	Loss 0.0808 (0.0808)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0861 (0.0861)	Loss KD (GCAM) 0.0329 (0.0329)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6476 (0.6476)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:04:32.766537
Epoch: [37][0/18], lr: 0.00001	Time 3.832 (3.832)	Data 2.098 (2.098)	Loss 0.0838 (0.0838)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0860 (0.0860)	Loss KD (GCAM) 0.0345 (0.0345)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6298 (0.6298)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:04:52.642222
Epoch: [38][0/18], lr: 0.00001	Time 3.732 (3.732)	Data 2.622 (2.622)	Loss 0.0744 (0.0744)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0848 (0.0848)	Loss KD (GCAM) 0.0300 (0.0300)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5974 (0.5974)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:05:12.270183
Epoch: [39][0/18], lr: 0.00001	Time 3.567 (3.567)	Data 2.262 (2.262)	Loss 0.0814 (0.0814)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0864 (0.0864)	Loss KD (GCAM) 0.0333 (0.0333)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6482 (0.6482)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:05:32.370084
Epoch: [40][0/18], lr: 0.00001	Time 3.719 (3.719)	Data 2.421 (2.421)	Loss 0.1008 (0.1008)	Loss CE 0.0166 (0.0166)	Loss KD (Logit) 0.0854 (0.0854)	Loss KD (GCAM) 0.0310 (0.0310)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6926 (0.6926)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:05:52.003744
Epoch: [41][0/18], lr: 0.00001	Time 3.588 (3.588)	Data 2.741 (2.741)	Loss 0.0809 (0.0809)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0834 (0.0834)	Loss KD (GCAM) 0.0309 (0.0309)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6582 (0.6582)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:06:11.612990
Epoch: [42][0/18], lr: 0.00001	Time 3.595 (3.595)	Data 2.526 (2.526)	Loss 0.0775 (0.0775)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0853 (0.0853)	Loss KD (GCAM) 0.0317 (0.0317)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6120 (0.6120)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:06:31.126428
Epoch: [43][0/18], lr: 0.00001	Time 3.487 (3.487)	Data 2.209 (2.209)	Loss 0.0755 (0.0755)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0829 (0.0829)	Loss KD (GCAM) 0.0309 (0.0309)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6024 (0.6024)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:06:50.933527
Epoch: [44][0/18], lr: 0.00001	Time 3.606 (3.606)	Data 2.078 (2.078)	Loss 0.0755 (0.0755)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0841 (0.0841)	Loss KD (GCAM) 0.0334 (0.0334)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5942 (0.5942)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:07:10.486645
Epoch: [45][0/18], lr: 0.00001	Time 3.608 (3.608)	Data 2.474 (2.474)	Loss 0.0730 (0.0730)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0817 (0.0817)	Loss KD (GCAM) 0.0318 (0.0318)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5805 (0.5805)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:07:29.962333
Epoch: [46][0/18], lr: 0.00001	Time 3.368 (3.368)	Data 1.890 (1.890)	Loss 0.0730 (0.0730)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0826 (0.0826)	Loss KD (GCAM) 0.0337 (0.0337)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5684 (0.5684)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:07:49.502194
Epoch: [47][0/18], lr: 0.00001	Time 3.712 (3.712)	Data 2.667 (2.667)	Loss 0.0779 (0.0779)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0835 (0.0835)	Loss KD (GCAM) 0.0321 (0.0321)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6272 (0.6272)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:08:08.971704
Epoch: [48][0/18], lr: 0.00001	Time 3.541 (3.541)	Data 2.172 (2.172)	Loss 0.0740 (0.0740)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0832 (0.0832)	Loss KD (GCAM) 0.0330 (0.0330)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5798 (0.5798)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
2022-03-23 21:08:28.794369
Epoch: [49][0/18], lr: 0.00001	Time 3.521 (3.521)	Data 1.945 (1.945)	Loss 0.0740 (0.0740)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0830 (0.0830)	Loss KD (GCAM) 0.0328 (0.0328)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5827 (0.5827)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0821], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=261, sigma=tensor([3.9678]), eta=tensor([3.0821])
  (fc1): CosineLinear(input_features=512, output_features=255, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 178
video number + exemplar : 178
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=261, sigma=tensor([3.9678]), eta=tensor([3.0821])
  (fc1): CosineLinear(input_features=512, output_features=255, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 435
DataLoader CBF Constructed : Train 13
Optimizer Constructed
2022-03-23 21:09:04.839678
Epoch: [0][0/13], lr: 0.00050	Time 3.061 (3.061)	Data 1.912 (1.912)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9675], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0819], device='cuda:0', requires_grad=True)
2022-03-23 21:09:15.321386
Epoch: [1][0/13], lr: 0.00050	Time 3.136 (3.136)	Data 1.947 (1.947)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9672], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0815], device='cuda:0', requires_grad=True)
2022-03-23 21:09:25.578381
Epoch: [2][0/13], lr: 0.00050	Time 3.117 (3.117)	Data 2.597 (2.597)	Loss 0.0042 (0.0042)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9672], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0814], device='cuda:0', requires_grad=True)
2022-03-23 21:09:35.604094
Epoch: [3][0/13], lr: 0.00050	Time 3.026 (3.026)	Data 1.877 (1.877)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9675], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0814], device='cuda:0', requires_grad=True)
2022-03-23 21:09:45.750894
Epoch: [4][0/13], lr: 0.00050	Time 3.058 (3.058)	Data 2.201 (2.201)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0815], device='cuda:0', requires_grad=True)
2022-03-23 21:09:55.876710
Epoch: [5][0/13], lr: 0.00050	Time 2.999 (2.999)	Data 2.016 (2.016)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0813], device='cuda:0', requires_grad=True)
2022-03-23 21:10:05.964840
Epoch: [6][0/13], lr: 0.00050	Time 3.214 (3.214)	Data 2.482 (2.482)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0812], device='cuda:0', requires_grad=True)
2022-03-23 21:10:16.102267
Epoch: [7][0/13], lr: 0.00050	Time 2.929 (2.929)	Data 1.836 (1.836)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0810], device='cuda:0', requires_grad=True)
2022-03-23 21:10:26.180610
Epoch: [8][0/13], lr: 0.00050	Time 3.016 (3.016)	Data 1.987 (1.987)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9675], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0807], device='cuda:0', requires_grad=True)
2022-03-23 21:10:36.300874
Epoch: [9][0/13], lr: 0.00050	Time 3.014 (3.014)	Data 2.289 (2.289)	Loss 0.0028 (0.0028)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9676], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0806], device='cuda:0', requires_grad=True)
2022-03-23 21:10:46.305088
Epoch: [10][0/13], lr: 0.00050	Time 3.126 (3.126)	Data 2.213 (2.213)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0805], device='cuda:0', requires_grad=True)
2022-03-23 21:10:56.597808
Epoch: [11][0/13], lr: 0.00050	Time 3.101 (3.101)	Data 2.130 (2.130)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0803], device='cuda:0', requires_grad=True)
2022-03-23 21:11:06.621517
Epoch: [12][0/13], lr: 0.00050	Time 3.034 (3.034)	Data 2.037 (2.037)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9678], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0803], device='cuda:0', requires_grad=True)
2022-03-23 21:11:16.750445
Epoch: [13][0/13], lr: 0.00050	Time 3.068 (3.068)	Data 1.978 (1.978)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9665], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0794], device='cuda:0', requires_grad=True)
2022-03-23 21:11:26.848270
Epoch: [14][0/13], lr: 0.00050	Time 3.039 (3.039)	Data 2.029 (2.029)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9651], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0786], device='cuda:0', requires_grad=True)
2022-03-23 21:11:36.823518
Epoch: [15][0/13], lr: 0.00050	Time 2.787 (2.787)	Data 1.830 (1.830)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9645], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0781], device='cuda:0', requires_grad=True)
2022-03-23 21:11:46.845831
Epoch: [16][0/13], lr: 0.00050	Time 3.083 (3.083)	Data 1.964 (1.964)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9643], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0779], device='cuda:0', requires_grad=True)
2022-03-23 21:11:57.144136
Epoch: [17][0/13], lr: 0.00050	Time 2.999 (2.999)	Data 2.246 (2.246)	Loss 0.0043 (0.0043)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9645], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0778], device='cuda:0', requires_grad=True)
2022-03-23 21:12:07.237378
Epoch: [18][0/13], lr: 0.00050	Time 3.013 (3.013)	Data 2.086 (2.086)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9642], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0775], device='cuda:0', requires_grad=True)
2022-03-23 21:12:17.354444
Epoch: [19][0/13], lr: 0.00050	Time 3.052 (3.052)	Data 2.148 (2.148)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9642], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0773], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_018.pth.tar
exemplar : 435
Computing the class mean vectors...
Eval Task 0 for Age 18
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.670 (4.670)	Prec@1 62.500 (62.500)
Test: [100/123]	Time 0.370 (0.489)	Prec@1 81.250 (69.616)
Testing Results: Prec@1 69.145
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 81.250 (73.144)
Testing Results (NME): Prec@1 72.811
Eval Task 1 for Age 18
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.766 (3.766)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 50.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 65.517
Eval Task 2 for Age 18
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.895 (3.895)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 32.308
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 46.154
Eval Task 3 for Age 18
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.889 (3.889)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 66.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 53.750
Eval Task 4 for Age 18
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.274 (4.274)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 62.353
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 74.118
Eval Task 5 for Age 18
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.790 (3.790)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 51.613
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 59.677
Eval Task 6 for Age 18
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.116 (4.116)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 69.136
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 50.617
Eval Task 7 for Age 18
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.709 (3.709)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.537
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 76.119
Eval Task 8 for Age 18
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.765 (3.765)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 46.970
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 51.515
Eval Task 9 for Age 18
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.806 (3.806)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 64.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 56.000
Eval Task 10 for Age 18
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.110 (4.110)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 77.907
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 77.907
Eval Task 11 for Age 18
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.728 (3.728)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 70.968
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 67.742
Eval Task 12 for Age 18
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.140 (4.140)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 18
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 4.117 (4.117)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 56.579
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 63.158
Eval Task 14 for Age 18
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.866 (3.866)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 81.707
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 87.805
Eval Task 15 for Age 18
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.724 (3.724)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 72.500
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 78.750
Eval Task 16 for Age 18
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.515 (3.515)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 71.429
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 67.857
Eval Task 17 for Age 18
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.134 (4.134)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 83.133
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 62.651
Eval Task 18 for Age 18
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.896 (3.896)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 93.750
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64]
Method : OURS
----AGE 19----
current_task  [5, 32]
current_head  89
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.0659545297913646]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=267, sigma=tensor([3.9642]), eta=tensor([3.0773])
  (fc1): CosineLinear(input_features=512, output_features=261, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 212
video number + exemplar : 647
DataLoader Constructed : Train 20
Optimizer Constructed
video number : 212
video number + exemplar : 212
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-23 21:18:05.058084
Epoch: [0][0/20], lr: 0.00100	Time 3.856 (3.856)	Data 2.635 (2.635)	Loss 0.4324 (0.4324)	Loss CE 0.3703 (0.3703)	Loss KD (Logit) 0.0187 (0.0187)	Loss KD (GCAM) 0.0086 (0.0086)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5829 (0.5829)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.9410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0624], device='cuda:0', requires_grad=True)
2022-03-23 21:18:25.887571
Epoch: [1][0/20], lr: 0.00100	Time 3.488 (3.488)	Data 1.928 (1.928)	Loss 0.1341 (0.1341)	Loss CE 0.0676 (0.0676)	Loss KD (Logit) 0.0198 (0.0198)	Loss KD (GCAM) 0.0127 (0.0127)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6142 (0.6142)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0571], device='cuda:0', requires_grad=True)
2022-03-23 21:18:47.102062
Epoch: [2][0/20], lr: 0.00100	Time 3.598 (3.598)	Data 2.377 (2.377)	Loss 0.0639 (0.0639)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0192 (0.0192)	Loss KD (GCAM) 0.0124 (0.0124)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5731 (0.5731)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9132], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0475], device='cuda:0', requires_grad=True)
2022-03-23 21:19:08.528153
Epoch: [3][0/20], lr: 0.00100	Time 3.555 (3.555)	Data 2.109 (2.109)	Loss 0.1859 (0.1859)	Loss CE 0.1187 (0.1187)	Loss KD (Logit) 0.0201 (0.0201)	Loss KD (GCAM) 0.0140 (0.0140)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6174 (0.6174)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9007], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0405], device='cuda:0', requires_grad=True)
2022-03-23 21:19:28.986060
Epoch: [4][0/20], lr: 0.00100	Time 3.064 (3.064)	Data 1.904 (1.904)	Loss 0.2837 (0.2837)	Loss CE 0.2160 (0.2160)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0149 (0.0149)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6188 (0.6188)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8940], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0365], device='cuda:0', requires_grad=True)
2022-03-23 21:19:49.687794
Epoch: [5][0/20], lr: 0.00100	Time 3.257 (3.257)	Data 2.045 (2.045)	Loss 0.1308 (0.1308)	Loss CE 0.0642 (0.0642)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0153 (0.0153)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6061 (0.6061)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0347], device='cuda:0', requires_grad=True)
2022-03-23 21:20:11.039774
Epoch: [6][0/20], lr: 0.00100	Time 3.584 (3.584)	Data 2.700 (2.700)	Loss 0.0717 (0.0717)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0199 (0.0199)	Loss KD (GCAM) 0.0156 (0.0156)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6075 (0.6075)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8878], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0339], device='cuda:0', requires_grad=True)
2022-03-23 21:20:32.168502
Epoch: [7][0/20], lr: 0.00100	Time 3.302 (3.302)	Data 1.942 (1.942)	Loss 0.0717 (0.0717)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0209 (0.0209)	Loss KD (GCAM) 0.0176 (0.0176)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6001 (0.6001)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8913], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0365], device='cuda:0', requires_grad=True)
2022-03-23 21:20:53.686282
Epoch: [8][0/20], lr: 0.00100	Time 3.861 (3.861)	Data 2.003 (2.003)	Loss 0.0688 (0.0688)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0201 (0.0201)	Loss KD (GCAM) 0.0159 (0.0159)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5761 (0.5761)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8905], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0362], device='cuda:0', requires_grad=True)
2022-03-23 21:21:15.321434
Epoch: [9][0/20], lr: 0.00100	Time 3.694 (3.694)	Data 2.430 (2.430)	Loss 0.0682 (0.0682)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0198 (0.0198)	Loss KD (GCAM) 0.0155 (0.0155)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8882], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0348], device='cuda:0', requires_grad=True)
2022-03-23 21:21:36.732795
Epoch: [10][0/20], lr: 0.00100	Time 3.549 (3.549)	Data 2.387 (2.387)	Loss 0.0710 (0.0710)	Loss CE 0.0119 (0.0119)	Loss KD (Logit) 0.0203 (0.0203)	Loss KD (GCAM) 0.0154 (0.0154)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5315 (0.5315)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8919], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0371], device='cuda:0', requires_grad=True)
2022-03-23 21:21:58.100173
Epoch: [11][0/20], lr: 0.00100	Time 3.632 (3.632)	Data 2.596 (2.596)	Loss 0.0793 (0.0793)	Loss CE 0.0159 (0.0159)	Loss KD (Logit) 0.0199 (0.0199)	Loss KD (GCAM) 0.0154 (0.0154)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5752 (0.5752)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8954], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0391], device='cuda:0', requires_grad=True)
2022-03-23 21:22:18.792783
Epoch: [12][0/20], lr: 0.00100	Time 3.320 (3.320)	Data 2.531 (2.531)	Loss 0.0658 (0.0658)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0198 (0.0198)	Loss KD (GCAM) 0.0144 (0.0144)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5976 (0.5976)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0402], device='cuda:0', requires_grad=True)
2022-03-23 21:22:40.033883
Epoch: [13][0/20], lr: 0.00100	Time 3.568 (3.568)	Data 2.071 (2.071)	Loss 0.0691 (0.0691)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0193 (0.0193)	Loss KD (GCAM) 0.0153 (0.0153)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6103 (0.6103)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8983], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0412], device='cuda:0', requires_grad=True)
2022-03-23 21:23:01.291020
Epoch: [14][0/20], lr: 0.00100	Time 3.553 (3.553)	Data 2.390 (2.390)	Loss 0.0637 (0.0637)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0196 (0.0196)	Loss KD (GCAM) 0.0142 (0.0142)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5705 (0.5705)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8999], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0421], device='cuda:0', requires_grad=True)
2022-03-23 21:23:22.585326
Epoch: [15][0/20], lr: 0.00100	Time 3.697 (3.697)	Data 2.718 (2.718)	Loss 0.0611 (0.0611)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0197 (0.0197)	Loss KD (GCAM) 0.0139 (0.0139)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5520 (0.5520)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9016], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0430], device='cuda:0', requires_grad=True)
2022-03-23 21:23:43.793172
Epoch: [16][0/20], lr: 0.00100	Time 3.377 (3.377)	Data 2.203 (2.203)	Loss 0.0645 (0.0645)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0193 (0.0193)	Loss KD (GCAM) 0.0133 (0.0133)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5875 (0.5875)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9035], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0443], device='cuda:0', requires_grad=True)
2022-03-23 21:24:04.960223
Epoch: [17][0/20], lr: 0.00100	Time 3.450 (3.450)	Data 1.936 (1.936)	Loss 0.0626 (0.0626)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0197 (0.0197)	Loss KD (GCAM) 0.0147 (0.0147)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5539 (0.5539)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0440], device='cuda:0', requires_grad=True)
2022-03-23 21:24:25.663334
Epoch: [18][0/20], lr: 0.00100	Time 3.286 (3.286)	Data 2.003 (2.003)	Loss 0.1126 (0.1126)	Loss CE 0.0450 (0.0450)	Loss KD (Logit) 0.0203 (0.0203)	Loss KD (GCAM) 0.0147 (0.0147)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6178 (0.6178)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9027], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0437], device='cuda:0', requires_grad=True)
2022-03-23 21:24:46.713411
Epoch: [19][0/20], lr: 0.00100	Time 3.538 (3.538)	Data 2.080 (2.080)	Loss 0.0659 (0.0659)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0146 (0.0146)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5852 (0.5852)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0395], device='cuda:0', requires_grad=True)
2022-03-23 21:25:07.582302
Epoch: [20][0/20], lr: 0.00010	Time 3.262 (3.262)	Data 2.032 (2.032)	Loss 0.0653 (0.0653)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0199 (0.0199)	Loss KD (GCAM) 0.0162 (0.0162)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5845 (0.5845)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0395], device='cuda:0', requires_grad=True)
2022-03-23 21:25:28.629830
Epoch: [21][0/20], lr: 0.00010	Time 3.540 (3.540)	Data 2.177 (2.177)	Loss 0.0722 (0.0722)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0202 (0.0202)	Loss KD (GCAM) 0.0161 (0.0161)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6263 (0.6263)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8971], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0395], device='cuda:0', requires_grad=True)
2022-03-23 21:25:49.893005
Epoch: [22][0/20], lr: 0.00010	Time 3.400 (3.400)	Data 1.970 (1.970)	Loss 0.0675 (0.0675)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0198 (0.0198)	Loss KD (GCAM) 0.0162 (0.0162)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6110 (0.6110)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8972], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0396], device='cuda:0', requires_grad=True)
2022-03-23 21:26:11.027715
Epoch: [23][0/20], lr: 0.00010	Time 3.435 (3.435)	Data 2.368 (2.368)	Loss 0.0649 (0.0649)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0206 (0.0206)	Loss KD (GCAM) 0.0157 (0.0157)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5850 (0.5850)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0396], device='cuda:0', requires_grad=True)
2022-03-23 21:26:31.347229
Epoch: [24][0/20], lr: 0.00010	Time 3.367 (3.367)	Data 2.098 (2.098)	Loss 0.0649 (0.0649)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0203 (0.0203)	Loss KD (GCAM) 0.0156 (0.0156)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5691 (0.5691)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8975], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0397], device='cuda:0', requires_grad=True)
2022-03-23 21:26:50.555081
Epoch: [25][0/20], lr: 0.00010	Time 3.362 (3.362)	Data 2.242 (2.242)	Loss 0.0680 (0.0680)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5918 (0.5918)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8976], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0398], device='cuda:0', requires_grad=True)
2022-03-23 21:27:09.566354
Epoch: [26][0/20], lr: 0.00010	Time 3.182 (3.182)	Data 2.140 (2.140)	Loss 0.0656 (0.0656)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0196 (0.0196)	Loss KD (GCAM) 0.0159 (0.0159)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5856 (0.5856)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8976], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0398], device='cuda:0', requires_grad=True)
2022-03-23 21:27:26.960323
Epoch: [27][0/20], lr: 0.00010	Time 3.331 (3.331)	Data 2.427 (2.427)	Loss 0.0636 (0.0636)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0149 (0.0149)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5730 (0.5730)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8977], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0398], device='cuda:0', requires_grad=True)
2022-03-23 21:27:44.639953
Epoch: [28][0/20], lr: 0.00010	Time 3.426 (3.426)	Data 2.554 (2.554)	Loss 0.0598 (0.0598)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0203 (0.0203)	Loss KD (GCAM) 0.0147 (0.0147)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5384 (0.5384)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8979], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0399], device='cuda:0', requires_grad=True)
2022-03-23 21:28:02.186257
Epoch: [29][0/20], lr: 0.00010	Time 3.256 (3.256)	Data 2.418 (2.418)	Loss 0.0619 (0.0619)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0202 (0.0202)	Loss KD (GCAM) 0.0155 (0.0155)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5528 (0.5528)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8980], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:28:19.746340
Epoch: [30][0/20], lr: 0.00001	Time 3.223 (3.223)	Data 2.436 (2.436)	Loss 0.0660 (0.0660)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0201 (0.0201)	Loss KD (GCAM) 0.0148 (0.0148)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5865 (0.5865)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8980], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:28:37.372557
Epoch: [31][0/20], lr: 0.00001	Time 3.336 (3.336)	Data 2.338 (2.338)	Loss 0.0574 (0.0574)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0203 (0.0203)	Loss KD (GCAM) 0.0156 (0.0156)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5101 (0.5101)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8980], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:28:55.128369
Epoch: [32][0/20], lr: 0.00001	Time 3.428 (3.428)	Data 2.582 (2.582)	Loss 0.0650 (0.0650)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0195 (0.0195)	Loss KD (GCAM) 0.0158 (0.0158)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5858 (0.5858)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8980], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:29:13.060295
Epoch: [33][0/20], lr: 0.00001	Time 3.170 (3.170)	Data 2.147 (2.147)	Loss 0.0631 (0.0631)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0197 (0.0197)	Loss KD (GCAM) 0.0154 (0.0154)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5697 (0.5697)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:29:31.022863
Epoch: [34][0/20], lr: 0.00001	Time 3.331 (3.331)	Data 2.357 (2.357)	Loss 0.0775 (0.0775)	Loss CE 0.0104 (0.0104)	Loss KD (Logit) 0.0199 (0.0199)	Loss KD (GCAM) 0.0161 (0.0161)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6097 (0.6097)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:29:48.779182
Epoch: [35][0/20], lr: 0.00001	Time 3.285 (3.285)	Data 2.199 (2.199)	Loss 0.0691 (0.0691)	Loss CE 0.0065 (0.0065)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0157 (0.0157)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5657 (0.5657)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:30:06.717901
Epoch: [36][0/20], lr: 0.00001	Time 3.429 (3.429)	Data 2.268 (2.268)	Loss 0.0656 (0.0656)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0150 (0.0150)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5653 (0.5653)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:30:24.665604
Epoch: [37][0/20], lr: 0.00001	Time 3.272 (3.272)	Data 2.210 (2.210)	Loss 0.0670 (0.0670)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0202 (0.0202)	Loss KD (GCAM) 0.0164 (0.0164)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5976 (0.5976)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:30:42.741701
Epoch: [38][0/20], lr: 0.00001	Time 3.133 (3.133)	Data 2.291 (2.291)	Loss 0.0670 (0.0670)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0147 (0.0147)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5915 (0.5915)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:31:00.571534
Epoch: [39][0/20], lr: 0.00001	Time 3.219 (3.219)	Data 2.447 (2.447)	Loss 0.0634 (0.0634)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0149 (0.0149)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5648 (0.5648)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:31:18.793845
Epoch: [40][0/20], lr: 0.00001	Time 3.350 (3.350)	Data 2.120 (2.120)	Loss 0.0574 (0.0574)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0199 (0.0199)	Loss KD (GCAM) 0.0155 (0.0155)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5100 (0.5100)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:31:36.621476
Epoch: [41][0/20], lr: 0.00001	Time 3.282 (3.282)	Data 1.942 (1.942)	Loss 0.0604 (0.0604)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0198 (0.0198)	Loss KD (GCAM) 0.0161 (0.0161)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5368 (0.5368)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:31:54.475448
Epoch: [42][0/20], lr: 0.00001	Time 3.384 (3.384)	Data 2.160 (2.160)	Loss 0.0658 (0.0658)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0199 (0.0199)	Loss KD (GCAM) 0.0159 (0.0159)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5893 (0.5893)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:32:11.560674
Epoch: [43][0/20], lr: 0.00001	Time 3.423 (3.423)	Data 2.274 (2.274)	Loss 0.0629 (0.0629)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0202 (0.0202)	Loss KD (GCAM) 0.0158 (0.0158)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5660 (0.5660)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:32:32.061252
Epoch: [44][0/20], lr: 0.00001	Time 3.346 (3.346)	Data 1.926 (1.926)	Loss 0.0636 (0.0636)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0201 (0.0201)	Loss KD (GCAM) 0.0154 (0.0154)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5725 (0.5725)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:32:52.862437
Epoch: [45][0/20], lr: 0.00001	Time 3.342 (3.342)	Data 2.426 (2.426)	Loss 0.0646 (0.0646)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0158 (0.0158)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5772 (0.5772)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:33:13.941320
Epoch: [46][0/20], lr: 0.00001	Time 3.466 (3.466)	Data 1.963 (1.963)	Loss 0.0639 (0.0639)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0153 (0.0153)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5665 (0.5665)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:33:35.268248
Epoch: [47][0/20], lr: 0.00001	Time 3.540 (3.540)	Data 2.089 (2.089)	Loss 0.0676 (0.0676)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0200 (0.0200)	Loss KD (GCAM) 0.0150 (0.0150)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6094 (0.6094)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:33:56.846302
Epoch: [48][0/20], lr: 0.00001	Time 3.650 (3.650)	Data 2.271 (2.271)	Loss 0.0661 (0.0661)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0203 (0.0203)	Loss KD (GCAM) 0.0163 (0.0163)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5876 (0.5876)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0401], device='cuda:0', requires_grad=True)
2022-03-23 21:34:18.176075
Epoch: [49][0/20], lr: 0.00001	Time 3.590 (3.590)	Data 2.394 (2.394)	Loss 0.0632 (0.0632)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0197 (0.0197)	Loss KD (GCAM) 0.0156 (0.0156)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5518 (0.5518)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0401], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=267, sigma=tensor([3.8982]), eta=tensor([3.0401])
  (fc1): CosineLinear(input_features=512, output_features=261, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 212
video number + exemplar : 212
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=267, sigma=tensor([3.8982]), eta=tensor([3.0401])
  (fc1): CosineLinear(input_features=512, output_features=261, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 445
DataLoader CBF Constructed : Train 13
Optimizer Constructed
2022-03-23 21:34:57.687545
Epoch: [0][0/13], lr: 0.00050	Time 3.240 (3.240)	Data 2.369 (2.369)	Loss 0.0233 (0.0233)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8979], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 21:35:08.007449
Epoch: [1][0/13], lr: 0.00050	Time 3.201 (3.201)	Data 2.001 (2.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0401], device='cuda:0', requires_grad=True)
2022-03-23 21:35:18.192430
Epoch: [2][0/13], lr: 0.00050	Time 3.024 (3.024)	Data 2.522 (2.522)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0392], device='cuda:0', requires_grad=True)
2022-03-23 21:35:28.266320
Epoch: [3][0/13], lr: 0.00050	Time 3.044 (3.044)	Data 2.079 (2.079)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8961], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0384], device='cuda:0', requires_grad=True)
2022-03-23 21:35:38.380905
Epoch: [4][0/13], lr: 0.00050	Time 3.026 (3.026)	Data 2.245 (2.245)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8961], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0382], device='cuda:0', requires_grad=True)
2022-03-23 21:35:48.476902
Epoch: [5][0/13], lr: 0.00050	Time 3.014 (3.014)	Data 2.416 (2.416)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8964], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0382], device='cuda:0', requires_grad=True)
2022-03-23 21:35:58.554629
Epoch: [6][0/13], lr: 0.00050	Time 3.028 (3.028)	Data 2.430 (2.430)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8968], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0382], device='cuda:0', requires_grad=True)
2022-03-23 21:36:08.790824
Epoch: [7][0/13], lr: 0.00050	Time 3.133 (3.133)	Data 2.260 (2.260)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8966], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0380], device='cuda:0', requires_grad=True)
2022-03-23 21:36:18.792991
Epoch: [8][0/13], lr: 0.00050	Time 3.000 (3.000)	Data 2.215 (2.215)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8971], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0382], device='cuda:0', requires_grad=True)
2022-03-23 21:36:28.882362
Epoch: [9][0/13], lr: 0.00050	Time 2.944 (2.944)	Data 2.065 (2.065)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8971], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0380], device='cuda:0', requires_grad=True)
2022-03-23 21:36:39.025301
Epoch: [10][0/13], lr: 0.00050	Time 3.029 (3.029)	Data 1.899 (1.899)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8968], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0377], device='cuda:0', requires_grad=True)
2022-03-23 21:36:49.130447
Epoch: [11][0/13], lr: 0.00050	Time 3.026 (3.026)	Data 2.417 (2.417)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8967], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0374], device='cuda:0', requires_grad=True)
2022-03-23 21:36:59.275836
Epoch: [12][0/13], lr: 0.00050	Time 3.064 (3.064)	Data 1.976 (1.976)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8969], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0374], device='cuda:0', requires_grad=True)
2022-03-23 21:37:09.434780
Epoch: [13][0/13], lr: 0.00050	Time 2.982 (2.982)	Data 2.080 (2.080)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0375], device='cuda:0', requires_grad=True)
2022-03-23 21:37:19.633811
Epoch: [14][0/13], lr: 0.00050	Time 3.115 (3.115)	Data 2.341 (2.341)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8976], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0375], device='cuda:0', requires_grad=True)
2022-03-23 21:37:29.731505
Epoch: [15][0/13], lr: 0.00050	Time 3.021 (3.021)	Data 2.477 (2.477)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8977], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0374], device='cuda:0', requires_grad=True)
2022-03-23 21:37:39.959618
Epoch: [16][0/13], lr: 0.00050	Time 3.180 (3.180)	Data 2.607 (2.607)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8978], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0373], device='cuda:0', requires_grad=True)
2022-03-23 21:37:50.149492
Epoch: [17][0/13], lr: 0.00050	Time 2.976 (2.976)	Data 2.030 (2.030)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8980], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0373], device='cuda:0', requires_grad=True)
2022-03-23 21:38:00.213051
Epoch: [18][0/13], lr: 0.00050	Time 3.011 (3.011)	Data 2.386 (2.386)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8978], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 21:38:10.371029
Epoch: [19][0/13], lr: 0.00050	Time 3.112 (3.112)	Data 2.161 (2.161)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_019.pth.tar
exemplar : 445
Computing the class mean vectors...
Eval Task 0 for Age 19
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.821 (4.821)	Prec@1 56.250 (56.250)
Test: [100/123]	Time 0.378 (0.549)	Prec@1 68.750 (66.337)
Testing Results: Prec@1 65.326
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (69.926)
Testing Results (NME): Prec@1 69.196
Eval Task 1 for Age 19
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.479 (3.479)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 65.517
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 63.793
Eval Task 2 for Age 19
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.374 (3.374)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 33.846
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 47.692
Eval Task 3 for Age 19
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.969 (3.969)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 61.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 56.250
Eval Task 4 for Age 19
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.832 (3.832)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 76.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 81.176
Eval Task 5 for Age 19
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.527 (3.527)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 59.677
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 53.226
Eval Task 6 for Age 19
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.184 (4.184)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 64.198
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 48.148
Eval Task 7 for Age 19
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.339 (3.339)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 94.030
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 76.119
Eval Task 8 for Age 19
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.967 (3.967)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 59.091
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 45.455
Eval Task 9 for Age 19
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.881 (3.881)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 65.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 60.000
Eval Task 10 for Age 19
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.003 (4.003)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 77.907
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 87.209
Eval Task 11 for Age 19
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.828 (3.828)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 79.032
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 69.355
Eval Task 12 for Age 19
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.135 (4.135)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.771
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 19
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.857 (3.857)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 53.947
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 53.947
Eval Task 14 for Age 19
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.340 (3.340)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 95.122
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.244
Eval Task 15 for Age 19
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.110 (4.110)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 65.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 60.000
Eval Task 16 for Age 19
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.815 (3.815)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 55.357
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 64.286
Eval Task 17 for Age 19
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.967 (3.967)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 79.518
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 54.217
Eval Task 18 for Age 19
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.798 (3.798)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.188
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 79.688
Eval Task 19 for Age 19
Current Task : [5, 32]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.281 (4.281)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.780
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.683
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64, 82]
Method : OURS
----AGE 20----
current_task  [4, 51]
current_head  91
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06670832032063168]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=273, sigma=tensor([3.8982]), eta=tensor([3.0370])
  (fc1): CosineLinear(input_features=512, output_features=267, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 167
video number + exemplar : 612
DataLoader Constructed : Train 19
Optimizer Constructed
video number : 167
video number + exemplar : 167
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 21:44:22.361187
Epoch: [0][0/19], lr: 0.00100	Time 3.586 (3.586)	Data 2.289 (2.289)	Loss 0.0762 (0.0762)	Loss CE 0.0179 (0.0179)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0042 (0.0042)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5669 (0.5669)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8875], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0308], device='cuda:0', requires_grad=True)
2022-03-23 21:44:39.503630
Epoch: [1][0/19], lr: 0.00100	Time 3.308 (3.308)	Data 2.125 (2.125)	Loss 0.1554 (0.1554)	Loss CE 0.0999 (0.0999)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5316 (0.5316)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8871], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0307], device='cuda:0', requires_grad=True)
2022-03-23 21:44:56.601324
Epoch: [2][0/19], lr: 0.00100	Time 3.534 (3.534)	Data 2.128 (2.128)	Loss 0.3072 (0.3072)	Loss CE 0.2510 (0.2510)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0062 (0.0062)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5382 (0.5382)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8883], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0313], device='cuda:0', requires_grad=True)
2022-03-23 21:45:13.293634
Epoch: [3][0/19], lr: 0.00100	Time 3.102 (3.102)	Data 2.164 (2.164)	Loss 0.0718 (0.0718)	Loss CE 0.0126 (0.0126)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5626 (0.5626)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0276], device='cuda:0', requires_grad=True)
2022-03-23 21:45:30.378387
Epoch: [4][0/19], lr: 0.00100	Time 3.138 (3.138)	Data 2.155 (2.155)	Loss 0.2241 (0.2241)	Loss CE 0.1639 (0.1639)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5735 (0.5735)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8872], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0318], device='cuda:0', requires_grad=True)
2022-03-23 21:45:46.671559
Epoch: [5][0/19], lr: 0.00100	Time 3.285 (3.285)	Data 2.478 (2.478)	Loss 0.0764 (0.0764)	Loss CE 0.0157 (0.0157)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5812 (0.5812)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0352], device='cuda:0', requires_grad=True)
2022-03-23 21:46:05.572007
Epoch: [6][0/19], lr: 0.00100	Time 3.429 (3.429)	Data 2.055 (2.055)	Loss 0.0693 (0.0693)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5974 (0.5974)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9005], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0410], device='cuda:0', requires_grad=True)
2022-03-23 21:46:25.673355
Epoch: [7][0/19], lr: 0.00100	Time 3.383 (3.383)	Data 2.002 (2.002)	Loss 0.0679 (0.0679)	Loss CE 0.0092 (0.0092)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0081 (0.0081)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5585 (0.5585)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9070], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0449], device='cuda:0', requires_grad=True)
2022-03-23 21:46:45.888958
Epoch: [8][0/19], lr: 0.00100	Time 3.664 (3.664)	Data 2.635 (2.635)	Loss 0.0719 (0.0719)	Loss CE 0.0146 (0.0146)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0083 (0.0083)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5435 (0.5435)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9148], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0493], device='cuda:0', requires_grad=True)
2022-03-23 21:47:05.929933
Epoch: [9][0/19], lr: 0.00100	Time 3.513 (3.513)	Data 2.199 (2.199)	Loss 0.0650 (0.0650)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0084 (0.0084)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6042 (0.6042)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0526], device='cuda:0', requires_grad=True)
2022-03-23 21:47:26.024523
Epoch: [10][0/19], lr: 0.00100	Time 3.306 (3.306)	Data 1.931 (1.931)	Loss 0.0826 (0.0826)	Loss CE 0.0247 (0.0247)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5502 (0.5502)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9272], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0567], device='cuda:0', requires_grad=True)
2022-03-23 21:47:45.975265
Epoch: [11][0/19], lr: 0.00100	Time 3.365 (3.365)	Data 2.209 (2.209)	Loss 0.0715 (0.0715)	Loss CE 0.0086 (0.0086)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6011 (0.6011)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9315], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0593], device='cuda:0', requires_grad=True)
2022-03-23 21:48:06.240996
Epoch: [12][0/19], lr: 0.00100	Time 3.329 (3.329)	Data 2.280 (2.280)	Loss 0.0789 (0.0789)	Loss CE 0.0150 (0.0150)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6091 (0.6091)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9361], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0621], device='cuda:0', requires_grad=True)
2022-03-23 21:48:26.536967
Epoch: [13][0/19], lr: 0.00100	Time 3.424 (3.424)	Data 1.941 (1.941)	Loss 0.0662 (0.0662)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5848 (0.5848)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9401], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0642], device='cuda:0', requires_grad=True)
2022-03-23 21:48:46.561659
Epoch: [14][0/19], lr: 0.00100	Time 3.321 (3.321)	Data 2.247 (2.247)	Loss 0.2479 (0.2479)	Loss CE 0.1875 (0.1875)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5771 (0.5771)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9406], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0647], device='cuda:0', requires_grad=True)
2022-03-23 21:49:06.723475
Epoch: [15][0/19], lr: 0.00100	Time 3.357 (3.357)	Data 2.499 (2.499)	Loss 0.0609 (0.0609)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0083 (0.0083)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5651 (0.5651)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9433], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0664], device='cuda:0', requires_grad=True)
2022-03-23 21:49:27.640603
Epoch: [16][0/19], lr: 0.00100	Time 3.892 (3.892)	Data 2.708 (2.708)	Loss 0.0759 (0.0759)	Loss CE 0.0196 (0.0196)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0091 (0.0091)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5309 (0.5309)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9471], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0688], device='cuda:0', requires_grad=True)
2022-03-23 21:49:47.634040
Epoch: [17][0/19], lr: 0.00100	Time 3.387 (3.387)	Data 1.910 (1.910)	Loss 0.0597 (0.0597)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0084 (0.0084)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5531 (0.5531)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0704], device='cuda:0', requires_grad=True)
2022-03-23 21:50:07.591882
Epoch: [18][0/19], lr: 0.00100	Time 3.397 (3.397)	Data 1.868 (1.868)	Loss 0.0684 (0.0684)	Loss CE 0.0068 (0.0068)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0083 (0.0083)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5872 (0.5872)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0712], device='cuda:0', requires_grad=True)
2022-03-23 21:50:27.854610
Epoch: [19][0/19], lr: 0.00100	Time 3.525 (3.525)	Data 2.358 (2.358)	Loss 0.0589 (0.0589)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5455 (0.5455)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9514], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0715], device='cuda:0', requires_grad=True)
2022-03-23 21:50:48.434818
Epoch: [20][0/19], lr: 0.00010	Time 3.474 (3.474)	Data 2.518 (2.518)	Loss 0.0588 (0.0588)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5476 (0.5476)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9514], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0715], device='cuda:0', requires_grad=True)
2022-03-23 21:51:08.490157
Epoch: [21][0/19], lr: 0.00010	Time 3.236 (3.236)	Data 2.184 (2.184)	Loss 0.0562 (0.0562)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5300 (0.5300)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9515], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0715], device='cuda:0', requires_grad=True)
2022-03-23 21:51:28.590836
Epoch: [22][0/19], lr: 0.00010	Time 3.231 (3.231)	Data 2.236 (2.236)	Loss 0.0644 (0.0644)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6113 (0.6113)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0717], device='cuda:0', requires_grad=True)
2022-03-23 21:51:48.714095
Epoch: [23][0/19], lr: 0.00010	Time 3.266 (3.266)	Data 2.207 (2.207)	Loss 0.0717 (0.0717)	Loss CE 0.0111 (0.0111)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5795 (0.5795)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9520], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:52:08.799815
Epoch: [24][0/19], lr: 0.00010	Time 3.600 (3.600)	Data 2.523 (2.523)	Loss 0.0680 (0.0680)	Loss CE 0.0097 (0.0097)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5559 (0.5559)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9519], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0717], device='cuda:0', requires_grad=True)
2022-03-23 21:52:28.785567
Epoch: [25][0/19], lr: 0.00010	Time 3.423 (3.423)	Data 2.455 (2.455)	Loss 0.0607 (0.0607)	Loss CE 0.0056 (0.0056)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5244 (0.5244)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9519], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0717], device='cuda:0', requires_grad=True)
2022-03-23 21:52:48.872447
Epoch: [26][0/19], lr: 0.00010	Time 3.436 (3.436)	Data 2.093 (2.093)	Loss 0.0720 (0.0720)	Loss CE 0.0105 (0.0105)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5867 (0.5867)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9520], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0718], device='cuda:0', requires_grad=True)
2022-03-23 21:53:09.238260
Epoch: [27][0/19], lr: 0.00010	Time 3.317 (3.317)	Data 1.975 (1.975)	Loss 0.0533 (0.0533)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5039 (0.5039)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9521], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0718], device='cuda:0', requires_grad=True)
2022-03-23 21:53:29.955525
Epoch: [28][0/19], lr: 0.00010	Time 3.658 (3.658)	Data 2.421 (2.421)	Loss 0.0589 (0.0589)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5562 (0.5562)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:53:50.458838
Epoch: [29][0/19], lr: 0.00010	Time 3.482 (3.482)	Data 2.347 (2.347)	Loss 0.0630 (0.0630)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5330 (0.5330)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:54:10.487843
Epoch: [30][0/19], lr: 0.00001	Time 3.335 (3.335)	Data 2.192 (2.192)	Loss 0.0636 (0.0636)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5736 (0.5736)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:54:30.492451
Epoch: [31][0/19], lr: 0.00001	Time 3.495 (3.495)	Data 2.131 (2.131)	Loss 0.0778 (0.0778)	Loss CE 0.0118 (0.0118)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6334 (0.6334)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:54:50.928965
Epoch: [32][0/19], lr: 0.00001	Time 3.390 (3.390)	Data 2.411 (2.411)	Loss 0.0610 (0.0610)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5737 (0.5737)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:55:10.994737
Epoch: [33][0/19], lr: 0.00001	Time 3.278 (3.278)	Data 2.429 (2.429)	Loss 0.0545 (0.0545)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5120 (0.5120)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:55:29.780995
Epoch: [34][0/19], lr: 0.00001	Time 3.352 (3.352)	Data 2.034 (2.034)	Loss 0.0558 (0.0558)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5286 (0.5286)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:55:48.547291
Epoch: [35][0/19], lr: 0.00001	Time 3.375 (3.375)	Data 2.480 (2.480)	Loss 0.0560 (0.0560)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5156 (0.5156)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:56:07.536647
Epoch: [36][0/19], lr: 0.00001	Time 3.607 (3.607)	Data 2.882 (2.882)	Loss 0.0617 (0.0617)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5703 (0.5703)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:56:24.454126
Epoch: [37][0/19], lr: 0.00001	Time 3.218 (3.218)	Data 2.024 (2.024)	Loss 0.0617 (0.0617)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5836 (0.5836)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:56:41.414715
Epoch: [38][0/19], lr: 0.00001	Time 3.278 (3.278)	Data 2.183 (2.183)	Loss 0.0621 (0.0621)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5725 (0.5725)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0719], device='cuda:0', requires_grad=True)
2022-03-23 21:56:57.934924
Epoch: [39][0/19], lr: 0.00001	Time 3.201 (3.201)	Data 2.163 (2.163)	Loss 0.0779 (0.0779)	Loss CE 0.0198 (0.0198)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5537 (0.5537)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:57:14.716491
Epoch: [40][0/19], lr: 0.00001	Time 3.340 (3.340)	Data 2.262 (2.262)	Loss 0.0598 (0.0598)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5645 (0.5645)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:57:31.419477
Epoch: [41][0/19], lr: 0.00001	Time 3.195 (3.195)	Data 2.027 (2.027)	Loss 0.0599 (0.0599)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5700 (0.5700)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:57:48.405846
Epoch: [42][0/19], lr: 0.00001	Time 3.178 (3.178)	Data 2.060 (2.060)	Loss 0.0605 (0.0605)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5664 (0.5664)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:58:05.970437
Epoch: [43][0/19], lr: 0.00001	Time 3.520 (3.520)	Data 2.636 (2.636)	Loss 0.0612 (0.0612)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5794 (0.5794)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:58:23.601768
Epoch: [44][0/19], lr: 0.00001	Time 3.754 (3.754)	Data 2.078 (2.078)	Loss 0.0629 (0.0629)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5786 (0.5786)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:58:40.722821
Epoch: [45][0/19], lr: 0.00001	Time 3.329 (3.329)	Data 2.222 (2.222)	Loss 0.0672 (0.0672)	Loss CE 0.0138 (0.0138)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5078 (0.5078)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9525], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:58:57.486229
Epoch: [46][0/19], lr: 0.00001	Time 3.258 (3.258)	Data 1.976 (1.976)	Loss 0.0626 (0.0626)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5890 (0.5890)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9525], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:59:14.805423
Epoch: [47][0/19], lr: 0.00001	Time 3.343 (3.343)	Data 2.211 (2.211)	Loss 0.0564 (0.0564)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5287 (0.5287)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9525], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:59:32.174825
Epoch: [48][0/19], lr: 0.00001	Time 3.318 (3.318)	Data 2.063 (2.063)	Loss 0.0616 (0.0616)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5844 (0.5844)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9525], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
2022-03-23 21:59:49.397991
Epoch: [49][0/19], lr: 0.00001	Time 3.351 (3.351)	Data 2.377 (2.377)	Loss 0.0585 (0.0585)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5571 (0.5571)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9525], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0720], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=273, sigma=tensor([3.9525]), eta=tensor([3.0720])
  (fc1): CosineLinear(input_features=512, output_features=267, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 167
video number + exemplar : 167
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=273, sigma=tensor([3.9525]), eta=tensor([3.0720])
  (fc1): CosineLinear(input_features=512, output_features=267, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 455
DataLoader CBF Constructed : Train 14
Optimizer Constructed
2022-03-23 22:00:22.653474
Epoch: [0][0/14], lr: 0.00050	Time 2.921 (2.921)	Data 2.043 (2.043)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9534], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0725], device='cuda:0', requires_grad=True)
2022-03-23 22:00:32.222960
Epoch: [1][0/14], lr: 0.00050	Time 2.969 (2.969)	Data 1.961 (1.961)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9540], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0727], device='cuda:0', requires_grad=True)
2022-03-23 22:00:41.529151
Epoch: [2][0/14], lr: 0.00050	Time 2.909 (2.909)	Data 2.209 (2.209)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9542], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0727], device='cuda:0', requires_grad=True)
2022-03-23 22:00:50.230197
Epoch: [3][0/14], lr: 0.00050	Time 2.942 (2.942)	Data 2.325 (2.325)	Loss 0.0023 (0.0023)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9544], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0727], device='cuda:0', requires_grad=True)
2022-03-23 22:00:59.794302
Epoch: [4][0/14], lr: 0.00050	Time 3.485 (3.485)	Data 2.340 (2.340)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9549], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0729], device='cuda:0', requires_grad=True)
2022-03-23 22:01:10.347464
Epoch: [5][0/14], lr: 0.00050	Time 3.027 (3.027)	Data 1.996 (1.996)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0729], device='cuda:0', requires_grad=True)
2022-03-23 22:01:20.763547
Epoch: [6][0/14], lr: 0.00050	Time 2.956 (2.956)	Data 2.284 (2.284)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9555], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0729], device='cuda:0', requires_grad=True)
2022-03-23 22:01:31.058277
Epoch: [7][0/14], lr: 0.00050	Time 2.858 (2.858)	Data 1.857 (1.857)	Loss 0.0043 (0.0043)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9561], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0731], device='cuda:0', requires_grad=True)
2022-03-23 22:01:41.429187
Epoch: [8][0/14], lr: 0.00050	Time 3.007 (3.007)	Data 2.387 (2.387)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9565], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0732], device='cuda:0', requires_grad=True)
2022-03-23 22:01:52.003926
Epoch: [9][0/14], lr: 0.00050	Time 3.071 (3.071)	Data 2.303 (2.303)	Loss 0.0038 (0.0038)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0736], device='cuda:0', requires_grad=True)
2022-03-23 22:02:02.487577
Epoch: [10][0/14], lr: 0.00050	Time 2.842 (2.842)	Data 2.024 (2.024)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9577], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0735], device='cuda:0', requires_grad=True)
2022-03-23 22:02:13.050109
Epoch: [11][0/14], lr: 0.00050	Time 2.962 (2.962)	Data 2.019 (2.019)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0729], device='cuda:0', requires_grad=True)
2022-03-23 22:02:24.072223
Epoch: [12][0/14], lr: 0.00050	Time 3.093 (3.093)	Data 2.426 (2.426)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9560], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0722], device='cuda:0', requires_grad=True)
2022-03-23 22:02:34.407738
Epoch: [13][0/14], lr: 0.00050	Time 2.775 (2.775)	Data 1.843 (1.843)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9561], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0721], device='cuda:0', requires_grad=True)
2022-03-23 22:02:44.847248
Epoch: [14][0/14], lr: 0.00050	Time 2.964 (2.964)	Data 1.881 (1.881)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9558], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0717], device='cuda:0', requires_grad=True)
2022-03-23 22:02:55.342887
Epoch: [15][0/14], lr: 0.00050	Time 3.038 (3.038)	Data 2.380 (2.380)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9547], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0709], device='cuda:0', requires_grad=True)
2022-03-23 22:03:05.998078
Epoch: [16][0/14], lr: 0.00050	Time 2.874 (2.874)	Data 1.962 (1.962)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9543], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0705], device='cuda:0', requires_grad=True)
2022-03-23 22:03:16.838301
Epoch: [17][0/14], lr: 0.00050	Time 3.064 (3.064)	Data 1.873 (1.873)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9542], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0702], device='cuda:0', requires_grad=True)
2022-03-23 22:03:27.494112
Epoch: [18][0/14], lr: 0.00050	Time 3.069 (3.069)	Data 2.576 (2.576)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9541], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0700], device='cuda:0', requires_grad=True)
2022-03-23 22:03:37.890509
Epoch: [19][0/14], lr: 0.00050	Time 3.024 (3.024)	Data 2.511 (2.511)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9542], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0699], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_020.pth.tar
exemplar : 455
Computing the class mean vectors...
Eval Task 0 for Age 20
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.995 (4.995)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.501 (0.553)	Prec@1 75.000 (63.366)
Testing Results: Prec@1 62.678
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (68.936)
Testing Results (NME): Prec@1 68.534
Eval Task 1 for Age 20
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.848 (3.848)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 39.655
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 43.103
Eval Task 2 for Age 20
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 4.184 (4.184)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 49.231
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 50.769
Eval Task 3 for Age 20
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.662 (3.662)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 65.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 61.250
Eval Task 4 for Age 20
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.663 (3.663)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 57.647
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 76.471
Eval Task 5 for Age 20
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.666 (3.666)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 54.839
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 58.065
Eval Task 6 for Age 20
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.128 (4.128)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 51.852
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 43.210
Eval Task 7 for Age 20
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.087 (4.087)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 89.552
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 76.119
Eval Task 8 for Age 20
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.276 (4.276)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 59.091
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 54.545
Eval Task 9 for Age 20
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.730 (3.730)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 57.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 54.667
Eval Task 10 for Age 20
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.214 (4.214)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 74.419
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 77.907
Eval Task 11 for Age 20
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.907 (3.907)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 87.097
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 83.871
Eval Task 12 for Age 20
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.353 (4.353)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 20
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.921 (3.921)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 55.263
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 56.579
Eval Task 14 for Age 20
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.523 (3.523)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 85.366
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 93.902
Eval Task 15 for Age 20
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.242 (4.242)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 55.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 58.750
Eval Task 16 for Age 20
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.758 (3.758)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 57.143
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 58.929
Eval Task 17 for Age 20
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.529 (3.529)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 65.060
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 55.422
Eval Task 18 for Age 20
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.862 (3.862)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 93.750
Eval Task 19 for Age 20
Current Task : [5, 32]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.344 (4.344)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 86.585
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 85.366
Eval Task 20 for Age 20
Current Task : [4, 51]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 4.080 (4.080)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 88.235
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 67.647
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64, 82, 68]
Method : OURS
----AGE 21----
current_task  [48, 73]
current_head  93
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06745368781616021]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=279, sigma=tensor([3.9542]), eta=tensor([3.0699])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 208
video number + exemplar : 663
DataLoader Constructed : Train 20
Optimizer Constructed
video number : 208
video number + exemplar : 208
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 22:10:11.869991
Epoch: [0][0/20], lr: 0.00100	Time 3.789 (3.789)	Data 2.555 (2.555)	Loss 0.0719 (0.0719)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.1172 (0.1172)	Loss KD (GCAM) 0.0218 (0.0218)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5589 (0.5589)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0643], device='cuda:0', requires_grad=True)
2022-03-23 22:10:29.412238
Epoch: [1][0/20], lr: 0.00100	Time 3.509 (3.509)	Data 2.310 (2.310)	Loss 0.0826 (0.0826)	Loss CE 0.0097 (0.0097)	Loss KD (Logit) 0.1200 (0.1200)	Loss KD (GCAM) 0.0292 (0.0292)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5600 (0.5600)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9392], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0605], device='cuda:0', requires_grad=True)
2022-03-23 22:10:47.308616
Epoch: [2][0/20], lr: 0.00100	Time 3.482 (3.482)	Data 2.291 (2.291)	Loss 0.0795 (0.0795)	Loss CE 0.0092 (0.0092)	Loss KD (Logit) 0.1234 (0.1234)	Loss KD (GCAM) 0.0257 (0.0257)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5419 (0.5419)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9267], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0541], device='cuda:0', requires_grad=True)
2022-03-23 22:11:05.334780
Epoch: [3][0/20], lr: 0.00100	Time 3.473 (3.473)	Data 2.403 (2.403)	Loss 0.1690 (0.1690)	Loss CE 0.0915 (0.0915)	Loss KD (Logit) 0.1237 (0.1237)	Loss KD (GCAM) 0.0307 (0.0307)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5996 (0.5996)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9170], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0494], device='cuda:0', requires_grad=True)
2022-03-23 22:11:23.296457
Epoch: [4][0/20], lr: 0.00100	Time 3.592 (3.592)	Data 2.347 (2.347)	Loss 0.0732 (0.0732)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.1286 (0.1286)	Loss KD (GCAM) 0.0322 (0.0322)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5424 (0.5424)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9154], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0481], device='cuda:0', requires_grad=True)
2022-03-23 22:11:41.302668
Epoch: [5][0/20], lr: 0.00100	Time 3.440 (3.440)	Data 2.364 (2.364)	Loss 0.0884 (0.0884)	Loss CE 0.0108 (0.0108)	Loss KD (Logit) 0.1303 (0.1303)	Loss KD (GCAM) 0.0363 (0.0363)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5794 (0.5794)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9155], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0479], device='cuda:0', requires_grad=True)
2022-03-23 22:11:59.508555
Epoch: [6][0/20], lr: 0.00100	Time 3.529 (3.529)	Data 2.489 (2.489)	Loss 0.0739 (0.0739)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.1296 (0.1296)	Loss KD (GCAM) 0.0334 (0.0334)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5347 (0.5347)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9162], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0487], device='cuda:0', requires_grad=True)
2022-03-23 22:12:17.965460
Epoch: [7][0/20], lr: 0.00100	Time 3.776 (3.776)	Data 2.610 (2.610)	Loss 0.0818 (0.0818)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.1285 (0.1285)	Loss KD (GCAM) 0.0346 (0.0346)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5577 (0.5577)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9129], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0468], device='cuda:0', requires_grad=True)
2022-03-23 22:12:35.898377
Epoch: [8][0/20], lr: 0.00100	Time 3.414 (3.414)	Data 2.272 (2.272)	Loss 0.0792 (0.0792)	Loss CE 0.0085 (0.0085)	Loss KD (Logit) 0.1292 (0.1292)	Loss KD (GCAM) 0.0338 (0.0338)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5176 (0.5176)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9154], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0484], device='cuda:0', requires_grad=True)
2022-03-23 22:12:54.001242
Epoch: [9][0/20], lr: 0.00100	Time 3.485 (3.485)	Data 2.680 (2.680)	Loss 0.0794 (0.0794)	Loss CE 0.0094 (0.0094)	Loss KD (Logit) 0.1244 (0.1244)	Loss KD (GCAM) 0.0329 (0.0329)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5173 (0.5173)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9169], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0491], device='cuda:0', requires_grad=True)
2022-03-23 22:13:11.937716
Epoch: [10][0/20], lr: 0.00100	Time 3.334 (3.334)	Data 2.212 (2.212)	Loss 0.0733 (0.0733)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.1252 (0.1252)	Loss KD (GCAM) 0.0311 (0.0311)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5482 (0.5482)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9186], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0499], device='cuda:0', requires_grad=True)
2022-03-23 22:13:29.880332
Epoch: [11][0/20], lr: 0.00100	Time 3.455 (3.455)	Data 2.109 (2.109)	Loss 0.0734 (0.0734)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1278 (0.1278)	Loss KD (GCAM) 0.0327 (0.0327)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5440 (0.5440)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
2022-03-23 22:13:48.041949
Epoch: [12][0/20], lr: 0.00100	Time 3.443 (3.443)	Data 2.378 (2.378)	Loss 0.0752 (0.0752)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.1247 (0.1247)	Loss KD (GCAM) 0.0303 (0.0303)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5605 (0.5605)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9232], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0527], device='cuda:0', requires_grad=True)
2022-03-23 22:14:06.006968
Epoch: [13][0/20], lr: 0.00100	Time 3.468 (3.468)	Data 2.453 (2.453)	Loss 0.0716 (0.0716)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.1299 (0.1299)	Loss KD (GCAM) 0.0340 (0.0340)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4972 (0.4972)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9204], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0510], device='cuda:0', requires_grad=True)
2022-03-23 22:14:23.880496
Epoch: [14][0/20], lr: 0.00100	Time 3.243 (3.243)	Data 2.471 (2.471)	Loss 0.1129 (0.1129)	Loss CE 0.0436 (0.0436)	Loss KD (Logit) 0.1290 (0.1290)	Loss KD (GCAM) 0.0339 (0.0339)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5045 (0.5045)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9202], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0508], device='cuda:0', requires_grad=True)
2022-03-23 22:14:40.905416
Epoch: [15][0/20], lr: 0.00100	Time 3.885 (3.885)	Data 2.945 (2.945)	Loss 0.0762 (0.0762)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.1274 (0.1274)	Loss KD (GCAM) 0.0313 (0.0313)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5716 (0.5716)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9202], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0506], device='cuda:0', requires_grad=True)
2022-03-23 22:15:01.964371
Epoch: [16][0/20], lr: 0.00100	Time 3.448 (3.448)	Data 1.960 (1.960)	Loss 0.0726 (0.0726)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1286 (0.1286)	Loss KD (GCAM) 0.0332 (0.0332)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5379 (0.5379)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0516], device='cuda:0', requires_grad=True)
2022-03-23 22:15:23.454838
Epoch: [17][0/20], lr: 0.00100	Time 3.752 (3.752)	Data 2.477 (2.477)	Loss 0.0755 (0.0755)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1256 (0.1256)	Loss KD (GCAM) 0.0298 (0.0298)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5767 (0.5767)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9217], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0512], device='cuda:0', requires_grad=True)
2022-03-23 22:15:44.759172
Epoch: [18][0/20], lr: 0.00100	Time 3.353 (3.353)	Data 1.965 (1.965)	Loss 0.0731 (0.0731)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.1297 (0.1297)	Loss KD (GCAM) 0.0321 (0.0321)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5377 (0.5377)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0510], device='cuda:0', requires_grad=True)
2022-03-23 22:16:05.636278
Epoch: [19][0/20], lr: 0.00100	Time 3.333 (3.333)	Data 2.404 (2.404)	Loss 0.0735 (0.0735)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1289 (0.1289)	Loss KD (GCAM) 0.0296 (0.0296)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5548 (0.5548)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0510], device='cuda:0', requires_grad=True)
2022-03-23 22:16:26.853065
Epoch: [20][0/20], lr: 0.00010	Time 3.449 (3.449)	Data 2.111 (2.111)	Loss 0.0722 (0.0722)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.1237 (0.1237)	Loss KD (GCAM) 0.0321 (0.0321)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5008 (0.5008)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0510], device='cuda:0', requires_grad=True)
2022-03-23 22:16:47.899872
Epoch: [21][0/20], lr: 0.00010	Time 3.638 (3.638)	Data 2.359 (2.359)	Loss 0.0732 (0.0732)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.1266 (0.1266)	Loss KD (GCAM) 0.0257 (0.0257)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5507 (0.5507)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9217], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0510], device='cuda:0', requires_grad=True)
2022-03-23 22:17:09.049640
Epoch: [22][0/20], lr: 0.00010	Time 3.389 (3.389)	Data 2.140 (2.140)	Loss 0.0716 (0.0716)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1279 (0.1279)	Loss KD (GCAM) 0.0296 (0.0296)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5391 (0.5391)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9217], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
2022-03-23 22:17:30.315860
Epoch: [23][0/20], lr: 0.00010	Time 3.307 (3.307)	Data 1.893 (1.893)	Loss 0.0764 (0.0764)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.1282 (0.1282)	Loss KD (GCAM) 0.0279 (0.0279)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5864 (0.5864)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9218], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
2022-03-23 22:17:51.482275
Epoch: [24][0/20], lr: 0.00010	Time 3.554 (3.554)	Data 2.372 (2.372)	Loss 0.0744 (0.0744)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.1225 (0.1225)	Loss KD (GCAM) 0.0279 (0.0279)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5471 (0.5471)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0512], device='cuda:0', requires_grad=True)
2022-03-23 22:18:13.081105
Epoch: [25][0/20], lr: 0.00010	Time 3.583 (3.583)	Data 2.153 (2.153)	Loss 0.0860 (0.0860)	Loss CE 0.0120 (0.0120)	Loss KD (Logit) 0.1230 (0.1230)	Loss KD (GCAM) 0.0292 (0.0292)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5689 (0.5689)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
2022-03-23 22:18:34.463001
Epoch: [26][0/20], lr: 0.00010	Time 3.671 (3.671)	Data 2.434 (2.434)	Loss 0.0705 (0.0705)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1225 (0.1225)	Loss KD (GCAM) 0.0257 (0.0257)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5430 (0.5430)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0512], device='cuda:0', requires_grad=True)
2022-03-23 22:18:55.880816
Epoch: [27][0/20], lr: 0.00010	Time 3.707 (3.707)	Data 2.233 (2.233)	Loss 0.0712 (0.0712)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1229 (0.1229)	Loss KD (GCAM) 0.0288 (0.0288)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5379 (0.5379)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0512], device='cuda:0', requires_grad=True)
2022-03-23 22:19:17.032016
Epoch: [28][0/20], lr: 0.00010	Time 3.461 (3.461)	Data 2.152 (2.152)	Loss 0.0771 (0.0771)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.1267 (0.1267)	Loss KD (GCAM) 0.0289 (0.0289)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5636 (0.5636)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9222], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0512], device='cuda:0', requires_grad=True)
2022-03-23 22:19:37.897576
Epoch: [29][0/20], lr: 0.00010	Time 3.197 (3.197)	Data 1.880 (1.880)	Loss 0.0706 (0.0706)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.1227 (0.1227)	Loss KD (GCAM) 0.0303 (0.0303)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5306 (0.5306)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:19:59.218639
Epoch: [30][0/20], lr: 0.00001	Time 3.531 (3.531)	Data 2.504 (2.504)	Loss 0.0742 (0.0742)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.1253 (0.1253)	Loss KD (GCAM) 0.0264 (0.0264)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5644 (0.5644)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:20:20.369255
Epoch: [31][0/20], lr: 0.00001	Time 3.498 (3.498)	Data 2.560 (2.560)	Loss 0.0700 (0.0700)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.1239 (0.1239)	Loss KD (GCAM) 0.0276 (0.0276)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5325 (0.5325)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:20:41.445889
Epoch: [32][0/20], lr: 0.00001	Time 3.343 (3.343)	Data 2.371 (2.371)	Loss 0.0728 (0.0728)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.1251 (0.1251)	Loss KD (GCAM) 0.0266 (0.0266)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5582 (0.5582)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:21:02.562013
Epoch: [33][0/20], lr: 0.00001	Time 3.406 (3.406)	Data 2.012 (2.012)	Loss 0.0714 (0.0714)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.1236 (0.1236)	Loss KD (GCAM) 0.0273 (0.0273)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5484 (0.5484)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:21:23.718545
Epoch: [34][0/20], lr: 0.00001	Time 3.447 (3.447)	Data 2.536 (2.536)	Loss 0.0729 (0.0729)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1272 (0.1272)	Loss KD (GCAM) 0.0272 (0.0272)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5573 (0.5573)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:21:44.795132
Epoch: [35][0/20], lr: 0.00001	Time 3.330 (3.330)	Data 2.147 (2.147)	Loss 0.0747 (0.0747)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.1236 (0.1236)	Loss KD (GCAM) 0.0257 (0.0257)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5744 (0.5744)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:22:05.398618
Epoch: [36][0/20], lr: 0.00001	Time 3.378 (3.378)	Data 2.472 (2.472)	Loss 0.0747 (0.0747)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.1263 (0.1263)	Loss KD (GCAM) 0.0312 (0.0312)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5670 (0.5670)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:22:26.549606
Epoch: [37][0/20], lr: 0.00001	Time 3.421 (3.421)	Data 2.154 (2.154)	Loss 0.0732 (0.0732)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1278 (0.1278)	Loss KD (GCAM) 0.0268 (0.0268)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5612 (0.5612)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:22:47.198036
Epoch: [38][0/20], lr: 0.00001	Time 3.264 (3.264)	Data 1.955 (1.955)	Loss 0.0704 (0.0704)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.1239 (0.1239)	Loss KD (GCAM) 0.0281 (0.0281)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5282 (0.5282)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:23:08.304538
Epoch: [39][0/20], lr: 0.00001	Time 3.626 (3.626)	Data 2.127 (2.127)	Loss 0.0711 (0.0711)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1302 (0.1302)	Loss KD (GCAM) 0.0300 (0.0300)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5287 (0.5287)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:23:29.332121
Epoch: [40][0/20], lr: 0.00001	Time 3.408 (3.408)	Data 2.247 (2.247)	Loss 0.0759 (0.0759)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.1279 (0.1279)	Loss KD (GCAM) 0.0275 (0.0275)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5804 (0.5804)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:23:50.518643
Epoch: [41][0/20], lr: 0.00001	Time 3.589 (3.589)	Data 2.151 (2.151)	Loss 0.0708 (0.0708)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.1243 (0.1243)	Loss KD (GCAM) 0.0273 (0.0273)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5362 (0.5362)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:24:10.968189
Epoch: [42][0/20], lr: 0.00001	Time 3.620 (3.620)	Data 2.256 (2.256)	Loss 0.0759 (0.0759)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 0.1307 (0.1307)	Loss KD (GCAM) 0.0308 (0.0308)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5189 (0.5189)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:24:30.200856
Epoch: [43][0/20], lr: 0.00001	Time 3.320 (3.320)	Data 2.308 (2.308)	Loss 0.0718 (0.0718)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.1254 (0.1254)	Loss KD (GCAM) 0.0313 (0.0313)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5330 (0.5330)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:24:49.435879
Epoch: [44][0/20], lr: 0.00001	Time 3.304 (3.304)	Data 2.080 (2.080)	Loss 0.0684 (0.0684)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1241 (0.1241)	Loss KD (GCAM) 0.0280 (0.0280)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5128 (0.5128)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:25:07.019725
Epoch: [45][0/20], lr: 0.00001	Time 3.443 (3.443)	Data 2.484 (2.484)	Loss 0.0779 (0.0779)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.1254 (0.1254)	Loss KD (GCAM) 0.0303 (0.0303)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5694 (0.5694)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:25:24.612301
Epoch: [46][0/20], lr: 0.00001	Time 3.333 (3.333)	Data 1.960 (1.960)	Loss 0.1390 (0.1390)	Loss CE 0.0655 (0.0655)	Loss KD (Logit) 0.1215 (0.1215)	Loss KD (GCAM) 0.0295 (0.0295)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5643 (0.5643)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:25:42.583983
Epoch: [47][0/20], lr: 0.00001	Time 3.630 (3.630)	Data 2.654 (2.654)	Loss 0.0748 (0.0748)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.1278 (0.1278)	Loss KD (GCAM) 0.0273 (0.0273)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5613 (0.5613)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:26:00.496038
Epoch: [48][0/20], lr: 0.00001	Time 3.743 (3.743)	Data 2.129 (2.129)	Loss 0.0735 (0.0735)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1248 (0.1248)	Loss KD (GCAM) 0.0283 (0.0283)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5644 (0.5644)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:26:17.979802
Epoch: [49][0/20], lr: 0.00001	Time 3.310 (3.310)	Data 1.950 (1.950)	Loss 0.0699 (0.0699)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.1264 (0.1264)	Loss KD (GCAM) 0.0276 (0.0276)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5222 (0.5222)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=279, sigma=tensor([3.9224]), eta=tensor([3.0513])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 208
video number + exemplar : 208
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=279, sigma=tensor([3.9224]), eta=tensor([3.0513])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 465
DataLoader CBF Constructed : Train 14
Optimizer Constructed
2022-03-23 22:26:52.011718
Epoch: [0][0/14], lr: 0.00050	Time 2.902 (2.902)	Data 2.373 (2.373)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9225], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:27:01.624913
Epoch: [1][0/14], lr: 0.00050	Time 2.911 (2.911)	Data 2.147 (2.147)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
2022-03-23 22:27:11.091902
Epoch: [2][0/14], lr: 0.00050	Time 2.916 (2.916)	Data 2.327 (2.327)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0505], device='cuda:0', requires_grad=True)
2022-03-23 22:27:20.844480
Epoch: [3][0/14], lr: 0.00050	Time 3.178 (3.178)	Data 2.185 (2.185)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0499], device='cuda:0', requires_grad=True)
2022-03-23 22:27:30.027646
Epoch: [4][0/14], lr: 0.00050	Time 2.807 (2.807)	Data 2.147 (2.147)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0495], device='cuda:0', requires_grad=True)
2022-03-23 22:27:39.652586
Epoch: [5][0/14], lr: 0.00050	Time 2.905 (2.905)	Data 1.920 (1.920)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0493], device='cuda:0', requires_grad=True)
2022-03-23 22:27:49.180882
Epoch: [6][0/14], lr: 0.00050	Time 2.997 (2.997)	Data 1.920 (1.920)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0494], device='cuda:0', requires_grad=True)
2022-03-23 22:27:58.481062
Epoch: [7][0/14], lr: 0.00050	Time 3.003 (3.003)	Data 2.022 (2.022)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9211], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0492], device='cuda:0', requires_grad=True)
2022-03-23 22:28:07.793124
Epoch: [8][0/14], lr: 0.00050	Time 2.943 (2.943)	Data 2.290 (2.290)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9210], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0490], device='cuda:0', requires_grad=True)
2022-03-23 22:28:17.416611
Epoch: [9][0/14], lr: 0.00050	Time 3.249 (3.249)	Data 2.212 (2.212)	Loss 0.0177 (0.0177)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0490], device='cuda:0', requires_grad=True)
2022-03-23 22:28:26.942518
Epoch: [10][0/14], lr: 0.00050	Time 2.950 (2.950)	Data 2.182 (2.182)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9211], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0488], device='cuda:0', requires_grad=True)
2022-03-23 22:28:36.300159
Epoch: [11][0/14], lr: 0.00050	Time 2.900 (2.900)	Data 2.174 (2.174)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0485], device='cuda:0', requires_grad=True)
2022-03-23 22:28:45.774998
Epoch: [12][0/14], lr: 0.00050	Time 3.058 (3.058)	Data 2.334 (2.334)	Loss 0.0113 (0.0113)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0483], device='cuda:0', requires_grad=True)
2022-03-23 22:28:55.613702
Epoch: [13][0/14], lr: 0.00050	Time 3.177 (3.177)	Data 2.659 (2.659)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9201], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 22:29:05.245472
Epoch: [14][0/14], lr: 0.00050	Time 2.880 (2.880)	Data 2.251 (2.251)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9200], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0475], device='cuda:0', requires_grad=True)
2022-03-23 22:29:14.503253
Epoch: [15][0/14], lr: 0.00050	Time 2.879 (2.879)	Data 1.858 (1.858)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9198], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0472], device='cuda:0', requires_grad=True)
2022-03-23 22:29:23.510384
Epoch: [16][0/14], lr: 0.00050	Time 2.909 (2.909)	Data 1.854 (1.854)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9195], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0469], device='cuda:0', requires_grad=True)
2022-03-23 22:29:32.919867
Epoch: [17][0/14], lr: 0.00050	Time 2.838 (2.838)	Data 1.942 (1.942)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9197], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0469], device='cuda:0', requires_grad=True)
2022-03-23 22:29:42.321172
Epoch: [18][0/14], lr: 0.00050	Time 3.319 (3.319)	Data 2.487 (2.487)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9198], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0468], device='cuda:0', requires_grad=True)
2022-03-23 22:29:51.801454
Epoch: [19][0/14], lr: 0.00050	Time 3.096 (3.096)	Data 2.305 (2.305)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9192], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0463], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_021.pth.tar
exemplar : 465
Computing the class mean vectors...
Eval Task 0 for Age 21
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.580 (4.580)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.359 (0.547)	Prec@1 81.250 (66.089)
Testing Results: Prec@1 65.326
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 81.250 (70.668)
Testing Results (NME): Prec@1 69.603
Eval Task 1 for Age 21
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.754 (3.754)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 41.379
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 56.897
Eval Task 2 for Age 21
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 4.012 (4.012)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 46.154
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 49.231
Eval Task 3 for Age 21
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.075 (4.075)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 65.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 61.250
Eval Task 4 for Age 21
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.240 (4.240)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 71.765
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 77.647
Eval Task 5 for Age 21
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.823 (3.823)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 67.742
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 62.903
Eval Task 6 for Age 21
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.342 (4.342)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 64.198
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 46.914
Eval Task 7 for Age 21
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.736 (3.736)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 79.104
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 71.642
Eval Task 8 for Age 21
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.036 (4.036)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 51.515
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 50.000
Eval Task 9 for Age 21
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.558 (3.558)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 48.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 50.667
Eval Task 10 for Age 21
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.431 (4.431)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 67.442
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 75.581
Eval Task 11 for Age 21
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 4.068 (4.068)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 85.484
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 79.032
Eval Task 12 for Age 21
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.087 (4.087)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 21
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.967 (3.967)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 56.579
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 68.421
Eval Task 14 for Age 21
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.298 (4.298)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.463
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 91.463
Eval Task 15 for Age 21
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.783 (3.783)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 58.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 62.500
Eval Task 16 for Age 21
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.600 (3.600)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 64.286
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 53.571
Eval Task 17 for Age 21
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.124 (4.124)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 60.241
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 55.422
Eval Task 18 for Age 21
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 4.072 (4.072)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 79.688
Eval Task 19 for Age 21
Current Task : [5, 32]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.449 (4.449)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 93.902
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.244
Eval Task 20 for Age 21
Current Task : [4, 51]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.964 (3.964)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 73.529
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 66.176
Eval Task 21 for Age 21
Current Task : [48, 73]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.952 (3.952)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.701
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 92.208
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64, 82, 68, 77]
Method : OURS
----AGE 22----
current_task  [93, 39]
current_head  95
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06819090848492927]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=285, sigma=tensor([3.9192]), eta=tensor([3.0463])
  (fc1): CosineLinear(input_features=512, output_features=279, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 173
video number + exemplar : 638
DataLoader Constructed : Train 19
Optimizer Constructed
video number : 173
video number + exemplar : 173
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 22:36:37.115131
Epoch: [0][0/19], lr: 0.00100	Time 3.777 (3.777)	Data 2.504 (2.504)	Loss 0.0685 (0.0685)	Loss CE 0.0064 (0.0064)	Loss KD (Logit) 0.0700 (0.0700)	Loss KD (GCAM) 0.0093 (0.0093)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5450 (0.5450)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9181], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0461], device='cuda:0', requires_grad=True)
2022-03-23 22:36:56.945406
Epoch: [1][0/19], lr: 0.00100	Time 3.532 (3.532)	Data 2.051 (2.051)	Loss 0.2852 (0.2852)	Loss CE 0.2209 (0.2209)	Loss KD (Logit) 0.0690 (0.0690)	Loss KD (GCAM) 0.0130 (0.0130)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5568 (0.5568)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
Sigma : Parameter containing:
tensor([3.9099], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0412], device='cuda:0', requires_grad=True)
2022-03-23 22:37:17.222006
Epoch: [2][0/19], lr: 0.00100	Time 3.452 (3.452)	Data 2.146 (2.146)	Loss 0.1078 (0.1078)	Loss CE 0.0425 (0.0425)	Loss KD (Logit) 0.0756 (0.0756)	Loss KD (GCAM) 0.0165 (0.0165)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5523 (0.5523)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9051], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0393], device='cuda:0', requires_grad=True)
2022-03-23 22:37:37.359508
Epoch: [3][0/19], lr: 0.00100	Time 3.429 (3.429)	Data 2.222 (2.222)	Loss 0.0793 (0.0793)	Loss CE 0.0145 (0.0145)	Loss KD (Logit) 0.0745 (0.0745)	Loss KD (GCAM) 0.0205 (0.0205)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5356 (0.5356)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9073], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0419], device='cuda:0', requires_grad=True)
2022-03-23 22:37:56.815541
Epoch: [4][0/19], lr: 0.00100	Time 3.387 (3.387)	Data 2.444 (2.444)	Loss 0.0954 (0.0954)	Loss CE 0.0317 (0.0317)	Loss KD (Logit) 0.0765 (0.0765)	Loss KD (GCAM) 0.0206 (0.0206)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5227 (0.5227)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9082], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0425], device='cuda:0', requires_grad=True)
2022-03-23 22:38:15.161019
Epoch: [5][0/19], lr: 0.00100	Time 3.278 (3.278)	Data 2.066 (2.066)	Loss 0.0696 (0.0696)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0747 (0.0747)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5498 (0.5498)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9039], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0396], device='cuda:0', requires_grad=True)
2022-03-23 22:38:33.897297
Epoch: [6][0/19], lr: 0.00100	Time 3.462 (3.462)	Data 2.679 (2.679)	Loss 0.0870 (0.0870)	Loss CE 0.0221 (0.0221)	Loss KD (Logit) 0.0719 (0.0719)	Loss KD (GCAM) 0.0184 (0.0184)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5447 (0.5447)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8999], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0370], device='cuda:0', requires_grad=True)
2022-03-23 22:38:51.279768
Epoch: [7][0/19], lr: 0.00100	Time 3.565 (3.565)	Data 1.919 (1.919)	Loss 0.1053 (0.1053)	Loss CE 0.0381 (0.0381)	Loss KD (Logit) 0.0774 (0.0774)	Loss KD (GCAM) 0.0208 (0.0208)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5574 (0.5574)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9014], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0378], device='cuda:0', requires_grad=True)
2022-03-23 22:39:08.193740
Epoch: [8][0/19], lr: 0.00100	Time 3.486 (3.486)	Data 2.416 (2.416)	Loss 0.0705 (0.0705)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0742 (0.0742)	Loss KD (GCAM) 0.0209 (0.0209)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5793 (0.5793)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9050], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0400], device='cuda:0', requires_grad=True)
2022-03-23 22:39:25.265743
Epoch: [9][0/19], lr: 0.00100	Time 3.299 (3.299)	Data 2.226 (2.226)	Loss 0.0802 (0.0802)	Loss CE 0.0141 (0.0141)	Loss KD (Logit) 0.0775 (0.0775)	Loss KD (GCAM) 0.0200 (0.0200)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5485 (0.5485)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9044], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0396], device='cuda:0', requires_grad=True)
2022-03-23 22:39:41.919052
Epoch: [10][0/19], lr: 0.00100	Time 3.231 (3.231)	Data 2.263 (2.263)	Loss 0.0690 (0.0690)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0729 (0.0729)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5753 (0.5753)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9073], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0415], device='cuda:0', requires_grad=True)
2022-03-23 22:39:58.697220
Epoch: [11][0/19], lr: 0.00100	Time 3.233 (3.233)	Data 1.919 (1.919)	Loss 0.0716 (0.0716)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0741 (0.0741)	Loss KD (GCAM) 0.0197 (0.0197)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5905 (0.5905)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9119], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0444], device='cuda:0', requires_grad=True)
2022-03-23 22:40:15.571738
Epoch: [12][0/19], lr: 0.00100	Time 3.323 (3.323)	Data 2.379 (2.379)	Loss 0.0702 (0.0702)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0760 (0.0760)	Loss KD (GCAM) 0.0205 (0.0205)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5511 (0.5511)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9158], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0468], device='cuda:0', requires_grad=True)
2022-03-23 22:40:32.718856
Epoch: [13][0/19], lr: 0.00100	Time 3.523 (3.523)	Data 2.440 (2.440)	Loss 0.0692 (0.0692)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0786 (0.0786)	Loss KD (GCAM) 0.0211 (0.0211)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5687 (0.5687)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9177], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0478], device='cuda:0', requires_grad=True)
2022-03-23 22:40:50.143590
Epoch: [14][0/19], lr: 0.00100	Time 3.441 (3.441)	Data 2.441 (2.441)	Loss 0.0664 (0.0664)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0752 (0.0752)	Loss KD (GCAM) 0.0196 (0.0196)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5469 (0.5469)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9176], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0477], device='cuda:0', requires_grad=True)
2022-03-23 22:41:07.406514
Epoch: [15][0/19], lr: 0.00100	Time 3.318 (3.318)	Data 1.943 (1.943)	Loss 0.0700 (0.0700)	Loss CE 0.0052 (0.0052)	Loss KD (Logit) 0.0754 (0.0754)	Loss KD (GCAM) 0.0175 (0.0175)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5434 (0.5434)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9191], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0486], device='cuda:0', requires_grad=True)
2022-03-23 22:41:24.499248
Epoch: [16][0/19], lr: 0.00100	Time 3.291 (3.291)	Data 1.966 (1.966)	Loss 0.0806 (0.0806)	Loss CE 0.0173 (0.0173)	Loss KD (Logit) 0.0760 (0.0760)	Loss KD (GCAM) 0.0221 (0.0221)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5142 (0.5142)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9237], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0514], device='cuda:0', requires_grad=True)
2022-03-23 22:41:41.589239
Epoch: [17][0/19], lr: 0.00100	Time 3.069 (3.069)	Data 1.846 (1.846)	Loss 0.0692 (0.0692)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0717 (0.0717)	Loss KD (GCAM) 0.0223 (0.0223)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5436 (0.5436)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9267], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0529], device='cuda:0', requires_grad=True)
2022-03-23 22:41:58.420088
Epoch: [18][0/19], lr: 0.00100	Time 3.167 (3.167)	Data 2.092 (2.092)	Loss 0.0668 (0.0668)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0710 (0.0710)	Loss KD (GCAM) 0.0217 (0.0217)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5504 (0.5504)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9261], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0520], device='cuda:0', requires_grad=True)
2022-03-23 22:42:15.231376
Epoch: [19][0/19], lr: 0.00100	Time 3.287 (3.287)	Data 2.034 (2.034)	Loss 0.0654 (0.0654)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0729 (0.0729)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5238 (0.5238)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9271], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0522], device='cuda:0', requires_grad=True)
2022-03-23 22:42:32.216649
Epoch: [20][0/19], lr: 0.00010	Time 3.332 (3.332)	Data 2.543 (2.543)	Loss 0.0658 (0.0658)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0716 (0.0716)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5462 (0.5462)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9272], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0523], device='cuda:0', requires_grad=True)
2022-03-23 22:42:49.603480
Epoch: [21][0/19], lr: 0.00010	Time 3.389 (3.389)	Data 2.496 (2.496)	Loss 0.0692 (0.0692)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0754 (0.0754)	Loss KD (GCAM) 0.0211 (0.0211)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5709 (0.5709)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9275], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0524], device='cuda:0', requires_grad=True)
2022-03-23 22:43:06.988820
Epoch: [22][0/19], lr: 0.00010	Time 3.337 (3.337)	Data 2.259 (2.259)	Loss 0.0626 (0.0626)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0726 (0.0726)	Loss KD (GCAM) 0.0207 (0.0207)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5107 (0.5107)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9277], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0525], device='cuda:0', requires_grad=True)
2022-03-23 22:43:24.365704
Epoch: [23][0/19], lr: 0.00010	Time 3.297 (3.297)	Data 2.011 (2.011)	Loss 0.0630 (0.0630)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0758 (0.0758)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5132 (0.5132)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9278], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0526], device='cuda:0', requires_grad=True)
2022-03-23 22:43:40.146719
Epoch: [24][0/19], lr: 0.00010	Time 3.176 (3.176)	Data 1.891 (1.891)	Loss 0.0679 (0.0679)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0743 (0.0743)	Loss KD (GCAM) 0.0208 (0.0208)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5531 (0.5531)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9280], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0527], device='cuda:0', requires_grad=True)
2022-03-23 22:44:00.693726
Epoch: [25][0/19], lr: 0.00010	Time 3.756 (3.756)	Data 2.186 (2.186)	Loss 0.0699 (0.0699)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0717 (0.0717)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5887 (0.5887)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0527], device='cuda:0', requires_grad=True)
2022-03-23 22:44:20.895709
Epoch: [26][0/19], lr: 0.00010	Time 3.345 (3.345)	Data 2.109 (2.109)	Loss 0.0721 (0.0721)	Loss CE 0.0057 (0.0057)	Loss KD (Logit) 0.0750 (0.0750)	Loss KD (GCAM) 0.0195 (0.0195)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5535 (0.5535)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9283], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0528], device='cuda:0', requires_grad=True)
2022-03-23 22:44:40.975723
Epoch: [27][0/19], lr: 0.00010	Time 3.445 (3.445)	Data 2.065 (2.065)	Loss 0.0963 (0.0963)	Loss CE 0.0302 (0.0302)	Loss KD (Logit) 0.0769 (0.0769)	Loss KD (GCAM) 0.0196 (0.0196)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5502 (0.5502)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9284], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0529], device='cuda:0', requires_grad=True)
2022-03-23 22:45:00.977552
Epoch: [28][0/19], lr: 0.00010	Time 3.463 (3.463)	Data 1.814 (1.814)	Loss 0.0725 (0.0725)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.0733 (0.0733)	Loss KD (GCAM) 0.0183 (0.0183)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5578 (0.5578)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9287], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0531], device='cuda:0', requires_grad=True)
2022-03-23 22:45:21.488198
Epoch: [29][0/19], lr: 0.00010	Time 3.771 (3.771)	Data 2.255 (2.255)	Loss 0.0660 (0.0660)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0775 (0.0775)	Loss KD (GCAM) 0.0196 (0.0196)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5353 (0.5353)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:45:41.527133
Epoch: [30][0/19], lr: 0.00001	Time 3.584 (3.584)	Data 2.629 (2.629)	Loss 0.0679 (0.0679)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0737 (0.0737)	Loss KD (GCAM) 0.0192 (0.0192)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5678 (0.5678)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:46:01.763839
Epoch: [31][0/19], lr: 0.00001	Time 3.318 (3.318)	Data 2.267 (2.267)	Loss 0.0655 (0.0655)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0756 (0.0756)	Loss KD (GCAM) 0.0197 (0.0197)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5372 (0.5372)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:46:22.194132
Epoch: [32][0/19], lr: 0.00001	Time 3.449 (3.449)	Data 2.389 (2.389)	Loss 0.0696 (0.0696)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0727 (0.0727)	Loss KD (GCAM) 0.0192 (0.0192)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5681 (0.5681)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:46:42.095467
Epoch: [33][0/19], lr: 0.00001	Time 3.429 (3.429)	Data 2.617 (2.617)	Loss 0.0676 (0.0676)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0743 (0.0743)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5672 (0.5672)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:47:02.829284
Epoch: [34][0/19], lr: 0.00001	Time 3.807 (3.807)	Data 2.609 (2.609)	Loss 0.0620 (0.0620)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0750 (0.0750)	Loss KD (GCAM) 0.0193 (0.0193)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4942 (0.4942)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:47:22.894461
Epoch: [35][0/19], lr: 0.00001	Time 3.329 (3.329)	Data 2.134 (2.134)	Loss 0.0729 (0.0729)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0745 (0.0745)	Loss KD (GCAM) 0.0191 (0.0191)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5623 (0.5623)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:47:43.010059
Epoch: [36][0/19], lr: 0.00001	Time 3.413 (3.413)	Data 2.135 (2.135)	Loss 0.0799 (0.0799)	Loss CE 0.0125 (0.0125)	Loss KD (Logit) 0.0745 (0.0745)	Loss KD (GCAM) 0.0182 (0.0182)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5693 (0.5693)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:48:03.296191
Epoch: [37][0/19], lr: 0.00001	Time 3.641 (3.641)	Data 2.675 (2.675)	Loss 0.0677 (0.0677)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0770 (0.0770)	Loss KD (GCAM) 0.0197 (0.0197)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5629 (0.5629)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9289], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:48:23.553745
Epoch: [38][0/19], lr: 0.00001	Time 3.409 (3.409)	Data 2.454 (2.454)	Loss 0.0673 (0.0673)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0757 (0.0757)	Loss KD (GCAM) 0.0193 (0.0193)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5249 (0.5249)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:48:43.693137
Epoch: [39][0/19], lr: 0.00001	Time 3.386 (3.386)	Data 2.397 (2.397)	Loss 0.0739 (0.0739)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0724 (0.0724)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5713 (0.5713)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:49:03.669512
Epoch: [40][0/19], lr: 0.00001	Time 3.236 (3.236)	Data 2.234 (2.234)	Loss 0.0702 (0.0702)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0728 (0.0728)	Loss KD (GCAM) 0.0188 (0.0188)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5775 (0.5775)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:49:23.925755
Epoch: [41][0/19], lr: 0.00001	Time 3.343 (3.343)	Data 2.533 (2.533)	Loss 0.0661 (0.0661)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0748 (0.0748)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5456 (0.5456)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:49:43.861263
Epoch: [42][0/19], lr: 0.00001	Time 3.272 (3.272)	Data 1.982 (1.982)	Loss 0.0676 (0.0676)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0749 (0.0749)	Loss KD (GCAM) 0.0204 (0.0204)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5601 (0.5601)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:50:03.826661
Epoch: [43][0/19], lr: 0.00001	Time 3.497 (3.497)	Data 2.507 (2.507)	Loss 0.0659 (0.0659)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0696 (0.0696)	Loss KD (GCAM) 0.0181 (0.0181)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5486 (0.5486)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:50:23.920922
Epoch: [44][0/19], lr: 0.00001	Time 3.420 (3.420)	Data 1.932 (1.932)	Loss 0.0638 (0.0638)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0764 (0.0764)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5260 (0.5260)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:50:43.820421
Epoch: [45][0/19], lr: 0.00001	Time 3.315 (3.315)	Data 1.868 (1.868)	Loss 0.0688 (0.0688)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0719 (0.0719)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5735 (0.5735)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:51:04.126683
Epoch: [46][0/19], lr: 0.00001	Time 3.347 (3.347)	Data 1.983 (1.983)	Loss 0.0638 (0.0638)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0740 (0.0740)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5164 (0.5164)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:51:24.375640
Epoch: [47][0/19], lr: 0.00001	Time 3.451 (3.451)	Data 2.365 (2.365)	Loss 0.0657 (0.0657)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0728 (0.0728)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5482 (0.5482)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9290], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:51:44.576773
Epoch: [48][0/19], lr: 0.00001	Time 3.437 (3.437)	Data 2.299 (2.299)	Loss 0.0712 (0.0712)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0725 (0.0725)	Loss KD (GCAM) 0.0210 (0.0210)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5862 (0.5862)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9291], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 22:52:04.578502
Epoch: [49][0/19], lr: 0.00001	Time 3.496 (3.496)	Data 2.015 (2.015)	Loss 0.0761 (0.0761)	Loss CE 0.0101 (0.0101)	Loss KD (Logit) 0.0727 (0.0727)	Loss KD (GCAM) 0.0196 (0.0196)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5521 (0.5521)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9291], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0533], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=285, sigma=tensor([3.9291]), eta=tensor([3.0533])
  (fc1): CosineLinear(input_features=512, output_features=279, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 173
video number + exemplar : 173
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=285, sigma=tensor([3.9291]), eta=tensor([3.0533])
  (fc1): CosineLinear(input_features=512, output_features=279, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 475
DataLoader CBF Constructed : Train 14
Optimizer Constructed
2022-03-23 22:52:42.407222
Epoch: [0][0/14], lr: 0.00050	Time 3.067 (3.067)	Data 1.884 (1.884)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9283], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0528], device='cuda:0', requires_grad=True)
2022-03-23 22:52:52.874627
Epoch: [1][0/14], lr: 0.00050	Time 2.810 (2.810)	Data 2.269 (2.269)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9276], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0524], device='cuda:0', requires_grad=True)
2022-03-23 22:53:02.774142
Epoch: [2][0/14], lr: 0.00050	Time 3.120 (3.120)	Data 2.177 (2.177)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9275], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0523], device='cuda:0', requires_grad=True)
2022-03-23 22:53:12.125707
Epoch: [3][0/14], lr: 0.00050	Time 2.984 (2.984)	Data 1.945 (1.945)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9280], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0525], device='cuda:0', requires_grad=True)
2022-03-23 22:53:21.560113
Epoch: [4][0/14], lr: 0.00050	Time 3.012 (3.012)	Data 2.470 (2.470)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9285], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0527], device='cuda:0', requires_grad=True)
2022-03-23 22:53:31.310201
Epoch: [5][0/14], lr: 0.00050	Time 2.859 (2.859)	Data 1.981 (1.981)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0524], device='cuda:0', requires_grad=True)
2022-03-23 22:53:40.966762
Epoch: [6][0/14], lr: 0.00050	Time 3.132 (3.132)	Data 2.567 (2.567)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9276], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0520], device='cuda:0', requires_grad=True)
2022-03-23 22:53:50.428726
Epoch: [7][0/14], lr: 0.00050	Time 2.920 (2.920)	Data 2.317 (2.317)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9277], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0519], device='cuda:0', requires_grad=True)
2022-03-23 22:53:59.706818
Epoch: [8][0/14], lr: 0.00050	Time 2.923 (2.923)	Data 2.229 (2.229)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9277], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0518], device='cuda:0', requires_grad=True)
2022-03-23 22:54:09.181940
Epoch: [9][0/14], lr: 0.00050	Time 3.093 (3.093)	Data 1.985 (1.985)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9279], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0519], device='cuda:0', requires_grad=True)
2022-03-23 22:54:18.890638
Epoch: [10][0/14], lr: 0.00050	Time 3.146 (3.146)	Data 2.311 (2.311)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9280], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0518], device='cuda:0', requires_grad=True)
2022-03-23 22:54:28.296876
Epoch: [11][0/14], lr: 0.00050	Time 3.055 (3.055)	Data 2.141 (2.141)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0518], device='cuda:0', requires_grad=True)
2022-03-23 22:54:37.635545
Epoch: [12][0/14], lr: 0.00050	Time 3.039 (3.039)	Data 2.010 (2.010)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0516], device='cuda:0', requires_grad=True)
2022-03-23 22:54:47.141568
Epoch: [13][0/14], lr: 0.00050	Time 3.041 (3.041)	Data 1.927 (1.927)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9281], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0515], device='cuda:0', requires_grad=True)
2022-03-23 22:54:56.713097
Epoch: [14][0/14], lr: 0.00050	Time 3.202 (3.202)	Data 2.645 (2.645)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9281], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0514], device='cuda:0', requires_grad=True)
2022-03-23 22:55:05.935745
Epoch: [15][0/14], lr: 0.00050	Time 2.842 (2.842)	Data 2.091 (2.091)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0513], device='cuda:0', requires_grad=True)
2022-03-23 22:55:15.251392
Epoch: [16][0/14], lr: 0.00050	Time 2.985 (2.985)	Data 1.961 (1.961)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0512], device='cuda:0', requires_grad=True)
2022-03-23 22:55:24.550235
Epoch: [17][0/14], lr: 0.00050	Time 3.021 (3.021)	Data 2.047 (2.047)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9284], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0512], device='cuda:0', requires_grad=True)
2022-03-23 22:55:34.343420
Epoch: [18][0/14], lr: 0.00050	Time 3.007 (3.007)	Data 1.972 (1.972)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9285], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
2022-03-23 22:55:43.788745
Epoch: [19][0/14], lr: 0.00050	Time 2.953 (2.953)	Data 2.295 (2.295)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9288], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0511], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_022.pth.tar
exemplar : 475
Computing the class mean vectors...
Eval Task 0 for Age 22
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.775 (4.775)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.568 (0.519)	Prec@1 56.250 (66.089)
Testing Results: Prec@1 65.530
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 68.750 (69.121)
Testing Results (NME): Prec@1 68.228
Eval Task 1 for Age 22
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.811 (3.811)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 51.724
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 62.069
Eval Task 2 for Age 22
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 4.172 (4.172)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 49.231
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 52.308
Eval Task 3 for Age 22
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.132 (4.132)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 66.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 62.500
Eval Task 4 for Age 22
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.858 (3.858)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 70.588
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 75.294
Eval Task 5 for Age 22
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.923 (3.923)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 66.129
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 62.903
Eval Task 6 for Age 22
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.422 (3.422)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 61.728
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 48.148
Eval Task 7 for Age 22
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.594 (3.594)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 88.060
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 77.612
Eval Task 8 for Age 22
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.220 (4.220)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 48.485
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 46.970
Eval Task 9 for Age 22
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.425 (4.425)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 61.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 54.667
Eval Task 10 for Age 22
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.246 (4.246)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 53.488
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 61.628
Eval Task 11 for Age 22
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.786 (3.786)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 82.258
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 77.419
Eval Task 12 for Age 22
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.191 (4.191)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 22
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 4.232 (4.232)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 73.684
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 65.789
Eval Task 14 for Age 22
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.429 (3.429)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 76.829
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.683
Eval Task 15 for Age 22
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.109 (4.109)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 65.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 61.250
Eval Task 16 for Age 22
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 4.046 (4.046)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 62.500
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 62.500
Eval Task 17 for Age 22
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.367 (4.367)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 56.627
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 53.012
Eval Task 18 for Age 22
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.846 (3.846)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 93.750
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 84.375
Eval Task 19 for Age 22
Current Task : [5, 32]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.254 (4.254)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 74.390
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 82.927
Eval Task 20 for Age 22
Current Task : [4, 51]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 4.244 (4.244)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 57.353
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 58.824
Eval Task 21 for Age 22
Current Task : [48, 73]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.849 (3.849)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 90.909
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 87.013
Eval Task 22 for Age 22
Current Task : [93, 39]
video number : 69
video number + exemplar : 69
DataLoader Constructed
Test: [0/5]	Time 4.253 (4.253)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 94.203
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 82.609
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64, 82, 68, 77, 69]
Method : OURS
----AGE 23----
current_task  [67, 29]
current_head  97
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06892024376045111]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=291, sigma=tensor([3.9288]), eta=tensor([3.0511])
  (fc1): CosineLinear(input_features=512, output_features=285, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 198
video number + exemplar : 673
DataLoader Constructed : Train 21
Optimizer Constructed
video number : 198
video number + exemplar : 198
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-23 23:02:31.508449
Epoch: [0][0/21], lr: 0.00100	Time 3.573 (3.573)	Data 1.832 (1.832)	Loss 0.0732 (0.0732)	Loss CE 0.0209 (0.0209)	Loss KD (Logit) 0.0040 (0.0040)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5158 (0.5158)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.9178], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0437], device='cuda:0', requires_grad=True)
2022-03-23 23:02:53.190246
Epoch: [1][0/21], lr: 0.00100	Time 3.725 (3.725)	Data 2.482 (2.482)	Loss 0.0574 (0.0574)	Loss CE 0.0060 (0.0060)	Loss KD (Logit) 0.0041 (0.0041)	Loss KD (GCAM) 0.0022 (0.0022)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5050 (0.5050)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9228], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0474], device='cuda:0', requires_grad=True)
2022-03-23 23:03:15.093409
Epoch: [2][0/21], lr: 0.00100	Time 3.426 (3.426)	Data 2.053 (2.053)	Loss 0.0611 (0.0611)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5575 (0.5575)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9331], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0545], device='cuda:0', requires_grad=True)
2022-03-23 23:03:36.907970
Epoch: [3][0/21], lr: 0.00100	Time 3.472 (3.472)	Data 2.123 (2.123)	Loss 0.1083 (0.1083)	Loss CE 0.0502 (0.0502)	Loss KD (Logit) 0.0041 (0.0041)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5708 (0.5708)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9397], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0585], device='cuda:0', requires_grad=True)
2022-03-23 23:03:58.847517
Epoch: [4][0/21], lr: 0.00100	Time 3.501 (3.501)	Data 2.296 (2.296)	Loss 0.1560 (0.1560)	Loss CE 0.0976 (0.0976)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5732 (0.5732)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0620], device='cuda:0', requires_grad=True)
2022-03-23 23:04:20.466085
Epoch: [5][0/21], lr: 0.00100	Time 3.168 (3.168)	Data 1.860 (1.860)	Loss 0.0973 (0.0973)	Loss CE 0.0400 (0.0400)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5604 (0.5604)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9466], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0638], device='cuda:0', requires_grad=True)
2022-03-23 23:04:42.523523
Epoch: [6][0/21], lr: 0.00100	Time 3.431 (3.431)	Data 2.348 (2.348)	Loss 0.0634 (0.0634)	Loss CE 0.0052 (0.0052)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0028 (0.0028)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5701 (0.5701)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9476], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0641], device='cuda:0', requires_grad=True)
2022-03-23 23:05:04.804972
Epoch: [7][0/21], lr: 0.00100	Time 3.862 (3.862)	Data 2.141 (2.141)	Loss 0.0676 (0.0676)	Loss CE 0.0122 (0.0122)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0027 (0.0027)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5419 (0.5419)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9532], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0674], device='cuda:0', requires_grad=True)
2022-03-23 23:05:27.077736
Epoch: [8][0/21], lr: 0.00100	Time 3.759 (3.759)	Data 2.837 (2.837)	Loss 0.0582 (0.0582)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0028 (0.0028)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5556 (0.5556)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9606], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0721], device='cuda:0', requires_grad=True)
2022-03-23 23:05:49.297289
Epoch: [9][0/21], lr: 0.00100	Time 3.831 (3.831)	Data 2.766 (2.766)	Loss 0.0578 (0.0578)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5562 (0.5562)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9667], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0760], device='cuda:0', requires_grad=True)
2022-03-23 23:06:11.197129
Epoch: [10][0/21], lr: 0.00100	Time 3.393 (3.393)	Data 1.917 (1.917)	Loss 0.0543 (0.0543)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5123 (0.5123)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9706], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0784], device='cuda:0', requires_grad=True)
2022-03-23 23:06:33.418464
Epoch: [11][0/21], lr: 0.00100	Time 3.582 (3.582)	Data 2.535 (2.535)	Loss 0.0566 (0.0566)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5336 (0.5336)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9737], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0802], device='cuda:0', requires_grad=True)
2022-03-23 23:06:53.777355
Epoch: [12][0/21], lr: 0.00100	Time 3.468 (3.468)	Data 2.228 (2.228)	Loss 0.0651 (0.0651)	Loss CE 0.0071 (0.0071)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5698 (0.5698)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9752], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0808], device='cuda:0', requires_grad=True)
2022-03-23 23:07:14.131207
Epoch: [13][0/21], lr: 0.00100	Time 3.346 (3.346)	Data 2.491 (2.491)	Loss 0.0589 (0.0589)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5642 (0.5642)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9772], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0818], device='cuda:0', requires_grad=True)
2022-03-23 23:07:34.101213
Epoch: [14][0/21], lr: 0.00100	Time 3.175 (3.175)	Data 2.477 (2.477)	Loss 0.0534 (0.0534)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5135 (0.5135)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9797], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0834], device='cuda:0', requires_grad=True)
2022-03-23 23:07:52.392180
Epoch: [15][0/21], lr: 0.00100	Time 3.313 (3.313)	Data 2.314 (2.314)	Loss 0.0554 (0.0554)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5078 (0.5078)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9815], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0844], device='cuda:0', requires_grad=True)
2022-03-23 23:08:10.425763
Epoch: [16][0/21], lr: 0.00100	Time 3.299 (3.299)	Data 1.970 (1.970)	Loss 0.0573 (0.0573)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5589 (0.5589)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9828], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0849], device='cuda:0', requires_grad=True)
2022-03-23 23:08:29.195703
Epoch: [17][0/21], lr: 0.00100	Time 3.495 (3.495)	Data 2.630 (2.630)	Loss 0.0580 (0.0580)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5616 (0.5616)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9847], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0860], device='cuda:0', requires_grad=True)
2022-03-23 23:08:47.524411
Epoch: [18][0/21], lr: 0.00100	Time 3.481 (3.481)	Data 1.961 (1.961)	Loss 0.0540 (0.0540)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5263 (0.5263)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9870], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0872], device='cuda:0', requires_grad=True)
2022-03-23 23:09:05.820931
Epoch: [19][0/21], lr: 0.00100	Time 3.312 (3.312)	Data 2.254 (2.254)	Loss 0.0580 (0.0580)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5387 (0.5387)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9893], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0884], device='cuda:0', requires_grad=True)
2022-03-23 23:09:24.519394
Epoch: [20][0/21], lr: 0.00010	Time 3.342 (3.342)	Data 2.554 (2.554)	Loss 0.0688 (0.0688)	Loss CE 0.0148 (0.0148)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5298 (0.5298)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9897], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0886], device='cuda:0', requires_grad=True)
2022-03-23 23:09:43.235362
Epoch: [21][0/21], lr: 0.00010	Time 3.475 (3.475)	Data 2.583 (2.583)	Loss 0.0566 (0.0566)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5182 (0.5182)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9901], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0889], device='cuda:0', requires_grad=True)
2022-03-23 23:10:02.026316
Epoch: [22][0/21], lr: 0.00010	Time 3.353 (3.353)	Data 2.515 (2.515)	Loss 0.0584 (0.0584)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0027 (0.0027)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5611 (0.5611)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0890], device='cuda:0', requires_grad=True)
2022-03-23 23:10:20.925620
Epoch: [23][0/21], lr: 0.00010	Time 3.286 (3.286)	Data 2.496 (2.496)	Loss 0.0557 (0.0557)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0023 (0.0023)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5388 (0.5388)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9907], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0891], device='cuda:0', requires_grad=True)
2022-03-23 23:10:39.476219
Epoch: [24][0/21], lr: 0.00010	Time 3.400 (3.400)	Data 2.260 (2.260)	Loss 0.0703 (0.0703)	Loss CE 0.0136 (0.0136)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5563 (0.5563)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9910], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0893], device='cuda:0', requires_grad=True)
2022-03-23 23:10:58.128143
Epoch: [25][0/21], lr: 0.00010	Time 3.150 (3.150)	Data 2.174 (2.174)	Loss 0.0550 (0.0550)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0041 (0.0041)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5282 (0.5282)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9911], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0894], device='cuda:0', requires_grad=True)
2022-03-23 23:11:16.717206
Epoch: [26][0/21], lr: 0.00010	Time 3.364 (3.364)	Data 2.231 (2.231)	Loss 0.0545 (0.0545)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5319 (0.5319)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9913], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0895], device='cuda:0', requires_grad=True)
2022-03-23 23:11:35.424650
Epoch: [27][0/21], lr: 0.00010	Time 3.262 (3.262)	Data 1.917 (1.917)	Loss 0.0535 (0.0535)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5180 (0.5180)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9914], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:11:54.137720
Epoch: [28][0/21], lr: 0.00010	Time 3.297 (3.297)	Data 2.230 (2.230)	Loss 0.0569 (0.0569)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5223 (0.5223)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9915], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0895], device='cuda:0', requires_grad=True)
2022-03-23 23:12:12.730901
Epoch: [29][0/21], lr: 0.00010	Time 3.094 (3.094)	Data 2.163 (2.163)	Loss 0.0618 (0.0618)	Loss CE 0.0074 (0.0074)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5335 (0.5335)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9915], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:12:30.150738
Epoch: [30][0/21], lr: 0.00001	Time 3.399 (3.399)	Data 2.150 (2.150)	Loss 0.0548 (0.0548)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5208 (0.5208)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9915], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:12:51.902911
Epoch: [31][0/21], lr: 0.00001	Time 3.481 (3.481)	Data 2.154 (2.154)	Loss 0.0530 (0.0530)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5120 (0.5120)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9915], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:13:13.466263
Epoch: [32][0/21], lr: 0.00001	Time 3.367 (3.367)	Data 2.305 (2.305)	Loss 0.0519 (0.0519)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5052 (0.5052)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:13:35.199973
Epoch: [33][0/21], lr: 0.00001	Time 3.396 (3.396)	Data 2.276 (2.276)	Loss 0.0611 (0.0611)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0040 (0.0040)	Loss KD (GCAM) 0.0023 (0.0023)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5630 (0.5630)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:13:57.010769
Epoch: [34][0/21], lr: 0.00001	Time 3.454 (3.454)	Data 2.423 (2.423)	Loss 0.0541 (0.0541)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0026 (0.0026)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5060 (0.5060)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:14:18.958393
Epoch: [35][0/21], lr: 0.00001	Time 3.313 (3.313)	Data 2.082 (2.082)	Loss 0.0581 (0.0581)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5532 (0.5532)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:14:40.629638
Epoch: [36][0/21], lr: 0.00001	Time 3.554 (3.554)	Data 2.236 (2.236)	Loss 0.0579 (0.0579)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5475 (0.5475)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:15:02.631426
Epoch: [37][0/21], lr: 0.00001	Time 3.306 (3.306)	Data 2.440 (2.440)	Loss 0.0582 (0.0582)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5419 (0.5419)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:15:24.213328
Epoch: [38][0/21], lr: 0.00001	Time 3.344 (3.344)	Data 2.221 (2.221)	Loss 0.0542 (0.0542)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5221 (0.5221)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:15:45.989538
Epoch: [39][0/21], lr: 0.00001	Time 3.471 (3.471)	Data 2.093 (2.093)	Loss 0.0561 (0.0561)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5476 (0.5476)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:16:07.792237
Epoch: [40][0/21], lr: 0.00001	Time 3.430 (3.430)	Data 2.268 (2.268)	Loss 0.0574 (0.0574)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0023 (0.0023)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5576 (0.5576)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0896], device='cuda:0', requires_grad=True)
2022-03-23 23:16:30.276721
Epoch: [41][0/21], lr: 0.00001	Time 3.476 (3.476)	Data 1.959 (1.959)	Loss 0.0652 (0.0652)	Loss CE 0.0102 (0.0102)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5399 (0.5399)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:16:52.459231
Epoch: [42][0/21], lr: 0.00001	Time 3.637 (3.637)	Data 2.667 (2.667)	Loss 0.0502 (0.0502)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4744 (0.4744)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:17:13.964415
Epoch: [43][0/21], lr: 0.00001	Time 3.342 (3.342)	Data 1.867 (1.867)	Loss 0.0614 (0.0614)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5874 (0.5874)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:17:35.997385
Epoch: [44][0/21], lr: 0.00001	Time 3.587 (3.587)	Data 2.785 (2.785)	Loss 0.0478 (0.0478)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4529 (0.4529)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:17:57.568228
Epoch: [45][0/21], lr: 0.00001	Time 3.399 (3.399)	Data 2.168 (2.168)	Loss 0.0597 (0.0597)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5652 (0.5652)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:18:19.526483
Epoch: [46][0/21], lr: 0.00001	Time 3.314 (3.314)	Data 2.253 (2.253)	Loss 0.0541 (0.0541)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0023 (0.0023)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5242 (0.5242)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:18:41.143868
Epoch: [47][0/21], lr: 0.00001	Time 3.396 (3.396)	Data 2.023 (2.023)	Loss 0.0570 (0.0570)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4934 (0.4934)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:19:02.777695
Epoch: [48][0/21], lr: 0.00001	Time 3.293 (3.293)	Data 1.888 (1.888)	Loss 0.0521 (0.0521)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0024 (0.0024)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4984 (0.4984)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
2022-03-23 23:19:24.706362
Epoch: [49][0/21], lr: 0.00001	Time 3.497 (3.497)	Data 2.018 (2.018)	Loss 0.0569 (0.0569)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0025 (0.0025)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5436 (0.5436)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0897], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=291, sigma=tensor([3.9918]), eta=tensor([3.0897])
  (fc1): CosineLinear(input_features=512, output_features=285, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 198
video number + exemplar : 198
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=291, sigma=tensor([3.9918]), eta=tensor([3.0897])
  (fc1): CosineLinear(input_features=512, output_features=285, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 485
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-23 23:20:05.618260
Epoch: [0][0/15], lr: 0.00050	Time 3.223 (3.223)	Data 1.980 (1.980)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0895], device='cuda:0', requires_grad=True)
2022-03-23 23:20:17.291773
Epoch: [1][0/15], lr: 0.00050	Time 3.070 (3.070)	Data 1.983 (1.983)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9914], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0892], device='cuda:0', requires_grad=True)
2022-03-23 23:20:28.685242
Epoch: [2][0/15], lr: 0.00050	Time 3.171 (3.171)	Data 2.363 (2.363)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9914], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0890], device='cuda:0', requires_grad=True)
2022-03-23 23:20:39.979111
Epoch: [3][0/15], lr: 0.00050	Time 2.852 (2.852)	Data 1.941 (1.941)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9910], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0885], device='cuda:0', requires_grad=True)
2022-03-23 23:20:51.360659
Epoch: [4][0/15], lr: 0.00050	Time 3.451 (3.451)	Data 2.354 (2.354)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0880], device='cuda:0', requires_grad=True)
2022-03-23 23:21:02.383383
Epoch: [5][0/15], lr: 0.00050	Time 2.872 (2.872)	Data 2.093 (2.093)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9900], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0876], device='cuda:0', requires_grad=True)
2022-03-23 23:21:13.483065
Epoch: [6][0/15], lr: 0.00050	Time 2.987 (2.987)	Data 1.846 (1.846)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9896], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0872], device='cuda:0', requires_grad=True)
2022-03-23 23:21:24.483133
Epoch: [7][0/15], lr: 0.00050	Time 2.996 (2.996)	Data 1.837 (1.837)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0867], device='cuda:0', requires_grad=True)
2022-03-23 23:21:35.504264
Epoch: [8][0/15], lr: 0.00050	Time 2.886 (2.886)	Data 1.896 (1.896)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9891], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0866], device='cuda:0', requires_grad=True)
2022-03-23 23:21:46.788970
Epoch: [9][0/15], lr: 0.00050	Time 3.068 (3.068)	Data 2.055 (2.055)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0865], device='cuda:0', requires_grad=True)
2022-03-23 23:21:57.982473
Epoch: [10][0/15], lr: 0.00050	Time 2.976 (2.976)	Data 1.997 (1.997)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9891], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0862], device='cuda:0', requires_grad=True)
2022-03-23 23:22:07.740136
Epoch: [11][0/15], lr: 0.00050	Time 2.943 (2.943)	Data 2.023 (2.023)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9885], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0859], device='cuda:0', requires_grad=True)
2022-03-23 23:22:17.560523
Epoch: [12][0/15], lr: 0.00050	Time 3.065 (3.065)	Data 2.143 (2.143)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9882], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0855], device='cuda:0', requires_grad=True)
2022-03-23 23:22:27.693767
Epoch: [13][0/15], lr: 0.00050	Time 3.073 (3.073)	Data 2.547 (2.547)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9877], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0851], device='cuda:0', requires_grad=True)
2022-03-23 23:22:37.836310
Epoch: [14][0/15], lr: 0.00050	Time 3.041 (3.041)	Data 2.404 (2.404)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9875], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0848], device='cuda:0', requires_grad=True)
2022-03-23 23:22:47.730704
Epoch: [15][0/15], lr: 0.00050	Time 2.968 (2.968)	Data 1.990 (1.990)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9872], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0844], device='cuda:0', requires_grad=True)
2022-03-23 23:22:57.482474
Epoch: [16][0/15], lr: 0.00050	Time 2.880 (2.880)	Data 2.066 (2.066)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9868], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0840], device='cuda:0', requires_grad=True)
2022-03-23 23:23:07.610614
Epoch: [17][0/15], lr: 0.00050	Time 3.116 (3.116)	Data 2.213 (2.213)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9865], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0836], device='cuda:0', requires_grad=True)
2022-03-23 23:23:17.636579
Epoch: [18][0/15], lr: 0.00050	Time 3.140 (3.140)	Data 2.459 (2.459)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9860], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0831], device='cuda:0', requires_grad=True)
2022-03-23 23:23:27.475082
Epoch: [19][0/15], lr: 0.00050	Time 3.026 (3.026)	Data 2.425 (2.425)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9855], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0827], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_023.pth.tar
exemplar : 485
Computing the class mean vectors...
Eval Task 0 for Age 23
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 3.792 (3.792)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.416 (0.496)	Prec@1 56.250 (65.161)
Testing Results: Prec@1 64.817
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 81.250 (69.307)
Testing Results (NME): Prec@1 68.585
Eval Task 1 for Age 23
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.259 (3.259)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 51.724
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 62.069
Eval Task 2 for Age 23
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.880 (3.880)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 36.923
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 46.154
Eval Task 3 for Age 23
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.998 (3.998)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 65.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 65.000
Eval Task 4 for Age 23
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.015 (4.015)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 62.353
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 70.588
Eval Task 5 for Age 23
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.860 (3.860)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 72.581
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.194
Eval Task 6 for Age 23
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.233 (4.233)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 54.321
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 41.975
Eval Task 7 for Age 23
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.992 (3.992)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 85.075
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 76.119
Eval Task 8 for Age 23
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.633 (3.633)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 45.455
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 46.970
Eval Task 9 for Age 23
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.156 (4.156)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 64.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 60.000
Eval Task 10 for Age 23
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 3.887 (3.887)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 46.512
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 55.814
Eval Task 11 for Age 23
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.838 (3.838)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 74.194
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 67.742
Eval Task 12 for Age 23
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.434 (4.434)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 87.952
Eval Task 13 for Age 23
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 4.131 (4.131)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 57.895
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 76.316
Eval Task 14 for Age 23
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.113 (4.113)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 80.488
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 91.463
Eval Task 15 for Age 23
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.191 (4.191)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 71.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 66.250
Eval Task 16 for Age 23
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.960 (3.960)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 57.143
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 50.000
Eval Task 17 for Age 23
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.030 (4.030)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 53.012
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 51.807
Eval Task 18 for Age 23
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.969 (3.969)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 87.500
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.375
Eval Task 19 for Age 23
Current Task : [5, 32]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.267 (4.267)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 63.415
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 73.171
Eval Task 20 for Age 23
Current Task : [4, 51]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.855 (3.855)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 58.824
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 63.235
Eval Task 21 for Age 23
Current Task : [48, 73]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.279 (3.279)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 88.312
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 88.312
Eval Task 22 for Age 23
Current Task : [93, 39]
video number : 69
video number + exemplar : 69
DataLoader Constructed
Test: [0/5]	Time 4.115 (4.115)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 47.826
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 63.768
Eval Task 23 for Age 23
Current Task : [67, 29]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.938 (3.938)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 98.684
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 86.842
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64, 82, 68, 77, 69, 76]
Method : OURS
----AGE 24----
current_task  [97, 49]
current_head  99
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.0696419413859206]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=297, sigma=tensor([3.9855]), eta=tensor([3.0827])
  (fc1): CosineLinear(input_features=512, output_features=291, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 176
video number + exemplar : 661
DataLoader Constructed : Train 20
Optimizer Constructed
video number : 176
video number + exemplar : 176
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-23 23:30:22.467416
Epoch: [0][0/20], lr: 0.00100	Time 3.748 (3.748)	Data 2.452 (2.452)	Loss 0.0687 (0.0687)	Loss CE 0.0150 (0.0150)	Loss KD (Logit) 0.0060 (0.0060)	Loss KD (GCAM) 0.0027 (0.0027)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5247 (0.5247)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9812], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0796], device='cuda:0', requires_grad=True)
2022-03-23 23:30:43.096901
Epoch: [1][0/20], lr: 0.00100	Time 3.328 (3.328)	Data 2.037 (2.037)	Loss 0.2279 (0.2279)	Loss CE 0.1717 (0.1717)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0044 (0.0044)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5442 (0.5442)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9698], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0725], device='cuda:0', requires_grad=True)
2022-03-23 23:31:04.464920
Epoch: [2][0/20], lr: 0.00100	Time 3.573 (3.573)	Data 2.388 (2.388)	Loss 0.0678 (0.0678)	Loss CE 0.0116 (0.0116)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5429 (0.5429)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9586], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0656], device='cuda:0', requires_grad=True)
2022-03-23 23:31:25.827011
Epoch: [3][0/20], lr: 0.00100	Time 3.781 (3.781)	Data 2.542 (2.542)	Loss 0.0571 (0.0571)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5167 (0.5167)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9396], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0539], device='cuda:0', requires_grad=True)
2022-03-23 23:31:47.459959
Epoch: [4][0/20], lr: 0.00100	Time 3.914 (3.914)	Data 2.378 (2.378)	Loss 0.0640 (0.0640)	Loss CE 0.0095 (0.0095)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5251 (0.5251)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9369], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0532], device='cuda:0', requires_grad=True)
2022-03-23 23:32:08.606647
Epoch: [5][0/20], lr: 0.00100	Time 3.509 (3.509)	Data 2.246 (2.246)	Loss 0.1353 (0.1353)	Loss CE 0.0780 (0.0780)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0054 (0.0054)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5529 (0.5529)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9391], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0550], device='cuda:0', requires_grad=True)
2022-03-23 23:32:30.028049
Epoch: [6][0/20], lr: 0.00100	Time 3.748 (3.748)	Data 2.630 (2.630)	Loss 0.0758 (0.0758)	Loss CE 0.0185 (0.0185)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5529 (0.5529)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9429], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0578], device='cuda:0', requires_grad=True)
2022-03-23 23:32:51.256041
Epoch: [7][0/20], lr: 0.00100	Time 3.596 (3.596)	Data 2.067 (2.067)	Loss 0.0661 (0.0661)	Loss CE 0.0079 (0.0079)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0054 (0.0054)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5610 (0.5610)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9421], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0575], device='cuda:0', requires_grad=True)
2022-03-23 23:33:12.230393
Epoch: [8][0/20], lr: 0.00100	Time 3.394 (3.394)	Data 2.167 (2.167)	Loss 0.0582 (0.0582)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0054 (0.0054)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5336 (0.5336)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9444], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0586], device='cuda:0', requires_grad=True)
2022-03-23 23:33:33.334053
Epoch: [9][0/20], lr: 0.00100	Time 3.523 (3.523)	Data 2.023 (2.023)	Loss 0.0670 (0.0670)	Loss CE 0.0112 (0.0112)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0054 (0.0054)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5372 (0.5372)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9456], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0599], device='cuda:0', requires_grad=True)
2022-03-23 23:33:54.735811
Epoch: [10][0/20], lr: 0.00100	Time 3.766 (3.766)	Data 2.614 (2.614)	Loss 0.0592 (0.0592)	Loss CE 0.0052 (0.0052)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5204 (0.5204)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9423], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0580], device='cuda:0', requires_grad=True)
2022-03-23 23:34:16.036352
Epoch: [11][0/20], lr: 0.00100	Time 3.626 (3.626)	Data 2.113 (2.113)	Loss 0.0634 (0.0634)	Loss CE 0.0066 (0.0066)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5475 (0.5475)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9447], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0596], device='cuda:0', requires_grad=True)
2022-03-23 23:34:37.497693
Epoch: [12][0/20], lr: 0.00100	Time 3.678 (3.678)	Data 2.339 (2.339)	Loss 0.0626 (0.0626)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5583 (0.5583)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9475], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0615], device='cuda:0', requires_grad=True)
2022-03-23 23:34:58.978856
Epoch: [13][0/20], lr: 0.00100	Time 3.611 (3.611)	Data 2.248 (2.248)	Loss 0.0775 (0.0775)	Loss CE 0.0269 (0.0269)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4862 (0.4862)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0630], device='cuda:0', requires_grad=True)
2022-03-23 23:35:19.985317
Epoch: [14][0/20], lr: 0.00100	Time 3.223 (3.223)	Data 1.870 (1.870)	Loss 0.0566 (0.0566)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5008 (0.5008)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9500], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0634], device='cuda:0', requires_grad=True)
2022-03-23 23:35:40.081409
Epoch: [15][0/20], lr: 0.00100	Time 3.373 (3.373)	Data 2.320 (2.320)	Loss 0.0638 (0.0638)	Loss CE 0.0081 (0.0081)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5358 (0.5358)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9533], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0654], device='cuda:0', requires_grad=True)
2022-03-23 23:35:59.238298
Epoch: [16][0/20], lr: 0.00100	Time 3.430 (3.430)	Data 2.312 (2.312)	Loss 0.0558 (0.0558)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5332 (0.5332)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9579], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
2022-03-23 23:36:18.630337
Epoch: [17][0/20], lr: 0.00100	Time 3.402 (3.402)	Data 2.594 (2.594)	Loss 0.0596 (0.0596)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5725 (0.5725)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0681], device='cuda:0', requires_grad=True)
2022-03-23 23:36:36.631601
Epoch: [18][0/20], lr: 0.00100	Time 3.461 (3.461)	Data 2.718 (2.718)	Loss 0.0602 (0.0602)	Loss CE 0.0040 (0.0040)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0056 (0.0056)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5407 (0.5407)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9566], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0674], device='cuda:0', requires_grad=True)
2022-03-23 23:36:54.404646
Epoch: [19][0/20], lr: 0.00100	Time 3.569 (3.569)	Data 2.160 (2.160)	Loss 0.0570 (0.0570)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5337 (0.5337)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9566], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0676], device='cuda:0', requires_grad=True)
2022-03-23 23:37:12.019332
Epoch: [20][0/20], lr: 0.00010	Time 3.427 (3.427)	Data 2.115 (2.115)	Loss 0.0644 (0.0644)	Loss CE 0.0052 (0.0052)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5729 (0.5729)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9567], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0676], device='cuda:0', requires_grad=True)
2022-03-23 23:37:29.661643
Epoch: [21][0/20], lr: 0.00010	Time 3.268 (3.268)	Data 1.890 (1.890)	Loss 0.0606 (0.0606)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5824 (0.5824)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9567], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0675], device='cuda:0', requires_grad=True)
2022-03-23 23:37:47.323597
Epoch: [22][0/20], lr: 0.00010	Time 3.323 (3.323)	Data 2.131 (2.131)	Loss 0.0526 (0.0526)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5018 (0.5018)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9568], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0676], device='cuda:0', requires_grad=True)
2022-03-23 23:38:04.903888
Epoch: [23][0/20], lr: 0.00010	Time 3.281 (3.281)	Data 2.222 (2.222)	Loss 0.0574 (0.0574)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5213 (0.5213)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9571], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0677], device='cuda:0', requires_grad=True)
2022-03-23 23:38:22.557023
Epoch: [24][0/20], lr: 0.00010	Time 3.194 (3.194)	Data 2.418 (2.418)	Loss 0.0565 (0.0565)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5129 (0.5129)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0678], device='cuda:0', requires_grad=True)
2022-03-23 23:38:40.423228
Epoch: [25][0/20], lr: 0.00010	Time 3.305 (3.305)	Data 2.191 (2.191)	Loss 0.0603 (0.0603)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5773 (0.5773)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9575], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0678], device='cuda:0', requires_grad=True)
2022-03-23 23:38:58.736879
Epoch: [26][0/20], lr: 0.00010	Time 3.514 (3.514)	Data 2.656 (2.656)	Loss 0.1037 (0.1037)	Loss CE 0.0465 (0.0465)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5521 (0.5521)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9576], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0680], device='cuda:0', requires_grad=True)
2022-03-23 23:39:16.839741
Epoch: [27][0/20], lr: 0.00010	Time 3.212 (3.212)	Data 2.212 (2.212)	Loss 0.0536 (0.0536)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4972 (0.4972)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9578], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0681], device='cuda:0', requires_grad=True)
2022-03-23 23:39:35.313750
Epoch: [28][0/20], lr: 0.00010	Time 3.425 (3.425)	Data 2.189 (2.189)	Loss 0.0611 (0.0611)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5833 (0.5833)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9580], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0682], device='cuda:0', requires_grad=True)
2022-03-23 23:39:53.091381
Epoch: [29][0/20], lr: 0.00010	Time 3.428 (3.428)	Data 2.108 (2.108)	Loss 0.0604 (0.0604)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5711 (0.5711)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9581], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0682], device='cuda:0', requires_grad=True)
2022-03-23 23:40:10.897682
Epoch: [30][0/20], lr: 0.00001	Time 3.387 (3.387)	Data 2.564 (2.564)	Loss 0.0587 (0.0587)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5302 (0.5302)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9581], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0682], device='cuda:0', requires_grad=True)
2022-03-23 23:40:28.547163
Epoch: [31][0/20], lr: 0.00001	Time 3.170 (3.170)	Data 2.091 (2.091)	Loss 0.0542 (0.0542)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5171 (0.5171)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9581], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:40:46.551113
Epoch: [32][0/20], lr: 0.00001	Time 3.446 (3.446)	Data 2.592 (2.592)	Loss 0.0562 (0.0562)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5368 (0.5368)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:41:04.528902
Epoch: [33][0/20], lr: 0.00001	Time 3.056 (3.056)	Data 1.927 (1.927)	Loss 0.0548 (0.0548)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5273 (0.5273)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:41:21.921445
Epoch: [34][0/20], lr: 0.00001	Time 3.926 (3.926)	Data 2.393 (2.393)	Loss 0.0585 (0.0585)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5389 (0.5389)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:41:43.279712
Epoch: [35][0/20], lr: 0.00001	Time 3.771 (3.771)	Data 2.451 (2.451)	Loss 0.0617 (0.0617)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5391 (0.5391)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:42:04.614673
Epoch: [36][0/20], lr: 0.00001	Time 3.616 (3.616)	Data 2.505 (2.505)	Loss 0.0574 (0.0574)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5100 (0.5100)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:42:26.106142
Epoch: [37][0/20], lr: 0.00001	Time 3.722 (3.722)	Data 2.608 (2.608)	Loss 0.0568 (0.0568)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5389 (0.5389)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:42:47.508758
Epoch: [38][0/20], lr: 0.00001	Time 3.546 (3.546)	Data 1.940 (1.940)	Loss 0.0580 (0.0580)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5576 (0.5576)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:43:08.928367
Epoch: [39][0/20], lr: 0.00001	Time 3.650 (3.650)	Data 2.397 (2.397)	Loss 0.0500 (0.0500)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4763 (0.4763)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:43:30.209030
Epoch: [40][0/20], lr: 0.00001	Time 3.639 (3.639)	Data 2.426 (2.426)	Loss 0.0613 (0.0613)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5695 (0.5695)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:43:51.717759
Epoch: [41][0/20], lr: 0.00001	Time 3.376 (3.376)	Data 2.144 (2.144)	Loss 0.0547 (0.0547)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5227 (0.5227)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:44:12.242612
Epoch: [42][0/20], lr: 0.00001	Time 3.110 (3.110)	Data 1.899 (1.899)	Loss 0.0571 (0.0571)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5462 (0.5462)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:44:33.448303
Epoch: [43][0/20], lr: 0.00001	Time 3.499 (3.499)	Data 2.127 (2.127)	Loss 0.0573 (0.0573)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5394 (0.5394)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
2022-03-23 23:44:54.642648
Epoch: [44][0/20], lr: 0.00001	Time 3.318 (3.318)	Data 1.996 (1.996)	Loss 0.0665 (0.0665)	Loss CE 0.0138 (0.0138)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5063 (0.5063)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
2022-03-23 23:45:16.019651
Epoch: [45][0/20], lr: 0.00001	Time 3.477 (3.477)	Data 2.032 (2.032)	Loss 0.0514 (0.0514)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4909 (0.4909)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
2022-03-23 23:45:37.037188
Epoch: [46][0/20], lr: 0.00001	Time 3.243 (3.243)	Data 1.920 (1.920)	Loss 0.0561 (0.0561)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5397 (0.5397)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
2022-03-23 23:45:58.043543
Epoch: [47][0/20], lr: 0.00001	Time 3.381 (3.381)	Data 2.026 (2.026)	Loss 0.0573 (0.0573)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5415 (0.5415)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
2022-03-23 23:46:19.057722
Epoch: [48][0/20], lr: 0.00001	Time 3.235 (3.235)	Data 2.193 (2.193)	Loss 0.0544 (0.0544)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5030 (0.5030)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
2022-03-23 23:46:40.122851
Epoch: [49][0/20], lr: 0.00001	Time 3.520 (3.520)	Data 2.132 (2.132)	Loss 0.0536 (0.0536)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5144 (0.5144)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0684], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=297, sigma=tensor([3.9584]), eta=tensor([3.0684])
  (fc1): CosineLinear(input_features=512, output_features=291, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 176
video number + exemplar : 176
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=297, sigma=tensor([3.9584]), eta=tensor([3.0684])
  (fc1): CosineLinear(input_features=512, output_features=291, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 495
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-23 23:47:19.072517
Epoch: [0][0/15], lr: 0.00050	Time 3.009 (3.009)	Data 2.053 (2.053)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9586], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0683], device='cuda:0', requires_grad=True)
2022-03-23 23:47:30.201580
Epoch: [1][0/15], lr: 0.00050	Time 3.161 (3.161)	Data 1.879 (1.879)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9587], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0681], device='cuda:0', requires_grad=True)
2022-03-23 23:47:41.801978
Epoch: [2][0/15], lr: 0.00050	Time 3.151 (3.151)	Data 2.061 (2.061)	Loss 0.0083 (0.0083)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9590], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0681], device='cuda:0', requires_grad=True)
2022-03-23 23:47:53.036829
Epoch: [3][0/15], lr: 0.00050	Time 2.980 (2.980)	Data 2.314 (2.314)	Loss 0.0039 (0.0039)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9594], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0682], device='cuda:0', requires_grad=True)
2022-03-23 23:48:04.470597
Epoch: [4][0/15], lr: 0.00050	Time 3.090 (3.090)	Data 2.455 (2.455)	Loss 0.0422 (0.0422)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9589], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0680], device='cuda:0', requires_grad=True)
2022-03-23 23:48:15.837400
Epoch: [5][0/15], lr: 0.00050	Time 3.229 (3.229)	Data 1.955 (1.955)	Loss 0.0045 (0.0045)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9591], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0680], device='cuda:0', requires_grad=True)
2022-03-23 23:48:27.071040
Epoch: [6][0/15], lr: 0.00050	Time 2.905 (2.905)	Data 2.048 (2.048)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9593], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0680], device='cuda:0', requires_grad=True)
2022-03-23 23:48:38.337081
Epoch: [7][0/15], lr: 0.00050	Time 3.013 (3.013)	Data 1.975 (1.975)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9596], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0680], device='cuda:0', requires_grad=True)
2022-03-23 23:48:49.624350
Epoch: [8][0/15], lr: 0.00050	Time 3.134 (3.134)	Data 1.975 (1.975)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9595], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0677], device='cuda:0', requires_grad=True)
2022-03-23 23:49:01.369204
Epoch: [9][0/15], lr: 0.00050	Time 3.318 (3.318)	Data 2.300 (2.300)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9595], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0675], device='cuda:0', requires_grad=True)
2022-03-23 23:49:12.898450
Epoch: [10][0/15], lr: 0.00050	Time 3.262 (3.262)	Data 2.329 (2.329)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9600], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0676], device='cuda:0', requires_grad=True)
2022-03-23 23:49:24.075897
Epoch: [11][0/15], lr: 0.00050	Time 3.175 (3.175)	Data 2.137 (2.137)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9602], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0675], device='cuda:0', requires_grad=True)
2022-03-23 23:49:35.482093
Epoch: [12][0/15], lr: 0.00050	Time 2.964 (2.964)	Data 2.002 (2.002)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0671], device='cuda:0', requires_grad=True)
2022-03-23 23:49:46.739166
Epoch: [13][0/15], lr: 0.00050	Time 3.155 (3.155)	Data 1.881 (1.881)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9598], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0668], device='cuda:0', requires_grad=True)
2022-03-23 23:49:58.295323
Epoch: [14][0/15], lr: 0.00050	Time 3.176 (3.176)	Data 2.352 (2.352)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0667], device='cuda:0', requires_grad=True)
2022-03-23 23:50:09.940092
Epoch: [15][0/15], lr: 0.00050	Time 3.140 (3.140)	Data 2.172 (2.172)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9600], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0666], device='cuda:0', requires_grad=True)
2022-03-23 23:50:21.840514
Epoch: [16][0/15], lr: 0.00050	Time 3.156 (3.156)	Data 1.826 (1.826)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0664], device='cuda:0', requires_grad=True)
2022-03-23 23:50:32.892717
Epoch: [17][0/15], lr: 0.00050	Time 2.671 (2.671)	Data 1.873 (1.873)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9600], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0663], device='cuda:0', requires_grad=True)
2022-03-23 23:50:44.621076
Epoch: [18][0/15], lr: 0.00050	Time 3.115 (3.115)	Data 2.520 (2.520)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0661], device='cuda:0', requires_grad=True)
2022-03-23 23:50:54.643731
Epoch: [19][0/15], lr: 0.00050	Time 3.081 (3.081)	Data 2.157 (2.157)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9597], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0659], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_024.pth.tar
exemplar : 495
Computing the class mean vectors...
Eval Task 0 for Age 24
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 4.507 (4.507)	Prec@1 56.250 (56.250)
Test: [100/123]	Time 0.591 (0.490)	Prec@1 62.500 (64.418)
Testing Results: Prec@1 63.697
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 62.500 (66.337)
Testing Results (NME): Prec@1 65.886
Eval Task 1 for Age 24
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.825 (3.825)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 41.379
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 44.828
Eval Task 2 for Age 24
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.762 (3.762)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 49.231
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 52.308
Eval Task 3 for Age 24
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.030 (4.030)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 68.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 63.750
Eval Task 4 for Age 24
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.184 (4.184)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 67.059
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.118
Eval Task 5 for Age 24
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.928 (3.928)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 59.677
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 69.355
Eval Task 6 for Age 24
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.966 (3.966)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 60.494
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 44.444
Eval Task 7 for Age 24
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.964 (3.964)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 86.567
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 77.612
Eval Task 8 for Age 24
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.697 (3.697)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 34.848
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 42.424
Eval Task 9 for Age 24
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.697 (3.697)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 53.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 62.667
Eval Task 10 for Age 24
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.062 (4.062)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 60.465
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 61.628
Eval Task 11 for Age 24
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.987 (3.987)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 66.129
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 69.355
Eval Task 12 for Age 24
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.940 (3.940)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.181
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.361
Eval Task 13 for Age 24
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 3.939 (3.939)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 67.105
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 64.474
Eval Task 14 for Age 24
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.549 (4.549)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 90.244
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.244
Eval Task 15 for Age 24
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.172 (4.172)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 56.250
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 70.000
Eval Task 16 for Age 24
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 3.773 (3.773)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 55.357
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 50.000
Eval Task 17 for Age 24
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.248 (4.248)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 51.807
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 49.398
Eval Task 18 for Age 24
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.699 (3.699)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 92.188
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 67.188
Eval Task 19 for Age 24
Current Task : [5, 32]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.234 (4.234)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 71.951
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 78.049
Eval Task 20 for Age 24
Current Task : [4, 51]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.282 (3.282)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 61.765
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 61.765
Eval Task 21 for Age 24
Current Task : [48, 73]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.921 (3.921)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 80.519
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 85.714
Eval Task 22 for Age 24
Current Task : [93, 39]
video number : 69
video number + exemplar : 69
DataLoader Constructed
Test: [0/5]	Time 3.665 (3.665)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 72.464
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 71.014
Eval Task 23 for Age 24
Current Task : [67, 29]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 4.345 (4.345)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 88.158
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 77.632
Eval Task 24 for Age 24
Current Task : [97, 49]
video number : 70
video number + exemplar : 70
DataLoader Constructed
Test: [0/5]	Time 3.933 (3.933)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.714
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 80.000
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64, 82, 68, 77, 69, 76, 70]
Method : OURS
----AGE 25----
current_task  [57, 33]
current_head  101
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.07035623639735145]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([3.9597]), eta=tensor([3.0659])
  (fc1): CosineLinear(input_features=512, output_features=297, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 177
video number + exemplar : 672
DataLoader Constructed : Train 21
Optimizer Constructed
video number : 177
video number + exemplar : 177
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-23 23:57:52.723679
Epoch: [0][0/21], lr: 0.00100	Time 3.642 (3.642)	Data 2.511 (2.511)	Loss 0.0786 (0.0786)	Loss CE 0.0093 (0.0093)	Loss KD (Logit) 0.1152 (0.1152)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5554 (0.5554)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.9531], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0626], device='cuda:0', requires_grad=True)
2022-03-23 23:58:14.423070
Epoch: [1][0/21], lr: 0.00100	Time 3.590 (3.590)	Data 2.133 (2.133)	Loss 0.0831 (0.0831)	Loss CE 0.0078 (0.0078)	Loss KD (Logit) 0.1189 (0.1189)	Loss KD (GCAM) 0.0266 (0.0266)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5899 (0.5899)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9576], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0657], device='cuda:0', requires_grad=True)
2022-03-23 23:58:36.035432
Epoch: [2][0/21], lr: 0.00100	Time 3.537 (3.537)	Data 2.445 (2.445)	Loss 0.1249 (0.1249)	Loss CE 0.0504 (0.0504)	Loss KD (Logit) 0.1229 (0.1229)	Loss KD (GCAM) 0.0313 (0.0313)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5645 (0.5645)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0627], device='cuda:0', requires_grad=True)
2022-03-23 23:58:57.851212
Epoch: [3][0/21], lr: 0.00100	Time 3.474 (3.474)	Data 2.055 (2.055)	Loss 0.0950 (0.0950)	Loss CE 0.0161 (0.0161)	Loss KD (Logit) 0.1239 (0.1239)	Loss KD (GCAM) 0.0368 (0.0368)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5919 (0.5919)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9580], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0660], device='cuda:0', requires_grad=True)
2022-03-23 23:59:19.639436
Epoch: [4][0/21], lr: 0.00100	Time 3.400 (3.400)	Data 2.083 (2.083)	Loss 0.0799 (0.0799)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.1217 (0.1217)	Loss KD (GCAM) 0.0363 (0.0363)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5931 (0.5931)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9612], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0691], device='cuda:0', requires_grad=True)
2022-03-23 23:59:41.459808
Epoch: [5][0/21], lr: 0.00100	Time 3.466 (3.466)	Data 2.125 (2.125)	Loss 0.0961 (0.0961)	Loss CE 0.0194 (0.0194)	Loss KD (Logit) 0.1295 (0.1295)	Loss KD (GCAM) 0.0392 (0.0392)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5580 (0.5580)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9564], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0669], device='cuda:0', requires_grad=True)
2022-03-24 00:00:03.267964
Epoch: [6][0/21], lr: 0.00100	Time 3.429 (3.429)	Data 1.986 (1.986)	Loss 0.1674 (0.1674)	Loss CE 0.0858 (0.0858)	Loss KD (Logit) 0.1198 (0.1198)	Loss KD (GCAM) 0.0378 (0.0378)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6177 (0.6177)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9561], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0662], device='cuda:0', requires_grad=True)
2022-03-24 00:00:25.204617
Epoch: [7][0/21], lr: 0.00100	Time 3.311 (3.311)	Data 2.236 (2.236)	Loss 0.1029 (0.1029)	Loss CE 0.0231 (0.0231)	Loss KD (Logit) 0.1221 (0.1221)	Loss KD (GCAM) 0.0402 (0.0402)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5918 (0.5918)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9579], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0681], device='cuda:0', requires_grad=True)
2022-03-24 00:00:46.966364
Epoch: [8][0/21], lr: 0.00100	Time 3.257 (3.257)	Data 2.338 (2.338)	Loss 0.1865 (0.1865)	Loss CE 0.1132 (0.1132)	Loss KD (Logit) 0.1238 (0.1238)	Loss KD (GCAM) 0.0391 (0.0391)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5287 (0.5287)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9612], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0705], device='cuda:0', requires_grad=True)
2022-03-24 00:01:09.143356
Epoch: [9][0/21], lr: 0.00100	Time 3.648 (3.648)	Data 2.514 (2.514)	Loss 0.0818 (0.0818)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.1259 (0.1259)	Loss KD (GCAM) 0.0410 (0.0410)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5750 (0.5750)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9668], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0747], device='cuda:0', requires_grad=True)
2022-03-24 00:01:31.267270
Epoch: [10][0/21], lr: 0.00100	Time 3.318 (3.318)	Data 2.160 (2.160)	Loss 0.0769 (0.0769)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.1256 (0.1256)	Loss KD (GCAM) 0.0360 (0.0360)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5524 (0.5524)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0762], device='cuda:0', requires_grad=True)
2022-03-24 00:01:52.994941
Epoch: [11][0/21], lr: 0.00100	Time 3.361 (3.361)	Data 2.302 (2.302)	Loss 0.1324 (0.1324)	Loss CE 0.0555 (0.0555)	Loss KD (Logit) 0.1266 (0.1266)	Loss KD (GCAM) 0.0371 (0.0371)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5682 (0.5682)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9737], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0797], device='cuda:0', requires_grad=True)
2022-03-24 00:02:14.765930
Epoch: [12][0/21], lr: 0.00100	Time 3.407 (3.407)	Data 2.220 (2.220)	Loss 0.0844 (0.0844)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 0.1245 (0.1245)	Loss KD (GCAM) 0.0377 (0.0377)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5677 (0.5677)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9776], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0820], device='cuda:0', requires_grad=True)
2022-03-24 00:02:36.723990
Epoch: [13][0/21], lr: 0.00100	Time 3.520 (3.520)	Data 2.285 (2.285)	Loss 0.0773 (0.0773)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.1215 (0.1215)	Loss KD (GCAM) 0.0362 (0.0362)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5690 (0.5690)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9795], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0831], device='cuda:0', requires_grad=True)
2022-03-24 00:02:58.558319
Epoch: [14][0/21], lr: 0.00100	Time 3.545 (3.545)	Data 2.720 (2.720)	Loss 0.0768 (0.0768)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.1258 (0.1258)	Loss KD (GCAM) 0.0377 (0.0377)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5578 (0.5578)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9849], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0866], device='cuda:0', requires_grad=True)
2022-03-24 00:03:20.298296
Epoch: [15][0/21], lr: 0.00100	Time 3.625 (3.625)	Data 2.334 (2.334)	Loss 0.0814 (0.0814)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.1262 (0.1262)	Loss KD (GCAM) 0.0396 (0.0396)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5866 (0.5866)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9898], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0893], device='cuda:0', requires_grad=True)
2022-03-24 00:03:41.841730
Epoch: [16][0/21], lr: 0.00100	Time 3.360 (3.360)	Data 1.898 (1.898)	Loss 0.0791 (0.0791)	Loss CE 0.0065 (0.0065)	Loss KD (Logit) 0.1213 (0.1213)	Loss KD (GCAM) 0.0336 (0.0336)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5405 (0.5405)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9947], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0923], device='cuda:0', requires_grad=True)
2022-03-24 00:04:03.923035
Epoch: [17][0/21], lr: 0.00100	Time 3.321 (3.321)	Data 2.097 (2.097)	Loss 0.0797 (0.0797)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1236 (0.1236)	Loss KD (GCAM) 0.0357 (0.0357)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6009 (0.6009)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9933], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0914], device='cuda:0', requires_grad=True)
2022-03-24 00:04:24.738748
Epoch: [18][0/21], lr: 0.00100	Time 3.418 (3.418)	Data 2.189 (2.189)	Loss 0.0829 (0.0829)	Loss CE 0.0084 (0.0084)	Loss KD (Logit) 0.1249 (0.1249)	Loss KD (GCAM) 0.0349 (0.0349)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5526 (0.5526)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9940], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0924], device='cuda:0', requires_grad=True)
2022-03-24 00:04:44.311957
Epoch: [19][0/21], lr: 0.00100	Time 3.498 (3.498)	Data 2.599 (2.599)	Loss 0.0853 (0.0853)	Loss CE 0.0112 (0.0112)	Loss KD (Logit) 0.1275 (0.1275)	Loss KD (GCAM) 0.0355 (0.0355)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5446 (0.5446)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-24 00:05:04.982476
Epoch: [20][0/21], lr: 0.00010	Time 3.518 (3.518)	Data 2.121 (2.121)	Loss 0.0724 (0.0724)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1271 (0.1271)	Loss KD (GCAM) 0.0358 (0.0358)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5227 (0.5227)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9986], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-24 00:05:22.970276
Epoch: [21][0/21], lr: 0.00010	Time 3.146 (3.146)	Data 1.922 (1.922)	Loss 0.0847 (0.0847)	Loss CE 0.0080 (0.0080)	Loss KD (Logit) 0.1236 (0.1236)	Loss KD (GCAM) 0.0345 (0.0345)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5767 (0.5767)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9990], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0955], device='cuda:0', requires_grad=True)
2022-03-24 00:05:41.585916
Epoch: [22][0/21], lr: 0.00010	Time 3.560 (3.560)	Data 2.270 (2.270)	Loss 0.0769 (0.0769)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.1249 (0.1249)	Loss KD (GCAM) 0.0342 (0.0342)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5417 (0.5417)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9994], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0957], device='cuda:0', requires_grad=True)
2022-03-24 00:05:59.880292
Epoch: [23][0/21], lr: 0.00010	Time 3.227 (3.227)	Data 2.142 (2.142)	Loss 0.0869 (0.0869)	Loss CE 0.0127 (0.0127)	Loss KD (Logit) 0.1260 (0.1260)	Loss KD (GCAM) 0.0325 (0.0325)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5560 (0.5560)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9993], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0957], device='cuda:0', requires_grad=True)
2022-03-24 00:06:18.199551
Epoch: [24][0/21], lr: 0.00010	Time 3.344 (3.344)	Data 2.529 (2.529)	Loss 0.0778 (0.0778)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.1240 (0.1240)	Loss KD (GCAM) 0.0369 (0.0369)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5727 (0.5727)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9992], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0956], device='cuda:0', requires_grad=True)
2022-03-24 00:06:36.312295
Epoch: [25][0/21], lr: 0.00010	Time 3.261 (3.261)	Data 2.147 (2.147)	Loss 0.0729 (0.0729)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.1247 (0.1247)	Loss KD (GCAM) 0.0344 (0.0344)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5267 (0.5267)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9994], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0957], device='cuda:0', requires_grad=True)
2022-03-24 00:06:55.103904
Epoch: [26][0/21], lr: 0.00010	Time 3.304 (3.304)	Data 2.328 (2.328)	Loss 0.0834 (0.0834)	Loss CE 0.0085 (0.0085)	Loss KD (Logit) 0.1280 (0.1280)	Loss KD (GCAM) 0.0347 (0.0347)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5544 (0.5544)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9998], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0959], device='cuda:0', requires_grad=True)
2022-03-24 00:07:13.774504
Epoch: [27][0/21], lr: 0.00010	Time 3.193 (3.193)	Data 2.378 (2.378)	Loss 0.0741 (0.0741)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1236 (0.1236)	Loss KD (GCAM) 0.0328 (0.0328)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5511 (0.5511)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0001], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0961], device='cuda:0', requires_grad=True)
2022-03-24 00:07:32.189267
Epoch: [28][0/21], lr: 0.00010	Time 3.176 (3.176)	Data 2.021 (2.021)	Loss 0.0927 (0.0927)	Loss CE 0.0153 (0.0153)	Loss KD (Logit) 0.1225 (0.1225)	Loss KD (GCAM) 0.0316 (0.0316)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5927 (0.5927)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0003], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0962], device='cuda:0', requires_grad=True)
2022-03-24 00:07:50.404959
Epoch: [29][0/21], lr: 0.00010	Time 3.381 (3.381)	Data 2.546 (2.546)	Loss 0.0784 (0.0784)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.1257 (0.1257)	Loss KD (GCAM) 0.0313 (0.0313)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5785 (0.5785)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0004], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:08:09.140901
Epoch: [30][0/21], lr: 0.00001	Time 3.313 (3.313)	Data 2.286 (2.286)	Loss 0.0810 (0.0810)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.1230 (0.1230)	Loss KD (GCAM) 0.0319 (0.0319)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5954 (0.5954)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0004], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:08:27.761272
Epoch: [31][0/21], lr: 0.00001	Time 3.212 (3.212)	Data 2.431 (2.431)	Loss 0.0812 (0.0812)	Loss CE 0.0064 (0.0064)	Loss KD (Logit) 0.1241 (0.1241)	Loss KD (GCAM) 0.0335 (0.0335)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5599 (0.5599)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0004], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:08:47.247087
Epoch: [32][0/21], lr: 0.00001	Time 3.759 (3.759)	Data 2.383 (2.383)	Loss 0.0719 (0.0719)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.1228 (0.1228)	Loss KD (GCAM) 0.0336 (0.0336)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5248 (0.5248)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0004], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:09:05.988206
Epoch: [33][0/21], lr: 0.00001	Time 3.300 (3.300)	Data 2.172 (2.172)	Loss 0.0737 (0.0737)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.1201 (0.1201)	Loss KD (GCAM) 0.0322 (0.0322)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5231 (0.5231)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0004], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:09:24.367730
Epoch: [34][0/21], lr: 0.00001	Time 3.132 (3.132)	Data 1.920 (1.920)	Loss 0.0763 (0.0763)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1257 (0.1257)	Loss KD (GCAM) 0.0321 (0.0321)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5735 (0.5735)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0005], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:09:42.599569
Epoch: [35][0/21], lr: 0.00001	Time 3.107 (3.107)	Data 1.905 (1.905)	Loss 0.0776 (0.0776)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.1235 (0.1235)	Loss KD (GCAM) 0.0347 (0.0347)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5691 (0.5691)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0005], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:10:00.461060
Epoch: [36][0/21], lr: 0.00001	Time 3.096 (3.096)	Data 1.853 (1.853)	Loss 0.0752 (0.0752)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.1211 (0.1211)	Loss KD (GCAM) 0.0351 (0.0351)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5547 (0.5547)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0005], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 00:10:20.209443
Epoch: [37][0/21], lr: 0.00001	Time 3.216 (3.216)	Data 1.956 (1.956)	Loss 0.0740 (0.0740)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1243 (0.1243)	Loss KD (GCAM) 0.0337 (0.0337)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5495 (0.5495)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0005], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:10:41.701646
Epoch: [38][0/21], lr: 0.00001	Time 3.289 (3.289)	Data 1.889 (1.889)	Loss 0.0769 (0.0769)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.1251 (0.1251)	Loss KD (GCAM) 0.0323 (0.0323)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5454 (0.5454)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0006], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:11:03.406276
Epoch: [39][0/21], lr: 0.00001	Time 3.296 (3.296)	Data 1.916 (1.916)	Loss 0.0788 (0.0788)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1251 (0.1251)	Loss KD (GCAM) 0.0307 (0.0307)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6057 (0.6057)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0006], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:11:25.192966
Epoch: [40][0/21], lr: 0.00001	Time 3.522 (3.522)	Data 2.088 (2.088)	Loss 0.0793 (0.0793)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1278 (0.1278)	Loss KD (GCAM) 0.0327 (0.0327)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6015 (0.6015)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0006], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:11:46.942520
Epoch: [41][0/21], lr: 0.00001	Time 3.320 (3.320)	Data 1.842 (1.842)	Loss 0.0751 (0.0751)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1235 (0.1235)	Loss KD (GCAM) 0.0327 (0.0327)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5643 (0.5643)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0007], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:12:08.656916
Epoch: [42][0/21], lr: 0.00001	Time 3.450 (3.450)	Data 2.221 (2.221)	Loss 0.0771 (0.0771)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.1259 (0.1259)	Loss KD (GCAM) 0.0315 (0.0315)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5855 (0.5855)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0007], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:12:30.522257
Epoch: [43][0/21], lr: 0.00001	Time 3.379 (3.379)	Data 2.296 (2.296)	Loss 0.0800 (0.0800)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.1258 (0.1258)	Loss KD (GCAM) 0.0341 (0.0341)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5725 (0.5725)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0007], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:12:52.334609
Epoch: [44][0/21], lr: 0.00001	Time 3.467 (3.467)	Data 2.543 (2.543)	Loss 0.0717 (0.0717)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.1211 (0.1211)	Loss KD (GCAM) 0.0326 (0.0326)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5301 (0.5301)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0007], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 00:13:14.188373
Epoch: [45][0/21], lr: 0.00001	Time 3.265 (3.265)	Data 2.137 (2.137)	Loss 0.0842 (0.0842)	Loss CE 0.0113 (0.0113)	Loss KD (Logit) 0.1261 (0.1261)	Loss KD (GCAM) 0.0373 (0.0373)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5285 (0.5285)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0007], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0965], device='cuda:0', requires_grad=True)
2022-03-24 00:13:36.022604
Epoch: [46][0/21], lr: 0.00001	Time 3.281 (3.281)	Data 2.281 (2.281)	Loss 0.0721 (0.0721)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.1270 (0.1270)	Loss KD (GCAM) 0.0362 (0.0362)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5116 (0.5116)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0008], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0965], device='cuda:0', requires_grad=True)
2022-03-24 00:13:57.821782
Epoch: [47][0/21], lr: 0.00001	Time 3.311 (3.311)	Data 2.037 (2.037)	Loss 0.0762 (0.0762)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.1227 (0.1227)	Loss KD (GCAM) 0.0318 (0.0318)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5762 (0.5762)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0008], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0965], device='cuda:0', requires_grad=True)
2022-03-24 00:14:19.642711
Epoch: [48][0/21], lr: 0.00001	Time 3.559 (3.559)	Data 2.537 (2.537)	Loss 0.0738 (0.0738)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.1268 (0.1268)	Loss KD (GCAM) 0.0333 (0.0333)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5437 (0.5437)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0008], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0965], device='cuda:0', requires_grad=True)
2022-03-24 00:14:41.538579
Epoch: [49][0/21], lr: 0.00001	Time 3.394 (3.394)	Data 2.147 (2.147)	Loss 0.0709 (0.0709)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.1274 (0.1274)	Loss KD (GCAM) 0.0361 (0.0361)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4808 (0.4808)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0008], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0965], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([4.0008]), eta=tensor([3.0965])
  (fc1): CosineLinear(input_features=512, output_features=297, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 177
video number + exemplar : 177
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([4.0008]), eta=tensor([3.0965])
  (fc1): CosineLinear(input_features=512, output_features=297, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 505
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-24 00:15:21.629572
Epoch: [0][0/15], lr: 0.00050	Time 3.043 (3.043)	Data 1.965 (1.965)	Loss 0.0049 (0.0049)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([4.0010], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0966], device='cuda:0', requires_grad=True)
2022-03-24 00:15:32.785124
Epoch: [1][0/15], lr: 0.00050	Time 2.959 (2.959)	Data 1.832 (1.832)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9991], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0955], device='cuda:0', requires_grad=True)
2022-03-24 00:15:44.508200
Epoch: [2][0/15], lr: 0.00050	Time 3.131 (3.131)	Data 2.126 (2.126)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0949], device='cuda:0', requires_grad=True)
2022-03-24 00:15:55.269084
Epoch: [3][0/15], lr: 0.00050	Time 2.931 (2.931)	Data 2.142 (2.142)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9967], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0939], device='cuda:0', requires_grad=True)
2022-03-24 00:16:06.539864
Epoch: [4][0/15], lr: 0.00050	Time 3.217 (3.217)	Data 2.544 (2.544)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9960], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0934], device='cuda:0', requires_grad=True)
2022-03-24 00:16:18.261434
Epoch: [5][0/15], lr: 0.00050	Time 3.299 (3.299)	Data 2.128 (2.128)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9957], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0929], device='cuda:0', requires_grad=True)
2022-03-24 00:16:29.871677
Epoch: [6][0/15], lr: 0.00050	Time 3.231 (3.231)	Data 1.907 (1.907)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9958], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
2022-03-24 00:16:41.157995
Epoch: [7][0/15], lr: 0.00050	Time 2.901 (2.901)	Data 2.219 (2.219)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9963], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0930], device='cuda:0', requires_grad=True)
2022-03-24 00:16:52.484513
Epoch: [8][0/15], lr: 0.00050	Time 3.077 (3.077)	Data 2.479 (2.479)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0934], device='cuda:0', requires_grad=True)
2022-03-24 00:17:03.768333
Epoch: [9][0/15], lr: 0.00050	Time 3.139 (3.139)	Data 2.017 (2.017)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9972], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0935], device='cuda:0', requires_grad=True)
2022-03-24 00:17:15.584209
Epoch: [10][0/15], lr: 0.00050	Time 3.179 (3.179)	Data 2.059 (2.059)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0934], device='cuda:0', requires_grad=True)
2022-03-24 00:17:26.686264
Epoch: [11][0/15], lr: 0.00050	Time 2.963 (2.963)	Data 1.850 (1.850)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0930], device='cuda:0', requires_grad=True)
2022-03-24 00:17:38.024308
Epoch: [12][0/15], lr: 0.00050	Time 3.042 (3.042)	Data 1.929 (1.929)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9965], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0925], device='cuda:0', requires_grad=True)
2022-03-24 00:17:49.497680
Epoch: [13][0/15], lr: 0.00050	Time 3.352 (3.352)	Data 2.569 (2.569)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9956], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0917], device='cuda:0', requires_grad=True)
2022-03-24 00:18:00.388697
Epoch: [14][0/15], lr: 0.00050	Time 2.966 (2.966)	Data 2.000 (2.000)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9953], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0914], device='cuda:0', requires_grad=True)
2022-03-24 00:18:11.368443
Epoch: [15][0/15], lr: 0.00050	Time 3.094 (3.094)	Data 2.343 (2.343)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9953], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0912], device='cuda:0', requires_grad=True)
2022-03-24 00:18:22.760132
Epoch: [16][0/15], lr: 0.00050	Time 3.272 (3.272)	Data 2.529 (2.529)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9949], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0909], device='cuda:0', requires_grad=True)
2022-03-24 00:18:34.067469
Epoch: [17][0/15], lr: 0.00050	Time 3.175 (3.175)	Data 2.144 (2.144)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9946], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0905], device='cuda:0', requires_grad=True)
2022-03-24 00:18:46.141082
Epoch: [18][0/15], lr: 0.00050	Time 3.342 (3.342)	Data 2.307 (2.307)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9945], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0902], device='cuda:0', requires_grad=True)
2022-03-24 00:18:57.433654
Epoch: [19][0/15], lr: 0.00050	Time 3.105 (3.105)	Data 2.298 (2.298)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9947], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0902], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/006/task_025.pth.tar
exemplar : 505
Computing the class mean vectors...
Eval Task 0 for Age 25
Current Task : [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37]
video number : 1964
video number + exemplar : 1964
DataLoader Constructed
Test: [0/123]	Time 5.137 (5.137)	Prec@1 50.000 (50.000)
Test: [100/123]	Time 0.388 (0.505)	Prec@1 75.000 (61.819)
Testing Results: Prec@1 61.507
Classify using the NME Classifier...
Test (NME): [0/123]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Test (NME): [100/123]	Time 0.000 (0.000)	Prec@1 75.000 (65.037)
Testing Results (NME): Prec@1 64.511
Eval Task 1 for Age 25
Current Task : [95, 14]
video number : 58
video number + exemplar : 58
DataLoader Constructed
Test: [0/4]	Time 3.854 (3.854)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 32.759
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 58.621
Eval Task 2 for Age 25
Current Task : [71, 96]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.948 (3.948)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 44.615
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 47.692
Eval Task 3 for Age 25
Current Task : [99, 98]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 3.454 (3.454)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 63.750
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 63.750
Eval Task 4 for Age 25
Current Task : [2, 64]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.523 (3.523)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 61.176
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 72.941
Eval Task 5 for Age 25
Current Task : [66, 42]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.903 (3.903)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 56.452
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 54.839
Eval Task 6 for Age 25
Current Task : [22, 35]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.970 (3.970)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 61.728
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 43.210
Eval Task 7 for Age 25
Current Task : [86, 24]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.258 (3.258)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 88.060
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 73.134
Eval Task 8 for Age 25
Current Task : [34, 87]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.126 (4.126)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 43.939
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 46.970
Eval Task 9 for Age 25
Current Task : [21, 100]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.982 (3.982)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 49.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 60.000
Eval Task 10 for Age 25
Current Task : [0, 88]
video number : 86
video number + exemplar : 86
DataLoader Constructed
Test: [0/6]	Time 4.055 (4.055)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 47.674
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 62.791
Eval Task 11 for Age 25
Current Task : [27, 18]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.909 (3.909)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 67.742
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 75.806
Eval Task 12 for Age 25
Current Task : [94, 11]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 3.414 (3.414)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 87.952
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.181
Eval Task 13 for Age 25
Current Task : [12, 47]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 4.093 (4.093)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 35.526
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 31.250 (31.250)
Testing Results (NME): Prec@1 35.526
Eval Task 14 for Age 25
Current Task : [25, 30]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.615 (3.615)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 95.122
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 91.463
Eval Task 15 for Age 25
Current Task : [46, 62]
video number : 80
video number + exemplar : 80
DataLoader Constructed
Test: [0/5]	Time 4.366 (4.366)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 62.500
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 68.750
Eval Task 16 for Age 25
Current Task : [69, 36]
video number : 56
video number + exemplar : 56
DataLoader Constructed
Test: [0/4]	Time 4.142 (4.142)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 51.786
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 51.786
Eval Task 17 for Age 25
Current Task : [61, 7]
video number : 83
video number + exemplar : 83
DataLoader Constructed
Test: [0/6]	Time 4.513 (4.513)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 53.012
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 53.012
Eval Task 18 for Age 25
Current Task : [63, 75]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.946 (3.946)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 93.750
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.375
Eval Task 19 for Age 25
Current Task : [5, 32]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.704 (3.704)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 78.049
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 71.951
Eval Task 20 for Age 25
Current Task : [4, 51]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.447 (3.447)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 52.941
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 60.294
Eval Task 21 for Age 25
Current Task : [48, 73]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.214 (4.214)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 80.519
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.416
Eval Task 22 for Age 25
Current Task : [93, 39]
video number : 69
video number + exemplar : 69
DataLoader Constructed
Test: [0/5]	Time 3.819 (3.819)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 65.217
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 65.217
Eval Task 23 for Age 25
Current Task : [67, 29]
video number : 76
video number + exemplar : 76
DataLoader Constructed
Test: [0/5]	Time 4.203 (4.203)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 89.474
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 73.684
Eval Task 24 for Age 25
Current Task : [97, 49]
video number : 70
video number + exemplar : 70
DataLoader Constructed
Test: [0/5]	Time 4.348 (4.348)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 75.714
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 64.286
Eval Task 25 for Age 25
Current Task : [57, 33]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.060 (4.060)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 95.455
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 69.697
num_test_videos [1964, 58, 65, 80, 85, 62, 81, 67, 66, 75, 86, 62, 83, 76, 82, 80, 56, 83, 64, 82, 68, 77, 69, 76, 70, 66]
n_vids [1964   58   65   80   85   62   81   67   66   75   86   62   83   76
   82   80   56   83   64   82   68   77   69   76   70   66]
n_vids_pad [[1964.]
 [  58.]
 [  65.]
 [  80.]
 [  85.]
 [  62.]
 [  81.]
 [  67.]
 [  66.]
 [  75.]
 [  86.]
 [  62.]
 [  83.]
 [  76.]
 [  82.]
 [  80.]
 [  56.]
 [  83.]
 [  64.]
 [  82.]
 [  68.]
 [  77.]
 [  69.]
 [  76.]
 [  70.]
 [  66.]]
tmp [[171799.99993896 155500.         158900.         153900.
  144000.         145399.99996948 141199.99996948 139800.
  140600.         135199.99996948 136600.         136199.99996948
  136599.99996948 131899.99996948 136100.         133999.99998474
  131700.         131700.         135800.         128299.99996948
  123099.99996948 128299.99996948 128699.99996948 127300.
  125099.99996948 120799.99996948]
 [-11600.           5600.           5000.           3600.
    4000.           3300.           3600.           3400.
    4400.           3200.           3500.           3800.
    4700.           3400.           3300.           2900.
    2600.           3100.           2900.           3800.
    2300.           2400.           3000.           3000.
    2400.           1900.        ]
 [-13000.         -13000.           5200.           5200.
    4900.           4000.           4200.           3500.
    4200.           3900.           4000.           3100.
    3000.           4000.           3500.           3400.
    2100.           2500.           2100.           2200.
    3200.           3000.           3200.           2400.
    3200.           2900.        ]
 [-16000.         -16000.         -16000.           7600.
    5900.           5000.           5600.           5500.
    4900.           5800.           6100.           6300.
    5600.           5500.           6000.           5000.
    4900.           5900.           5300.           4900.
    5200.           5200.           5300.           5200.
    5500.           5100.        ]
 [-17000.         -17000.         -17000.         -17000.
    8300.           5300.           6300.           6200.
    6200.           6300.           6200.           6500.
    5900.           6100.           6700.           6500.
    6500.           4800.           5300.           6500.
    4900.           6100.           6000.           5300.
    5700.           5200.        ]
 [-12400.         -12400.         -12400.         -12400.
  -12400.           5999.99995422   4699.99996948   5700.
    5299.99995422   4100.00003052   4899.99995422   4299.99996948
    3799.99999237   4399.99998474   4599.99996948   4199.99998474
    4100.00003052   3800.00001526   3199.99999237   3700.00003052
    3399.99998474   4200.00003052   4099.99996948   4500.00001526
    3699.99998474   3500.        ]
 [-16200.         -16200.         -16200.         -16200.
  -16200.         -16200.           7600.           7200.
    6700.           6600.           6500.           6300.
    6300.           5500.           6100.           5400.
    5400.           5400.           5600.           5200.
    4200.           5200.           5000.           4400.
    4900.           5000.        ]
 [-13400.         -13400.         -13400.         -13400.
  -13400.         -13400.         -13400.           6600.
    6400.           6300.           6200.           6300.
    6000.           5799.99999237   6099.99999237   5999.99999237
    6400.           6299.99999237   6199.99999237   6300.
    6000.           5299.99999237   5900.           5700.
    5800.           5900.        ]
 [-13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
    5800.           4500.           3900.           3500.
    3800.           3700.           3300.           3000.
    3200.           3800.           3100.           3900.
    3900.           3400.           3200.           3000.
    2300.           2900.        ]
 [-15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.           7200.           5800.00000381   5700.00001526
    5900.00002289   5299.99998474   5099.99999619   5300.00001526
    5199.99999619   4999.99998474   4799.99998474   4900.00000763
    4300.00000763   3600.00000763   4599.99999619   4799.99998474
    4000.00001526   3699.99999619]
 [-17200.         -17200.         -17200.         -17200.
  -17200.         -17200.         -17200.         -17200.
  -17200.         -17200.           8500.           8000.
    7399.99996948   7199.99996948   6300.           6399.99998474
    7099.99998474   6700.           6700.           6699.99998474
    6399.99998474   5799.99998474   4600.           3999.99999237
    5200.           4099.99999237]
 [-12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.           6200.
    5900.00001526   5699.99995422   5300.00003052   5399.99998474
    5399.99996948   4899.99998474   4400.00003052   4899.99995422
    5399.99995422   5300.00001526   5099.99995422   4599.99996948
    4099.99999237   4199.99996948]
 [-16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
    8000.           7900.           7900.           7700.
    7500.           7400.           7900.           7700.
    7900.           7900.           7900.           7900.
    7900.           7300.        ]
 [-15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.           7399.99996948   6999.99996948   5299.99998474
    4999.99998474   4299.99998474   4299.99998474   4099.99996948
    4199.99998474   4299.99998474   5599.99996948   4399.99998474
    5100.           2699.99996948]
 [-16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.           8200.           8000.
    8100.           7700.           6700.           7800.
    7000.           7500.           6300.           6600.
    7400.           7800.        ]
 [-16000.         -16000.         -16000.         -16000.
  -16000.         -16000.         -16000.         -16000.
  -16000.         -16000.         -16000.         -16000.
  -16000.         -16000.         -16000.           8000.
    6400.           5400.           5800.           5200.
    4400.           4700.           5200.           5700.
    4500.           5000.        ]
 [-11200.         -11200.         -11200.         -11200.
  -11200.         -11200.         -11200.         -11200.
  -11200.         -11200.         -11200.         -11200.
  -11200.         -11200.         -11200.         -11200.
    5100.           3800.           4000.           3100.
    3200.           3600.           3500.           3200.
    3100.           2900.        ]
 [-16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.           8200.           6899.99999237   6599.99999237
    5399.99999619   5000.           4700.           4400.
    4300.           4400.        ]
 [-12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.           6400.           5900.
    6400.           6400.           6000.           5600.
    5900.           6000.        ]
 [-16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.           8100.
    7100.           7700.           6100.           5200.
    5900.           6400.        ]
 [-13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
    6000.           5000.           3900.           4000.
    4200.           3600.        ]
 [-15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.           7600.           7000.           6800.
    6200.           6200.        ]
 [-13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.           6500.           3300.
    5000.           4500.        ]
 [-15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.           7500.
    6699.99996948   6799.99996948]
 [-14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
    6700.           5300.        ]
 [-13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.           6300.        ]]
tmp [[ 1.62999999e+04 -3.40000000e+03  5.00000000e+03  9.90000000e+03
  -1.39999997e+03  4.20000000e+03  1.39999997e+03 -8.00000000e+02
   5.40000003e+03 -1.40000003e+03  4.00000031e+02 -4.00000000e+02
   4.70000000e+03 -4.20000003e+03  2.10000002e+03  2.29999998e+03
  -0.00000000e+00 -4.10000000e+03  7.50000003e+03  5.20000000e+03
  -5.20000000e+03 -4.00000000e+02  1.39999997e+03  2.20000003e+03
   4.30000000e+03]
 [-1.72000000e+04  6.00000000e+02  1.40000000e+03 -4.00000000e+02
   7.00000000e+02 -3.00000000e+02  2.00000000e+02 -1.00000000e+03
   1.20000000e+03 -3.00000000e+02 -3.00000000e+02 -9.00000000e+02
   1.30000000e+03  1.00000000e+02  4.00000000e+02  3.00000000e+02
  -5.00000000e+02  2.00000000e+02 -9.00000000e+02  1.50000000e+03
  -1.00000000e+02 -6.00000000e+02 -0.00000000e+00  6.00000000e+02
   5.00000000e+02]
 [-0.00000000e+00 -1.82000000e+04 -0.00000000e+00  3.00000000e+02
   9.00000000e+02 -2.00000000e+02  7.00000000e+02 -7.00000000e+02
   3.00000000e+02 -1.00000000e+02  9.00000000e+02  1.00000000e+02
  -1.00000000e+03  5.00000000e+02  1.00000000e+02  1.30000000e+03
  -4.00000000e+02  4.00000000e+02 -1.00000000e+02 -1.00000000e+03
   2.00000000e+02 -2.00000000e+02  8.00000000e+02 -8.00000000e+02
   3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -2.36000000e+04  1.70000000e+03
   9.00000000e+02 -6.00000000e+02  1.00000000e+02  6.00000000e+02
  -9.00000000e+02 -3.00000000e+02 -2.00000000e+02  7.00000000e+02
   1.00000000e+02 -5.00000000e+02  1.00000000e+03  1.00000000e+02
  -1.00000000e+03  6.00000000e+02  4.00000000e+02 -3.00000000e+02
  -0.00000000e+00 -1.00000000e+02  1.00000000e+02 -3.00000000e+02
   4.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.53000000e+04
   3.00000000e+03 -1.00000000e+03  1.00000000e+02 -0.00000000e+00
  -1.00000000e+02  1.00000000e+02 -3.00000000e+02  6.00000000e+02
  -2.00000000e+02 -6.00000000e+02  2.00000000e+02 -0.00000000e+00
   1.70000000e+03 -5.00000000e+02 -1.20000000e+03  1.60000000e+03
  -1.20000000e+03  1.00000000e+02  7.00000000e+02 -4.00000000e+02
   5.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -1.84000000e+04  1.29999998e+03 -1.00000003e+03  4.00000046e+02
   1.19999992e+03 -7.99999924e+02  5.99999985e+02  4.99999977e+02
  -5.99999992e+02 -1.99999985e+02  3.99999985e+02  9.99999542e+01
   3.00000015e+02  6.00000023e+02 -5.00000038e+02  3.00000046e+02
  -8.00000046e+02  1.00000061e+02 -4.00000046e+02  8.00000031e+02
   1.99999985e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.38000000e+04  4.00000000e+02  5.00000000e+02
   1.00000000e+02  1.00000000e+02  2.00000000e+02 -0.00000000e+00
   8.00000000e+02 -6.00000000e+02  7.00000000e+02 -0.00000000e+00
  -0.00000000e+00 -2.00000000e+02  4.00000000e+02  1.00000000e+03
  -1.00000000e+03  2.00000000e+02  6.00000000e+02 -5.00000000e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.00000000e+04  2.00000000e+02
   1.00000000e+02  1.00000000e+02 -1.00000000e+02  3.00000000e+02
   2.00000008e+02 -3.00000000e+02  1.00000000e+02 -4.00000008e+02
   1.00000008e+02  1.00000000e+02 -1.00000008e+02  3.00000000e+02
   7.00000008e+02 -6.00000008e+02  2.00000000e+02 -1.00000000e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.90000000e+04
   1.30000000e+03  6.00000000e+02  4.00000000e+02 -3.00000000e+02
   1.00000000e+02  4.00000000e+02  3.00000000e+02 -2.00000000e+02
  -6.00000000e+02  7.00000000e+02 -8.00000000e+02 -0.00000000e+00
   5.00000000e+02  2.00000000e+02  2.00000000e+02  7.00000000e+02
  -6.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.22000000e+04  1.40000000e+03  9.99999886e+01 -2.00000008e+02
   6.00000038e+02  1.99999989e+02 -2.00000019e+02  1.00000019e+02
   2.00000011e+02  2.00000000e+02 -1.00000023e+02  6.00000000e+02
   7.00000000e+02 -9.99999989e+02 -1.99999989e+02  7.99999969e+02
   3.00000019e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.57000000e+04  5.00000000e+02  6.00000031e+02
   2.00000000e+02  8.99999969e+02 -9.99999847e+01 -7.00000000e+02
   3.99999985e+02 -0.00000000e+00  1.52587909e-05  3.00000000e+02
   6.00000000e+02  1.19999998e+03  6.00000008e+02 -1.20000001e+03
   1.10000001e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.86000000e+04  2.99999985e+02
   2.00000061e+02  3.99999924e+02 -9.99999542e+01  1.52587891e-05
   4.99999985e+02  4.99999954e+02 -4.99999924e+02 -5.00000000e+02
   9.99999390e+01  2.00000061e+02  4.99999985e+02  4.99999977e+02
  -9.99999771e+01]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.46000000e+04
   1.00000000e+02 -0.00000000e+00  2.00000000e+02  2.00000000e+02
   1.00000000e+02 -5.00000000e+02  2.00000000e+02 -2.00000000e+02
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
   6.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.26000000e+04  4.00000000e+02  1.69999998e+03  3.00000000e+02
   7.00000000e+02 -0.00000000e+00  2.00000015e+02 -1.00000015e+02
  -1.00000000e+02 -1.29999998e+03  1.19999998e+03 -7.00000015e+02
   2.40000003e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.46000000e+04  2.00000000e+02 -1.00000000e+02
   4.00000000e+02  1.00000000e+03 -1.10000000e+03  8.00000000e+02
  -5.00000000e+02  1.20000000e+03 -3.00000000e+02 -8.00000000e+02
  -4.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.40000000e+04  1.60000000e+03
   1.00000000e+03 -4.00000000e+02  6.00000000e+02  8.00000000e+02
  -3.00000000e+02 -5.00000000e+02 -5.00000000e+02  1.20000000e+03
  -5.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.63000000e+04
   1.30000000e+03 -2.00000000e+02  9.00000000e+02 -1.00000000e+02
  -4.00000000e+02  1.00000000e+02  3.00000000e+02  1.00000000e+02
   2.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.48000000e+04  1.30000001e+03  3.00000000e+02  1.20000000e+03
   3.99999996e+02  3.00000000e+02  3.00000000e+02  1.00000000e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -1.92000000e+04  5.00000000e+02 -5.00000000e+02
  -0.00000000e+00  4.00000000e+02  4.00000000e+02 -3.00000000e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.45000000e+04  1.00000000e+03
  -6.00000000e+02  1.60000000e+03  9.00000000e+02 -7.00000000e+02
  -5.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.96000000e+04
   1.00000000e+03  1.10000000e+03 -1.00000000e+02 -2.00000000e+02
   6.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.30000000e+04  6.00000000e+02  2.00000000e+02  6.00000000e+02
  -0.00000000e+00]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.03000000e+04  3.20000000e+03 -1.70000000e+03
   5.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.27000000e+04  8.00000031e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.07000000e+04
   1.40000000e+03]]
tmp [[ 1.62999999e+04 -3.40000000e+03  5.00000000e+03  9.90000000e+03
  -1.39999997e+03  4.20000000e+03  1.39999997e+03 -8.00000000e+02
   5.40000003e+03 -1.40000003e+03  4.00000031e+02 -4.00000000e+02
   4.70000000e+03 -4.20000003e+03  2.10000002e+03  2.29999998e+03
  -0.00000000e+00 -4.10000000e+03  7.50000003e+03  5.20000000e+03
  -5.20000000e+03 -4.00000000e+02  1.39999997e+03  2.20000003e+03
   4.30000000e+03]
 [ 0.00000000e+00  6.00000000e+02  1.40000000e+03 -4.00000000e+02
   7.00000000e+02 -3.00000000e+02  2.00000000e+02 -1.00000000e+03
   1.20000000e+03 -3.00000000e+02 -3.00000000e+02 -9.00000000e+02
   1.30000000e+03  1.00000000e+02  4.00000000e+02  3.00000000e+02
  -5.00000000e+02  2.00000000e+02 -9.00000000e+02  1.50000000e+03
  -1.00000000e+02 -6.00000000e+02 -0.00000000e+00  6.00000000e+02
   5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00  3.00000000e+02
   9.00000000e+02 -2.00000000e+02  7.00000000e+02 -7.00000000e+02
   3.00000000e+02 -1.00000000e+02  9.00000000e+02  1.00000000e+02
  -1.00000000e+03  5.00000000e+02  1.00000000e+02  1.30000000e+03
  -4.00000000e+02  4.00000000e+02 -1.00000000e+02 -1.00000000e+03
   2.00000000e+02 -2.00000000e+02  8.00000000e+02 -8.00000000e+02
   3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.70000000e+03
   9.00000000e+02 -6.00000000e+02  1.00000000e+02  6.00000000e+02
  -9.00000000e+02 -3.00000000e+02 -2.00000000e+02  7.00000000e+02
   1.00000000e+02 -5.00000000e+02  1.00000000e+03  1.00000000e+02
  -1.00000000e+03  6.00000000e+02  4.00000000e+02 -3.00000000e+02
  -0.00000000e+00 -1.00000000e+02  1.00000000e+02 -3.00000000e+02
   4.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   3.00000000e+03 -1.00000000e+03  1.00000000e+02 -0.00000000e+00
  -1.00000000e+02  1.00000000e+02 -3.00000000e+02  6.00000000e+02
  -2.00000000e+02 -6.00000000e+02  2.00000000e+02 -0.00000000e+00
   1.70000000e+03 -5.00000000e+02 -1.20000000e+03  1.60000000e+03
  -1.20000000e+03  1.00000000e+02  7.00000000e+02 -4.00000000e+02
   5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  1.29999998e+03 -1.00000003e+03  4.00000046e+02
   1.19999992e+03 -7.99999924e+02  5.99999985e+02  4.99999977e+02
  -5.99999992e+02 -1.99999985e+02  3.99999985e+02  9.99999542e+01
   3.00000015e+02  6.00000023e+02 -5.00000038e+02  3.00000046e+02
  -8.00000046e+02  1.00000061e+02 -4.00000046e+02  8.00000031e+02
   1.99999985e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  4.00000000e+02  5.00000000e+02
   1.00000000e+02  1.00000000e+02  2.00000000e+02 -0.00000000e+00
   8.00000000e+02 -6.00000000e+02  7.00000000e+02 -0.00000000e+00
  -0.00000000e+00 -2.00000000e+02  4.00000000e+02  1.00000000e+03
  -1.00000000e+03  2.00000000e+02  6.00000000e+02 -5.00000000e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.00000000e+02
   1.00000000e+02  1.00000000e+02 -1.00000000e+02  3.00000000e+02
   2.00000008e+02 -3.00000000e+02  1.00000000e+02 -4.00000008e+02
   1.00000008e+02  1.00000000e+02 -1.00000008e+02  3.00000000e+02
   7.00000008e+02 -6.00000008e+02  2.00000000e+02 -1.00000000e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.30000000e+03  6.00000000e+02  4.00000000e+02 -3.00000000e+02
   1.00000000e+02  4.00000000e+02  3.00000000e+02 -2.00000000e+02
  -6.00000000e+02  7.00000000e+02 -8.00000000e+02 -0.00000000e+00
   5.00000000e+02  2.00000000e+02  2.00000000e+02  7.00000000e+02
  -6.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  1.40000000e+03  9.99999886e+01 -2.00000008e+02
   6.00000038e+02  1.99999989e+02 -2.00000019e+02  1.00000019e+02
   2.00000011e+02  2.00000000e+02 -1.00000023e+02  6.00000000e+02
   7.00000000e+02 -9.99999989e+02 -1.99999989e+02  7.99999969e+02
   3.00000019e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  5.00000000e+02  6.00000031e+02
   2.00000000e+02  8.99999969e+02 -9.99999847e+01 -7.00000000e+02
   3.99999985e+02 -0.00000000e+00  1.52587909e-05  3.00000000e+02
   6.00000000e+02  1.19999998e+03  6.00000008e+02 -1.20000001e+03
   1.10000001e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.99999985e+02
   2.00000061e+02  3.99999924e+02 -9.99999542e+01  1.52587891e-05
   4.99999985e+02  4.99999954e+02 -4.99999924e+02 -5.00000000e+02
   9.99999390e+01  2.00000061e+02  4.99999985e+02  4.99999977e+02
  -9.99999771e+01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.00000000e+02 -0.00000000e+00  2.00000000e+02  2.00000000e+02
   1.00000000e+02 -5.00000000e+02  2.00000000e+02 -2.00000000e+02
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
   6.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  4.00000000e+02  1.69999998e+03  3.00000000e+02
   7.00000000e+02 -0.00000000e+00  2.00000015e+02 -1.00000015e+02
  -1.00000000e+02 -1.29999998e+03  1.19999998e+03 -7.00000015e+02
   2.40000003e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  2.00000000e+02 -1.00000000e+02
   4.00000000e+02  1.00000000e+03 -1.10000000e+03  8.00000000e+02
  -5.00000000e+02  1.20000000e+03 -3.00000000e+02 -8.00000000e+02
  -4.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.60000000e+03
   1.00000000e+03 -4.00000000e+02  6.00000000e+02  8.00000000e+02
  -3.00000000e+02 -5.00000000e+02 -5.00000000e+02  1.20000000e+03
  -5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.30000000e+03 -2.00000000e+02  9.00000000e+02 -1.00000000e+02
  -4.00000000e+02  1.00000000e+02  3.00000000e+02  1.00000000e+02
   2.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  1.30000001e+03  3.00000000e+02  1.20000000e+03
   3.99999996e+02  3.00000000e+02  3.00000000e+02  1.00000000e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  5.00000000e+02 -5.00000000e+02
  -0.00000000e+00  4.00000000e+02  4.00000000e+02 -3.00000000e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+03
  -6.00000000e+02  1.60000000e+03  9.00000000e+02 -7.00000000e+02
  -5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.00000000e+03  1.10000000e+03 -1.00000000e+02 -2.00000000e+02
   6.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  6.00000000e+02  2.00000000e+02  6.00000000e+02
  -0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  3.20000000e+03 -1.70000000e+03
   5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  8.00000031e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.40000000e+03]]
tmp [16299.99993896 -2800.          6400.         11500.
  4100.00003052  3399.99998474  1899.99993896  -799.99995422
  8599.99995422  -599.99995804  2200.00000381  1299.99998474
  6500.00011444 -3500.00013351  7000.0000267   4899.99996567
  4200.00000381  -300.00001526  5700.00006866 11900.0000267
 -6000.000103    2600.00012589 10099.99991226   700.00001526
 10700.00006485]
cumsum_n_vids [1964 2022 2087 2167 2252 2314 2395 2462 2528 2603 2689 2751 2834 2910
 2992 3072 3128 3211 3275 3357 3425 3502 3571 3647 3717]
fgt [ 8.29938897 -1.38476756  3.06660278  5.30687587  1.82060392  1.46931719
  0.79331939 -0.32493906  3.40189872 -0.23050325  0.81814801  0.47255543
  2.29357802 -1.20274919  2.3395722   1.59505207  1.342711   -0.09342884
  1.74045804  3.5448317  -1.75182485  0.74243293  2.82833938  0.19193858
  2.87866561]
fgt 1.598323082803818
fgt [1.59832308]
n_vids [1964   58   65   80   85   62   81   67   66   75   86   62   83   76
   82   80   56   83   64   82   68   77   69   76   70   66]
n_vids_pad [[1964.]
 [  58.]
 [  65.]
 [  80.]
 [  85.]
 [  62.]
 [  81.]
 [  67.]
 [  66.]
 [  75.]
 [  86.]
 [  62.]
 [  83.]
 [  76.]
 [  82.]
 [  80.]
 [  56.]
 [  83.]
 [  64.]
 [  82.]
 [  68.]
 [  77.]
 [  69.]
 [  76.]
 [  70.]
 [  66.]]
tmp [[170899.99993896 163200.         164099.99993896 159299.99993896
  158199.99993896 155199.99993896 153500.         151300.
  153800.         148199.99993896 147200.         148399.99993896
  147900.         146100.         147299.99993896 148500.
  145500.         141700.         142999.99993896 135900.
  134600.         136700.         133999.99996948 134700.
  129399.99996948 126699.99996948]
 [-11600.           5000.           4800.           3600.
    3700.           3900.           3900.           3900.
    4100.           3700.           4100.           4200.
    4500.           3800.           4300.           4000.
    3500.           3800.           3800.           3700.
    2500.           3300.           3600.           3600.
    2600.           3400.        ]
 [-13000.         -13000.           3800.           4000.
    3500.           3400.           3400.           3900.
    3800.           3300.           3200.           3500.
    3500.           3600.           3500.           3200.
    2900.           3500.           3000.           3100.
    3300.           3200.           3400.           3000.
    3400.           3100.        ]
 [-16000.         -16000.         -16000.           6500.
    6300.           5500.           5100.           5000.
    4800.           5800.           6000.           6200.
    5000.           5000.           5100.           4900.
    5000.           4400.           4300.           4500.
    4900.           4900.           5000.           5200.
    5100.           5100.        ]
 [-17000.         -17000.         -17000.         -17000.
    6700.           6100.           5700.           5500.
    5300.           5900.           6100.           5800.
    5200.           5800.           5800.           6600.
    6600.           5700.           6300.           6900.
    6500.           6600.           6400.           6000.
    6300.           6200.        ]
 [-12400.         -12400.         -12400.         -12400.
  -12400.           4999.99995422   4200.00003052   4400.00003052
    5099.99995422   4900.00001526   4399.99996948   3899.99996948
    4200.00003052   4299.99996948   4500.00001526   4199.99996948
    4399.99995422   3999.99996948   3700.00003052   3299.99998474
    3599.99999237   3899.99996948   3899.99998474   4599.99996948
    4299.99998474   3400.00000763]
 [-16200.         -16200.         -16200.         -16200.
  -16200.         -16200.           4600.           4100.
    4000.           4600.           4100.           4100.
    4400.           4100.           4400.           4300.
    3400.           4000.           4100.           3900.
    3500.           3800.           3900.           3400.
    3600.           3500.        ]
 [-13400.         -13400.         -13400.         -13400.
  -13400.         -13400.         -13400.           5700.
    5700.           5400.           5400.           5400.
    5199.99999237   5099.99999237   4999.99999237   4999.99999237
    5399.99999237   5499.99999237   5099.99999237   5099.99999237
    5099.99999237   4799.99999237   5200.           5100.
    5200.           4900.        ]
 [-13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
    4600.           3800.           3900.           3700.
    3200.           3400.           3300.           3700.
    3500.           3400.           3400.           3000.
    3600.           3300.           3100.           3100.
    2800.           3100.        ]
 [-15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.           4999.99998474   3800.00000763   4199.99999619
    4099.99999619   3700.00000763   3999.99999619   3799.99999619
    4200.00000763   4500.00000763   4199.99999809   4499.99999619
    4100.00000763   3800.00000763   4100.00000763   4500.00000763
    4699.99999809   4500.00000763]
 [-17200.         -17200.         -17200.         -17200.
  -17200.         -17200.         -17200.         -17200.
  -17200.         -17200.           8100.           8200.
    7799.99996948   7099.99998474   6699.99998474   6799.99998474
    6799.99998474   6799.99998474   6699.99998474   7499.99996948
    6699.99998474   6499.99998474   5300.           4800.
    5300.           5399.99999237]
 [-12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.           4899.99996948
    4199.99999237   4299.99998474   4599.99998474   4799.99998474
    5099.99995422   4400.00003052   4199.99998474   4300.00003052
    5199.99995422   4900.00001526   4799.99996948   4199.99998474
    4299.99998474   4700.00001526]
 [-16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
    7900.           7900.           7800.           7900.
    7900.           7900.           7900.           7900.
    7900.           7900.           7900.           7300.
    7500.           7900.        ]
 [-15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.           6799.99996948   6799.99993896   6300.
    5399.99998474   4599.99996948   4799.99998474   4099.99998474
    4299.99998474   5200.           4999.99996948   5799.99996948
    4900.           2700.        ]
 [-16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.           8100.           7800.
    7900.           7700.           7200.           7400.
    7700.           7500.           7600.           7500.
    7400.           7500.        ]
 [-16000.         -16000.         -16000.         -16000.
  -16000.         -16000.         -16000.         -16000.
  -16000.         -16000.         -16000.         -16000.
  -16000.         -16000.         -16000.           7400.
    6100.           5800.           6300.           4800.
    4700.           5000.           4900.           5300.
    5600.           5500.        ]
 [-11200.         -11200.         -11200.         -11200.
  -11200.         -11200.         -11200.         -11200.
  -11200.         -11200.         -11200.         -11200.
  -11200.         -11200.         -11200.         -11200.
    4200.           3800.           3800.           3600.
    3300.           3000.           3500.           2800.
    2800.           2900.        ]
 [-16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.         -16600.         -16600.         -16600.
  -16600.           5500.           5200.           4500.
    4600.           4600.           4400.           4300.
    4100.           4400.        ]
 [-12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.           6000.           5100.
    6000.           5100.           5400.           5400.
    4300.           5400.        ]
 [-16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.           7600.
    7000.           7400.           6800.           6000.
    6400.           5900.        ]
 [-13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
    4600.           4500.           4000.           4300.
    4200.           4100.        ]
 [-15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.           7100.           6700.           6800.
    6600.           6500.        ]
 [-13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.         -13800.         -13800.
  -13800.         -13800.           5700.           4400.
    4900.           4500.        ]
 [-15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.         -15200.
  -15200.         -15200.         -15200.           6599.99993896
    5899.99998474   5599.99996948]
 [-14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
  -14000.         -14000.         -14000.         -14000.
    5599.99996948   4499.99998474]
 [-13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
  -13200.           4600.        ]]
tmp [[ 7.69999994e+03 -8.99999939e+02  4.80000000e+03  1.10000000e+03
   3.00000000e+03  1.69999994e+03  2.20000000e+03 -2.50000000e+03
   5.60000006e+03  9.99999939e+02 -1.19999994e+03  4.99999939e+02
   1.80000000e+03 -1.19999994e+03 -1.20000006e+03  3.00000000e+03
   3.80000000e+03 -1.29999994e+03  7.09999994e+03  1.30000000e+03
  -2.10000000e+03  2.70000003e+03 -7.00000031e+02  5.30000003e+03
   2.70000000e+03]
 [-1.66000000e+04  2.00000000e+02  1.20000000e+03 -1.00000000e+02
  -2.00000000e+02 -0.00000000e+00 -0.00000000e+00 -2.00000000e+02
   4.00000000e+02 -4.00000000e+02 -1.00000000e+02 -3.00000000e+02
   7.00000000e+02 -5.00000000e+02  3.00000000e+02  5.00000000e+02
  -3.00000000e+02 -0.00000000e+00  1.00000000e+02  1.20000000e+03
  -8.00000000e+02 -3.00000000e+02 -0.00000000e+00  1.00000000e+03
  -8.00000000e+02]
 [-0.00000000e+00 -1.68000000e+04 -2.00000000e+02  5.00000000e+02
   1.00000000e+02 -0.00000000e+00 -5.00000000e+02  1.00000000e+02
   5.00000000e+02  1.00000000e+02 -3.00000000e+02 -0.00000000e+00
  -1.00000000e+02  1.00000000e+02  3.00000000e+02  3.00000000e+02
  -6.00000000e+02  5.00000000e+02 -1.00000000e+02 -2.00000000e+02
   1.00000000e+02 -2.00000000e+02  4.00000000e+02 -4.00000000e+02
   3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -2.25000000e+04  2.00000000e+02
   8.00000000e+02  4.00000000e+02  1.00000000e+02  2.00000000e+02
  -1.00000000e+03 -2.00000000e+02 -2.00000000e+02  1.20000000e+03
  -0.00000000e+00 -1.00000000e+02  2.00000000e+02 -1.00000000e+02
   6.00000000e+02  1.00000000e+02 -2.00000000e+02 -4.00000000e+02
  -0.00000000e+00 -1.00000000e+02 -2.00000000e+02  1.00000000e+02
  -0.00000000e+00]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.37000000e+04
   6.00000000e+02  4.00000000e+02  2.00000000e+02  2.00000000e+02
  -6.00000000e+02 -2.00000000e+02  3.00000000e+02  6.00000000e+02
  -6.00000000e+02 -0.00000000e+00 -8.00000000e+02 -0.00000000e+00
   9.00000000e+02 -6.00000000e+02 -6.00000000e+02  4.00000000e+02
  -1.00000000e+02  2.00000000e+02  4.00000000e+02 -3.00000000e+02
   1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -1.74000000e+04  7.99999924e+02 -2.00000000e+02 -6.99999924e+02
   1.99999939e+02  5.00000046e+02  5.00000000e+02 -3.00000061e+02
  -9.99999390e+01 -2.00000046e+02  3.00000046e+02 -1.99999985e+02
   3.99999985e+02  2.99999939e+02  4.00000046e+02 -3.00000008e+02
  -2.99999977e+02 -1.52587900e-05 -6.99999985e+02  2.99999985e+02
   8.99999977e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.08000000e+04  5.00000000e+02  1.00000000e+02
  -6.00000000e+02  5.00000000e+02 -0.00000000e+00 -3.00000000e+02
   3.00000000e+02 -3.00000000e+02  1.00000000e+02  9.00000000e+02
  -6.00000000e+02 -1.00000000e+02  2.00000000e+02  4.00000000e+02
  -3.00000000e+02 -1.00000000e+02  5.00000000e+02 -2.00000000e+02
   1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.91000000e+04 -0.00000000e+00
   3.00000000e+02 -0.00000000e+00 -0.00000000e+00  2.00000008e+02
   1.00000000e+02  1.00000000e+02 -0.00000000e+00 -4.00000000e+02
  -1.00000000e+02  4.00000000e+02 -0.00000000e+00 -0.00000000e+00
   3.00000000e+02 -4.00000008e+02  1.00000000e+02 -1.00000000e+02
   3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.78000000e+04
   8.00000000e+02 -1.00000000e+02  2.00000000e+02  5.00000000e+02
  -2.00000000e+02  1.00000000e+02 -4.00000000e+02  2.00000000e+02
   1.00000000e+02 -0.00000000e+00  4.00000000e+02 -6.00000000e+02
   3.00000000e+02  2.00000000e+02 -0.00000000e+00  3.00000000e+02
  -3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.00000000e+04  1.19999998e+03 -3.99999989e+02  1.00000000e+02
   3.99999989e+02 -2.99999989e+02  2.00000000e+02 -4.00000011e+02
  -3.00000000e+02  3.00000010e+02 -2.99999998e+02  3.99999989e+02
   3.00000000e+02 -3.00000000e+02 -4.00000000e+02 -1.99999990e+02
   1.99999990e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.53000000e+04 -1.00000000e+02  4.00000031e+02
   6.99999985e+02  4.00000000e+02 -1.00000000e+02 -0.00000000e+00
  -0.00000000e+00  1.00000000e+02 -7.99999985e+02  7.99999985e+02
   2.00000000e+02  1.19999998e+03  5.00000000e+02 -5.00000000e+02
  -9.99999924e+01]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.73000000e+04  6.99999977e+02
  -9.99999924e+01 -3.00000000e+02 -2.00000000e+02 -2.99999969e+02
   6.99999924e+02  2.00000046e+02 -1.00000046e+02 -8.99999924e+02
   2.99999939e+02  1.00000046e+02  5.99999985e+02 -1.00000000e+02
  -4.00000031e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.45000000e+04
  -0.00000000e+00  1.00000000e+02 -1.00000000e+02 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00  6.00000000e+02 -2.00000000e+02
  -4.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.20000000e+04  3.05175790e-05  4.99999939e+02  9.00000015e+02
   8.00000015e+02 -2.00000015e+02  7.00000000e+02 -2.00000000e+02
  -9.00000015e+02  2.00000031e+02 -8.00000000e+02  8.99999969e+02
   2.20000000e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.45000000e+04  3.00000000e+02 -1.00000000e+02
   2.00000000e+02  5.00000000e+02 -2.00000000e+02 -3.00000000e+02
   2.00000000e+02 -1.00000000e+02  1.00000000e+02  1.00000000e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.34000000e+04  1.30000000e+03
   3.00000000e+02 -5.00000000e+02  1.50000000e+03  1.00000000e+02
  -3.00000000e+02  1.00000000e+02 -4.00000000e+02 -3.00000000e+02
   1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.54000000e+04
   4.00000000e+02 -0.00000000e+00  2.00000000e+02  3.00000000e+02
   3.00000000e+02 -5.00000000e+02  7.00000000e+02 -0.00000000e+00
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.21000000e+04  3.00000000e+02  7.00000000e+02 -1.00000000e+02
  -0.00000000e+00  2.00000000e+02  1.00000000e+02  2.00000000e+02
  -3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -1.88000000e+04  9.00000000e+02 -9.00000000e+02
   9.00000000e+02 -3.00000000e+02 -0.00000000e+00  1.10000000e+03
  -1.10000000e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.40000000e+04  6.00000000e+02
  -4.00000000e+02  6.00000000e+02  8.00000000e+02 -4.00000000e+02
   5.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.82000000e+04
   1.00000000e+02  5.00000000e+02 -3.00000000e+02  1.00000000e+02
   1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.25000000e+04  4.00000000e+02 -1.00000000e+02  2.00000000e+02
   1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -1.95000000e+04  1.30000000e+03 -5.00000000e+02
   4.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.17999999e+04  6.99999954e+02
   3.00000015e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.96000000e+04
   1.09999998e+03]]
tmp [[ 7.69999994e+03 -8.99999939e+02  4.80000000e+03  1.10000000e+03
   3.00000000e+03  1.69999994e+03  2.20000000e+03 -2.50000000e+03
   5.60000006e+03  9.99999939e+02 -1.19999994e+03  4.99999939e+02
   1.80000000e+03 -1.19999994e+03 -1.20000006e+03  3.00000000e+03
   3.80000000e+03 -1.29999994e+03  7.09999994e+03  1.30000000e+03
  -2.10000000e+03  2.70000003e+03 -7.00000031e+02  5.30000003e+03
   2.70000000e+03]
 [ 0.00000000e+00  2.00000000e+02  1.20000000e+03 -1.00000000e+02
  -2.00000000e+02 -0.00000000e+00 -0.00000000e+00 -2.00000000e+02
   4.00000000e+02 -4.00000000e+02 -1.00000000e+02 -3.00000000e+02
   7.00000000e+02 -5.00000000e+02  3.00000000e+02  5.00000000e+02
  -3.00000000e+02 -0.00000000e+00  1.00000000e+02  1.20000000e+03
  -8.00000000e+02 -3.00000000e+02 -0.00000000e+00  1.00000000e+03
  -8.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00 -2.00000000e+02  5.00000000e+02
   1.00000000e+02 -0.00000000e+00 -5.00000000e+02  1.00000000e+02
   5.00000000e+02  1.00000000e+02 -3.00000000e+02 -0.00000000e+00
  -1.00000000e+02  1.00000000e+02  3.00000000e+02  3.00000000e+02
  -6.00000000e+02  5.00000000e+02 -1.00000000e+02 -2.00000000e+02
   1.00000000e+02 -2.00000000e+02  4.00000000e+02 -4.00000000e+02
   3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.00000000e+02
   8.00000000e+02  4.00000000e+02  1.00000000e+02  2.00000000e+02
  -1.00000000e+03 -2.00000000e+02 -2.00000000e+02  1.20000000e+03
  -0.00000000e+00 -1.00000000e+02  2.00000000e+02 -1.00000000e+02
   6.00000000e+02  1.00000000e+02 -2.00000000e+02 -4.00000000e+02
  -0.00000000e+00 -1.00000000e+02 -2.00000000e+02  1.00000000e+02
  -0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   6.00000000e+02  4.00000000e+02  2.00000000e+02  2.00000000e+02
  -6.00000000e+02 -2.00000000e+02  3.00000000e+02  6.00000000e+02
  -6.00000000e+02 -0.00000000e+00 -8.00000000e+02 -0.00000000e+00
   9.00000000e+02 -6.00000000e+02 -6.00000000e+02  4.00000000e+02
  -1.00000000e+02  2.00000000e+02  4.00000000e+02 -3.00000000e+02
   1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  7.99999924e+02 -2.00000000e+02 -6.99999924e+02
   1.99999939e+02  5.00000046e+02  5.00000000e+02 -3.00000061e+02
  -9.99999390e+01 -2.00000046e+02  3.00000046e+02 -1.99999985e+02
   3.99999985e+02  2.99999939e+02  4.00000046e+02 -3.00000008e+02
  -2.99999977e+02 -1.52587900e-05 -6.99999985e+02  2.99999985e+02
   8.99999977e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  5.00000000e+02  1.00000000e+02
  -6.00000000e+02  5.00000000e+02 -0.00000000e+00 -3.00000000e+02
   3.00000000e+02 -3.00000000e+02  1.00000000e+02  9.00000000e+02
  -6.00000000e+02 -1.00000000e+02  2.00000000e+02  4.00000000e+02
  -3.00000000e+02 -1.00000000e+02  5.00000000e+02 -2.00000000e+02
   1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00
   3.00000000e+02 -0.00000000e+00 -0.00000000e+00  2.00000008e+02
   1.00000000e+02  1.00000000e+02 -0.00000000e+00 -4.00000000e+02
  -1.00000000e+02  4.00000000e+02 -0.00000000e+00 -0.00000000e+00
   3.00000000e+02 -4.00000008e+02  1.00000000e+02 -1.00000000e+02
   3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   8.00000000e+02 -1.00000000e+02  2.00000000e+02  5.00000000e+02
  -2.00000000e+02  1.00000000e+02 -4.00000000e+02  2.00000000e+02
   1.00000000e+02 -0.00000000e+00  4.00000000e+02 -6.00000000e+02
   3.00000000e+02  2.00000000e+02 -0.00000000e+00  3.00000000e+02
  -3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  1.19999998e+03 -3.99999989e+02  1.00000000e+02
   3.99999989e+02 -2.99999989e+02  2.00000000e+02 -4.00000011e+02
  -3.00000000e+02  3.00000010e+02 -2.99999998e+02  3.99999989e+02
   3.00000000e+02 -3.00000000e+02 -4.00000000e+02 -1.99999990e+02
   1.99999990e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00 -1.00000000e+02  4.00000031e+02
   6.99999985e+02  4.00000000e+02 -1.00000000e+02 -0.00000000e+00
  -0.00000000e+00  1.00000000e+02 -7.99999985e+02  7.99999985e+02
   2.00000000e+02  1.19999998e+03  5.00000000e+02 -5.00000000e+02
  -9.99999924e+01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.99999977e+02
  -9.99999924e+01 -3.00000000e+02 -2.00000000e+02 -2.99999969e+02
   6.99999924e+02  2.00000046e+02 -1.00000046e+02 -8.99999924e+02
   2.99999939e+02  1.00000046e+02  5.99999985e+02 -1.00000000e+02
  -4.00000031e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  -0.00000000e+00  1.00000000e+02 -1.00000000e+02 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00  6.00000000e+02 -2.00000000e+02
  -4.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  3.05175790e-05  4.99999939e+02  9.00000015e+02
   8.00000015e+02 -2.00000015e+02  7.00000000e+02 -2.00000000e+02
  -9.00000015e+02  2.00000031e+02 -8.00000000e+02  8.99999969e+02
   2.20000000e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  3.00000000e+02 -1.00000000e+02
   2.00000000e+02  5.00000000e+02 -2.00000000e+02 -3.00000000e+02
   2.00000000e+02 -1.00000000e+02  1.00000000e+02  1.00000000e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.30000000e+03
   3.00000000e+02 -5.00000000e+02  1.50000000e+03  1.00000000e+02
  -3.00000000e+02  1.00000000e+02 -4.00000000e+02 -3.00000000e+02
   1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   4.00000000e+02 -0.00000000e+00  2.00000000e+02  3.00000000e+02
   3.00000000e+02 -5.00000000e+02  7.00000000e+02 -0.00000000e+00
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  3.00000000e+02  7.00000000e+02 -1.00000000e+02
  -0.00000000e+00  2.00000000e+02  1.00000000e+02  2.00000000e+02
  -3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  9.00000000e+02 -9.00000000e+02
   9.00000000e+02 -3.00000000e+02 -0.00000000e+00  1.10000000e+03
  -1.10000000e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.00000000e+02
  -4.00000000e+02  6.00000000e+02  8.00000000e+02 -4.00000000e+02
   5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.00000000e+02  5.00000000e+02 -3.00000000e+02  1.00000000e+02
   1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  4.00000000e+02 -1.00000000e+02  2.00000000e+02
   1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  1.30000000e+03 -5.00000000e+02
   4.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.99999954e+02
   3.00000015e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.09999998e+03]]
tmp [ 7.69999994e+03 -6.99999939e+02  5.80000000e+03  1.70000000e+03
  4.30000000e+03  3.29999986e+03  2.30000000e+03 -2.79999992e+03
  5.60000000e+03  2.39999996e+03 -1.29999993e+03  3.29999989e+03
  2.90000004e+03 -2.09999994e+03 -6.00000076e+02  5.60000005e+03
  6.29999992e+03  4.00543208e-05  9.89999996e+03  1.60000004e+03
 -2.20000005e+03  4.10000007e+03  2.49999997e+03  7.09999995e+03
  5.79999994e+03]
cumsum_n_vids [1964 2022 2087 2167 2252 2314 2395 2462 2528 2603 2689 2751 2834 2910
 2992 3072 3128 3211 3275 3357 3425 3502 3571 3647 3717]
fgt [ 3.92057023e+00 -3.46191859e-01  2.77910877e+00  7.84494693e-01
  1.90941385e+00  1.42610193e+00  9.60334029e-01 -1.13728673e+00
  2.21518987e+00  9.22013047e-01 -4.83451070e-01  1.19956376e+00
  1.02328865e+00 -7.21649465e-01 -2.00534785e-01  1.82291668e+00
  2.01406647e+00  1.24740956e-08  3.02290075e+00  4.76616039e-01
 -6.42335782e-01  1.17075959e+00  7.00084002e-01  1.94680558e+00
  1.56039816e+00]
fgt 1.052927057058768
fgt [1.05292706]