ucf101: 101 classes
creating folder log/ucf101/51/2/007
creating folder checkpoint/ucf101/51/2/007
Method : OURS
----AGE 0----
current_task  [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
current_head  51
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
CosineLinear(input_features=512, output_features=153, sigma=tensor([1.]), eta=tensor([1.]))
video number : 4778
video number + exemplar : 4778
DataLoader Constructed : Train 149
Optimizer Constructed
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 00:28:51.935794
Epoch: [0][0/149], lr: 0.00100	Time 14.227 (14.227)	Data 1.550 (1.550)	Loss 4.0007 (4.0007)	Loss CE 3.9373 (3.9373)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6339 (0.6339)	Loss REG 0.0000 (0.0000)	Prec@1 0.000 (0.000)
2022-03-24 00:29:49.585221
Epoch: [0][100/149], lr: 0.00100	Time 0.480 (0.712)	Data 0.000 (0.016)	Loss 3.9843 (3.9928)	Loss CE 3.9217 (3.9297)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6261 (0.6310)	Loss REG 0.0000 (0.0000)	Prec@1 6.250 (2.847)
Sigma : Parameter containing:
tensor([1.0365], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.0160], device='cuda:0', requires_grad=True)
2022-03-24 00:30:18.623013
Epoch: [1][0/149], lr: 0.00100	Time 2.802 (2.802)	Data 1.944 (1.944)	Loss 3.9793 (3.9793)	Loss CE 3.9203 (3.9203)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5903 (0.5903)	Loss REG 0.0000 (0.0000)	Prec@1 3.125 (3.125)
2022-03-24 00:31:12.441699
Epoch: [1][100/149], lr: 0.00100	Time 0.409 (0.561)	Data 0.000 (0.019)	Loss 3.9540 (3.9770)	Loss CE 3.8930 (3.9156)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6102 (0.6139)	Loss REG 0.0000 (0.0000)	Prec@1 9.375 (5.972)
Sigma : Parameter containing:
tensor([1.2760], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.1410], device='cuda:0', requires_grad=True)
2022-03-24 00:31:42.400504
Epoch: [2][0/149], lr: 0.00100	Time 2.965 (2.965)	Data 2.269 (2.269)	Loss 3.9551 (3.9551)	Loss CE 3.8944 (3.8944)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6073 (0.6073)	Loss REG 0.0000 (0.0000)	Prec@1 12.500 (12.500)
2022-03-24 00:32:33.991625
Epoch: [2][100/149], lr: 0.00100	Time 0.447 (0.540)	Data 0.000 (0.023)	Loss 3.8016 (3.9048)	Loss CE 3.7407 (3.8431)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6096 (0.6176)	Loss REG 0.0000 (0.0000)	Prec@1 18.750 (16.522)
Sigma : Parameter containing:
tensor([2.4328], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.8426], device='cuda:0', requires_grad=True)
2022-03-24 00:33:00.547149
Epoch: [3][0/149], lr: 0.00100	Time 2.753 (2.753)	Data 1.797 (1.797)	Loss 3.2917 (3.2917)	Loss CE 3.2270 (3.2270)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6471 (0.6471)	Loss REG 0.0000 (0.0000)	Prec@1 37.500 (37.500)
2022-03-24 00:33:47.576760
Epoch: [3][100/149], lr: 0.00100	Time 0.438 (0.493)	Data 0.000 (0.018)	Loss 1.6900 (2.4471)	Loss CE 1.6225 (2.3809)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6757 (0.6628)	Loss REG 0.0000 (0.0000)	Prec@1 56.250 (39.851)
Sigma : Parameter containing:
tensor([3.5846], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.6954], device='cuda:0', requires_grad=True)
2022-03-24 00:34:13.150324
Epoch: [4][0/149], lr: 0.00100	Time 2.823 (2.823)	Data 2.042 (2.042)	Loss 1.1210 (1.1210)	Loss CE 1.0509 (1.0509)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7012 (0.7012)	Loss REG 0.0000 (0.0000)	Prec@1 78.125 (78.125)
2022-03-24 00:34:59.401354
Epoch: [4][100/149], lr: 0.00100	Time 0.486 (0.486)	Data 0.000 (0.021)	Loss 0.8585 (1.3299)	Loss CE 0.7935 (1.2625)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6497 (0.6739)	Loss REG 0.0000 (0.0000)	Prec@1 81.250 (67.048)
Sigma : Parameter containing:
tensor([3.5905], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.7743], device='cuda:0', requires_grad=True)
2022-03-24 00:35:25.274217
Epoch: [5][0/149], lr: 0.00100	Time 2.895 (2.895)	Data 2.065 (2.065)	Loss 0.9311 (0.9311)	Loss CE 0.8625 (0.8625)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6861 (0.6861)	Loss REG 0.0000 (0.0000)	Prec@1 84.375 (84.375)
2022-03-24 00:36:13.128863
Epoch: [5][100/149], lr: 0.00100	Time 0.498 (0.502)	Data 0.000 (0.021)	Loss 0.7275 (0.9329)	Loss CE 0.6548 (0.8655)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7269 (0.6742)	Loss REG 0.0000 (0.0000)	Prec@1 81.250 (76.269)
Sigma : Parameter containing:
tensor([3.6245], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.8469], device='cuda:0', requires_grad=True)
2022-03-24 00:36:40.370697
Epoch: [6][0/149], lr: 0.00100	Time 2.983 (2.983)	Data 2.354 (2.354)	Loss 0.5281 (0.5281)	Loss CE 0.4618 (0.4618)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6629 (0.6629)	Loss REG 0.0000 (0.0000)	Prec@1 81.250 (81.250)
2022-03-24 00:37:28.536536
Epoch: [6][100/149], lr: 0.00100	Time 0.426 (0.506)	Data 0.000 (0.024)	Loss 0.7823 (0.6752)	Loss CE 0.7170 (0.6082)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6533 (0.6706)	Loss REG 0.0000 (0.0000)	Prec@1 84.375 (83.168)
Sigma : Parameter containing:
tensor([3.6215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.8845], device='cuda:0', requires_grad=True)
2022-03-24 00:37:55.288899
Epoch: [7][0/149], lr: 0.00100	Time 2.980 (2.980)	Data 2.217 (2.217)	Loss 0.6572 (0.6572)	Loss CE 0.5874 (0.5874)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6988 (0.6988)	Loss REG 0.0000 (0.0000)	Prec@1 81.250 (81.250)
2022-03-24 00:38:44.154856
Epoch: [7][100/149], lr: 0.00100	Time 0.590 (0.513)	Data 0.000 (0.022)	Loss 0.3799 (0.5842)	Loss CE 0.3128 (0.5171)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6705 (0.6709)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (85.582)
Sigma : Parameter containing:
tensor([3.6572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9347], device='cuda:0', requires_grad=True)
2022-03-24 00:39:10.931589
Epoch: [8][0/149], lr: 0.00100	Time 2.937 (2.937)	Data 2.252 (2.252)	Loss 0.4339 (0.4339)	Loss CE 0.3689 (0.3689)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6501 (0.6501)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-24 00:40:00.168551
Epoch: [8][100/149], lr: 0.00100	Time 0.512 (0.517)	Data 0.000 (0.023)	Loss 1.2016 (0.4683)	Loss CE 1.1363 (0.4015)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6534 (0.6673)	Loss REG 0.0000 (0.0000)	Prec@1 68.750 (89.171)
Sigma : Parameter containing:
tensor([3.6824], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.9763], device='cuda:0', requires_grad=True)
2022-03-24 00:40:24.668625
Epoch: [9][0/149], lr: 0.00100	Time 3.000 (3.000)	Data 1.972 (1.972)	Loss 0.3040 (0.3040)	Loss CE 0.2376 (0.2376)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6642 (0.6642)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-24 00:41:18.931628
Epoch: [9][100/149], lr: 0.00100	Time 0.539 (0.567)	Data 0.000 (0.020)	Loss 0.3840 (0.4007)	Loss CE 0.3162 (0.3341)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6782 (0.6660)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (90.811)
Sigma : Parameter containing:
tensor([3.7240], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0207], device='cuda:0', requires_grad=True)
2022-03-24 00:41:49.292657
Epoch: [10][0/149], lr: 0.00100	Time 2.671 (2.671)	Data 1.751 (1.751)	Loss 0.4714 (0.4714)	Loss CE 0.4051 (0.4051)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6624 (0.6624)	Loss REG 0.0000 (0.0000)	Prec@1 81.250 (81.250)
2022-03-24 00:42:45.994473
Epoch: [10][100/149], lr: 0.00100	Time 0.634 (0.588)	Data 0.000 (0.018)	Loss 0.2857 (0.3611)	Loss CE 0.2189 (0.2949)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6676 (0.6623)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (91.553)
Sigma : Parameter containing:
tensor([3.7307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0386], device='cuda:0', requires_grad=True)
2022-03-24 00:43:17.316839
Epoch: [11][0/149], lr: 0.00100	Time 3.102 (3.102)	Data 2.230 (2.230)	Loss 0.1826 (0.1826)	Loss CE 0.1160 (0.1160)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6666 (0.6666)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 00:44:12.192088
Epoch: [11][100/149], lr: 0.00100	Time 0.549 (0.574)	Data 0.000 (0.022)	Loss 0.3052 (0.3206)	Loss CE 0.2413 (0.2544)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6387 (0.6619)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (92.946)
Sigma : Parameter containing:
tensor([3.7701], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0710], device='cuda:0', requires_grad=True)
2022-03-24 00:44:42.259176
Epoch: [12][0/149], lr: 0.00100	Time 3.111 (3.111)	Data 2.205 (2.205)	Loss 0.4239 (0.4239)	Loss CE 0.3553 (0.3553)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6861 (0.6861)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-24 00:45:36.821129
Epoch: [12][100/149], lr: 0.00100	Time 0.678 (0.571)	Data 0.000 (0.022)	Loss 0.3748 (0.3368)	Loss CE 0.3069 (0.2709)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6789 (0.6595)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (92.543)
Sigma : Parameter containing:
tensor([3.7679], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0764], device='cuda:0', requires_grad=True)
2022-03-24 00:46:06.472733
Epoch: [13][0/149], lr: 0.00100	Time 2.823 (2.823)	Data 2.125 (2.125)	Loss 0.4857 (0.4857)	Loss CE 0.4164 (0.4164)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6928 (0.6928)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-24 00:47:01.681709
Epoch: [13][100/149], lr: 0.00100	Time 0.540 (0.575)	Data 0.000 (0.021)	Loss 0.1402 (0.2787)	Loss CE 0.0763 (0.2128)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6386 (0.6597)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (94.338)
Sigma : Parameter containing:
tensor([3.7798], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0895], device='cuda:0', requires_grad=True)
2022-03-24 00:47:31.251693
Epoch: [14][0/149], lr: 0.00100	Time 2.814 (2.814)	Data 2.337 (2.337)	Loss 0.3471 (0.3471)	Loss CE 0.2810 (0.2810)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6611 (0.6611)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-24 00:48:26.468260
Epoch: [14][100/149], lr: 0.00100	Time 0.502 (0.575)	Data 0.000 (0.023)	Loss 0.4090 (0.2736)	Loss CE 0.3508 (0.2077)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5824 (0.6591)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (93.998)
Sigma : Parameter containing:
tensor([3.7317], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0713], device='cuda:0', requires_grad=True)
2022-03-24 00:48:55.864635
Epoch: [15][0/149], lr: 0.00100	Time 2.711 (2.711)	Data 1.825 (1.825)	Loss 0.2118 (0.2118)	Loss CE 0.1458 (0.1458)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6597 (0.6597)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-24 00:49:50.569199
Epoch: [15][100/149], lr: 0.00100	Time 0.507 (0.568)	Data 0.000 (0.018)	Loss 0.1761 (0.2177)	Loss CE 0.1128 (0.1523)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6325 (0.6540)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (95.483)
Sigma : Parameter containing:
tensor([3.7337], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0735], device='cuda:0', requires_grad=True)
2022-03-24 00:50:20.282879
Epoch: [16][0/149], lr: 0.00100	Time 3.119 (3.119)	Data 2.009 (2.009)	Loss 0.2118 (0.2118)	Loss CE 0.1491 (0.1491)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6263 (0.6263)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 00:51:15.158057
Epoch: [16][100/149], lr: 0.00100	Time 0.470 (0.574)	Data 0.000 (0.020)	Loss 0.1605 (0.2586)	Loss CE 0.0940 (0.1931)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6655 (0.6555)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (94.493)
Sigma : Parameter containing:
tensor([3.7035], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0642], device='cuda:0', requires_grad=True)
2022-03-24 00:51:45.180431
Epoch: [17][0/149], lr: 0.00100	Time 2.564 (2.564)	Data 1.754 (1.754)	Loss 0.5217 (0.5217)	Loss CE 0.4547 (0.4547)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6700 (0.6700)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-24 00:52:39.389285
Epoch: [17][100/149], lr: 0.00100	Time 0.698 (0.562)	Data 0.000 (0.018)	Loss 0.1125 (0.2094)	Loss CE 0.0489 (0.1441)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6357 (0.6533)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (96.225)
Sigma : Parameter containing:
tensor([3.7345], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0903], device='cuda:0', requires_grad=True)
2022-03-24 00:53:07.494158
Epoch: [18][0/149], lr: 0.00100	Time 2.905 (2.905)	Data 1.743 (1.743)	Loss 0.2199 (0.2199)	Loss CE 0.1523 (0.1523)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6764 (0.6764)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-24 00:53:55.474458
Epoch: [18][100/149], lr: 0.00100	Time 0.474 (0.504)	Data 0.000 (0.018)	Loss 0.1055 (0.1614)	Loss CE 0.0407 (0.0958)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6486 (0.6554)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (97.339)
Sigma : Parameter containing:
tensor([3.7776], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1169], device='cuda:0', requires_grad=True)
2022-03-24 00:54:21.789321
Epoch: [19][0/149], lr: 0.00100	Time 2.886 (2.886)	Data 2.008 (2.008)	Loss 0.2528 (0.2528)	Loss CE 0.1887 (0.1887)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6410 (0.6410)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-24 00:55:08.594156
Epoch: [19][100/149], lr: 0.00100	Time 0.424 (0.492)	Data 0.000 (0.020)	Loss 0.0895 (0.2212)	Loss CE 0.0269 (0.1560)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6262 (0.6519)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (95.266)
Sigma : Parameter containing:
tensor([3.7338], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0936], device='cuda:0', requires_grad=True)
2022-03-24 00:55:34.453469
Epoch: [20][0/149], lr: 0.00010	Time 2.867 (2.867)	Data 2.136 (2.136)	Loss 0.1553 (0.1553)	Loss CE 0.0903 (0.0903)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6500 (0.6500)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 00:56:21.042058
Epoch: [20][100/149], lr: 0.00010	Time 0.451 (0.490)	Data 0.000 (0.021)	Loss 0.1154 (0.1381)	Loss CE 0.0493 (0.0729)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6605 (0.6516)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (97.834)
Sigma : Parameter containing:
tensor([3.7402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0979], device='cuda:0', requires_grad=True)
2022-03-24 00:56:47.265226
Epoch: [21][0/149], lr: 0.00010	Time 2.676 (2.676)	Data 1.761 (1.761)	Loss 0.0679 (0.0679)	Loss CE 0.0057 (0.0057)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6220 (0.6220)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 00:57:36.123049
Epoch: [21][100/149], lr: 0.00010	Time 0.429 (0.510)	Data 0.000 (0.018)	Loss 0.0708 (0.1145)	Loss CE 0.0055 (0.0495)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6533 (0.6499)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (98.762)
Sigma : Parameter containing:
tensor([3.7463], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1017], device='cuda:0', requires_grad=True)
2022-03-24 00:58:02.836905
Epoch: [22][0/149], lr: 0.00010	Time 2.829 (2.829)	Data 2.357 (2.357)	Loss 0.0676 (0.0676)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6546 (0.6546)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 00:58:51.368782
Epoch: [22][100/149], lr: 0.00010	Time 0.450 (0.509)	Data 0.000 (0.024)	Loss 0.1278 (0.1040)	Loss CE 0.0604 (0.0393)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6735 (0.6470)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (98.855)
Sigma : Parameter containing:
tensor([3.7542], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1062], device='cuda:0', requires_grad=True)
2022-03-24 00:59:17.644201
Epoch: [23][0/149], lr: 0.00010	Time 2.492 (2.492)	Data 1.708 (1.708)	Loss 0.3723 (0.3723)	Loss CE 0.3057 (0.3057)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6660 (0.6660)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-24 01:00:06.167127
Epoch: [23][100/149], lr: 0.00010	Time 0.440 (0.505)	Data 0.000 (0.017)	Loss 0.0749 (0.1018)	Loss CE 0.0102 (0.0367)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6471 (0.6511)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.103)
Sigma : Parameter containing:
tensor([3.7602], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1098], device='cuda:0', requires_grad=True)
2022-03-24 01:00:33.061295
Epoch: [24][0/149], lr: 0.00010	Time 3.012 (3.012)	Data 1.942 (1.942)	Loss 0.1658 (0.1658)	Loss CE 0.0991 (0.0991)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6674 (0.6674)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 01:01:20.682377
Epoch: [24][100/149], lr: 0.00010	Time 0.397 (0.501)	Data 0.000 (0.020)	Loss 0.1838 (0.1028)	Loss CE 0.1208 (0.0381)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6293 (0.6477)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.072)
Sigma : Parameter containing:
tensor([3.7687], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 01:01:50.786592
Epoch: [25][0/149], lr: 0.00010	Time 2.857 (2.857)	Data 2.259 (2.259)	Loss 0.0682 (0.0682)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6472 (0.6472)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:02:44.356101
Epoch: [25][100/149], lr: 0.00010	Time 0.462 (0.559)	Data 0.000 (0.023)	Loss 0.1991 (0.1073)	Loss CE 0.1334 (0.0424)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6572 (0.6494)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.010)
Sigma : Parameter containing:
tensor([3.7741], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1182], device='cuda:0', requires_grad=True)
2022-03-24 01:03:14.291306
Epoch: [26][0/149], lr: 0.00010	Time 2.947 (2.947)	Data 2.108 (2.108)	Loss 0.0720 (0.0720)	Loss CE 0.0044 (0.0044)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6769 (0.6769)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:04:09.725272
Epoch: [26][100/149], lr: 0.00010	Time 0.667 (0.578)	Data 0.000 (0.021)	Loss 0.0694 (0.0915)	Loss CE 0.0062 (0.0266)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6311 (0.6490)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.226)
Sigma : Parameter containing:
tensor([3.7799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1219], device='cuda:0', requires_grad=True)
2022-03-24 01:04:39.753873
Epoch: [27][0/149], lr: 0.00010	Time 3.120 (3.120)	Data 2.218 (2.218)	Loss 0.1643 (0.1643)	Loss CE 0.0978 (0.0978)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6652 (0.6652)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 01:05:34.441115
Epoch: [27][100/149], lr: 0.00010	Time 0.586 (0.572)	Data 0.000 (0.022)	Loss 0.0732 (0.0912)	Loss CE 0.0118 (0.0265)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6145 (0.6468)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.288)
Sigma : Parameter containing:
tensor([3.7852], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1250], device='cuda:0', requires_grad=True)
2022-03-24 01:06:04.501335
Epoch: [28][0/149], lr: 0.00010	Time 2.700 (2.700)	Data 1.777 (1.777)	Loss 0.0673 (0.0673)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6628 (0.6628)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:06:59.053129
Epoch: [28][100/149], lr: 0.00010	Time 0.715 (0.567)	Data 0.000 (0.018)	Loss 0.0651 (0.0940)	Loss CE 0.0007 (0.0288)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6441 (0.6511)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.319)
Sigma : Parameter containing:
tensor([3.7904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1281], device='cuda:0', requires_grad=True)
2022-03-24 01:07:29.390493
Epoch: [29][0/149], lr: 0.00010	Time 2.785 (2.785)	Data 1.884 (1.884)	Loss 0.0682 (0.0682)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6575 (0.6575)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:08:24.807585
Epoch: [29][100/149], lr: 0.00010	Time 0.506 (0.576)	Data 0.000 (0.019)	Loss 0.0649 (0.0927)	Loss CE 0.0005 (0.0277)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6448 (0.6499)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.443)
Sigma : Parameter containing:
tensor([3.7955], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1309], device='cuda:0', requires_grad=True)
2022-03-24 01:08:54.805974
Epoch: [30][0/149], lr: 0.00001	Time 3.093 (3.093)	Data 2.230 (2.230)	Loss 0.0706 (0.0706)	Loss CE 0.0065 (0.0065)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6415 (0.6415)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:09:50.783877
Epoch: [30][100/149], lr: 0.00001	Time 0.499 (0.585)	Data 0.000 (0.022)	Loss 0.0923 (0.0931)	Loss CE 0.0283 (0.0284)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6405 (0.6471)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.257)
Sigma : Parameter containing:
tensor([3.7958], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1311], device='cuda:0', requires_grad=True)
2022-03-24 01:10:20.750543
Epoch: [31][0/149], lr: 0.00001	Time 3.188 (3.188)	Data 2.231 (2.231)	Loss 0.2734 (0.2734)	Loss CE 0.2103 (0.2103)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6309 (0.6309)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
2022-03-24 01:11:15.575895
Epoch: [31][100/149], lr: 0.00001	Time 0.411 (0.574)	Data 0.000 (0.022)	Loss 0.0664 (0.0950)	Loss CE 0.0046 (0.0304)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6185 (0.6464)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.226)
Sigma : Parameter containing:
tensor([3.7962], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1314], device='cuda:0', requires_grad=True)
2022-03-24 01:11:46.422740
Epoch: [32][0/149], lr: 0.00001	Time 2.890 (2.890)	Data 2.066 (2.066)	Loss 0.0676 (0.0676)	Loss CE 0.0050 (0.0050)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6257 (0.6257)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:12:41.514926
Epoch: [32][100/149], lr: 0.00001	Time 0.659 (0.574)	Data 0.000 (0.021)	Loss 0.0868 (0.0924)	Loss CE 0.0196 (0.0274)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6726 (0.6497)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.134)
Sigma : Parameter containing:
tensor([3.7967], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1317], device='cuda:0', requires_grad=True)
2022-03-24 01:13:11.278278
Epoch: [33][0/149], lr: 0.00001	Time 2.676 (2.676)	Data 1.737 (1.737)	Loss 0.0683 (0.0683)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6286 (0.6286)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:14:00.814566
Epoch: [33][100/149], lr: 0.00001	Time 0.521 (0.517)	Data 0.000 (0.017)	Loss 0.0702 (0.0936)	Loss CE 0.0085 (0.0289)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6164 (0.6469)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.288)
Sigma : Parameter containing:
tensor([3.7971], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1318], device='cuda:0', requires_grad=True)
2022-03-24 01:14:27.712157
Epoch: [34][0/149], lr: 0.00001	Time 3.022 (3.022)	Data 1.990 (1.990)	Loss 0.1062 (0.1062)	Loss CE 0.0395 (0.0395)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6674 (0.6674)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:15:14.749963
Epoch: [34][100/149], lr: 0.00001	Time 0.451 (0.496)	Data 0.000 (0.020)	Loss 0.0840 (0.0903)	Loss CE 0.0204 (0.0254)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6352 (0.6487)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.319)
Sigma : Parameter containing:
tensor([3.7975], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1321], device='cuda:0', requires_grad=True)
2022-03-24 01:15:40.454437
Epoch: [35][0/149], lr: 0.00001	Time 2.859 (2.859)	Data 2.049 (2.049)	Loss 0.0975 (0.0975)	Loss CE 0.0328 (0.0328)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6476 (0.6476)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:16:26.871676
Epoch: [35][100/149], lr: 0.00001	Time 0.440 (0.488)	Data 0.000 (0.021)	Loss 0.0704 (0.0895)	Loss CE 0.0013 (0.0251)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6913 (0.6442)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.381)
Sigma : Parameter containing:
tensor([3.7981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1324], device='cuda:0', requires_grad=True)
2022-03-24 01:16:52.984896
Epoch: [36][0/149], lr: 0.00001	Time 2.972 (2.972)	Data 2.399 (2.399)	Loss 0.0664 (0.0664)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6490 (0.6490)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:17:40.838518
Epoch: [36][100/149], lr: 0.00001	Time 0.468 (0.503)	Data 0.000 (0.024)	Loss 0.0726 (0.0934)	Loss CE 0.0047 (0.0286)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6791 (0.6480)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.350)
Sigma : Parameter containing:
tensor([3.7986], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1327], device='cuda:0', requires_grad=True)
2022-03-24 01:18:07.463490
Epoch: [37][0/149], lr: 0.00001	Time 2.786 (2.786)	Data 1.911 (1.911)	Loss 0.0696 (0.0696)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6374 (0.6374)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:18:55.745665
Epoch: [37][100/149], lr: 0.00001	Time 0.507 (0.506)	Data 0.000 (0.019)	Loss 0.0750 (0.0890)	Loss CE 0.0090 (0.0241)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6601 (0.6495)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.319)
Sigma : Parameter containing:
tensor([3.7992], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1330], device='cuda:0', requires_grad=True)
2022-03-24 01:19:22.462474
Epoch: [38][0/149], lr: 0.00001	Time 2.886 (2.886)	Data 2.295 (2.295)	Loss 0.0836 (0.0836)	Loss CE 0.0189 (0.0189)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6467 (0.6467)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:20:10.530952
Epoch: [38][100/149], lr: 0.00001	Time 0.481 (0.504)	Data 0.000 (0.023)	Loss 0.1229 (0.0889)	Loss CE 0.0587 (0.0241)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6421 (0.6486)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.505)
Sigma : Parameter containing:
tensor([3.7997], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1334], device='cuda:0', requires_grad=True)
2022-03-24 01:20:37.313592
Epoch: [39][0/149], lr: 0.00001	Time 3.051 (3.051)	Data 2.409 (2.409)	Loss 0.0719 (0.0719)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7084 (0.7084)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:21:23.952924
Epoch: [39][100/149], lr: 0.00001	Time 0.418 (0.492)	Data 0.000 (0.024)	Loss 0.0685 (0.0869)	Loss CE 0.0054 (0.0223)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6311 (0.6453)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.567)
Sigma : Parameter containing:
tensor([3.8003], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1337], device='cuda:0', requires_grad=True)
2022-03-24 01:21:51.710604
Epoch: [40][0/149], lr: 0.00001	Time 2.734 (2.734)	Data 1.938 (1.938)	Loss 0.0741 (0.0741)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6655 (0.6655)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:22:46.342406
Epoch: [40][100/149], lr: 0.00001	Time 0.397 (0.568)	Data 0.000 (0.019)	Loss 0.1094 (0.0883)	Loss CE 0.0431 (0.0235)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6626 (0.6478)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.412)
Sigma : Parameter containing:
tensor([3.8009], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1341], device='cuda:0', requires_grad=True)
2022-03-24 01:23:17.142843
Epoch: [41][0/149], lr: 0.00001	Time 3.268 (3.268)	Data 2.508 (2.508)	Loss 0.0724 (0.0724)	Loss CE 0.0053 (0.0053)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6709 (0.6709)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:24:13.472544
Epoch: [41][100/149], lr: 0.00001	Time 0.547 (0.590)	Data 0.000 (0.025)	Loss 0.0951 (0.0939)	Loss CE 0.0293 (0.0290)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6580 (0.6491)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.443)
Sigma : Parameter containing:
tensor([3.8013], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1343], device='cuda:0', requires_grad=True)
2022-03-24 01:24:43.645220
Epoch: [42][0/149], lr: 0.00001	Time 2.900 (2.900)	Data 1.712 (1.712)	Loss 0.0703 (0.0703)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6722 (0.6722)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:25:38.672729
Epoch: [42][100/149], lr: 0.00001	Time 0.614 (0.574)	Data 0.000 (0.017)	Loss 0.1383 (0.1011)	Loss CE 0.0722 (0.0363)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6611 (0.6477)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (99.072)
Sigma : Parameter containing:
tensor([3.8016], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1345], device='cuda:0', requires_grad=True)
2022-03-24 01:26:09.891960
Epoch: [43][0/149], lr: 0.00001	Time 3.188 (3.188)	Data 2.248 (2.248)	Loss 0.2409 (0.2409)	Loss CE 0.1757 (0.1757)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6518 (0.6518)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 01:27:06.259636
Epoch: [43][100/149], lr: 0.00001	Time 0.675 (0.590)	Data 0.000 (0.022)	Loss 0.0862 (0.0894)	Loss CE 0.0173 (0.0244)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6892 (0.6495)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.319)
Sigma : Parameter containing:
tensor([3.8020], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 01:27:35.455471
Epoch: [44][0/149], lr: 0.00001	Time 2.758 (2.758)	Data 1.696 (1.696)	Loss 0.2620 (0.2620)	Loss CE 0.1942 (0.1942)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6779 (0.6779)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
2022-03-24 01:28:30.141912
Epoch: [44][100/149], lr: 0.00001	Time 0.691 (0.569)	Data 0.000 (0.017)	Loss 0.0790 (0.0972)	Loss CE 0.0134 (0.0325)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6555 (0.6469)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.196)
Sigma : Parameter containing:
tensor([3.8022], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 01:28:59.709902
Epoch: [45][0/149], lr: 0.00001	Time 2.960 (2.960)	Data 2.226 (2.226)	Loss 0.1215 (0.1215)	Loss CE 0.0543 (0.0543)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6720 (0.6720)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 01:29:54.460702
Epoch: [45][100/149], lr: 0.00001	Time 0.407 (0.571)	Data 0.000 (0.022)	Loss 0.0650 (0.0887)	Loss CE 0.0025 (0.0238)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6258 (0.6484)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.288)
Sigma : Parameter containing:
tensor([3.8027], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 01:30:24.682576
Epoch: [46][0/149], lr: 0.00001	Time 2.804 (2.804)	Data 2.219 (2.219)	Loss 0.0680 (0.0680)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6704 (0.6704)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:31:18.724590
Epoch: [46][100/149], lr: 0.00001	Time 0.673 (0.563)	Data 0.000 (0.022)	Loss 0.0768 (0.0851)	Loss CE 0.0109 (0.0202)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6591 (0.6486)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.443)
Sigma : Parameter containing:
tensor([3.8032], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1354], device='cuda:0', requires_grad=True)
2022-03-24 01:31:48.964072
Epoch: [47][0/149], lr: 0.00001	Time 2.803 (2.803)	Data 1.720 (1.720)	Loss 0.0723 (0.0723)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6881 (0.6881)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
2022-03-24 01:32:43.860696
Epoch: [47][100/149], lr: 0.00001	Time 0.413 (0.571)	Data 0.000 (0.017)	Loss 0.0710 (0.0878)	Loss CE 0.0055 (0.0230)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6551 (0.6488)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.598)
Sigma : Parameter containing:
tensor([3.8037], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1357], device='cuda:0', requires_grad=True)
2022-03-24 01:33:14.923578
Epoch: [48][0/149], lr: 0.00001	Time 2.892 (2.892)	Data 2.160 (2.160)	Loss 0.1183 (0.1183)	Loss CE 0.0525 (0.0525)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6577 (0.6577)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 01:34:07.881697
Epoch: [48][100/149], lr: 0.00001	Time 0.497 (0.553)	Data 0.000 (0.022)	Loss 0.0636 (0.0862)	Loss CE 0.0024 (0.0215)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6123 (0.6464)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.474)
Sigma : Parameter containing:
tensor([3.8042], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1359], device='cuda:0', requires_grad=True)
2022-03-24 01:34:34.293682
Epoch: [49][0/149], lr: 0.00001	Time 2.922 (2.922)	Data 1.933 (1.933)	Loss 0.1197 (0.1197)	Loss CE 0.0533 (0.0533)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6642 (0.6642)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
2022-03-24 01:35:22.048431
Epoch: [49][100/149], lr: 0.00001	Time 0.518 (0.502)	Data 0.000 (0.019)	Loss 0.1108 (0.0850)	Loss CE 0.0446 (0.0202)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6616 (0.6473)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (99.474)
Sigma : Parameter containing:
tensor([3.8048], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1363], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
CosineLinear(input_features=512, output_features=153, sigma=tensor([3.8048]), eta=tensor([3.1363]))
Exemplar per class : 5
video number : 4778
video number + exemplar : 4778
Phase 4 : Class-balanced Fine-Tuning : SKIP
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_000.pth.tar
exemplar : 255
Computing the class mean vectors...
Eval Task 0 for Age 0
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.241 (5.241)	Prec@1 87.500 (87.500)
Test: [100/120]	Time 0.457 (0.528)	Prec@1 93.750 (82.611)
Testing Results: Prec@1 82.448
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (80.198)
Testing Results (NME): Prec@1 80.104
num_test_videos [1920]
Method : OURS
----AGE 1----
current_task  [17, 71]
current_head  53
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05049752469181039]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=159, sigma=tensor([3.8048]), eta=tensor([3.1363])
  (fc1): CosineLinear(input_features=512, output_features=153, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 169
video number + exemplar : 424
DataLoader Constructed : Train 13
Optimizer Constructed
video number : 169
video number + exemplar : 169
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 01:39:58.803947
Epoch: [0][0/13], lr: 0.00100	Time 3.303 (3.303)	Data 2.403 (2.403)	Loss 0.3547 (0.3547)	Loss CE 0.2255 (0.2255)	Loss KD (Logit) 1.0922 (1.0922)	Loss KD (GCAM) 0.0423 (0.0423)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6138 (0.6138)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8011], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1352], device='cuda:0', requires_grad=True)
2022-03-24 01:40:10.532064
Epoch: [1][0/13], lr: 0.00100	Time 3.214 (3.214)	Data 2.026 (2.026)	Loss 0.1690 (0.1690)	Loss CE 0.0239 (0.0239)	Loss KD (Logit) 1.1477 (1.1477)	Loss KD (GCAM) 0.0782 (0.0782)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6358 (0.6358)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8021], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1363], device='cuda:0', requires_grad=True)
2022-03-24 01:40:24.786843
Epoch: [2][0/13], lr: 0.00100	Time 3.297 (3.297)	Data 2.213 (2.213)	Loss 0.1931 (0.1931)	Loss CE 0.0470 (0.0470)	Loss KD (Logit) 1.1507 (1.1507)	Loss KD (GCAM) 0.0760 (0.0760)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6516 (0.6516)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8020], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 01:40:39.639532
Epoch: [3][0/13], lr: 0.00100	Time 3.440 (3.440)	Data 2.259 (2.259)	Loss 0.1599 (0.1599)	Loss CE 0.0121 (0.0121)	Loss KD (Logit) 1.1702 (1.1702)	Loss KD (GCAM) 0.0841 (0.0841)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6343 (0.6343)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8037], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1378], device='cuda:0', requires_grad=True)
2022-03-24 01:40:54.377961
Epoch: [4][0/13], lr: 0.00100	Time 3.405 (3.405)	Data 2.227 (2.227)	Loss 0.1587 (0.1587)	Loss CE 0.0068 (0.0068)	Loss KD (Logit) 1.1926 (1.1926)	Loss KD (GCAM) 0.0872 (0.0872)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6557 (0.6557)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8074], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1401], device='cuda:0', requires_grad=True)
2022-03-24 01:41:09.550365
Epoch: [5][0/13], lr: 0.00100	Time 3.664 (3.664)	Data 2.272 (2.272)	Loss 0.1834 (0.1834)	Loss CE 0.0344 (0.0344)	Loss KD (Logit) 1.1606 (1.1606)	Loss KD (GCAM) 0.0826 (0.0826)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6561 (0.6561)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8131], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1437], device='cuda:0', requires_grad=True)
2022-03-24 01:41:24.586686
Epoch: [6][0/13], lr: 0.00100	Time 3.527 (3.527)	Data 2.187 (2.187)	Loss 0.1643 (0.1643)	Loss CE 0.0143 (0.0143)	Loss KD (Logit) 1.1683 (1.1683)	Loss KD (GCAM) 0.0804 (0.0804)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6684 (0.6684)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8179], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1465], device='cuda:0', requires_grad=True)
2022-03-24 01:41:39.537959
Epoch: [7][0/13], lr: 0.00100	Time 3.437 (3.437)	Data 2.237 (2.237)	Loss 0.1482 (0.1482)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 1.1516 (1.1516)	Loss KD (GCAM) 0.0773 (0.0773)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6529 (0.6529)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1482], device='cuda:0', requires_grad=True)
2022-03-24 01:41:54.517752
Epoch: [8][0/13], lr: 0.00100	Time 3.328 (3.328)	Data 2.156 (2.156)	Loss 0.1684 (0.1684)	Loss CE 0.0217 (0.0217)	Loss KD (Logit) 1.1617 (1.1617)	Loss KD (GCAM) 0.0797 (0.0797)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6415 (0.6415)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8246], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1508], device='cuda:0', requires_grad=True)
2022-03-24 01:42:09.733797
Epoch: [9][0/13], lr: 0.00100	Time 3.385 (3.385)	Data 2.365 (2.365)	Loss 0.1493 (0.1493)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1762 (1.1762)	Loss KD (GCAM) 0.0721 (0.0721)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6795 (0.6795)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1532], device='cuda:0', requires_grad=True)
2022-03-24 01:42:24.801962
Epoch: [10][0/13], lr: 0.00100	Time 3.403 (3.403)	Data 2.080 (2.080)	Loss 0.1926 (0.1926)	Loss CE 0.0421 (0.0421)	Loss KD (Logit) 1.1693 (1.1693)	Loss KD (GCAM) 0.0823 (0.0823)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6684 (0.6684)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8297], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1539], device='cuda:0', requires_grad=True)
2022-03-24 01:42:39.860596
Epoch: [11][0/13], lr: 0.00100	Time 3.486 (3.486)	Data 2.509 (2.509)	Loss 0.1501 (0.1501)	Loss CE 0.0036 (0.0036)	Loss KD (Logit) 1.1678 (1.1678)	Loss KD (GCAM) 0.0834 (0.0834)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6245 (0.6245)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8287], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1535], device='cuda:0', requires_grad=True)
2022-03-24 01:42:54.966004
Epoch: [12][0/13], lr: 0.00100	Time 3.574 (3.574)	Data 2.473 (2.473)	Loss 0.1555 (0.1555)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 1.1842 (1.1842)	Loss KD (GCAM) 0.0792 (0.0792)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6984 (0.6984)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8267], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1520], device='cuda:0', requires_grad=True)
2022-03-24 01:43:09.950513
Epoch: [13][0/13], lr: 0.00100	Time 3.379 (3.379)	Data 2.466 (2.466)	Loss 0.1486 (0.1486)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 1.1713 (1.1713)	Loss KD (GCAM) 0.0819 (0.0819)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6419 (0.6419)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8271], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1521], device='cuda:0', requires_grad=True)
2022-03-24 01:43:24.868696
Epoch: [14][0/13], lr: 0.00100	Time 3.385 (3.385)	Data 2.061 (2.061)	Loss 0.1526 (0.1526)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 1.1724 (1.1724)	Loss KD (GCAM) 0.0862 (0.0862)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6495 (0.6495)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8281], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1529], device='cuda:0', requires_grad=True)
2022-03-24 01:43:39.916471
Epoch: [15][0/13], lr: 0.00100	Time 3.461 (3.461)	Data 2.283 (2.283)	Loss 0.1891 (0.1891)	Loss CE 0.0425 (0.0425)	Loss KD (Logit) 1.1552 (1.1552)	Loss KD (GCAM) 0.0854 (0.0854)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6266 (0.6266)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8281], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1530], device='cuda:0', requires_grad=True)
2022-03-24 01:43:55.147518
Epoch: [16][0/13], lr: 0.00100	Time 3.485 (3.485)	Data 2.007 (2.007)	Loss 0.1599 (0.1599)	Loss CE 0.0077 (0.0077)	Loss KD (Logit) 1.1870 (1.1870)	Loss KD (GCAM) 0.0872 (0.0872)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6615 (0.6615)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8293], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1538], device='cuda:0', requires_grad=True)
2022-03-24 01:44:10.223294
Epoch: [17][0/13], lr: 0.00100	Time 3.465 (3.465)	Data 1.918 (1.918)	Loss 0.1636 (0.1636)	Loss CE 0.0137 (0.0137)	Loss KD (Logit) 1.1884 (1.1884)	Loss KD (GCAM) 0.0908 (0.0908)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6257 (0.6257)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8322], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1551], device='cuda:0', requires_grad=True)
2022-03-24 01:44:25.086585
Epoch: [18][0/13], lr: 0.00100	Time 3.319 (3.319)	Data 1.900 (1.900)	Loss 0.1554 (0.1554)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 1.1892 (1.1892)	Loss KD (GCAM) 0.0903 (0.0903)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6574 (0.6574)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1574], device='cuda:0', requires_grad=True)
2022-03-24 01:44:40.385363
Epoch: [19][0/13], lr: 0.00100	Time 3.515 (3.515)	Data 2.572 (2.572)	Loss 0.1580 (0.1580)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 1.1732 (1.1732)	Loss KD (GCAM) 0.0851 (0.0851)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6626 (0.6626)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8373], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1572], device='cuda:0', requires_grad=True)
2022-03-24 01:44:55.407237
Epoch: [20][0/13], lr: 0.00010	Time 3.431 (3.431)	Data 2.511 (2.511)	Loss 0.1609 (0.1609)	Loss CE 0.0109 (0.0109)	Loss KD (Logit) 1.1873 (1.1873)	Loss KD (GCAM) 0.0836 (0.0836)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6491 (0.6491)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1570], device='cuda:0', requires_grad=True)
2022-03-24 01:45:10.694147
Epoch: [21][0/13], lr: 0.00010	Time 3.372 (3.372)	Data 2.487 (2.487)	Loss 0.1484 (0.1484)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 1.1872 (1.1872)	Loss KD (GCAM) 0.0858 (0.0858)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6063 (0.6063)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1570], device='cuda:0', requires_grad=True)
2022-03-24 01:45:25.446367
Epoch: [22][0/13], lr: 0.00010	Time 3.387 (3.387)	Data 1.973 (1.973)	Loss 0.1603 (0.1603)	Loss CE 0.0095 (0.0095)	Loss KD (Logit) 1.1807 (1.1807)	Loss KD (GCAM) 0.0858 (0.0858)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6543 (0.6543)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1569], device='cuda:0', requires_grad=True)
2022-03-24 01:45:40.334248
Sigma : Parameter containing:
tensor([3.8372], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1570], device='cuda:0', requires_grad=True)
2022-03-24 01:45:54.910846
Epoch: [24][0/13], lr: 0.00010	Time 3.019 (3.019)	Data 1.952 (1.952)	Loss 0.1735 (0.1735)	Loss CE 0.0231 (0.0231)	Loss KD (Logit) 1.1790 (1.1790)	Loss KD (GCAM) 0.0840 (0.0840)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6568 (0.6568)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8374], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1571], device='cuda:0', requires_grad=True)
2022-03-24 01:46:09.817769
Epoch: [25][0/13], lr: 0.00010	Time 3.254 (3.254)	Data 2.075 (2.075)	Loss 0.1494 (0.1494)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 1.1647 (1.1647)	Loss KD (GCAM) 0.0797 (0.0797)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6647 (0.6647)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8375], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1571], device='cuda:0', requires_grad=True)
2022-03-24 01:46:24.336097
Epoch: [26][0/13], lr: 0.00010	Time 3.176 (3.176)	Data 1.949 (1.949)	Loss 0.1482 (0.1482)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 1.1743 (1.1743)	Loss KD (GCAM) 0.0778 (0.0778)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6536 (0.6536)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8378], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1573], device='cuda:0', requires_grad=True)
2022-03-24 01:46:39.405221
Epoch: [27][0/13], lr: 0.00010	Time 3.682 (3.682)	Data 1.848 (1.848)	Loss 0.2016 (0.2016)	Loss CE 0.0476 (0.0476)	Loss KD (Logit) 1.1956 (1.1956)	Loss KD (GCAM) 0.0974 (0.0974)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6443 (0.6443)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8380], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1574], device='cuda:0', requires_grad=True)
2022-03-24 01:46:53.829592
Epoch: [28][0/13], lr: 0.00010	Time 3.056 (3.056)	Data 1.881 (1.881)	Loss 0.1435 (0.1435)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 1.1587 (1.1587)	Loss KD (GCAM) 0.0780 (0.0780)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6136 (0.6136)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8382], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1575], device='cuda:0', requires_grad=True)
2022-03-24 01:47:08.585842
Epoch: [29][0/13], lr: 0.00010	Time 3.416 (3.416)	Data 2.398 (2.398)	Loss 0.1545 (0.1545)	Loss CE 0.0061 (0.0061)	Loss KD (Logit) 1.1775 (1.1775)	Loss KD (GCAM) 0.0799 (0.0799)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6503 (0.6503)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8384], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:47:23.591602
Epoch: [30][0/13], lr: 0.00001	Time 3.349 (3.349)	Data 1.946 (1.946)	Loss 0.1522 (0.1522)	Loss CE 0.0063 (0.0063)	Loss KD (Logit) 1.1699 (1.1699)	Loss KD (GCAM) 0.0815 (0.0815)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6234 (0.6234)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:47:38.627088
Epoch: [31][0/13], lr: 0.00001	Time 3.324 (3.324)	Data 2.109 (2.109)	Loss 0.1493 (0.1493)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 1.1746 (1.1746)	Loss KD (GCAM) 0.0780 (0.0780)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6491 (0.6491)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:47:53.967695
Epoch: [32][0/13], lr: 0.00001	Time 3.584 (3.584)	Data 2.231 (2.231)	Loss 0.1665 (0.1665)	Loss CE 0.0220 (0.0220)	Loss KD (Logit) 1.1709 (1.1709)	Loss KD (GCAM) 0.0801 (0.0801)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6132 (0.6132)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:48:09.119743
Epoch: [33][0/13], lr: 0.00001	Time 3.508 (3.508)	Data 2.083 (2.083)	Loss 0.1455 (0.1455)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 1.1581 (1.1581)	Loss KD (GCAM) 0.0820 (0.0820)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6168 (0.6168)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:48:24.163336
Epoch: [34][0/13], lr: 0.00001	Time 3.404 (3.404)	Data 2.309 (2.309)	Loss 0.1442 (0.1442)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 1.1570 (1.1570)	Loss KD (GCAM) 0.0809 (0.0809)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6131 (0.6131)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:48:39.220492
Epoch: [35][0/13], lr: 0.00001	Time 3.519 (3.519)	Data 2.221 (2.221)	Loss 0.1489 (0.1489)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 1.1340 (1.1340)	Loss KD (GCAM) 0.0759 (0.0759)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6845 (0.6845)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:48:54.317697
Epoch: [36][0/13], lr: 0.00001	Time 3.610 (3.610)	Data 2.515 (2.515)	Loss 0.1596 (0.1596)	Loss CE 0.0094 (0.0094)	Loss KD (Logit) 1.1610 (1.1610)	Loss KD (GCAM) 0.0770 (0.0770)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6855 (0.6855)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:49:09.045487
Epoch: [37][0/13], lr: 0.00001	Time 3.214 (3.214)	Data 2.542 (2.542)	Loss 0.1442 (0.1442)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1610 (1.1610)	Loss KD (GCAM) 0.0859 (0.0859)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5945 (0.5945)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1576], device='cuda:0', requires_grad=True)
2022-03-24 01:49:22.677807
Epoch: [38][0/13], lr: 0.00001	Time 3.299 (3.299)	Data 2.091 (2.091)	Loss 0.1460 (0.1460)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 1.1618 (1.1618)	Loss KD (GCAM) 0.0790 (0.0790)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6306 (0.6306)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:49:35.799720
Epoch: [39][0/13], lr: 0.00001	Time 3.256 (3.256)	Data 1.984 (1.984)	Loss 0.1494 (0.1494)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 1.1615 (1.1615)	Loss KD (GCAM) 0.0760 (0.0760)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6706 (0.6706)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:49:49.009068
Epoch: [40][0/13], lr: 0.00001	Time 3.122 (3.122)	Data 2.236 (2.236)	Loss 0.1473 (0.1473)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 1.1694 (1.1694)	Loss KD (GCAM) 0.0833 (0.0833)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6133 (0.6133)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:50:02.492564
Epoch: [41][0/13], lr: 0.00001	Time 3.397 (3.397)	Data 2.580 (2.580)	Loss 0.1486 (0.1486)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 1.1705 (1.1705)	Loss KD (GCAM) 0.0746 (0.0746)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6648 (0.6648)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8385], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:50:15.220431
Epoch: [42][0/13], lr: 0.00001	Time 3.195 (3.195)	Data 2.014 (2.014)	Loss 0.1482 (0.1482)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 1.1779 (1.1779)	Loss KD (GCAM) 0.0750 (0.0750)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6558 (0.6558)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:50:28.017599
Epoch: [43][0/13], lr: 0.00001	Time 3.352 (3.352)	Data 2.267 (2.267)	Loss 0.1495 (0.1495)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 1.1751 (1.1751)	Loss KD (GCAM) 0.0792 (0.0792)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6627 (0.6627)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:50:40.683358
Epoch: [44][0/13], lr: 0.00001	Time 3.291 (3.291)	Data 2.147 (2.147)	Loss 0.1446 (0.1446)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 1.1693 (1.1693)	Loss KD (GCAM) 0.0790 (0.0790)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6113 (0.6113)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:50:53.329699
Epoch: [45][0/13], lr: 0.00001	Time 3.175 (3.175)	Data 1.889 (1.889)	Loss 0.1530 (0.1530)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 1.1583 (1.1583)	Loss KD (GCAM) 0.0775 (0.0775)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6425 (0.6425)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:51:05.888843
Epoch: [46][0/13], lr: 0.00001	Time 3.232 (3.232)	Data 2.440 (2.440)	Loss 0.1477 (0.1477)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 1.1678 (1.1678)	Loss KD (GCAM) 0.0759 (0.0759)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6485 (0.6485)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:51:18.241903
Epoch: [47][0/13], lr: 0.00001	Time 3.111 (3.111)	Data 2.223 (2.223)	Loss 0.1486 (0.1486)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 1.1706 (1.1706)	Loss KD (GCAM) 0.0836 (0.0836)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6407 (0.6407)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:51:30.715462
Epoch: [48][0/13], lr: 0.00001	Time 3.228 (3.228)	Data 2.426 (2.426)	Loss 0.1491 (0.1491)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 1.1744 (1.1744)	Loss KD (GCAM) 0.0789 (0.0789)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6482 (0.6482)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
2022-03-24 01:51:43.716931
Epoch: [49][0/13], lr: 0.00001	Time 3.278 (3.278)	Data 2.505 (2.505)	Loss 0.1484 (0.1484)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 1.1595 (1.1595)	Loss KD (GCAM) 0.0804 (0.0804)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6550 (0.6550)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1577], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=159, sigma=tensor([3.8386]), eta=tensor([3.1577])
  (fc1): CosineLinear(input_features=512, output_features=153, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 169
video number + exemplar : 169
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=159, sigma=tensor([3.8386]), eta=tensor([3.1577])
  (fc1): CosineLinear(input_features=512, output_features=153, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 265
DataLoader CBF Constructed : Train 8
Optimizer Constructed
2022-03-24 01:52:08.442101
Epoch: [0][0/8], lr: 0.00050	Time 2.737 (2.737)	Data 1.908 (1.908)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8389], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1578], device='cuda:0', requires_grad=True)
2022-03-24 01:52:15.134688
Epoch: [1][0/8], lr: 0.00050	Time 2.891 (2.891)	Data 2.406 (2.406)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8394], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1580], device='cuda:0', requires_grad=True)
2022-03-24 01:52:21.665630
Epoch: [2][0/8], lr: 0.00050	Time 2.854 (2.854)	Data 2.209 (2.209)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8399], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1582], device='cuda:0', requires_grad=True)
2022-03-24 01:52:28.276510
Epoch: [3][0/8], lr: 0.00050	Time 2.838 (2.838)	Data 2.293 (2.293)	Loss 0.0086 (0.0086)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8409], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1586], device='cuda:0', requires_grad=True)
2022-03-24 01:52:34.996315
Epoch: [4][0/8], lr: 0.00050	Time 2.910 (2.910)	Data 1.966 (1.966)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1587], device='cuda:0', requires_grad=True)
2022-03-24 01:52:41.579861
Epoch: [5][0/8], lr: 0.00050	Time 2.770 (2.770)	Data 2.112 (2.112)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8417], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1587], device='cuda:0', requires_grad=True)
2022-03-24 01:52:48.186774
Epoch: [6][0/8], lr: 0.00050	Time 2.856 (2.856)	Data 1.987 (1.987)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8420], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1586], device='cuda:0', requires_grad=True)
2022-03-24 01:52:54.681480
Epoch: [7][0/8], lr: 0.00050	Time 2.780 (2.780)	Data 1.934 (1.934)	Loss 0.0171 (0.0171)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8427], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1588], device='cuda:0', requires_grad=True)
2022-03-24 01:53:01.403243
Epoch: [8][0/8], lr: 0.00050	Time 3.003 (3.003)	Data 2.183 (2.183)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8431], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1589], device='cuda:0', requires_grad=True)
2022-03-24 01:53:08.083398
Epoch: [9][0/8], lr: 0.00050	Time 3.019 (3.019)	Data 2.265 (2.265)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8439], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1593], device='cuda:0', requires_grad=True)
2022-03-24 01:53:14.645393
Epoch: [10][0/8], lr: 0.00050	Time 2.810 (2.810)	Data 1.985 (1.985)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8446], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1595], device='cuda:0', requires_grad=True)
2022-03-24 01:53:21.301874
Epoch: [11][0/8], lr: 0.00050	Time 2.926 (2.926)	Data 2.459 (2.459)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8452], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1597], device='cuda:0', requires_grad=True)
2022-03-24 01:53:27.879412
Epoch: [12][0/8], lr: 0.00050	Time 2.831 (2.831)	Data 2.316 (2.316)	Loss 0.0052 (0.0052)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8460], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1600], device='cuda:0', requires_grad=True)
2022-03-24 01:53:34.508775
Epoch: [13][0/8], lr: 0.00050	Time 2.842 (2.842)	Data 2.236 (2.236)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8467], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1603], device='cuda:0', requires_grad=True)
2022-03-24 01:53:40.834820
Epoch: [14][0/8], lr: 0.00050	Time 2.721 (2.721)	Data 2.007 (2.007)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8476], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1607], device='cuda:0', requires_grad=True)
2022-03-24 01:53:47.441681
Epoch: [15][0/8], lr: 0.00050	Time 2.901 (2.901)	Data 2.027 (2.027)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1609], device='cuda:0', requires_grad=True)
2022-03-24 01:53:54.034888
Epoch: [16][0/8], lr: 0.00050	Time 2.798 (2.798)	Data 1.872 (1.872)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8486], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1610], device='cuda:0', requires_grad=True)
2022-03-24 01:54:00.569115
Epoch: [17][0/8], lr: 0.00050	Time 2.803 (2.803)	Data 1.944 (1.944)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8491], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1611], device='cuda:0', requires_grad=True)
2022-03-24 01:54:07.162502
Epoch: [18][0/8], lr: 0.00050	Time 2.863 (2.863)	Data 2.276 (2.276)	Loss 0.0404 (0.0404)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8490], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1612], device='cuda:0', requires_grad=True)
2022-03-24 01:54:13.607893
Epoch: [19][0/8], lr: 0.00050	Time 2.787 (2.787)	Data 1.949 (1.949)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8493], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1612], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_001.pth.tar
exemplar : 265
Computing the class mean vectors...
Eval Task 0 for Age 1
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.050 (5.050)	Prec@1 75.000 (75.000)
Test: [100/120]	Time 0.508 (0.545)	Prec@1 81.250 (77.475)
Testing Results: Prec@1 77.812
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (79.455)
Testing Results (NME): Prec@1 79.323
Eval Task 1 for Age 1
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.334 (4.334)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 88.060
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 77.612
num_test_videos [1920, 67]
Method : OURS
----AGE 2----
current_task  [96, 64]
current_head  55
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.051478150704935006]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=165, sigma=tensor([3.8493]), eta=tensor([3.1612])
  (fc1): CosineLinear(input_features=512, output_features=159, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 194
video number + exemplar : 459
DataLoader Constructed : Train 14
Optimizer Constructed
video number : 194
video number + exemplar : 194
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 01:56:53.361446
Epoch: [0][0/14], lr: 0.00100	Time 3.945 (3.945)	Data 2.478 (2.478)	Loss 0.1330 (0.1330)	Loss CE 0.0219 (0.0219)	Loss KD (Logit) 0.6483 (0.6483)	Loss KD (GCAM) 0.0299 (0.0299)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6872 (0.6872)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8357], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1533], device='cuda:0', requires_grad=True)
2022-03-24 01:57:08.851633
Epoch: [1][0/14], lr: 0.00100	Time 3.251 (3.251)	Data 2.346 (2.346)	Loss 0.1183 (0.1183)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.6856 (0.6856)	Loss KD (GCAM) 0.0454 (0.0454)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6853 (0.6853)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8274], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1485], device='cuda:0', requires_grad=True)
2022-03-24 01:57:24.678004
Epoch: [2][0/14], lr: 0.00100	Time 3.357 (3.357)	Data 2.039 (2.039)	Loss 0.1460 (0.1460)	Loss CE 0.0249 (0.0249)	Loss KD (Logit) 0.6866 (0.6866)	Loss KD (GCAM) 0.0484 (0.0484)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7128 (0.7128)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8247], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1469], device='cuda:0', requires_grad=True)
2022-03-24 01:57:40.609438
Epoch: [3][0/14], lr: 0.00100	Time 3.513 (3.513)	Data 2.472 (2.472)	Loss 0.1496 (0.1496)	Loss CE 0.0356 (0.0356)	Loss KD (Logit) 0.6819 (0.6819)	Loss KD (GCAM) 0.0529 (0.0529)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6301 (0.6301)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8274], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1485], device='cuda:0', requires_grad=True)
2022-03-24 01:57:56.775760
Epoch: [4][0/14], lr: 0.00100	Time 3.682 (3.682)	Data 2.796 (2.796)	Loss 0.1190 (0.1190)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.6656 (0.6656)	Loss KD (GCAM) 0.0508 (0.0508)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6523 (0.6523)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8295], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 01:58:13.079189
Epoch: [5][0/14], lr: 0.00100	Time 3.685 (3.685)	Data 2.463 (2.463)	Loss 0.1210 (0.1210)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.6763 (0.6763)	Loss KD (GCAM) 0.0531 (0.0531)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6883 (0.6883)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8314], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1507], device='cuda:0', requires_grad=True)
2022-03-24 01:58:29.080296
Epoch: [6][0/14], lr: 0.00100	Time 3.408 (3.408)	Data 1.885 (1.885)	Loss 0.1162 (0.1162)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.6535 (0.6535)	Loss KD (GCAM) 0.0569 (0.0569)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6447 (0.6447)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8259], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1475], device='cuda:0', requires_grad=True)
2022-03-24 01:58:44.847055
Epoch: [7][0/14], lr: 0.00100	Time 3.521 (3.521)	Data 2.033 (2.033)	Loss 0.1625 (0.1625)	Loss CE 0.0479 (0.0479)	Loss KD (Logit) 0.6804 (0.6804)	Loss KD (GCAM) 0.0581 (0.0581)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6214 (0.6214)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8251], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1468], device='cuda:0', requires_grad=True)
2022-03-24 01:59:00.482642
Epoch: [8][0/14], lr: 0.00100	Time 3.249 (3.249)	Data 2.286 (2.286)	Loss 0.1159 (0.1159)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.6639 (0.6639)	Loss KD (GCAM) 0.0531 (0.0531)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6553 (0.6553)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8250], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1465], device='cuda:0', requires_grad=True)
2022-03-24 01:59:16.420834
Epoch: [9][0/14], lr: 0.00100	Time 3.503 (3.503)	Data 2.470 (2.470)	Loss 0.1179 (0.1179)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.6767 (0.6767)	Loss KD (GCAM) 0.0511 (0.0511)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6586 (0.6586)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8238], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1457], device='cuda:0', requires_grad=True)
2022-03-24 01:59:32.074869
Epoch: [10][0/14], lr: 0.00100	Time 3.304 (3.304)	Data 1.965 (1.965)	Loss 0.1175 (0.1175)	Loss CE 0.0082 (0.0082)	Loss KD (Logit) 0.6502 (0.6502)	Loss KD (GCAM) 0.0489 (0.0489)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6125 (0.6125)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8256], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1466], device='cuda:0', requires_grad=True)
2022-03-24 01:59:47.813180
Epoch: [11][0/14], lr: 0.00100	Time 3.322 (3.322)	Data 2.206 (2.206)	Loss 0.1191 (0.1191)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.6787 (0.6787)	Loss KD (GCAM) 0.0473 (0.0473)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6828 (0.6828)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8250], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1458], device='cuda:0', requires_grad=True)
2022-03-24 02:00:03.821469
Epoch: [12][0/14], lr: 0.00100	Time 3.627 (3.627)	Data 2.601 (2.601)	Loss 0.1155 (0.1155)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6618 (0.6618)	Loss KD (GCAM) 0.0555 (0.0555)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6384 (0.6384)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8263], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1462], device='cuda:0', requires_grad=True)
2022-03-24 02:00:19.973695
Epoch: [13][0/14], lr: 0.00100	Time 3.377 (3.377)	Data 2.188 (2.188)	Loss 0.1569 (0.1569)	Loss CE 0.0421 (0.0421)	Loss KD (Logit) 0.6470 (0.6470)	Loss KD (GCAM) 0.0446 (0.0446)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6812 (0.6812)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8277], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1471], device='cuda:0', requires_grad=True)
2022-03-24 02:00:36.005786
Epoch: [14][0/14], lr: 0.00100	Time 3.367 (3.367)	Data 2.374 (2.374)	Loss 0.1194 (0.1194)	Loss CE 0.0061 (0.0061)	Loss KD (Logit) 0.6821 (0.6821)	Loss KD (GCAM) 0.0463 (0.0463)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6428 (0.6428)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8304], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1486], device='cuda:0', requires_grad=True)
2022-03-24 02:00:51.967383
Epoch: [15][0/14], lr: 0.00100	Time 3.510 (3.510)	Data 2.346 (2.346)	Loss 0.1186 (0.1186)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.6622 (0.6622)	Loss KD (GCAM) 0.0497 (0.0497)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6542 (0.6542)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8326], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1497], device='cuda:0', requires_grad=True)
2022-03-24 02:01:07.863068
Epoch: [16][0/14], lr: 0.00100	Time 3.271 (3.271)	Data 2.411 (2.411)	Loss 0.1203 (0.1203)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.6741 (0.6741)	Loss KD (GCAM) 0.0495 (0.0495)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6816 (0.6816)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8332], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1501], device='cuda:0', requires_grad=True)
2022-03-24 02:01:23.560970
Epoch: [17][0/14], lr: 0.00100	Time 3.345 (3.345)	Data 2.192 (2.192)	Loss 0.1138 (0.1138)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.6544 (0.6544)	Loss KD (GCAM) 0.0442 (0.0442)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6265 (0.6265)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8332], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1497], device='cuda:0', requires_grad=True)
2022-03-24 02:01:39.322994
Epoch: [18][0/14], lr: 0.00100	Time 3.505 (3.505)	Data 2.212 (2.212)	Loss 0.1144 (0.1144)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.6557 (0.6557)	Loss KD (GCAM) 0.0516 (0.0516)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6431 (0.6431)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8347], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1504], device='cuda:0', requires_grad=True)
2022-03-24 02:01:55.004289
Epoch: [19][0/14], lr: 0.00100	Time 3.246 (3.246)	Data 1.976 (1.976)	Loss 0.1114 (0.1114)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6498 (0.6498)	Loss KD (GCAM) 0.0466 (0.0466)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6307 (0.6307)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8363], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:02:11.008788
Epoch: [20][0/14], lr: 0.00010	Time 3.582 (3.582)	Data 2.366 (2.366)	Loss 0.1178 (0.1178)	Loss CE 0.0054 (0.0054)	Loss KD (Logit) 0.6387 (0.6387)	Loss KD (GCAM) 0.0451 (0.0451)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6596 (0.6596)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8364], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:02:26.817927
Epoch: [21][0/14], lr: 0.00010	Time 3.264 (3.264)	Data 2.134 (2.134)	Loss 0.1168 (0.1168)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.6556 (0.6556)	Loss KD (GCAM) 0.0468 (0.0468)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6882 (0.6882)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8364], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:02:42.725402
Epoch: [22][0/14], lr: 0.00010	Time 3.493 (3.493)	Data 2.080 (2.080)	Loss 0.1163 (0.1163)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.6737 (0.6737)	Loss KD (GCAM) 0.0430 (0.0430)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6648 (0.6648)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8365], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:02:58.946730
Epoch: [23][0/14], lr: 0.00010	Time 3.613 (3.613)	Data 2.463 (2.463)	Loss 0.1131 (0.1131)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6430 (0.6430)	Loss KD (GCAM) 0.0468 (0.0468)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6563 (0.6563)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8366], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:03:14.803784
Epoch: [24][0/14], lr: 0.00010	Time 3.215 (3.215)	Data 1.926 (1.926)	Loss 0.1133 (0.1133)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.6510 (0.6510)	Loss KD (GCAM) 0.0419 (0.0419)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6354 (0.6354)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8366], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:03:29.991674
Epoch: [25][0/14], lr: 0.00010	Time 3.330 (3.330)	Data 2.349 (2.349)	Loss 0.1107 (0.1107)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6399 (0.6399)	Loss KD (GCAM) 0.0451 (0.0451)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6392 (0.6392)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8366], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:03:44.146385
Epoch: [26][0/14], lr: 0.00010	Time 3.246 (3.246)	Data 1.834 (1.834)	Loss 0.1206 (0.1206)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6505 (0.6505)	Loss KD (GCAM) 0.0486 (0.0486)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7164 (0.7164)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8367], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:03:58.490031
Epoch: [27][0/14], lr: 0.00010	Time 3.169 (3.169)	Data 2.371 (2.371)	Loss 0.1148 (0.1148)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.6926 (0.6926)	Loss KD (GCAM) 0.0424 (0.0424)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6623 (0.6623)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:04:12.740867
Epoch: [28][0/14], lr: 0.00010	Time 3.214 (3.214)	Data 2.078 (2.078)	Loss 0.1105 (0.1105)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.6444 (0.6444)	Loss KD (GCAM) 0.0483 (0.0483)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6229 (0.6229)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:04:26.141191
Epoch: [29][0/14], lr: 0.00010	Time 3.350 (3.350)	Data 2.486 (2.486)	Loss 0.1141 (0.1141)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.6374 (0.6374)	Loss KD (GCAM) 0.0451 (0.0451)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6754 (0.6754)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:04:39.572398
Epoch: [30][0/14], lr: 0.00001	Time 3.359 (3.359)	Data 2.331 (2.331)	Loss 0.1149 (0.1149)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.6483 (0.6483)	Loss KD (GCAM) 0.0409 (0.0409)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6675 (0.6675)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8367], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:04:53.291989
Epoch: [31][0/14], lr: 0.00001	Time 3.500 (3.500)	Data 2.432 (2.432)	Loss 0.1137 (0.1137)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.6394 (0.6394)	Loss KD (GCAM) 0.0480 (0.0480)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6460 (0.6460)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:05:06.747555
Epoch: [32][0/14], lr: 0.00001	Time 3.158 (3.158)	Data 1.951 (1.951)	Loss 0.1120 (0.1120)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.6383 (0.6383)	Loss KD (GCAM) 0.0415 (0.0415)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6588 (0.6588)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:05:20.129323
Epoch: [33][0/14], lr: 0.00001	Time 3.400 (3.400)	Data 2.386 (2.386)	Loss 0.1106 (0.1106)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6382 (0.6382)	Loss KD (GCAM) 0.0465 (0.0465)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6351 (0.6351)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:05:33.331858
Epoch: [34][0/14], lr: 0.00001	Time 3.168 (3.168)	Data 2.334 (2.334)	Loss 0.1142 (0.1142)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6348 (0.6348)	Loss KD (GCAM) 0.0467 (0.0467)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6664 (0.6664)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:05:46.942401
Epoch: [35][0/14], lr: 0.00001	Time 3.487 (3.487)	Data 2.628 (2.628)	Loss 0.1123 (0.1123)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6470 (0.6470)	Loss KD (GCAM) 0.0470 (0.0470)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6463 (0.6463)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:06:00.551859
Epoch: [36][0/14], lr: 0.00001	Time 3.104 (3.104)	Data 2.008 (2.008)	Loss 0.1146 (0.1146)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.6431 (0.6431)	Loss KD (GCAM) 0.0510 (0.0510)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6539 (0.6539)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:06:14.415589
Epoch: [37][0/14], lr: 0.00001	Time 3.505 (3.505)	Data 2.561 (2.561)	Loss 0.1111 (0.1111)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6365 (0.6365)	Loss KD (GCAM) 0.0450 (0.0450)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6460 (0.6460)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:06:27.903237
Epoch: [38][0/14], lr: 0.00001	Time 3.268 (3.268)	Data 2.005 (2.005)	Loss 0.1171 (0.1171)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.6557 (0.6557)	Loss KD (GCAM) 0.0466 (0.0466)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6830 (0.6830)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:06:41.446094
Epoch: [39][0/14], lr: 0.00001	Time 3.184 (3.184)	Data 2.272 (2.272)	Loss 0.1155 (0.1155)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.6413 (0.6413)	Loss KD (GCAM) 0.0421 (0.0421)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6981 (0.6981)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:06:55.048120
Epoch: [40][0/14], lr: 0.00001	Time 3.190 (3.190)	Data 2.495 (2.495)	Loss 0.1136 (0.1136)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6531 (0.6531)	Loss KD (GCAM) 0.0422 (0.0422)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6645 (0.6645)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:07:08.401648
Epoch: [41][0/14], lr: 0.00001	Time 3.076 (3.076)	Data 2.360 (2.360)	Loss 0.1077 (0.1077)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.6435 (0.6435)	Loss KD (GCAM) 0.0407 (0.0407)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6220 (0.6220)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:07:22.157451
Epoch: [42][0/14], lr: 0.00001	Time 3.506 (3.506)	Data 2.653 (2.653)	Loss 0.1117 (0.1117)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.6377 (0.6377)	Loss KD (GCAM) 0.0450 (0.0450)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6303 (0.6303)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:07:35.658305
Epoch: [43][0/14], lr: 0.00001	Time 3.179 (3.179)	Data 1.886 (1.886)	Loss 0.1139 (0.1139)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.6369 (0.6369)	Loss KD (GCAM) 0.0455 (0.0455)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6737 (0.6737)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:07:49.160209
Epoch: [44][0/14], lr: 0.00001	Time 3.133 (3.133)	Data 2.320 (2.320)	Loss 0.1101 (0.1101)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.6723 (0.6723)	Loss KD (GCAM) 0.0438 (0.0438)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6226 (0.6226)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:08:03.021279
Epoch: [45][0/14], lr: 0.00001	Time 3.344 (3.344)	Data 2.531 (2.531)	Loss 0.1157 (0.1157)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.6473 (0.6473)	Loss KD (GCAM) 0.0440 (0.0440)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6494 (0.6494)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:08:16.653601
Epoch: [46][0/14], lr: 0.00001	Time 3.256 (3.256)	Data 2.183 (2.183)	Loss 0.1123 (0.1123)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6525 (0.6525)	Loss KD (GCAM) 0.0470 (0.0470)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6362 (0.6362)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:08:29.971447
Epoch: [47][0/14], lr: 0.00001	Time 3.073 (3.073)	Data 1.811 (1.811)	Loss 0.1123 (0.1123)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.6550 (0.6550)	Loss KD (GCAM) 0.0433 (0.0433)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6414 (0.6414)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:08:43.577856
Epoch: [48][0/14], lr: 0.00001	Time 3.310 (3.310)	Data 2.146 (2.146)	Loss 0.1117 (0.1117)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.6500 (0.6500)	Loss KD (GCAM) 0.0420 (0.0420)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6517 (0.6517)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 02:08:56.572866
Epoch: [49][0/14], lr: 0.00001	Time 3.287 (3.287)	Data 2.553 (2.553)	Loss 0.1099 (0.1099)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.6446 (0.6446)	Loss KD (GCAM) 0.0436 (0.0436)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6324 (0.6324)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=165, sigma=tensor([3.8368]), eta=tensor([3.1511])
  (fc1): CosineLinear(input_features=512, output_features=159, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 194
video number + exemplar : 194
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=165, sigma=tensor([3.8368]), eta=tensor([3.1511])
  (fc1): CosineLinear(input_features=512, output_features=159, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 275
DataLoader CBF Constructed : Train 8
Optimizer Constructed
2022-03-24 02:09:26.354808
Epoch: [0][0/8], lr: 0.00050	Time 2.957 (2.957)	Data 2.250 (2.250)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1512], device='cuda:0', requires_grad=True)
2022-03-24 02:09:33.509303
Epoch: [1][0/8], lr: 0.00050	Time 2.850 (2.850)	Data 2.403 (2.403)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8374], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1513], device='cuda:0', requires_grad=True)
2022-03-24 02:09:40.947265
Epoch: [2][0/8], lr: 0.00050	Time 2.988 (2.988)	Data 2.273 (2.273)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1509], device='cuda:0', requires_grad=True)
2022-03-24 02:09:48.036342
Epoch: [3][0/8], lr: 0.00050	Time 2.806 (2.806)	Data 2.178 (2.178)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8370], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1506], device='cuda:0', requires_grad=True)
2022-03-24 02:09:55.521376
Epoch: [4][0/8], lr: 0.00050	Time 2.984 (2.984)	Data 1.815 (1.815)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8373], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1506], device='cuda:0', requires_grad=True)
2022-03-24 02:10:02.410437
Epoch: [5][0/8], lr: 0.00050	Time 2.913 (2.913)	Data 1.867 (1.867)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8378], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1508], device='cuda:0', requires_grad=True)
2022-03-24 02:10:09.556619
Epoch: [6][0/8], lr: 0.00050	Time 2.835 (2.835)	Data 1.999 (1.999)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8383], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1509], device='cuda:0', requires_grad=True)
2022-03-24 02:10:17.020692
Epoch: [7][0/8], lr: 0.00050	Time 3.005 (3.005)	Data 1.934 (1.934)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8387], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 02:10:24.109866
Epoch: [8][0/8], lr: 0.00050	Time 2.799 (2.799)	Data 2.156 (2.156)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8393], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1512], device='cuda:0', requires_grad=True)
2022-03-24 02:10:31.659782
Epoch: [9][0/8], lr: 0.00050	Time 3.022 (3.022)	Data 2.306 (2.306)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8398], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1514], device='cuda:0', requires_grad=True)
2022-03-24 02:10:38.767661
Epoch: [10][0/8], lr: 0.00050	Time 2.841 (2.841)	Data 2.167 (2.167)	Loss 0.0029 (0.0029)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8401], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1515], device='cuda:0', requires_grad=True)
2022-03-24 02:10:46.188142
Epoch: [11][0/8], lr: 0.00050	Time 2.969 (2.969)	Data 2.229 (2.229)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1514], device='cuda:0', requires_grad=True)
2022-03-24 02:10:53.310869
Epoch: [12][0/8], lr: 0.00050	Time 2.836 (2.836)	Data 2.175 (2.175)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8404], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1513], device='cuda:0', requires_grad=True)
2022-03-24 02:11:00.814887
Epoch: [13][0/8], lr: 0.00050	Time 3.138 (3.138)	Data 2.363 (2.363)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8406], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1513], device='cuda:0', requires_grad=True)
2022-03-24 02:11:07.980163
Epoch: [14][0/8], lr: 0.00050	Time 2.772 (2.772)	Data 2.065 (2.065)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1515], device='cuda:0', requires_grad=True)
2022-03-24 02:11:15.420010
Epoch: [15][0/8], lr: 0.00050	Time 3.012 (3.012)	Data 2.235 (2.235)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1518], device='cuda:0', requires_grad=True)
2022-03-24 02:11:22.550706
Epoch: [16][0/8], lr: 0.00050	Time 2.783 (2.783)	Data 2.020 (2.020)	Loss 0.0032 (0.0032)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8421], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1519], device='cuda:0', requires_grad=True)
2022-03-24 02:11:29.964497
Epoch: [17][0/8], lr: 0.00050	Time 3.051 (3.051)	Data 2.185 (2.185)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8423], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1519], device='cuda:0', requires_grad=True)
2022-03-24 02:11:37.044594
Epoch: [18][0/8], lr: 0.00050	Time 2.943 (2.943)	Data 2.055 (2.055)	Loss 0.0168 (0.0168)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8427], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1521], device='cuda:0', requires_grad=True)
2022-03-24 02:11:44.546825
Epoch: [19][0/8], lr: 0.00050	Time 3.258 (3.258)	Data 2.395 (2.395)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8433], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1523], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_002.pth.tar
exemplar : 275
Computing the class mean vectors...
Eval Task 0 for Age 2
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.870 (4.870)	Prec@1 75.000 (75.000)
Test: [100/120]	Time 0.523 (0.546)	Prec@1 87.500 (73.700)
Testing Results: Prec@1 73.854
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (77.104)
Testing Results (NME): Prec@1 77.135
Eval Task 1 for Age 2
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.671 (3.671)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 83.582
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 74.627
Eval Task 2 for Age 2
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.770 (3.770)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 94.937
num_test_videos [1920, 67, 79]
Method : OURS
----AGE 3----
current_task  [11, 53]
current_head  57
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05244044240850758]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=171, sigma=tensor([3.8433]), eta=tensor([3.1523])
  (fc1): CosineLinear(input_features=512, output_features=165, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 201
video number + exemplar : 476
DataLoader Constructed : Train 14
Optimizer Constructed
video number : 201
video number + exemplar : 201
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 02:14:36.839571
Epoch: [0][0/14], lr: 0.00100	Time 3.466 (3.466)	Data 1.893 (1.893)	Loss 0.0735 (0.0735)	Loss CE 0.0076 (0.0076)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6573 (0.6573)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1494], device='cuda:0', requires_grad=True)
2022-03-24 02:14:52.471458
Epoch: [1][0/14], lr: 0.00100	Time 3.359 (3.359)	Data 2.557 (2.557)	Loss 0.0721 (0.0721)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6894 (0.6894)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8301], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1452], device='cuda:0', requires_grad=True)
2022-03-24 02:15:08.636510
Epoch: [2][0/14], lr: 0.00100	Time 3.569 (3.569)	Data 2.260 (2.260)	Loss 0.0960 (0.0960)	Loss CE 0.0275 (0.0275)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6834 (0.6834)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8276], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1436], device='cuda:0', requires_grad=True)
2022-03-24 02:15:24.642878
Epoch: [3][0/14], lr: 0.00100	Time 3.393 (3.393)	Data 2.015 (2.015)	Loss 0.0690 (0.0690)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6670 (0.6670)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8258], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1423], device='cuda:0', requires_grad=True)
2022-03-24 02:15:40.360584
Epoch: [4][0/14], lr: 0.00100	Time 3.336 (3.336)	Data 1.886 (1.886)	Loss 0.0705 (0.0705)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6568 (0.6568)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8270], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:15:56.105182
Epoch: [5][0/14], lr: 0.00100	Time 3.274 (3.274)	Data 2.534 (2.534)	Loss 0.0635 (0.0635)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6282 (0.6282)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8274], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1425], device='cuda:0', requires_grad=True)
2022-03-24 02:16:11.792246
Epoch: [6][0/14], lr: 0.00100	Time 3.377 (3.377)	Data 2.172 (2.172)	Loss 0.0645 (0.0645)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6274 (0.6274)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8282], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1427], device='cuda:0', requires_grad=True)
2022-03-24 02:16:27.806679
Epoch: [7][0/14], lr: 0.00100	Time 3.225 (3.225)	Data 2.021 (2.021)	Loss 0.0651 (0.0651)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6416 (0.6416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8292], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1431], device='cuda:0', requires_grad=True)
2022-03-24 02:16:43.873098
Epoch: [8][0/14], lr: 0.00100	Time 3.527 (3.527)	Data 2.446 (2.446)	Loss 0.0686 (0.0686)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6834 (0.6834)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8298], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1431], device='cuda:0', requires_grad=True)
2022-03-24 02:16:59.653256
Epoch: [9][0/14], lr: 0.00100	Time 3.260 (3.260)	Data 2.243 (2.243)	Loss 0.0649 (0.0649)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6281 (0.6281)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8305], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1432], device='cuda:0', requires_grad=True)
2022-03-24 02:17:15.488065
Epoch: [10][0/14], lr: 0.00100	Time 3.342 (3.342)	Data 2.127 (2.127)	Loss 0.0633 (0.0633)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6273 (0.6273)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1431], device='cuda:0', requires_grad=True)
2022-03-24 02:17:31.366003
Epoch: [11][0/14], lr: 0.00100	Time 3.494 (3.494)	Data 2.339 (2.339)	Loss 0.1455 (0.1455)	Loss CE 0.0845 (0.0845)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6072 (0.6072)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8298], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1419], device='cuda:0', requires_grad=True)
2022-03-24 02:17:47.475937
Epoch: [12][0/14], lr: 0.00100	Time 3.521 (3.521)	Data 2.775 (2.775)	Loss 0.0686 (0.0686)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6626 (0.6626)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8296], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1413], device='cuda:0', requires_grad=True)
2022-03-24 02:18:02.494708
Epoch: [13][0/14], lr: 0.00100	Time 3.467 (3.467)	Data 2.427 (2.427)	Loss 0.0648 (0.0648)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6382 (0.6382)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8303], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1413], device='cuda:0', requires_grad=True)
2022-03-24 02:18:16.821288
Epoch: [14][0/14], lr: 0.00100	Time 3.257 (3.257)	Data 2.244 (2.244)	Loss 0.0758 (0.0758)	Loss CE 0.0077 (0.0077)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6782 (0.6782)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8322], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1420], device='cuda:0', requires_grad=True)
2022-03-24 02:18:31.589485
Epoch: [15][0/14], lr: 0.00100	Time 3.273 (3.273)	Data 2.370 (2.370)	Loss 0.0662 (0.0662)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6534 (0.6534)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8341], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:18:44.867056
Epoch: [16][0/14], lr: 0.00100	Time 3.266 (3.266)	Data 2.349 (2.349)	Loss 0.0667 (0.0667)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6628 (0.6628)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8347], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1429], device='cuda:0', requires_grad=True)
2022-03-24 02:18:58.313682
Epoch: [17][0/14], lr: 0.00100	Time 3.208 (3.208)	Data 1.902 (1.902)	Loss 0.0645 (0.0645)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6405 (0.6405)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8348], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:19:11.522728
Epoch: [18][0/14], lr: 0.00100	Time 3.107 (3.107)	Data 1.926 (1.926)	Loss 0.0651 (0.0651)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6465 (0.6465)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:19:24.811251
Epoch: [19][0/14], lr: 0.00100	Time 3.155 (3.155)	Data 2.022 (2.022)	Loss 0.0774 (0.0774)	Loss CE 0.0089 (0.0089)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6831 (0.6831)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:19:37.792644
Epoch: [20][0/14], lr: 0.00010	Time 3.110 (3.110)	Data 2.007 (2.007)	Loss 0.0659 (0.0659)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6549 (0.6549)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:19:51.136440
Epoch: [21][0/14], lr: 0.00010	Time 3.317 (3.317)	Data 2.269 (2.269)	Loss 0.0704 (0.0704)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6545 (0.6545)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:20:04.379713
Epoch: [22][0/14], lr: 0.00010	Time 3.250 (3.250)	Data 2.438 (2.438)	Loss 0.0636 (0.0636)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6253 (0.6253)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1427], device='cuda:0', requires_grad=True)
2022-03-24 02:20:17.804019
Epoch: [23][0/14], lr: 0.00010	Time 3.160 (3.160)	Data 2.081 (2.081)	Loss 0.0683 (0.0683)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6594 (0.6594)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8360], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:20:31.433052
Epoch: [24][0/14], lr: 0.00010	Time 3.298 (3.298)	Data 2.549 (2.549)	Loss 0.0661 (0.0661)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6572 (0.6572)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8360], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 02:20:44.829196
Epoch: [25][0/14], lr: 0.00010	Time 3.149 (3.149)	Data 1.965 (1.965)	Loss 0.0630 (0.0630)	Loss CE 0.0000 (0.0000)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6279 (0.6279)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8360], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1427], device='cuda:0', requires_grad=True)
2022-03-24 02:20:58.449084
Epoch: [26][0/14], lr: 0.00010	Time 3.238 (3.238)	Data 2.350 (2.350)	Loss 0.0660 (0.0660)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6545 (0.6545)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8360], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1427], device='cuda:0', requires_grad=True)
2022-03-24 02:21:12.186507
Epoch: [27][0/14], lr: 0.00010	Time 3.144 (3.144)	Data 1.923 (1.923)	Loss 0.0678 (0.0678)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6721 (0.6721)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1427], device='cuda:0', requires_grad=True)
2022-03-24 02:21:25.774909
Epoch: [28][0/14], lr: 0.00010	Time 3.206 (3.206)	Data 2.286 (2.286)	Loss 0.0672 (0.0672)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6651 (0.6651)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1427], device='cuda:0', requires_grad=True)
2022-03-24 02:21:39.306831
Epoch: [29][0/14], lr: 0.00010	Time 3.323 (3.323)	Data 2.452 (2.452)	Loss 0.0675 (0.0675)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6670 (0.6670)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:21:52.565133
Epoch: [30][0/14], lr: 0.00001	Time 3.151 (3.151)	Data 2.096 (2.096)	Loss 0.0676 (0.0676)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6724 (0.6724)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:22:06.333253
Epoch: [31][0/14], lr: 0.00001	Time 3.190 (3.190)	Data 2.444 (2.444)	Loss 0.0714 (0.0714)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6662 (0.6662)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:22:19.827248
Epoch: [32][0/14], lr: 0.00001	Time 3.213 (3.213)	Data 2.396 (2.396)	Loss 0.0688 (0.0688)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6807 (0.6807)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:22:33.099573
Epoch: [33][0/14], lr: 0.00001	Time 3.092 (3.092)	Data 1.874 (1.874)	Loss 0.0639 (0.0639)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6350 (0.6350)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:22:46.692435
Epoch: [34][0/14], lr: 0.00001	Time 3.305 (3.305)	Data 2.495 (2.495)	Loss 0.0654 (0.0654)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6475 (0.6475)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:23:00.255439
Epoch: [35][0/14], lr: 0.00001	Time 3.286 (3.286)	Data 2.537 (2.537)	Loss 0.0668 (0.0668)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6585 (0.6585)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:23:13.169047
Epoch: [36][0/14], lr: 0.00001	Time 3.372 (3.372)	Data 2.082 (2.082)	Loss 0.0803 (0.0803)	Loss CE 0.0141 (0.0141)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6595 (0.6595)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:23:27.600885
Epoch: [37][0/14], lr: 0.00001	Time 3.457 (3.457)	Data 2.466 (2.466)	Loss 0.0648 (0.0648)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6416 (0.6416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:23:43.370815
Epoch: [38][0/14], lr: 0.00001	Time 3.333 (3.333)	Data 2.231 (2.231)	Loss 0.0634 (0.0634)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6299 (0.6299)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:23:58.819580
Epoch: [39][0/14], lr: 0.00001	Time 3.103 (3.103)	Data 2.113 (2.113)	Loss 0.0688 (0.0688)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6462 (0.6462)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:24:14.813931
Epoch: [40][0/14], lr: 0.00001	Time 3.502 (3.502)	Data 2.291 (2.291)	Loss 0.0654 (0.0654)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6498 (0.6498)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:24:30.367807
Epoch: [41][0/14], lr: 0.00001	Time 3.212 (3.212)	Data 2.216 (2.216)	Loss 0.0698 (0.0698)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6657 (0.6657)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:24:46.186871
Epoch: [42][0/14], lr: 0.00001	Time 3.318 (3.318)	Data 2.286 (2.286)	Loss 0.0657 (0.0657)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6475 (0.6475)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:25:01.928273
Epoch: [43][0/14], lr: 0.00001	Time 3.476 (3.476)	Data 2.171 (2.171)	Loss 0.0674 (0.0674)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6706 (0.6706)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:25:17.900053
Epoch: [44][0/14], lr: 0.00001	Time 3.318 (3.318)	Data 2.123 (2.123)	Loss 0.0644 (0.0644)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6407 (0.6407)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:25:33.672095
Epoch: [45][0/14], lr: 0.00001	Time 3.350 (3.350)	Data 2.228 (2.228)	Loss 0.0655 (0.0655)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6515 (0.6515)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:25:49.427559
Epoch: [46][0/14], lr: 0.00001	Time 3.306 (3.306)	Data 2.370 (2.370)	Loss 0.0642 (0.0642)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6380 (0.6380)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:26:05.258751
Epoch: [47][0/14], lr: 0.00001	Time 3.501 (3.501)	Data 2.116 (2.116)	Loss 0.0650 (0.0650)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6426 (0.6426)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:26:21.032023
Epoch: [48][0/14], lr: 0.00001	Time 3.203 (3.203)	Data 2.310 (2.310)	Loss 0.0684 (0.0684)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6721 (0.6721)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:26:36.593448
Epoch: [49][0/14], lr: 0.00001	Time 3.324 (3.324)	Data 2.358 (2.358)	Loss 0.0666 (0.0666)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6615 (0.6615)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=171, sigma=tensor([3.8359]), eta=tensor([3.1426])
  (fc1): CosineLinear(input_features=512, output_features=165, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 201
video number + exemplar : 201
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=171, sigma=tensor([3.8359]), eta=tensor([3.1426])
  (fc1): CosineLinear(input_features=512, output_features=165, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 285
DataLoader CBF Constructed : Train 8
Optimizer Constructed
2022-03-24 02:27:07.023975
Epoch: [0][0/8], lr: 0.00050	Time 2.953 (2.953)	Data 2.274 (2.274)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8363], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1427], device='cuda:0', requires_grad=True)
2022-03-24 02:27:14.124810
Epoch: [1][0/8], lr: 0.00050	Time 2.759 (2.759)	Data 1.982 (1.982)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1429], device='cuda:0', requires_grad=True)
2022-03-24 02:27:21.628675
Epoch: [2][0/8], lr: 0.00050	Time 3.047 (3.047)	Data 2.064 (2.064)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8373], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1431], device='cuda:0', requires_grad=True)
2022-03-24 02:27:28.767165
Epoch: [3][0/8], lr: 0.00050	Time 2.815 (2.815)	Data 2.364 (2.364)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8376], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1432], device='cuda:0', requires_grad=True)
2022-03-24 02:27:36.278953
Epoch: [4][0/8], lr: 0.00050	Time 2.975 (2.975)	Data 2.099 (2.099)	Loss 0.0358 (0.0358)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8379], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1432], device='cuda:0', requires_grad=True)
2022-03-24 02:27:43.405847
Epoch: [5][0/8], lr: 0.00050	Time 2.855 (2.855)	Data 2.328 (2.328)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8380], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1431], device='cuda:0', requires_grad=True)
2022-03-24 02:27:50.852476
Epoch: [6][0/8], lr: 0.00050	Time 2.980 (2.980)	Data 2.237 (2.237)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8383], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1432], device='cuda:0', requires_grad=True)
2022-03-24 02:27:58.025154
Epoch: [7][0/8], lr: 0.00050	Time 2.848 (2.848)	Data 2.283 (2.283)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1433], device='cuda:0', requires_grad=True)
2022-03-24 02:28:05.514631
Epoch: [8][0/8], lr: 0.00050	Time 2.981 (2.981)	Data 1.970 (1.970)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8388], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1432], device='cuda:0', requires_grad=True)
2022-03-24 02:28:12.557691
Epoch: [9][0/8], lr: 0.00050	Time 2.752 (2.752)	Data 1.917 (1.917)	Loss 0.0073 (0.0073)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8393], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1433], device='cuda:0', requires_grad=True)
2022-03-24 02:28:20.084554
Epoch: [10][0/8], lr: 0.00050	Time 3.130 (3.130)	Data 2.450 (2.450)	Loss 0.0044 (0.0044)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8396], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1434], device='cuda:0', requires_grad=True)
2022-03-24 02:28:27.463777
Epoch: [11][0/8], lr: 0.00050	Time 3.081 (3.081)	Data 2.377 (2.377)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8399], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1435], device='cuda:0', requires_grad=True)
2022-03-24 02:28:34.698446
Epoch: [12][0/8], lr: 0.00050	Time 2.896 (2.896)	Data 2.304 (2.304)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8401], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1435], device='cuda:0', requires_grad=True)
2022-03-24 02:28:41.784564
Epoch: [13][0/8], lr: 0.00050	Time 2.775 (2.775)	Data 1.839 (1.839)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8406], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1437], device='cuda:0', requires_grad=True)
2022-03-24 02:28:49.325516
Epoch: [14][0/8], lr: 0.00050	Time 2.992 (2.992)	Data 2.232 (2.232)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8409], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1438], device='cuda:0', requires_grad=True)
2022-03-24 02:28:56.439127
Epoch: [15][0/8], lr: 0.00050	Time 2.835 (2.835)	Data 2.097 (2.097)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1438], device='cuda:0', requires_grad=True)
2022-03-24 02:29:03.918059
Epoch: [16][0/8], lr: 0.00050	Time 2.983 (2.983)	Data 2.348 (2.348)	Loss 0.0305 (0.0305)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8417], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1440], device='cuda:0', requires_grad=True)
2022-03-24 02:29:11.288386
Epoch: [17][0/8], lr: 0.00050	Time 3.063 (3.063)	Data 2.238 (2.238)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8418], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1439], device='cuda:0', requires_grad=True)
2022-03-24 02:29:18.600309
Epoch: [18][0/8], lr: 0.00050	Time 2.998 (2.998)	Data 2.387 (2.387)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8419], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1438], device='cuda:0', requires_grad=True)
2022-03-24 02:29:26.002470
Epoch: [19][0/8], lr: 0.00050	Time 3.092 (3.092)	Data 2.084 (2.084)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8423], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1439], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_003.pth.tar
exemplar : 285
Computing the class mean vectors...
Eval Task 0 for Age 3
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.803 (4.803)	Prec@1 68.750 (68.750)
Test: [100/120]	Time 0.379 (0.557)	Prec@1 81.250 (74.134)
Testing Results: Prec@1 74.635
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (77.104)
Testing Results (NME): Prec@1 77.656
Eval Task 1 for Age 3
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.657 (3.657)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 88.060
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 80.597
Eval Task 2 for Age 3
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.123 (4.123)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 97.468
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 78.481
Eval Task 3 for Age 3
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.278 (4.278)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.824
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 88.235
num_test_videos [1920, 67, 79, 85]
Method : OURS
----AGE 4----
current_task  [89, 42]
current_head  59
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05338539126015656]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=177, sigma=tensor([3.8423]), eta=tensor([3.1439])
  (fc1): CosineLinear(input_features=512, output_features=171, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 192
video number + exemplar : 477
DataLoader Constructed : Train 14
Optimizer Constructed
video number : 192
video number + exemplar : 192
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 02:32:32.164689
Epoch: [0][0/14], lr: 0.00100	Time 3.363 (3.363)	Data 2.003 (2.003)	Loss 0.1780 (0.1780)	Loss CE 0.1099 (0.1099)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6787 (0.6787)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8390], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1420], device='cuda:0', requires_grad=True)
2022-03-24 02:32:46.148855
Epoch: [1][0/14], lr: 0.00100	Time 3.149 (3.149)	Data 2.236 (2.236)	Loss 0.0824 (0.0824)	Loss CE 0.0161 (0.0161)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6596 (0.6596)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8347], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1392], device='cuda:0', requires_grad=True)
2022-03-24 02:32:59.319466
Epoch: [2][0/14], lr: 0.00100	Time 3.230 (3.230)	Data 2.249 (2.249)	Loss 0.3132 (0.3132)	Loss CE 0.2455 (0.2455)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6735 (0.6735)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8259], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1341], device='cuda:0', requires_grad=True)
2022-03-24 02:33:12.525649
Epoch: [3][0/14], lr: 0.00100	Time 3.207 (3.207)	Data 1.918 (1.918)	Loss 0.0915 (0.0915)	Loss CE 0.0199 (0.0199)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0011 (0.0011)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7122 (0.7122)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8265], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1346], device='cuda:0', requires_grad=True)
2022-03-24 02:33:25.954802
Epoch: [4][0/14], lr: 0.00100	Time 3.329 (3.329)	Data 2.130 (2.130)	Loss 0.0895 (0.0895)	Loss CE 0.0225 (0.0225)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6662 (0.6662)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1317], device='cuda:0', requires_grad=True)
2022-03-24 02:33:39.240085
Epoch: [5][0/14], lr: 0.00100	Time 3.204 (3.204)	Data 2.155 (2.155)	Loss 0.0652 (0.0652)	Loss CE 0.0054 (0.0054)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5942 (0.5942)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8192], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1311], device='cuda:0', requires_grad=True)
2022-03-24 02:33:52.275505
Epoch: [6][0/14], lr: 0.00100	Time 3.122 (3.122)	Data 1.828 (1.828)	Loss 0.1131 (0.1131)	Loss CE 0.0470 (0.0470)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6574 (0.6574)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8226], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1332], device='cuda:0', requires_grad=True)
2022-03-24 02:34:05.722772
Epoch: [7][0/14], lr: 0.00100	Time 3.468 (3.468)	Data 2.358 (2.358)	Loss 0.1767 (0.1767)	Loss CE 0.1095 (0.1095)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6678 (0.6678)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8227], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
2022-03-24 02:34:19.046159
Epoch: [8][0/14], lr: 0.00100	Time 3.244 (3.244)	Data 1.932 (1.932)	Loss 0.1021 (0.1021)	Loss CE 0.0358 (0.0358)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6591 (0.6591)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8265], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1357], device='cuda:0', requires_grad=True)
2022-03-24 02:34:32.863492
Epoch: [9][0/14], lr: 0.00100	Time 3.402 (3.402)	Data 2.494 (2.494)	Loss 0.0734 (0.0734)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6919 (0.6919)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8292], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1371], device='cuda:0', requires_grad=True)
2022-03-24 02:34:46.302726
Epoch: [10][0/14], lr: 0.00100	Time 3.108 (3.108)	Data 2.114 (2.114)	Loss 0.0790 (0.0790)	Loss CE 0.0098 (0.0098)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6868 (0.6868)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8298], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1372], device='cuda:0', requires_grad=True)
2022-03-24 02:34:59.595119
Epoch: [11][0/14], lr: 0.00100	Time 3.108 (3.108)	Data 1.847 (1.847)	Loss 0.0761 (0.0761)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7015 (0.7015)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8267], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1355], device='cuda:0', requires_grad=True)
2022-03-24 02:35:12.964554
Epoch: [12][0/14], lr: 0.00100	Time 3.132 (3.132)	Data 2.105 (2.105)	Loss 0.0711 (0.0711)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7005 (0.7005)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8301], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1378], device='cuda:0', requires_grad=True)
2022-03-24 02:35:26.517777
Epoch: [13][0/14], lr: 0.00100	Time 3.123 (3.123)	Data 2.398 (2.398)	Loss 0.0948 (0.0948)	Loss CE 0.0295 (0.0295)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6477 (0.6477)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8316], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1380], device='cuda:0', requires_grad=True)
2022-03-24 02:35:40.086729
Epoch: [14][0/14], lr: 0.00100	Time 3.071 (3.071)	Data 2.093 (2.093)	Loss 0.0793 (0.0793)	Loss CE 0.0124 (0.0124)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6636 (0.6636)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8323], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1379], device='cuda:0', requires_grad=True)
2022-03-24 02:35:53.419827
Epoch: [15][0/14], lr: 0.00100	Time 3.106 (3.106)	Data 1.935 (1.935)	Loss 0.0739 (0.0739)	Loss CE 0.0054 (0.0054)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6809 (0.6809)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8366], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1402], device='cuda:0', requires_grad=True)
2022-03-24 02:36:06.899467
Epoch: [16][0/14], lr: 0.00100	Time 3.181 (3.181)	Data 2.124 (2.124)	Loss 0.1652 (0.1652)	Loss CE 0.0996 (0.0996)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6517 (0.6517)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8390], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1416], device='cuda:0', requires_grad=True)
2022-03-24 02:36:20.608077
Epoch: [17][0/14], lr: 0.00100	Time 3.227 (3.227)	Data 2.286 (2.286)	Loss 0.0692 (0.0692)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6642 (0.6642)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1426], device='cuda:0', requires_grad=True)
2022-03-24 02:36:34.089451
Epoch: [18][0/14], lr: 0.00100	Time 3.052 (3.052)	Data 1.979 (1.979)	Loss 0.0672 (0.0672)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6601 (0.6601)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1429], device='cuda:0', requires_grad=True)
2022-03-24 02:36:47.593244
Epoch: [19][0/14], lr: 0.00100	Time 3.173 (3.173)	Data 2.087 (2.087)	Loss 0.0689 (0.0689)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6732 (0.6732)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8422], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1433], device='cuda:0', requires_grad=True)
2022-03-24 02:37:00.966421
Epoch: [20][0/14], lr: 0.00010	Time 3.261 (3.261)	Data 2.198 (2.198)	Loss 0.0722 (0.0722)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6970 (0.6970)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8425], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1434], device='cuda:0', requires_grad=True)
2022-03-24 02:37:14.506960
Epoch: [21][0/14], lr: 0.00010	Time 3.211 (3.211)	Data 2.543 (2.543)	Loss 0.0679 (0.0679)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6709 (0.6709)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8427], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1435], device='cuda:0', requires_grad=True)
2022-03-24 02:37:27.322028
Epoch: [22][0/14], lr: 0.00010	Time 3.116 (3.116)	Data 2.049 (2.049)	Loss 0.0887 (0.0887)	Loss CE 0.0224 (0.0224)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6586 (0.6586)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8429], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1437], device='cuda:0', requires_grad=True)
2022-03-24 02:37:42.113391
Epoch: [23][0/14], lr: 0.00010	Time 3.412 (3.412)	Data 2.150 (2.150)	Loss 0.0711 (0.0711)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6836 (0.6836)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8432], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1438], device='cuda:0', requires_grad=True)
2022-03-24 02:37:57.960763
Epoch: [24][0/14], lr: 0.00010	Time 3.247 (3.247)	Data 2.210 (2.210)	Loss 0.0659 (0.0659)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6516 (0.6516)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8433], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1438], device='cuda:0', requires_grad=True)
2022-03-24 02:38:13.461297
Epoch: [25][0/14], lr: 0.00010	Time 3.339 (3.339)	Data 2.008 (2.008)	Loss 0.0677 (0.0677)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6603 (0.6603)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8435], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1440], device='cuda:0', requires_grad=True)
2022-03-24 02:38:28.916470
Epoch: [26][0/14], lr: 0.00010	Time 3.146 (3.146)	Data 2.022 (2.022)	Loss 0.0645 (0.0645)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6338 (0.6338)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8438], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1441], device='cuda:0', requires_grad=True)
2022-03-24 02:38:44.670216
Epoch: [27][0/14], lr: 0.00010	Time 3.414 (3.414)	Data 2.300 (2.300)	Loss 0.0728 (0.0728)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7072 (0.7072)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8440], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:39:00.506430
Epoch: [28][0/14], lr: 0.00010	Time 3.150 (3.150)	Data 1.884 (1.884)	Loss 0.0664 (0.0664)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6543 (0.6543)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8439], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1441], device='cuda:0', requires_grad=True)
2022-03-24 02:39:16.078885
Epoch: [29][0/14], lr: 0.00010	Time 3.207 (3.207)	Data 2.348 (2.348)	Loss 0.0684 (0.0684)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6575 (0.6575)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:39:31.489604
Epoch: [30][0/14], lr: 0.00001	Time 3.252 (3.252)	Data 2.047 (2.047)	Loss 0.0670 (0.0670)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6598 (0.6598)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:39:46.890149
Epoch: [31][0/14], lr: 0.00001	Time 3.222 (3.222)	Data 2.224 (2.224)	Loss 0.0663 (0.0663)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6479 (0.6479)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:40:02.756727
Epoch: [32][0/14], lr: 0.00001	Time 3.342 (3.342)	Data 2.277 (2.277)	Loss 0.0710 (0.0710)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6638 (0.6638)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:40:18.414904
Epoch: [33][0/14], lr: 0.00001	Time 3.311 (3.311)	Data 1.933 (1.933)	Loss 0.0726 (0.0726)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6512 (0.6512)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:40:34.255880
Epoch: [34][0/14], lr: 0.00001	Time 3.356 (3.356)	Data 2.325 (2.325)	Loss 0.0682 (0.0682)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6692 (0.6692)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:40:50.262607
Epoch: [35][0/14], lr: 0.00001	Time 3.470 (3.470)	Data 2.028 (2.028)	Loss 0.0687 (0.0687)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6487 (0.6487)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:41:05.803814
Epoch: [36][0/14], lr: 0.00001	Time 3.235 (3.235)	Data 2.284 (2.284)	Loss 0.0749 (0.0749)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6981 (0.6981)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:41:21.426439
Epoch: [37][0/14], lr: 0.00001	Time 3.075 (3.075)	Data 1.802 (1.802)	Loss 0.0888 (0.0888)	Loss CE 0.0218 (0.0218)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6655 (0.6655)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:41:37.108019
Epoch: [38][0/14], lr: 0.00001	Time 3.361 (3.361)	Data 1.905 (1.905)	Loss 0.0673 (0.0673)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6596 (0.6596)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:41:53.000026
Epoch: [39][0/14], lr: 0.00001	Time 3.610 (3.610)	Data 2.080 (2.080)	Loss 0.0715 (0.0715)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7014 (0.7014)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:42:09.072959
Epoch: [40][0/14], lr: 0.00001	Time 3.519 (3.519)	Data 2.401 (2.401)	Loss 0.2577 (0.2577)	Loss CE 0.1937 (0.1937)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6353 (0.6353)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:42:24.702787
Epoch: [41][0/14], lr: 0.00001	Time 3.051 (3.051)	Data 1.816 (1.816)	Loss 0.0734 (0.0734)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7268 (0.7268)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:42:40.217802
Epoch: [42][0/14], lr: 0.00001	Time 3.451 (3.451)	Data 2.322 (2.322)	Loss 0.0702 (0.0702)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6640 (0.6640)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:42:56.186006
Epoch: [43][0/14], lr: 0.00001	Time 3.418 (3.418)	Data 2.194 (2.194)	Loss 0.0678 (0.0678)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6630 (0.6630)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:43:11.933931
Epoch: [44][0/14], lr: 0.00001	Time 3.337 (3.337)	Data 2.360 (2.360)	Loss 0.0706 (0.0706)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6971 (0.6971)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:43:27.795479
Epoch: [45][0/14], lr: 0.00001	Time 3.217 (3.217)	Data 1.968 (1.968)	Loss 0.0700 (0.0700)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6662 (0.6662)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:43:43.533864
Epoch: [46][0/14], lr: 0.00001	Time 3.409 (3.409)	Data 2.049 (2.049)	Loss 0.0680 (0.0680)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6632 (0.6632)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:43:59.415423
Epoch: [47][0/14], lr: 0.00001	Time 3.231 (3.231)	Data 2.178 (2.178)	Loss 0.0679 (0.0679)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0008 (0.0008)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6496 (0.6496)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:44:15.177633
Epoch: [48][0/14], lr: 0.00001	Time 3.297 (3.297)	Data 2.239 (2.239)	Loss 0.0683 (0.0683)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6763 (0.6763)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8443], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:44:31.025714
Epoch: [49][0/14], lr: 0.00001	Time 3.458 (3.458)	Data 2.124 (2.124)	Loss 0.0688 (0.0688)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0007 (0.0007)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6535 (0.6535)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8443], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1443], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=177, sigma=tensor([3.8443]), eta=tensor([3.1443])
  (fc1): CosineLinear(input_features=512, output_features=171, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 192
video number + exemplar : 192
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=177, sigma=tensor([3.8443]), eta=tensor([3.1443])
  (fc1): CosineLinear(input_features=512, output_features=171, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 295
DataLoader CBF Constructed : Train 9
Optimizer Constructed
2022-03-24 02:45:01.200469
Epoch: [0][0/9], lr: 0.00050	Time 2.904 (2.904)	Data 2.268 (2.268)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8443], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:45:09.066709
Epoch: [1][0/9], lr: 0.00050	Time 3.003 (3.003)	Data 2.253 (2.253)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8446], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1443], device='cuda:0', requires_grad=True)
2022-03-24 02:45:17.036397
Epoch: [2][0/9], lr: 0.00050	Time 3.106 (3.106)	Data 2.181 (2.181)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8455], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1448], device='cuda:0', requires_grad=True)
2022-03-24 02:45:25.005677
Epoch: [3][0/9], lr: 0.00050	Time 3.043 (3.043)	Data 2.153 (2.153)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1448], device='cuda:0', requires_grad=True)
2022-03-24 02:45:32.359094
Epoch: [4][0/9], lr: 0.00050	Time 2.653 (2.653)	Data 1.845 (1.845)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8460], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1447], device='cuda:0', requires_grad=True)
2022-03-24 02:45:40.290202
Epoch: [5][0/9], lr: 0.00050	Time 3.128 (3.128)	Data 2.211 (2.211)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8459], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1446], device='cuda:0', requires_grad=True)
2022-03-24 02:45:47.858638
Epoch: [6][0/9], lr: 0.00050	Time 2.857 (2.857)	Data 2.118 (2.118)	Loss 0.0031 (0.0031)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8460], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1445], device='cuda:0', requires_grad=True)
2022-03-24 02:45:55.796198
Epoch: [7][0/9], lr: 0.00050	Time 3.146 (3.146)	Data 2.258 (2.258)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8460], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1443], device='cuda:0', requires_grad=True)
2022-03-24 02:46:03.638050
Epoch: [8][0/9], lr: 0.00050	Time 2.997 (2.997)	Data 2.154 (2.154)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8459], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1441], device='cuda:0', requires_grad=True)
2022-03-24 02:46:11.524480
Epoch: [9][0/9], lr: 0.00050	Time 3.044 (3.044)	Data 2.169 (2.169)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1440], device='cuda:0', requires_grad=True)
2022-03-24 02:46:19.426194
Epoch: [10][0/9], lr: 0.00050	Time 3.163 (3.163)	Data 2.425 (2.425)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1439], device='cuda:0', requires_grad=True)
2022-03-24 02:46:27.281370
Epoch: [11][0/9], lr: 0.00050	Time 2.970 (2.970)	Data 2.017 (2.017)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1438], device='cuda:0', requires_grad=True)
2022-03-24 02:46:35.165000
Epoch: [12][0/9], lr: 0.00050	Time 2.873 (2.873)	Data 2.005 (2.005)	Loss 0.0090 (0.0090)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8462], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1439], device='cuda:0', requires_grad=True)
2022-03-24 02:46:42.182626
Epoch: [13][0/9], lr: 0.00050	Time 2.935 (2.935)	Data 2.145 (2.145)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8468], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
2022-03-24 02:46:49.288590
Epoch: [14][0/9], lr: 0.00050	Time 3.002 (3.002)	Data 2.409 (2.409)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8467], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1441], device='cuda:0', requires_grad=True)
2022-03-24 02:46:56.539666
Epoch: [15][0/9], lr: 0.00050	Time 3.054 (3.054)	Data 2.478 (2.478)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8462], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1436], device='cuda:0', requires_grad=True)
2022-03-24 02:47:03.507173
Epoch: [16][0/9], lr: 0.00050	Time 2.724 (2.724)	Data 1.823 (1.823)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8462], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1435], device='cuda:0', requires_grad=True)
2022-03-24 02:47:10.713348
Epoch: [17][0/9], lr: 0.00050	Time 2.937 (2.937)	Data 2.363 (2.363)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8468], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1436], device='cuda:0', requires_grad=True)
2022-03-24 02:47:17.853471
Epoch: [18][0/9], lr: 0.00050	Time 2.852 (2.852)	Data 2.236 (2.236)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8475], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1439], device='cuda:0', requires_grad=True)
2022-03-24 02:47:24.893601
Epoch: [19][0/9], lr: 0.00050	Time 2.869 (2.869)	Data 2.189 (2.189)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1442], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_004.pth.tar
exemplar : 295
Computing the class mean vectors...
Eval Task 0 for Age 4
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.678 (4.678)	Prec@1 68.750 (68.750)
Test: [100/120]	Time 0.543 (0.488)	Prec@1 93.750 (69.678)
Testing Results: Prec@1 70.000
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (72.153)
Testing Results (NME): Prec@1 72.344
Eval Task 1 for Age 4
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.643 (3.643)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 65.672
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 59.701
Eval Task 2 for Age 4
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.567 (3.567)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 93.671
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 74.684
Eval Task 3 for Age 4
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.868 (3.868)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.588
Eval Task 4 for Age 4
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.991 (3.991)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 97.260
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 83.562
num_test_videos [1920, 67, 79, 85, 73]
Method : OURS
----AGE 5----
current_task  [40, 15]
current_head  61
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05431390245600108]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=183, sigma=tensor([3.8482]), eta=tensor([3.1442])
  (fc1): CosineLinear(input_features=512, output_features=177, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 201
video number + exemplar : 496
DataLoader Constructed : Train 15
Optimizer Constructed
video number : 201
video number + exemplar : 201
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 02:50:29.940958
Epoch: [0][0/15], lr: 0.00100	Time 3.641 (3.641)	Data 2.601 (2.601)	Loss 0.0667 (0.0667)	Loss CE 0.0090 (0.0090)	Loss KD (Logit) 0.0062 (0.0062)	Loss KD (GCAM) 0.0056 (0.0056)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5566 (0.5566)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8445], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1415], device='cuda:0', requires_grad=True)
2022-03-24 02:50:43.623572
Epoch: [1][0/15], lr: 0.00100	Time 3.095 (3.095)	Data 1.770 (1.770)	Loss 0.0787 (0.0787)	Loss CE 0.0140 (0.0140)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6236 (0.6236)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8447], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1414], device='cuda:0', requires_grad=True)
2022-03-24 02:50:58.159698
Epoch: [2][0/15], lr: 0.00100	Time 3.416 (3.416)	Data 2.508 (2.508)	Loss 0.0651 (0.0651)	Loss CE 0.0061 (0.0061)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5627 (0.5627)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8431], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1405], device='cuda:0', requires_grad=True)
2022-03-24 02:51:12.886452
Epoch: [3][0/15], lr: 0.00100	Time 3.418 (3.418)	Data 2.388 (2.388)	Loss 0.1113 (0.1113)	Loss CE 0.0520 (0.0520)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5649 (0.5649)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1396], device='cuda:0', requires_grad=True)
2022-03-24 02:51:27.257779
Epoch: [4][0/15], lr: 0.00100	Time 3.278 (3.278)	Data 2.376 (2.376)	Loss 0.1074 (0.1074)	Loss CE 0.0457 (0.0457)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0100 (0.0100)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5833 (0.5833)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8420], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1402], device='cuda:0', requires_grad=True)
2022-03-24 02:51:40.837533
Epoch: [5][0/15], lr: 0.00100	Time 3.540 (3.540)	Data 2.394 (2.394)	Loss 0.0666 (0.0666)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0088 (0.0088)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6103 (0.6103)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8431], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1412], device='cuda:0', requires_grad=True)
2022-03-24 02:51:56.895212
Epoch: [6][0/15], lr: 0.00100	Time 3.411 (3.411)	Data 2.081 (2.081)	Loss 0.0677 (0.0677)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0091 (0.0091)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6346 (0.6346)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8447], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1422], device='cuda:0', requires_grad=True)
2022-03-24 02:52:13.916524
Epoch: [7][0/15], lr: 0.00100	Time 3.549 (3.549)	Data 2.446 (2.446)	Loss 0.0696 (0.0696)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0106 (0.0106)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5915 (0.5915)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8471], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1433], device='cuda:0', requires_grad=True)
2022-03-24 02:52:30.532075
Epoch: [8][0/15], lr: 0.00100	Time 3.379 (3.379)	Data 2.455 (2.455)	Loss 0.0646 (0.0646)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0101 (0.0101)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5910 (0.5910)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1437], device='cuda:0', requires_grad=True)
2022-03-24 02:52:47.171317
Epoch: [9][0/15], lr: 0.00100	Time 3.504 (3.504)	Data 2.054 (2.054)	Loss 0.0644 (0.0644)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0091 (0.0091)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6069 (0.6069)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8495], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1444], device='cuda:0', requires_grad=True)
2022-03-24 02:53:03.926093
Epoch: [10][0/15], lr: 0.00100	Time 3.446 (3.446)	Data 2.163 (2.163)	Loss 0.0705 (0.0705)	Loss CE 0.0088 (0.0088)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0096 (0.0096)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5853 (0.5853)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8520], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1458], device='cuda:0', requires_grad=True)
2022-03-24 02:53:20.874259
Epoch: [11][0/15], lr: 0.00100	Time 3.590 (3.590)	Data 2.455 (2.455)	Loss 0.0595 (0.0595)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0099 (0.0099)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5541 (0.5541)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1474], device='cuda:0', requires_grad=True)
2022-03-24 02:53:37.728042
Epoch: [12][0/15], lr: 0.00100	Time 3.251 (3.251)	Data 2.067 (2.067)	Loss 0.0635 (0.0635)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0100 (0.0100)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5987 (0.5987)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8566], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1479], device='cuda:0', requires_grad=True)
2022-03-24 02:53:54.260256
Epoch: [13][0/15], lr: 0.00100	Time 3.325 (3.325)	Data 1.996 (1.996)	Loss 0.0652 (0.0652)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0095 (0.0095)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6181 (0.6181)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1479], device='cuda:0', requires_grad=True)
2022-03-24 02:54:10.829136
Epoch: [14][0/15], lr: 0.00100	Time 3.561 (3.561)	Data 2.599 (2.599)	Loss 0.0625 (0.0625)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0104 (0.0104)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5863 (0.5863)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8578], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1482], device='cuda:0', requires_grad=True)
2022-03-24 02:54:27.723961
Epoch: [15][0/15], lr: 0.00100	Time 3.571 (3.571)	Data 2.003 (2.003)	Loss 0.0656 (0.0656)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0091 (0.0091)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5880 (0.5880)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8594], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1490], device='cuda:0', requires_grad=True)
2022-03-24 02:54:44.607722
Epoch: [16][0/15], lr: 0.00100	Time 3.505 (3.505)	Data 1.960 (1.960)	Loss 0.0624 (0.0624)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0098 (0.0098)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5854 (0.5854)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8604], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1493], device='cuda:0', requires_grad=True)
2022-03-24 02:55:01.134309
Epoch: [17][0/15], lr: 0.00100	Time 3.338 (3.338)	Data 1.978 (1.978)	Loss 0.0636 (0.0636)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0094 (0.0094)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5925 (0.5925)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8611], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1495], device='cuda:0', requires_grad=True)
2022-03-24 02:55:17.823028
Epoch: [18][0/15], lr: 0.00100	Time 3.473 (3.473)	Data 2.107 (2.107)	Loss 0.0625 (0.0625)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0090 (0.0090)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5925 (0.5925)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8614], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1494], device='cuda:0', requires_grad=True)
2022-03-24 02:55:34.535476
Epoch: [19][0/15], lr: 0.00100	Time 3.335 (3.335)	Data 2.420 (2.420)	Loss 0.0603 (0.0603)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0086 (0.0086)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5726 (0.5726)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8621], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:55:51.402667
Epoch: [20][0/15], lr: 0.00010	Time 3.278 (3.278)	Data 1.926 (1.926)	Loss 0.0625 (0.0625)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0093 (0.0093)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5826 (0.5826)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8622], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:56:07.931467
Epoch: [21][0/15], lr: 0.00010	Time 3.408 (3.408)	Data 1.905 (1.905)	Loss 0.0638 (0.0638)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0093 (0.0093)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6026 (0.6026)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8623], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:56:24.579729
Epoch: [22][0/15], lr: 0.00010	Time 3.532 (3.532)	Data 2.134 (2.134)	Loss 0.0600 (0.0600)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5658 (0.5658)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8623], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:56:41.391933
Epoch: [23][0/15], lr: 0.00010	Time 3.347 (3.347)	Data 2.395 (2.395)	Loss 0.0591 (0.0591)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0086 (0.0086)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5581 (0.5581)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8623], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:56:58.181261
Epoch: [24][0/15], lr: 0.00010	Time 3.492 (3.492)	Data 2.298 (2.298)	Loss 0.0640 (0.0640)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0092 (0.0092)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6054 (0.6054)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8623], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:57:15.032882
Epoch: [25][0/15], lr: 0.00010	Time 3.276 (3.276)	Data 2.055 (2.055)	Loss 0.0710 (0.0710)	Loss CE 0.0106 (0.0106)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0092 (0.0092)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5724 (0.5724)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8624], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:57:31.689135
Epoch: [26][0/15], lr: 0.00010	Time 3.645 (3.645)	Data 2.265 (2.265)	Loss 0.0590 (0.0590)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0094 (0.0094)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5545 (0.5545)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8624], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:57:48.208413
Epoch: [27][0/15], lr: 0.00010	Time 3.310 (3.310)	Data 2.166 (2.166)	Loss 0.0646 (0.0646)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0087 (0.0087)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6114 (0.6114)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8625], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:58:04.608509
Epoch: [28][0/15], lr: 0.00010	Time 3.162 (3.162)	Data 1.890 (1.890)	Loss 0.0584 (0.0584)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0095 (0.0095)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5501 (0.5501)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8625], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:58:21.553787
Epoch: [29][0/15], lr: 0.00010	Time 3.576 (3.576)	Data 2.429 (2.429)	Loss 0.0596 (0.0596)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0090 (0.0090)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5626 (0.5626)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:58:38.205628
Epoch: [30][0/15], lr: 0.00001	Time 3.261 (3.261)	Data 2.229 (2.229)	Loss 0.0638 (0.0638)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0087 (0.0087)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6072 (0.6072)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:58:54.897737
Epoch: [31][0/15], lr: 0.00001	Time 3.432 (3.432)	Data 2.343 (2.343)	Loss 0.0577 (0.0577)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0089 (0.0089)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5449 (0.5449)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:59:11.623650
Epoch: [32][0/15], lr: 0.00001	Time 3.376 (3.376)	Data 1.834 (1.834)	Loss 0.0691 (0.0691)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0090 (0.0090)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6389 (0.6389)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:59:28.138050
Epoch: [33][0/15], lr: 0.00001	Time 3.396 (3.396)	Data 2.541 (2.541)	Loss 0.0573 (0.0573)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0094 (0.0094)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5370 (0.5370)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 02:59:44.893071
Epoch: [34][0/15], lr: 0.00001	Time 3.312 (3.312)	Data 2.236 (2.236)	Loss 0.0598 (0.0598)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0093 (0.0093)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5599 (0.5599)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:00:01.644414
Epoch: [35][0/15], lr: 0.00001	Time 3.359 (3.359)	Data 2.463 (2.463)	Loss 0.0695 (0.0695)	Loss CE 0.0099 (0.0099)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0093 (0.0093)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5647 (0.5647)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:00:18.308782
Epoch: [36][0/15], lr: 0.00001	Time 3.598 (3.598)	Data 2.282 (2.282)	Loss 0.0648 (0.0648)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6175 (0.6175)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:00:35.112919
Epoch: [37][0/15], lr: 0.00001	Time 3.517 (3.517)	Data 2.749 (2.749)	Loss 0.0575 (0.0575)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0086 (0.0086)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5407 (0.5407)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:00:51.819021
Epoch: [38][0/15], lr: 0.00001	Time 3.351 (3.351)	Data 2.542 (2.542)	Loss 0.0637 (0.0637)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0094 (0.0094)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6035 (0.6035)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:01:07.266812
Epoch: [39][0/15], lr: 0.00001	Time 3.450 (3.450)	Data 2.329 (2.329)	Loss 0.0683 (0.0683)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0091 (0.0091)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6181 (0.6181)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:01:22.801027
Epoch: [40][0/15], lr: 0.00001	Time 3.110 (3.110)	Data 2.077 (2.077)	Loss 0.0598 (0.0598)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0065 (0.0065)	Loss KD (GCAM) 0.0091 (0.0091)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5639 (0.5639)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:01:38.315031
Epoch: [41][0/15], lr: 0.00001	Time 3.474 (3.474)	Data 2.287 (2.287)	Loss 0.0620 (0.0620)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0093 (0.0093)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5865 (0.5865)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:01:52.609902
Epoch: [42][0/15], lr: 0.00001	Time 3.292 (3.292)	Data 2.325 (2.325)	Loss 0.0620 (0.0620)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0088 (0.0088)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5806 (0.5806)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:02:06.553653
Epoch: [43][0/15], lr: 0.00001	Time 3.230 (3.230)	Data 2.055 (2.055)	Loss 0.0597 (0.0597)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0093 (0.0093)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5645 (0.5645)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:02:20.470258
Epoch: [44][0/15], lr: 0.00001	Time 3.192 (3.192)	Data 1.901 (1.901)	Loss 0.0603 (0.0603)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0098 (0.0098)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5667 (0.5667)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:02:34.501407
Epoch: [45][0/15], lr: 0.00001	Time 3.231 (3.231)	Data 2.146 (2.146)	Loss 0.0628 (0.0628)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0094 (0.0094)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5935 (0.5935)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:02:48.658749
Epoch: [46][0/15], lr: 0.00001	Time 3.404 (3.404)	Data 2.087 (2.087)	Loss 0.0623 (0.0623)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0094 (0.0094)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5862 (0.5862)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:03:02.594965
Epoch: [47][0/15], lr: 0.00001	Time 3.226 (3.226)	Data 2.133 (2.133)	Loss 0.0624 (0.0624)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0091 (0.0091)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5889 (0.5889)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:03:16.597604
Epoch: [48][0/15], lr: 0.00001	Time 3.180 (3.180)	Data 1.889 (1.889)	Loss 0.0658 (0.0658)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0064 (0.0064)	Loss KD (GCAM) 0.0092 (0.0092)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6205 (0.6205)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:03:31.019498
Epoch: [49][0/15], lr: 0.00001	Time 3.088 (3.088)	Data 1.886 (1.886)	Loss 0.0619 (0.0619)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0088 (0.0088)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5836 (0.5836)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8626], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=183, sigma=tensor([3.8626]), eta=tensor([3.1496])
  (fc1): CosineLinear(input_features=512, output_features=177, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 201
video number + exemplar : 201
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=183, sigma=tensor([3.8626]), eta=tensor([3.1496])
  (fc1): CosineLinear(input_features=512, output_features=177, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 305
DataLoader CBF Constructed : Train 9
Optimizer Constructed
2022-03-24 03:03:59.325396
Epoch: [0][0/9], lr: 0.00050	Time 2.774 (2.774)	Data 1.824 (1.824)	Loss 0.0168 (0.0168)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8628], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1497], device='cuda:0', requires_grad=True)
2022-03-24 03:04:06.374311
Epoch: [1][0/9], lr: 0.00050	Time 2.847 (2.847)	Data 2.043 (2.043)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8629], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1497], device='cuda:0', requires_grad=True)
2022-03-24 03:04:13.635491
Epoch: [2][0/9], lr: 0.00050	Time 3.044 (3.044)	Data 2.308 (2.308)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8630], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1496], device='cuda:0', requires_grad=True)
2022-03-24 03:04:20.845244
Epoch: [3][0/9], lr: 0.00050	Time 2.916 (2.916)	Data 1.884 (1.884)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8629], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1495], device='cuda:0', requires_grad=True)
2022-03-24 03:04:27.856171
Epoch: [4][0/9], lr: 0.00050	Time 2.867 (2.867)	Data 2.118 (2.118)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8633], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1495], device='cuda:0', requires_grad=True)
2022-03-24 03:04:34.896548
Epoch: [5][0/9], lr: 0.00050	Time 2.908 (2.908)	Data 2.020 (2.020)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8635], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1495], device='cuda:0', requires_grad=True)
2022-03-24 03:04:41.927923
Epoch: [6][0/9], lr: 0.00050	Time 2.784 (2.784)	Data 1.935 (1.935)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8637], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1494], device='cuda:0', requires_grad=True)
2022-03-24 03:04:49.106804
Epoch: [7][0/9], lr: 0.00050	Time 3.030 (3.030)	Data 2.502 (2.502)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8637], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1492], device='cuda:0', requires_grad=True)
2022-03-24 03:04:55.968992
Epoch: [8][0/9], lr: 0.00050	Time 2.575 (2.575)	Data 1.834 (1.834)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8635], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1489], device='cuda:0', requires_grad=True)
2022-03-24 03:05:02.841979
Epoch: [9][0/9], lr: 0.00050	Time 2.873 (2.873)	Data 2.055 (2.055)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8629], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1484], device='cuda:0', requires_grad=True)
2022-03-24 03:05:09.787395
Epoch: [10][0/9], lr: 0.00050	Time 2.870 (2.870)	Data 2.267 (2.267)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8613], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1472], device='cuda:0', requires_grad=True)
2022-03-24 03:05:16.793463
Epoch: [11][0/9], lr: 0.00050	Time 2.790 (2.790)	Data 2.046 (2.046)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8601], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1464], device='cuda:0', requires_grad=True)
2022-03-24 03:05:23.875083
Epoch: [12][0/9], lr: 0.00050	Time 2.944 (2.944)	Data 2.382 (2.382)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8595], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1458], device='cuda:0', requires_grad=True)
2022-03-24 03:05:30.991617
Epoch: [13][0/9], lr: 0.00050	Time 2.982 (2.982)	Data 1.957 (1.957)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8591], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1455], device='cuda:0', requires_grad=True)
2022-03-24 03:05:38.059494
Epoch: [14][0/9], lr: 0.00050	Time 2.933 (2.933)	Data 2.357 (2.357)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8588], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1453], device='cuda:0', requires_grad=True)
2022-03-24 03:05:45.043941
Epoch: [15][0/9], lr: 0.00050	Time 2.870 (2.870)	Data 2.388 (2.388)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8586], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1451], device='cuda:0', requires_grad=True)
2022-03-24 03:05:52.028502
Epoch: [16][0/9], lr: 0.00050	Time 2.762 (2.762)	Data 2.009 (2.009)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1448], device='cuda:0', requires_grad=True)
2022-03-24 03:05:58.956343
Epoch: [17][0/9], lr: 0.00050	Time 2.864 (2.864)	Data 2.334 (2.334)	Loss 0.0127 (0.0127)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8588], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1448], device='cuda:0', requires_grad=True)
2022-03-24 03:06:05.376892
Epoch: [18][0/9], lr: 0.00050	Time 2.733 (2.733)	Data 2.048 (2.048)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8590], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1448], device='cuda:0', requires_grad=True)
2022-03-24 03:06:11.921363
Epoch: [19][0/9], lr: 0.00050	Time 2.894 (2.894)	Data 2.424 (2.424)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8590], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1447], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_005.pth.tar
exemplar : 305
Computing the class mean vectors...
Eval Task 0 for Age 5
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.851 (4.851)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.575 (0.556)	Prec@1 81.250 (70.421)
Testing Results: Prec@1 70.573
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (75.309)
Testing Results (NME): Prec@1 75.781
Eval Task 1 for Age 5
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.969 (3.969)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 68.657
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 67.164
Eval Task 2 for Age 5
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.000 (4.000)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 91.139
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 78.481
Eval Task 3 for Age 5
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.435 (4.435)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 91.765
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 85.882
Eval Task 4 for Age 5
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.597 (3.597)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 89.041
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 83.562
Eval Task 5 for Age 5
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.952 (3.952)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 98.718
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 89.744
num_test_videos [1920, 67, 79, 85, 73, 78]
Method : OURS
----AGE 6----
current_task  [83, 18]
current_head  63
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.055226805085936304]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=189, sigma=tensor([3.8590]), eta=tensor([3.1447])
  (fc1): CosineLinear(input_features=512, output_features=183, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 181
video number + exemplar : 486
DataLoader Constructed : Train 15
Optimizer Constructed
video number : 181
video number + exemplar : 181
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 03:09:43.368932
Epoch: [0][0/15], lr: 0.00100	Time 3.526 (3.526)	Data 2.149 (2.149)	Loss 0.2204 (0.2204)	Loss CE 0.1605 (0.1605)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5960 (0.5960)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8425], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 03:09:59.750085
Epoch: [1][0/15], lr: 0.00100	Time 3.560 (3.560)	Data 2.286 (2.286)	Loss 0.0856 (0.0856)	Loss CE 0.0258 (0.0258)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5955 (0.5955)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8352], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1308], device='cuda:0', requires_grad=True)
2022-03-24 03:10:16.795787
Epoch: [2][0/15], lr: 0.00100	Time 3.490 (3.490)	Data 2.302 (2.302)	Loss 0.0613 (0.0613)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5958 (0.5958)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8229], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 03:10:33.393691
Epoch: [3][0/15], lr: 0.00100	Time 3.404 (3.404)	Data 2.366 (2.366)	Loss 0.4636 (0.4636)	Loss CE 0.4024 (0.4024)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6085 (0.6085)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8183], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1225], device='cuda:0', requires_grad=True)
2022-03-24 03:10:50.085723
Epoch: [4][0/15], lr: 0.00100	Time 3.387 (3.387)	Data 2.105 (2.105)	Loss 0.1370 (0.1370)	Loss CE 0.0713 (0.0713)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6533 (0.6533)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8242], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1263], device='cuda:0', requires_grad=True)
2022-03-24 03:11:06.868433
Epoch: [5][0/15], lr: 0.00100	Time 3.455 (3.455)	Data 1.965 (1.965)	Loss 0.0744 (0.0744)	Loss CE 0.0080 (0.0080)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6600 (0.6600)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8293], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1295], device='cuda:0', requires_grad=True)
2022-03-24 03:11:23.838303
Epoch: [6][0/15], lr: 0.00100	Time 3.589 (3.589)	Data 2.697 (2.697)	Loss 0.0681 (0.0681)	Loss CE 0.0081 (0.0081)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5965 (0.5965)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8339], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1325], device='cuda:0', requires_grad=True)
2022-03-24 03:11:40.577573
Epoch: [7][0/15], lr: 0.00100	Time 3.338 (3.338)	Data 1.893 (1.893)	Loss 0.1279 (0.1279)	Loss CE 0.0687 (0.0687)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5890 (0.5890)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8353], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1337], device='cuda:0', requires_grad=True)
2022-03-24 03:11:57.165605
Epoch: [8][0/15], lr: 0.00100	Time 3.358 (3.358)	Data 2.243 (2.243)	Loss 0.0817 (0.0817)	Loss CE 0.0238 (0.0238)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5752 (0.5752)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8368], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1352], device='cuda:0', requires_grad=True)
2022-03-24 03:12:13.814521
Epoch: [9][0/15], lr: 0.00100	Time 3.420 (3.420)	Data 2.289 (2.289)	Loss 0.0705 (0.0705)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6393 (0.6393)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 03:12:30.738342
Epoch: [10][0/15], lr: 0.00100	Time 3.476 (3.476)	Data 2.152 (2.152)	Loss 0.0620 (0.0620)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6081 (0.6081)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8466], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1414], device='cuda:0', requires_grad=True)
2022-03-24 03:12:47.581662
Epoch: [11][0/15], lr: 0.00100	Time 3.591 (3.591)	Data 2.533 (2.533)	Loss 0.0654 (0.0654)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6286 (0.6286)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1434], device='cuda:0', requires_grad=True)
2022-03-24 03:13:04.230935
Epoch: [12][0/15], lr: 0.00100	Time 3.326 (3.326)	Data 2.110 (2.110)	Loss 0.0696 (0.0696)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6217 (0.6217)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1450], device='cuda:0', requires_grad=True)
2022-03-24 03:13:21.030945
Epoch: [13][0/15], lr: 0.00100	Time 3.534 (3.534)	Data 2.143 (2.143)	Loss 0.0863 (0.0863)	Loss CE 0.0267 (0.0267)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5924 (0.5924)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8561], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1469], device='cuda:0', requires_grad=True)
2022-03-24 03:13:37.754224
Epoch: [14][0/15], lr: 0.00100	Time 3.368 (3.368)	Data 1.993 (1.993)	Loss 0.0729 (0.0729)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6885 (0.6885)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8554], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1466], device='cuda:0', requires_grad=True)
2022-03-24 03:13:54.538089
Epoch: [15][0/15], lr: 0.00100	Time 3.495 (3.495)	Data 2.156 (2.156)	Loss 0.0633 (0.0633)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6189 (0.6189)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1478], device='cuda:0', requires_grad=True)
2022-03-24 03:14:11.168244
Epoch: [16][0/15], lr: 0.00100	Time 3.398 (3.398)	Data 2.103 (2.103)	Loss 0.0881 (0.0881)	Loss CE 0.0278 (0.0278)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5993 (0.5993)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8590], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1491], device='cuda:0', requires_grad=True)
2022-03-24 03:14:27.899091
Epoch: [17][0/15], lr: 0.00100	Time 3.515 (3.515)	Data 2.414 (2.414)	Loss 0.0659 (0.0659)	Loss CE 0.0095 (0.0095)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5601 (0.5601)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8609], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1497], device='cuda:0', requires_grad=True)
2022-03-24 03:14:44.841220
Epoch: [18][0/15], lr: 0.00100	Time 3.403 (3.403)	Data 2.222 (2.222)	Loss 0.0639 (0.0639)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6068 (0.6068)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8637], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1512], device='cuda:0', requires_grad=True)
2022-03-24 03:15:01.653658
Epoch: [19][0/15], lr: 0.00100	Time 3.297 (3.297)	Data 2.097 (2.097)	Loss 0.0622 (0.0622)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6092 (0.6092)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1526], device='cuda:0', requires_grad=True)
2022-03-24 03:15:17.333959
Epoch: [20][0/15], lr: 0.00010	Time 3.360 (3.360)	Data 2.337 (2.337)	Loss 0.0641 (0.0641)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6254 (0.6254)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8664], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1526], device='cuda:0', requires_grad=True)
2022-03-24 03:15:32.846235
Epoch: [21][0/15], lr: 0.00010	Time 3.308 (3.308)	Data 2.510 (2.510)	Loss 0.0608 (0.0608)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5918 (0.5918)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8666], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1528], device='cuda:0', requires_grad=True)
2022-03-24 03:15:48.947836
Epoch: [22][0/15], lr: 0.00010	Time 3.540 (3.540)	Data 2.700 (2.700)	Loss 0.0673 (0.0673)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6414 (0.6414)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8669], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1529], device='cuda:0', requires_grad=True)
2022-03-24 03:16:03.109770
Epoch: [23][0/15], lr: 0.00010	Time 3.289 (3.289)	Data 2.235 (2.235)	Loss 0.0719 (0.0719)	Loss CE 0.0085 (0.0085)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6300 (0.6300)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8670], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1530], device='cuda:0', requires_grad=True)
2022-03-24 03:16:17.158224
Epoch: [24][0/15], lr: 0.00010	Time 3.270 (3.270)	Data 2.489 (2.489)	Loss 0.0612 (0.0612)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6065 (0.6065)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8671], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1531], device='cuda:0', requires_grad=True)
2022-03-24 03:16:31.129753
Epoch: [25][0/15], lr: 0.00010	Time 3.281 (3.281)	Data 2.338 (2.338)	Loss 0.0728 (0.0728)	Loss CE 0.0121 (0.0121)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6025 (0.6025)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8673], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1532], device='cuda:0', requires_grad=True)
2022-03-24 03:16:44.983684
Epoch: [26][0/15], lr: 0.00010	Time 3.240 (3.240)	Data 1.975 (1.975)	Loss 0.0644 (0.0644)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6281 (0.6281)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8675], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1533], device='cuda:0', requires_grad=True)
2022-03-24 03:16:58.920999
Epoch: [27][0/15], lr: 0.00010	Time 3.080 (3.080)	Data 1.863 (1.863)	Loss 0.0596 (0.0596)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5852 (0.5852)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8677], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1533], device='cuda:0', requires_grad=True)
2022-03-24 03:17:13.109095
Epoch: [28][0/15], lr: 0.00010	Time 3.266 (3.266)	Data 2.068 (2.068)	Loss 0.0585 (0.0585)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5784 (0.5784)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8679], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1534], device='cuda:0', requires_grad=True)
2022-03-24 03:17:27.235085
Epoch: [29][0/15], lr: 0.00010	Time 3.175 (3.175)	Data 1.941 (1.941)	Loss 0.0685 (0.0685)	Loss CE 0.0086 (0.0086)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5954 (0.5954)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8680], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1535], device='cuda:0', requires_grad=True)
2022-03-24 03:17:41.589874
Epoch: [30][0/15], lr: 0.00001	Time 3.502 (3.502)	Data 2.619 (2.619)	Loss 0.0892 (0.0892)	Loss CE 0.0282 (0.0282)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6064 (0.6064)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8680], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1535], device='cuda:0', requires_grad=True)
2022-03-24 03:17:56.153381
Epoch: [31][0/15], lr: 0.00001	Time 3.281 (3.281)	Data 2.450 (2.450)	Loss 0.0627 (0.0627)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5847 (0.5847)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1535], device='cuda:0', requires_grad=True)
2022-03-24 03:18:10.481659
Epoch: [32][0/15], lr: 0.00001	Time 3.234 (3.234)	Data 2.315 (2.315)	Loss 0.0614 (0.0614)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5806 (0.5806)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1535], device='cuda:0', requires_grad=True)
2022-03-24 03:18:25.120926
Epoch: [33][0/15], lr: 0.00001	Time 3.401 (3.401)	Data 2.629 (2.629)	Loss 0.0605 (0.0605)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5922 (0.5922)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1535], device='cuda:0', requires_grad=True)
2022-03-24 03:18:39.450830
Epoch: [34][0/15], lr: 0.00001	Time 3.289 (3.289)	Data 2.506 (2.506)	Loss 0.0615 (0.0615)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5947 (0.5947)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1535], device='cuda:0', requires_grad=True)
2022-03-24 03:18:53.701758
Epoch: [35][0/15], lr: 0.00001	Time 3.153 (3.153)	Data 2.416 (2.416)	Loss 0.0686 (0.0686)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6209 (0.6209)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:19:08.086538
Epoch: [36][0/15], lr: 0.00001	Time 3.239 (3.239)	Data 2.347 (2.347)	Loss 0.0596 (0.0596)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5798 (0.5798)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:19:22.349896
Epoch: [37][0/15], lr: 0.00001	Time 3.275 (3.275)	Data 2.320 (2.320)	Loss 0.0613 (0.0613)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6025 (0.6025)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:19:36.526708
Epoch: [38][0/15], lr: 0.00001	Time 3.229 (3.229)	Data 2.203 (2.203)	Loss 0.0607 (0.0607)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5957 (0.5957)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:19:50.587815
Epoch: [39][0/15], lr: 0.00001	Time 3.146 (3.146)	Data 1.943 (1.943)	Loss 0.0629 (0.0629)	Loss CE 0.0074 (0.0074)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5503 (0.5503)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:20:04.688498
Epoch: [40][0/15], lr: 0.00001	Time 3.187 (3.187)	Data 2.399 (2.399)	Loss 0.0626 (0.0626)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6008 (0.6008)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:20:18.857991
Epoch: [41][0/15], lr: 0.00001	Time 3.100 (3.100)	Data 2.214 (2.214)	Loss 0.1686 (0.1686)	Loss CE 0.1093 (0.1093)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5898 (0.5898)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:20:32.088227
Epoch: [42][0/15], lr: 0.00001	Time 3.220 (3.220)	Data 2.396 (2.396)	Loss 0.0594 (0.0594)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5697 (0.5697)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8681], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:20:48.514464
Epoch: [43][0/15], lr: 0.00001	Time 3.314 (3.314)	Data 2.401 (2.401)	Loss 0.0617 (0.0617)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6122 (0.6122)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8682], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:21:05.606810
Epoch: [44][0/15], lr: 0.00001	Time 3.716 (3.716)	Data 2.324 (2.324)	Loss 0.0656 (0.0656)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6103 (0.6103)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8682], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:21:22.569332
Epoch: [45][0/15], lr: 0.00001	Time 3.311 (3.311)	Data 1.909 (1.909)	Loss 0.0608 (0.0608)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5996 (0.5996)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8682], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:21:39.014726
Epoch: [46][0/15], lr: 0.00001	Time 3.376 (3.376)	Data 2.444 (2.444)	Loss 0.0641 (0.0641)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6281 (0.6281)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8682], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:21:56.102102
Epoch: [47][0/15], lr: 0.00001	Time 3.485 (3.485)	Data 2.209 (2.209)	Loss 0.0599 (0.0599)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5888 (0.5888)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8682], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:22:12.809322
Epoch: [48][0/15], lr: 0.00001	Time 3.502 (3.502)	Data 2.230 (2.230)	Loss 0.0619 (0.0619)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6071 (0.6071)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8682], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:22:29.521528
Epoch: [49][0/15], lr: 0.00001	Time 3.378 (3.378)	Data 2.224 (2.224)	Loss 0.0622 (0.0622)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0010 (0.0010)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6095 (0.6095)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8682], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=189, sigma=tensor([3.8682]), eta=tensor([3.1536])
  (fc1): CosineLinear(input_features=512, output_features=183, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 181
video number + exemplar : 181
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=189, sigma=tensor([3.8682]), eta=tensor([3.1536])
  (fc1): CosineLinear(input_features=512, output_features=183, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 315
DataLoader CBF Constructed : Train 9
Optimizer Constructed
2022-03-24 03:23:01.303721
Epoch: [0][0/9], lr: 0.00050	Time 2.896 (2.896)	Data 2.058 (2.058)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8688], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1538], device='cuda:0', requires_grad=True)
2022-03-24 03:23:09.110368
Epoch: [1][0/9], lr: 0.00050	Time 2.903 (2.903)	Data 2.389 (2.389)	Loss 0.0176 (0.0176)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8696], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1542], device='cuda:0', requires_grad=True)
2022-03-24 03:23:17.090133
Epoch: [2][0/9], lr: 0.00050	Time 2.977 (2.977)	Data 2.088 (2.088)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8700], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1542], device='cuda:0', requires_grad=True)
2022-03-24 03:23:24.982342
Epoch: [3][0/9], lr: 0.00050	Time 3.057 (3.057)	Data 2.092 (2.092)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8704], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1543], device='cuda:0', requires_grad=True)
2022-03-24 03:23:32.556036
Epoch: [4][0/9], lr: 0.00050	Time 2.830 (2.830)	Data 2.322 (2.322)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8707], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1543], device='cuda:0', requires_grad=True)
2022-03-24 03:23:40.357583
Epoch: [5][0/9], lr: 0.00050	Time 2.954 (2.954)	Data 2.359 (2.359)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8710], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1544], device='cuda:0', requires_grad=True)
2022-03-24 03:23:47.633287
Epoch: [6][0/9], lr: 0.00050	Time 2.459 (2.459)	Data 1.810 (1.810)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8715], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1545], device='cuda:0', requires_grad=True)
2022-03-24 03:23:55.465544
Epoch: [7][0/9], lr: 0.00050	Time 2.947 (2.947)	Data 2.051 (2.051)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8720], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1545], device='cuda:0', requires_grad=True)
2022-03-24 03:24:03.468954
Epoch: [8][0/9], lr: 0.00050	Time 3.158 (3.158)	Data 2.280 (2.280)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8720], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1543], device='cuda:0', requires_grad=True)
2022-03-24 03:24:10.944905
Epoch: [9][0/9], lr: 0.00050	Time 2.847 (2.847)	Data 2.386 (2.386)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1536], device='cuda:0', requires_grad=True)
2022-03-24 03:24:18.762486
Epoch: [10][0/9], lr: 0.00050	Time 2.966 (2.966)	Data 2.136 (2.136)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8710], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1532], device='cuda:0', requires_grad=True)
2022-03-24 03:24:26.665771
Epoch: [11][0/9], lr: 0.00050	Time 3.053 (3.053)	Data 1.937 (1.937)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8709], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1530], device='cuda:0', requires_grad=True)
2022-03-24 03:24:34.728370
Epoch: [12][0/9], lr: 0.00050	Time 3.093 (3.093)	Data 2.120 (2.120)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8710], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1529], device='cuda:0', requires_grad=True)
2022-03-24 03:24:42.153932
Epoch: [13][0/9], lr: 0.00050	Time 2.697 (2.697)	Data 1.829 (1.829)	Loss 0.0139 (0.0139)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8711], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1527], device='cuda:0', requires_grad=True)
2022-03-24 03:24:50.004207
Epoch: [14][0/9], lr: 0.00050	Time 3.002 (3.002)	Data 1.960 (1.960)	Loss 0.0094 (0.0094)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1527], device='cuda:0', requires_grad=True)
2022-03-24 03:24:57.912531
Epoch: [15][0/9], lr: 0.00050	Time 3.053 (3.053)	Data 2.289 (2.289)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1526], device='cuda:0', requires_grad=True)
2022-03-24 03:25:05.850700
Epoch: [16][0/9], lr: 0.00050	Time 3.254 (3.254)	Data 2.551 (2.551)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8711], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1524], device='cuda:0', requires_grad=True)
2022-03-24 03:25:13.398251
Epoch: [17][0/9], lr: 0.00050	Time 2.728 (2.728)	Data 1.813 (1.813)	Loss 0.0036 (0.0036)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8704], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1518], device='cuda:0', requires_grad=True)
2022-03-24 03:25:21.280417
Epoch: [18][0/9], lr: 0.00050	Time 3.069 (3.069)	Data 2.139 (2.139)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8703], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1516], device='cuda:0', requires_grad=True)
2022-03-24 03:25:29.205323
Epoch: [19][0/9], lr: 0.00050	Time 3.107 (3.107)	Data 1.934 (1.934)	Loss 0.0042 (0.0042)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8707], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1517], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_006.pth.tar
exemplar : 315
Computing the class mean vectors...
Eval Task 0 for Age 6
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.246 (4.246)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.391 (0.551)	Prec@1 87.500 (68.193)
Testing Results: Prec@1 68.698
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (73.453)
Testing Results (NME): Prec@1 73.698
Eval Task 1 for Age 6
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.967 (3.967)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 65.672
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 70.149
Eval Task 2 for Age 6
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.259 (4.259)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 86.076
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 83.544
Eval Task 3 for Age 6
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.666 (3.666)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 90.588
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 85.882
Eval Task 4 for Age 6
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 4.198 (4.198)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 80.822
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 73.973
Eval Task 5 for Age 6
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.160 (4.160)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 96.154
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 89.744
Eval Task 6 for Age 6
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.337 (3.337)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 98.507
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 89.552
num_test_videos [1920, 67, 79, 85, 73, 78, 67]
Method : OURS
----AGE 7----
current_task  [99, 19]
current_head  65
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.056124860801609125]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=195, sigma=tensor([3.8707]), eta=tensor([3.1517])
  (fc1): CosineLinear(input_features=512, output_features=189, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 202
video number + exemplar : 517
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 202
video number + exemplar : 202
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 03:29:10.793433
Epoch: [0][0/16], lr: 0.00100	Time 3.458 (3.458)	Data 2.101 (2.101)	Loss 0.1028 (0.1028)	Loss CE 0.0400 (0.0400)	Loss KD (Logit) 0.0031 (0.0031)	Loss KD (GCAM) 0.0012 (0.0012)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6222 (0.6222)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1399], device='cuda:0', requires_grad=True)
2022-03-24 03:29:27.198264
Epoch: [1][0/16], lr: 0.00100	Time 3.399 (3.399)	Data 2.211 (2.211)	Loss 0.1277 (0.1277)	Loss CE 0.0641 (0.0641)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0022 (0.0022)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6278 (0.6278)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8260], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1250], device='cuda:0', requires_grad=True)
2022-03-24 03:29:43.326598
Epoch: [2][0/16], lr: 0.00100	Time 3.248 (3.248)	Data 2.289 (2.289)	Loss 0.2593 (0.2593)	Loss CE 0.1923 (0.1923)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0027 (0.0027)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6599 (0.6599)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8063], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1127], device='cuda:0', requires_grad=True)
2022-03-24 03:29:59.726433
Epoch: [3][0/16], lr: 0.00100	Time 3.358 (3.358)	Data 2.321 (2.321)	Loss 0.0750 (0.0750)	Loss CE 0.0117 (0.0117)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0034 (0.0034)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6204 (0.6204)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7915], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1030], device='cuda:0', requires_grad=True)
2022-03-24 03:30:14.356931
Epoch: [4][0/16], lr: 0.00100	Time 3.196 (3.196)	Data 2.100 (2.100)	Loss 0.1864 (0.1864)	Loss CE 0.1200 (0.1200)	Loss KD (Logit) 0.0035 (0.0035)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6499 (0.6499)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.7835], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0990], device='cuda:0', requires_grad=True)
2022-03-24 03:30:29.110815
Epoch: [5][0/16], lr: 0.00100	Time 3.274 (3.274)	Data 2.351 (2.351)	Loss 0.0720 (0.0720)	Loss CE 0.0057 (0.0057)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0032 (0.0032)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6512 (0.6512)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7844], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0996], device='cuda:0', requires_grad=True)
2022-03-24 03:30:43.889985
Epoch: [6][0/16], lr: 0.00100	Time 3.305 (3.305)	Data 2.099 (2.099)	Loss 0.0709 (0.0709)	Loss CE 0.0101 (0.0101)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5973 (0.5973)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7894], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1024], device='cuda:0', requires_grad=True)
2022-03-24 03:30:58.754362
Epoch: [7][0/16], lr: 0.00100	Time 3.271 (3.271)	Data 2.420 (2.420)	Loss 0.0660 (0.0660)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6376 (0.6376)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.7955], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1056], device='cuda:0', requires_grad=True)
2022-03-24 03:31:13.692110
Epoch: [8][0/16], lr: 0.00100	Time 3.614 (3.614)	Data 2.478 (2.478)	Loss 0.0952 (0.0952)	Loss CE 0.0300 (0.0300)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6408 (0.6408)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8006], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1084], device='cuda:0', requires_grad=True)
2022-03-24 03:31:28.414715
Epoch: [9][0/16], lr: 0.00100	Time 3.229 (3.229)	Data 2.246 (2.246)	Loss 0.0697 (0.0697)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0035 (0.0035)	Loss KD (GCAM) 0.0034 (0.0034)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6548 (0.6548)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8042], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1105], device='cuda:0', requires_grad=True)
2022-03-24 03:31:43.333448
Epoch: [10][0/16], lr: 0.00100	Time 3.309 (3.309)	Data 2.331 (2.331)	Loss 0.0657 (0.0657)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0032 (0.0032)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6302 (0.6302)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8072], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1123], device='cuda:0', requires_grad=True)
2022-03-24 03:31:58.391827
Epoch: [11][0/16], lr: 0.00100	Time 3.359 (3.359)	Data 2.190 (2.190)	Loss 0.0694 (0.0694)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0032 (0.0032)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6738 (0.6738)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8095], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1134], device='cuda:0', requires_grad=True)
2022-03-24 03:32:13.935619
Epoch: [12][0/16], lr: 0.00100	Time 3.682 (3.682)	Data 2.879 (2.879)	Loss 0.0706 (0.0706)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0032 (0.0032)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6744 (0.6744)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8125], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 03:32:29.070604
Epoch: [13][0/16], lr: 0.00100	Time 3.427 (3.427)	Data 2.576 (2.576)	Loss 0.0676 (0.0676)	Loss CE 0.0057 (0.0057)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6075 (0.6075)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8166], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1176], device='cuda:0', requires_grad=True)
2022-03-24 03:32:44.125589
Epoch: [14][0/16], lr: 0.00100	Time 3.390 (3.390)	Data 2.262 (2.262)	Loss 0.0834 (0.0834)	Loss CE 0.0163 (0.0163)	Loss KD (Logit) 0.0035 (0.0035)	Loss KD (GCAM) 0.0032 (0.0032)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6599 (0.6599)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8197], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1195], device='cuda:0', requires_grad=True)
2022-03-24 03:32:59.030450
Epoch: [15][0/16], lr: 0.00100	Time 3.299 (3.299)	Data 1.883 (1.883)	Loss 0.0689 (0.0689)	Loss CE 0.0080 (0.0080)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0032 (0.0032)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5979 (0.5979)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8232], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1213], device='cuda:0', requires_grad=True)
2022-03-24 03:33:13.840813
Epoch: [16][0/16], lr: 0.00100	Time 3.228 (3.228)	Data 2.024 (2.024)	Loss 0.0636 (0.0636)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0032 (0.0032)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6211 (0.6211)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8252], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1223], device='cuda:0', requires_grad=True)
2022-03-24 03:33:29.296628
Epoch: [17][0/16], lr: 0.00100	Time 3.538 (3.538)	Data 2.577 (2.577)	Loss 0.0693 (0.0693)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6334 (0.6334)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8263], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1228], device='cuda:0', requires_grad=True)
2022-03-24 03:33:44.291947
Epoch: [18][0/16], lr: 0.00100	Time 3.330 (3.330)	Data 2.029 (2.029)	Loss 0.0685 (0.0685)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6624 (0.6624)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8285], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1238], device='cuda:0', requires_grad=True)
2022-03-24 03:33:59.487910
Epoch: [19][0/16], lr: 0.00100	Time 3.497 (3.497)	Data 2.587 (2.587)	Loss 0.0674 (0.0674)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6331 (0.6331)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8305], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:34:14.724869
Epoch: [20][0/16], lr: 0.00010	Time 3.344 (3.344)	Data 2.322 (2.322)	Loss 0.0644 (0.0644)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0035 (0.0035)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6220 (0.6220)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8305], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:34:29.731140
Epoch: [21][0/16], lr: 0.00010	Time 3.213 (3.213)	Data 2.032 (2.032)	Loss 0.0661 (0.0661)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6426 (0.6426)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8305], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 03:34:44.342119
Epoch: [22][0/16], lr: 0.00010	Time 3.179 (3.179)	Data 2.297 (2.297)	Loss 0.0672 (0.0672)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6488 (0.6488)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8305], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 03:34:59.770354
Epoch: [23][0/16], lr: 0.00010	Time 3.673 (3.673)	Data 2.592 (2.592)	Loss 0.0644 (0.0644)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0028 (0.0028)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6303 (0.6303)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 03:35:17.496928
Epoch: [24][0/16], lr: 0.00010	Time 3.340 (3.340)	Data 2.064 (2.064)	Loss 0.0671 (0.0671)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6242 (0.6242)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 03:35:35.088825
Epoch: [25][0/16], lr: 0.00010	Time 3.471 (3.471)	Data 2.065 (2.065)	Loss 0.0648 (0.0648)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6334 (0.6334)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8308], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:35:53.065567
Epoch: [26][0/16], lr: 0.00010	Time 3.515 (3.515)	Data 2.093 (2.093)	Loss 0.0656 (0.0656)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6263 (0.6263)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8309], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:36:10.979823
Epoch: [27][0/16], lr: 0.00010	Time 3.530 (3.530)	Data 2.245 (2.245)	Loss 0.0794 (0.0794)	Loss CE 0.0151 (0.0151)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6314 (0.6314)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8309], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:36:28.852912
Epoch: [28][0/16], lr: 0.00010	Time 3.613 (3.613)	Data 2.427 (2.427)	Loss 0.0651 (0.0651)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6346 (0.6346)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8309], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:36:46.630374
Epoch: [29][0/16], lr: 0.00010	Time 3.308 (3.308)	Data 2.000 (2.000)	Loss 0.0653 (0.0653)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6347 (0.6347)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:37:04.350958
Epoch: [30][0/16], lr: 0.00001	Time 3.468 (3.468)	Data 1.943 (1.943)	Loss 0.0616 (0.0616)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6004 (0.6004)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:37:22.301957
Epoch: [31][0/16], lr: 0.00001	Time 3.830 (3.830)	Data 2.347 (2.347)	Loss 0.0682 (0.0682)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6679 (0.6679)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:37:39.650653
Epoch: [32][0/16], lr: 0.00001	Time 3.191 (3.191)	Data 1.892 (1.892)	Loss 0.0648 (0.0648)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0028 (0.0028)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6238 (0.6238)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:37:57.207109
Epoch: [33][0/16], lr: 0.00001	Time 3.414 (3.414)	Data 2.039 (2.039)	Loss 0.0638 (0.0638)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6215 (0.6215)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:38:14.598117
Epoch: [34][0/16], lr: 0.00001	Time 3.506 (3.506)	Data 2.166 (2.166)	Loss 0.0693 (0.0693)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6762 (0.6762)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:38:31.933581
Epoch: [35][0/16], lr: 0.00001	Time 3.276 (3.276)	Data 2.026 (2.026)	Loss 0.0644 (0.0644)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0028 (0.0028)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6308 (0.6308)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:38:49.861749
Epoch: [36][0/16], lr: 0.00001	Time 3.628 (3.628)	Data 2.231 (2.231)	Loss 0.0669 (0.0669)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0028 (0.0028)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6576 (0.6576)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:39:07.681992
Epoch: [37][0/16], lr: 0.00001	Time 3.537 (3.537)	Data 2.375 (2.375)	Loss 0.1897 (0.1897)	Loss CE 0.1252 (0.1252)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6335 (0.6335)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:39:25.236932
Epoch: [38][0/16], lr: 0.00001	Time 3.272 (3.272)	Data 2.082 (2.082)	Loss 0.0620 (0.0620)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6071 (0.6071)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:39:43.120702
Epoch: [39][0/16], lr: 0.00001	Time 3.448 (3.448)	Data 2.586 (2.586)	Loss 0.0667 (0.0667)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6452 (0.6452)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:40:00.811972
Epoch: [40][0/16], lr: 0.00001	Time 3.470 (3.470)	Data 1.958 (1.958)	Loss 0.0602 (0.0602)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5794 (0.5794)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:40:18.269177
Epoch: [41][0/16], lr: 0.00001	Time 3.201 (3.201)	Data 1.919 (1.919)	Loss 0.0689 (0.0689)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6201 (0.6201)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:40:35.370429
Epoch: [42][0/16], lr: 0.00001	Time 3.237 (3.237)	Data 2.328 (2.328)	Loss 0.0623 (0.0623)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5948 (0.5948)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:40:52.939747
Epoch: [43][0/16], lr: 0.00001	Time 3.401 (3.401)	Data 1.951 (1.951)	Loss 0.0647 (0.0647)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6313 (0.6313)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:41:10.452121
Epoch: [44][0/16], lr: 0.00001	Time 3.341 (3.341)	Data 1.936 (1.936)	Loss 0.0676 (0.0676)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6622 (0.6622)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:41:28.098138
Epoch: [45][0/16], lr: 0.00001	Time 3.371 (3.371)	Data 1.950 (1.950)	Loss 0.0642 (0.0642)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0034 (0.0034)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6271 (0.6271)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:41:45.703782
Epoch: [46][0/16], lr: 0.00001	Time 3.535 (3.535)	Data 2.242 (2.242)	Loss 0.0650 (0.0650)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0028 (0.0028)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6347 (0.6347)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:42:03.599450
Epoch: [47][0/16], lr: 0.00001	Time 3.698 (3.698)	Data 2.703 (2.703)	Loss 0.0675 (0.0675)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6417 (0.6417)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:42:21.654562
Epoch: [48][0/16], lr: 0.00001	Time 3.787 (3.787)	Data 2.605 (2.605)	Loss 0.0792 (0.0792)	Loss CE 0.0150 (0.0150)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6316 (0.6316)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:42:39.439430
Epoch: [49][0/16], lr: 0.00001	Time 3.515 (3.515)	Data 2.175 (2.175)	Loss 0.0686 (0.0686)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0033 (0.0033)	Loss KD (GCAM) 0.0029 (0.0029)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6700 (0.6700)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8311], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=195, sigma=tensor([3.8311]), eta=tensor([3.1248])
  (fc1): CosineLinear(input_features=512, output_features=189, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 202
video number + exemplar : 202
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=195, sigma=tensor([3.8311]), eta=tensor([3.1248])
  (fc1): CosineLinear(input_features=512, output_features=189, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 325
DataLoader CBF Constructed : Train 10
Optimizer Constructed
2022-03-24 03:43:13.148859
Epoch: [0][0/10], lr: 0.00050	Time 3.218 (3.218)	Data 2.147 (2.147)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8314], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1249], device='cuda:0', requires_grad=True)
2022-03-24 03:43:21.693854
Epoch: [1][0/10], lr: 0.00050	Time 2.965 (2.965)	Data 1.836 (1.836)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8320], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1252], device='cuda:0', requires_grad=True)
2022-03-24 03:43:30.263570
Epoch: [2][0/10], lr: 0.00050	Time 3.231 (3.231)	Data 2.459 (2.459)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8325], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1253], device='cuda:0', requires_grad=True)
2022-03-24 03:43:38.485340
Epoch: [3][0/10], lr: 0.00050	Time 2.928 (2.928)	Data 1.898 (1.898)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8327], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1253], device='cuda:0', requires_grad=True)
2022-03-24 03:43:46.913616
Epoch: [4][0/10], lr: 0.00050	Time 3.007 (3.007)	Data 2.494 (2.494)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8329], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1252], device='cuda:0', requires_grad=True)
2022-03-24 03:43:55.181055
Epoch: [5][0/10], lr: 0.00050	Time 2.844 (2.844)	Data 2.024 (2.024)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8330], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1251], device='cuda:0', requires_grad=True)
2022-03-24 03:44:03.204173
Epoch: [6][0/10], lr: 0.00050	Time 3.203 (3.203)	Data 2.564 (2.564)	Loss 0.0188 (0.0188)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8331], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1250], device='cuda:0', requires_grad=True)
2022-03-24 03:44:10.672196
Epoch: [7][0/10], lr: 0.00050	Time 2.916 (2.916)	Data 1.909 (1.909)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8333], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1249], device='cuda:0', requires_grad=True)
2022-03-24 03:44:18.127938
Epoch: [8][0/10], lr: 0.00050	Time 2.913 (2.913)	Data 2.413 (2.413)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8335], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1249], device='cuda:0', requires_grad=True)
2022-03-24 03:44:25.315009
Epoch: [9][0/10], lr: 0.00050	Time 2.683 (2.683)	Data 1.837 (1.837)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8337], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1249], device='cuda:0', requires_grad=True)
2022-03-24 03:44:33.034845
Epoch: [10][0/10], lr: 0.00050	Time 3.034 (3.034)	Data 2.380 (2.380)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8341], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1250], device='cuda:0', requires_grad=True)
2022-03-24 03:44:40.544268
Epoch: [11][0/10], lr: 0.00050	Time 2.927 (2.927)	Data 2.352 (2.352)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8347], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1252], device='cuda:0', requires_grad=True)
2022-03-24 03:44:48.107243
Epoch: [12][0/10], lr: 0.00050	Time 2.977 (2.977)	Data 2.099 (2.099)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1252], device='cuda:0', requires_grad=True)
2022-03-24 03:44:55.482320
Epoch: [13][0/10], lr: 0.00050	Time 2.858 (2.858)	Data 2.381 (2.381)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1251], device='cuda:0', requires_grad=True)
2022-03-24 03:45:03.151451
Epoch: [14][0/10], lr: 0.00050	Time 3.105 (3.105)	Data 2.204 (2.204)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8348], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 03:45:10.615760
Epoch: [15][0/10], lr: 0.00050	Time 2.844 (2.844)	Data 2.042 (2.042)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 03:45:18.103800
Epoch: [16][0/10], lr: 0.00050	Time 2.933 (2.933)	Data 2.077 (2.077)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8351], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 03:45:25.606808
Epoch: [17][0/10], lr: 0.00050	Time 2.993 (2.993)	Data 2.341 (2.341)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8351], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1243], device='cuda:0', requires_grad=True)
2022-03-24 03:45:32.903661
Epoch: [18][0/10], lr: 0.00050	Time 2.784 (2.784)	Data 2.028 (2.028)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8349], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1241], device='cuda:0', requires_grad=True)
2022-03-24 03:45:40.653433
Epoch: [19][0/10], lr: 0.00050	Time 3.221 (3.221)	Data 2.236 (2.236)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8348], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1238], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_007.pth.tar
exemplar : 325
Computing the class mean vectors...
Eval Task 0 for Age 7
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 3.617 (3.617)	Prec@1 56.250 (56.250)
Test: [100/120]	Time 0.382 (0.510)	Prec@1 93.750 (67.265)
Testing Results: Prec@1 67.500
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (72.030)
Testing Results (NME): Prec@1 72.135
Eval Task 1 for Age 7
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.195 (3.195)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 41.791
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 59.701
Eval Task 2 for Age 7
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.053 (4.053)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 88.608
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 77.215
Eval Task 3 for Age 7
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.048 (4.048)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 88.235
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 87.059
Eval Task 4 for Age 7
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.944 (3.944)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 82.192
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Test: [0/5]	Time 3.801 (3.801)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 96.154
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 88.462
Eval Task 6 for Age 7
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.870 (3.870)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 95.522
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 85.075
Eval Task 7 for Age 7
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.451 (4.451)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.765
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 92.593
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81]
Method : OURS
----AGE 8----
current_task  [36, 10]
current_head  67
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.057008771254956896]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=201, sigma=tensor([3.8348]), eta=tensor([3.1238])
  (fc1): CosineLinear(input_features=512, output_features=195, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 196
video number + exemplar : 521
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 196
video number + exemplar : 196
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 03:49:24.052208
Epoch: [0][0/16], lr: 0.00100	Time 3.755 (3.755)	Data 2.343 (2.343)	Loss 0.0778 (0.0778)	Loss CE 0.0164 (0.0164)	Loss KD (Logit) 0.0004 (0.0004)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6125 (0.6125)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8361], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 03:49:41.039403
Epoch: [1][0/16], lr: 0.00100	Time 3.132 (3.132)	Data 1.905 (1.905)	Loss 0.0645 (0.0645)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6346 (0.6346)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8257], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1187], device='cuda:0', requires_grad=True)
2022-03-24 03:49:58.992557
Epoch: [2][0/16], lr: 0.00100	Time 3.458 (3.458)	Data 2.022 (2.022)	Loss 0.0683 (0.0683)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0003 (0.0003)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6498 (0.6498)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8177], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1140], device='cuda:0', requires_grad=True)
2022-03-24 03:50:16.820209
Epoch: [3][0/16], lr: 0.00100	Time 3.540 (3.540)	Data 2.068 (2.068)	Loss 0.0584 (0.0584)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5433 (0.5433)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1109], device='cuda:0', requires_grad=True)
2022-03-24 03:50:34.706664
Epoch: [4][0/16], lr: 0.00100	Time 3.391 (3.391)	Data 2.280 (2.280)	Loss 0.0758 (0.0758)	Loss CE 0.0119 (0.0119)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6369 (0.6369)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8121], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1108], device='cuda:0', requires_grad=True)
2022-03-24 03:50:52.797284
Epoch: [5][0/16], lr: 0.00100	Time 3.566 (3.566)	Data 2.025 (2.025)	Loss 0.0812 (0.0812)	Loss CE 0.0166 (0.0166)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6443 (0.6443)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8172], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1139], device='cuda:0', requires_grad=True)
2022-03-24 03:51:10.400095
Epoch: [6][0/16], lr: 0.00100	Time 3.260 (3.260)	Data 2.416 (2.416)	Loss 0.0760 (0.0760)	Loss CE 0.0148 (0.0148)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6098 (0.6098)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8198], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1156], device='cuda:0', requires_grad=True)
2022-03-24 03:51:28.211895
Epoch: [7][0/16], lr: 0.00100	Time 3.397 (3.397)	Data 1.900 (1.900)	Loss 0.0916 (0.0916)	Loss CE 0.0283 (0.0283)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6312 (0.6312)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1171], device='cuda:0', requires_grad=True)
2022-03-24 03:51:45.616573
Epoch: [8][0/16], lr: 0.00100	Time 3.397 (3.397)	Data 2.543 (2.543)	Loss 0.0724 (0.0724)	Loss CE 0.0140 (0.0140)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5829 (0.5829)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8246], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1185], device='cuda:0', requires_grad=True)
2022-03-24 03:52:03.182787
Epoch: [9][0/16], lr: 0.00100	Time 3.493 (3.493)	Data 2.002 (2.002)	Loss 0.0606 (0.0606)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5940 (0.5940)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8264], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1197], device='cuda:0', requires_grad=True)
2022-03-24 03:52:21.354585
Epoch: [10][0/16], lr: 0.00100	Time 3.892 (3.892)	Data 2.702 (2.702)	Loss 0.0704 (0.0704)	Loss CE 0.0087 (0.0087)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6155 (0.6155)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8279], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1206], device='cuda:0', requires_grad=True)
2022-03-24 03:52:39.586615
Epoch: [11][0/16], lr: 0.00100	Time 3.736 (3.736)	Data 2.608 (2.608)	Loss 0.0804 (0.0804)	Loss CE 0.0190 (0.0190)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6121 (0.6121)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8302], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1218], device='cuda:0', requires_grad=True)
2022-03-24 03:52:57.480392
Epoch: [12][0/16], lr: 0.00100	Time 3.652 (3.652)	Data 2.158 (2.158)	Loss 0.1175 (0.1175)	Loss CE 0.0555 (0.0555)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6184 (0.6184)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8320], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1225], device='cuda:0', requires_grad=True)
2022-03-24 03:53:15.445911
Epoch: [13][0/16], lr: 0.00100	Time 3.557 (3.557)	Data 2.243 (2.243)	Loss 0.0683 (0.0683)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6655 (0.6655)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8314], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1219], device='cuda:0', requires_grad=True)
2022-03-24 03:53:33.282666
Epoch: [14][0/16], lr: 0.00100	Time 3.536 (3.536)	Data 2.601 (2.601)	Loss 0.0601 (0.0601)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5857 (0.5857)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8323], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1225], device='cuda:0', requires_grad=True)
2022-03-24 03:53:51.058225
Epoch: [15][0/16], lr: 0.00100	Time 3.217 (3.217)	Data 2.141 (2.141)	Loss 0.0668 (0.0668)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6386 (0.6386)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8339], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1235], device='cuda:0', requires_grad=True)
2022-03-24 03:54:08.798460
Epoch: [16][0/16], lr: 0.00100	Time 3.447 (3.447)	Data 2.205 (2.205)	Loss 0.0597 (0.0597)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5885 (0.5885)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8347], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1236], device='cuda:0', requires_grad=True)
2022-03-24 03:54:26.806215
Epoch: [17][0/16], lr: 0.00100	Time 3.513 (3.513)	Data 2.335 (2.335)	Loss 0.0630 (0.0630)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6141 (0.6141)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8359], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
2022-03-24 03:54:44.884847
Epoch: [18][0/16], lr: 0.00100	Time 3.715 (3.715)	Data 2.600 (2.600)	Loss 0.0624 (0.0624)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6132 (0.6132)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8382], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1252], device='cuda:0', requires_grad=True)
2022-03-24 03:55:02.627056
Epoch: [19][0/16], lr: 0.00100	Time 3.403 (3.403)	Data 1.991 (1.991)	Loss 0.0660 (0.0660)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6075 (0.6075)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1252], device='cuda:0', requires_grad=True)
2022-03-24 03:55:19.964805
Epoch: [20][0/16], lr: 0.00010	Time 3.301 (3.301)	Data 2.071 (2.071)	Loss 0.0655 (0.0655)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6309 (0.6309)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8388], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1253], device='cuda:0', requires_grad=True)
2022-03-24 03:55:37.700909
Epoch: [21][0/16], lr: 0.00010	Time 3.604 (3.604)	Data 2.181 (2.181)	Loss 0.0649 (0.0649)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6402 (0.6402)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8390], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1254], device='cuda:0', requires_grad=True)
2022-03-24 03:55:55.467440
Epoch: [22][0/16], lr: 0.00010	Time 3.250 (3.250)	Data 2.338 (2.338)	Loss 0.0697 (0.0697)	Loss CE 0.0044 (0.0044)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6512 (0.6512)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8393], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1255], device='cuda:0', requires_grad=True)
2022-03-24 03:56:13.354700
Epoch: [23][0/16], lr: 0.00010	Time 3.673 (3.673)	Data 2.817 (2.817)	Loss 0.0642 (0.0642)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5990 (0.5990)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8395], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1257], device='cuda:0', requires_grad=True)
2022-03-24 03:56:31.353656
Epoch: [24][0/16], lr: 0.00010	Time 3.586 (3.586)	Data 2.365 (2.365)	Loss 0.0654 (0.0654)	Loss CE 0.0057 (0.0057)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5956 (0.5956)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8397], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1257], device='cuda:0', requires_grad=True)
2022-03-24 03:56:48.756521
Epoch: [25][0/16], lr: 0.00010	Time 3.231 (3.231)	Data 2.048 (2.048)	Loss 0.0609 (0.0609)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6011 (0.6011)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8399], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1258], device='cuda:0', requires_grad=True)
2022-03-24 03:57:06.630213
Epoch: [26][0/16], lr: 0.00010	Time 3.418 (3.418)	Data 1.943 (1.943)	Loss 0.0622 (0.0622)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6149 (0.6149)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8398], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1258], device='cuda:0', requires_grad=True)
2022-03-24 03:57:24.453051
Epoch: [27][0/16], lr: 0.00010	Time 3.596 (3.596)	Data 2.057 (2.057)	Loss 0.0690 (0.0690)	Loss CE 0.0072 (0.0072)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6161 (0.6161)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8400], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:57:42.663924
Epoch: [28][0/16], lr: 0.00010	Time 3.681 (3.681)	Data 2.643 (2.643)	Loss 0.0648 (0.0648)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5908 (0.5908)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:58:00.773986
Epoch: [29][0/16], lr: 0.00010	Time 3.718 (3.718)	Data 2.396 (2.396)	Loss 0.0634 (0.0634)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6293 (0.6293)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:58:17.426622
Epoch: [30][0/16], lr: 0.00001	Time 3.119 (3.119)	Data 1.946 (1.946)	Loss 0.0668 (0.0668)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6359 (0.6359)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:58:33.758267
Epoch: [31][0/16], lr: 0.00001	Time 3.288 (3.288)	Data 2.047 (2.047)	Loss 0.0638 (0.0638)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6321 (0.6321)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:58:50.013433
Epoch: [32][0/16], lr: 0.00001	Time 3.407 (3.407)	Data 2.527 (2.527)	Loss 0.0657 (0.0657)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6489 (0.6489)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:59:05.592992
Epoch: [33][0/16], lr: 0.00001	Time 3.381 (3.381)	Data 2.061 (2.061)	Loss 0.0624 (0.0624)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6150 (0.6150)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:59:20.527357
Epoch: [34][0/16], lr: 0.00001	Time 3.159 (3.159)	Data 1.931 (1.931)	Loss 0.0596 (0.0596)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5919 (0.5919)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:59:35.444982
Epoch: [35][0/16], lr: 0.00001	Time 3.134 (3.134)	Data 1.986 (1.986)	Loss 0.0619 (0.0619)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6031 (0.6031)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 03:59:50.307687
Epoch: [36][0/16], lr: 0.00001	Time 3.214 (3.214)	Data 2.000 (2.000)	Loss 0.0642 (0.0642)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6367 (0.6367)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:00:05.241812
Epoch: [37][0/16], lr: 0.00001	Time 3.267 (3.267)	Data 2.211 (2.211)	Loss 0.0635 (0.0635)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6235 (0.6235)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:00:19.696649
Epoch: [38][0/16], lr: 0.00001	Time 3.184 (3.184)	Data 2.258 (2.258)	Loss 0.0621 (0.0621)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6155 (0.6155)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:00:34.539274
Epoch: [39][0/16], lr: 0.00001	Time 3.298 (3.298)	Data 2.419 (2.419)	Loss 0.0658 (0.0658)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6231 (0.6231)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:00:49.536049
Epoch: [40][0/16], lr: 0.00001	Time 3.327 (3.327)	Data 2.098 (2.098)	Loss 0.0639 (0.0639)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6292 (0.6292)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:01:04.761797
Epoch: [41][0/16], lr: 0.00001	Time 3.308 (3.308)	Data 2.236 (2.236)	Loss 0.0625 (0.0625)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6222 (0.6222)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:01:19.766255
Epoch: [42][0/16], lr: 0.00001	Time 3.303 (3.303)	Data 2.426 (2.426)	Loss 0.0605 (0.0605)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6004 (0.6004)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:01:34.907942
Epoch: [43][0/16], lr: 0.00001	Time 3.404 (3.404)	Data 2.323 (2.323)	Loss 0.0633 (0.0633)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6208 (0.6208)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:01:49.905524
Epoch: [44][0/16], lr: 0.00001	Time 3.245 (3.245)	Data 2.212 (2.212)	Loss 0.0669 (0.0669)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6164 (0.6164)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:02:05.015416
Epoch: [45][0/16], lr: 0.00001	Time 3.206 (3.206)	Data 2.075 (2.075)	Loss 0.0637 (0.0637)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6306 (0.6306)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:02:20.055014
Epoch: [46][0/16], lr: 0.00001	Time 3.197 (3.197)	Data 2.394 (2.394)	Loss 0.0663 (0.0663)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6518 (0.6518)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:02:34.951603
Epoch: [47][0/16], lr: 0.00001	Time 3.171 (3.171)	Data 1.904 (1.904)	Loss 0.0595 (0.0595)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5826 (0.5826)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8404], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:02:50.142744
Epoch: [48][0/16], lr: 0.00001	Time 3.439 (3.439)	Data 2.336 (2.336)	Loss 0.0654 (0.0654)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6338 (0.6338)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8404], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:03:05.058179
Epoch: [49][0/16], lr: 0.00001	Time 3.200 (3.200)	Data 2.057 (2.057)	Loss 0.0598 (0.0598)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5901 (0.5901)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8404], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=201, sigma=tensor([3.8404]), eta=tensor([3.1260])
  (fc1): CosineLinear(input_features=512, output_features=195, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 196
video number + exemplar : 196
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=201, sigma=tensor([3.8404]), eta=tensor([3.1260])
  (fc1): CosineLinear(input_features=512, output_features=195, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 335
DataLoader CBF Constructed : Train 10
Optimizer Constructed
2022-03-24 04:03:34.591260
Epoch: [0][0/10], lr: 0.00050	Time 2.796 (2.796)	Data 2.076 (2.076)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8405], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:03:41.863058
Epoch: [1][0/10], lr: 0.00050	Time 3.049 (3.049)	Data 2.511 (2.511)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8409], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1261], device='cuda:0', requires_grad=True)
2022-03-24 04:03:49.355941
Epoch: [2][0/10], lr: 0.00050	Time 3.003 (3.003)	Data 1.976 (1.976)	Loss 0.0077 (0.0077)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8418], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1265], device='cuda:0', requires_grad=True)
2022-03-24 04:03:57.717626
Epoch: [3][0/10], lr: 0.00050	Time 3.065 (3.065)	Data 2.344 (2.344)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8427], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1270], device='cuda:0', requires_grad=True)
2022-03-24 04:04:05.913430
Epoch: [4][0/10], lr: 0.00050	Time 2.944 (2.944)	Data 2.456 (2.456)	Loss 0.0061 (0.0061)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8434], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1272], device='cuda:0', requires_grad=True)
2022-03-24 04:04:14.238618
Epoch: [5][0/10], lr: 0.00050	Time 2.974 (2.974)	Data 2.489 (2.489)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8436], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1272], device='cuda:0', requires_grad=True)
2022-03-24 04:04:22.657238
Epoch: [6][0/10], lr: 0.00050	Time 3.043 (3.043)	Data 1.930 (1.930)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8439], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1272], device='cuda:0', requires_grad=True)
2022-03-24 04:04:30.778768
Epoch: [7][0/10], lr: 0.00050	Time 2.918 (2.918)	Data 2.259 (2.259)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1271], device='cuda:0', requires_grad=True)
2022-03-24 04:04:39.138288
Epoch: [8][0/10], lr: 0.00050	Time 2.957 (2.957)	Data 2.196 (2.196)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1271], device='cuda:0', requires_grad=True)
2022-03-24 04:04:47.484247
Epoch: [9][0/10], lr: 0.00050	Time 2.970 (2.970)	Data 1.990 (1.990)	Loss 0.0030 (0.0030)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8439], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1267], device='cuda:0', requires_grad=True)
2022-03-24 04:04:55.997202
Epoch: [10][0/10], lr: 0.00050	Time 3.093 (3.093)	Data 2.516 (2.516)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8439], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1266], device='cuda:0', requires_grad=True)
2022-03-24 04:05:04.157555
Epoch: [11][0/10], lr: 0.00050	Time 2.925 (2.925)	Data 2.330 (2.330)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8440], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1265], device='cuda:0', requires_grad=True)
2022-03-24 04:05:12.312419
Epoch: [12][0/10], lr: 0.00050	Time 2.854 (2.854)	Data 1.859 (1.859)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8442], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1264], device='cuda:0', requires_grad=True)
2022-03-24 04:05:20.572230
Epoch: [13][0/10], lr: 0.00050	Time 2.946 (2.946)	Data 1.894 (1.894)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8441], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1262], device='cuda:0', requires_grad=True)
2022-03-24 04:05:28.963853
Epoch: [14][0/10], lr: 0.00050	Time 3.020 (3.020)	Data 2.002 (2.002)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8439], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1259], device='cuda:0', requires_grad=True)
2022-03-24 04:05:37.400875
Epoch: [15][0/10], lr: 0.00050	Time 3.104 (3.104)	Data 2.057 (2.057)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8438], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1257], device='cuda:0', requires_grad=True)
2022-03-24 04:05:45.733494
Epoch: [16][0/10], lr: 0.00050	Time 3.125 (3.125)	Data 2.324 (2.324)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8422], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 04:05:54.028734
Epoch: [17][0/10], lr: 0.00050	Time 3.032 (3.032)	Data 1.963 (1.963)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
2022-03-24 04:06:02.372405
Epoch: [18][0/10], lr: 0.00050	Time 3.030 (3.030)	Data 1.904 (1.904)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1237], device='cuda:0', requires_grad=True)
2022-03-24 04:06:10.646874
Epoch: [19][0/10], lr: 0.00050	Time 2.905 (2.905)	Data 1.893 (1.893)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1236], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_008.pth.tar
exemplar : 335
Computing the class mean vectors...
Eval Task 0 for Age 8
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.074 (5.074)	Prec@1 68.750 (68.750)
Test: [100/120]	Time 0.425 (0.560)	Prec@1 87.500 (66.399)
Testing Results: Prec@1 66.771
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (71.473)
Testing Results (NME): Prec@1 71.875
Eval Task 1 for Age 8
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.600 (3.600)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 49.254
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 50.746
Eval Task 2 for Age 8
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.007 (4.007)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 88.608
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 73.418
Eval Task 3 for Age 8
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.296 (3.296)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 78.824
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 84.706
Eval Task 4 for Age 8
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 4.540 (4.540)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 79.452
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 71.233
Eval Task 5 for Age 8
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.235 (4.235)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 94.872
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 88.462
Eval Task 6 for Age 8
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.903 (3.903)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 56.716
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 73.134
Eval Task 7 for Age 8
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.318 (3.318)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 88.889
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 91.358
Eval Task 8 for Age 8
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.431 (3.431)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 96.970
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 80.303
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66]
Method : OURS
----AGE 9----
current_task  [25, 93]
current_head  69
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05787918451395113]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=207, sigma=tensor([3.8410]), eta=tensor([3.1236])
  (fc1): CosineLinear(input_features=512, output_features=201, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 192
video number + exemplar : 527
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 192
video number + exemplar : 192
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 04:10:20.129767
Epoch: [0][0/16], lr: 0.00100	Time 3.583 (3.583)	Data 1.846 (1.846)	Loss 0.0894 (0.0894)	Loss CE 0.0308 (0.0308)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5846 (0.5846)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8390], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1232], device='cuda:0', requires_grad=True)
2022-03-24 04:10:37.826303
Epoch: [1][0/16], lr: 0.00100	Time 3.778 (3.778)	Data 2.495 (2.495)	Loss 0.0844 (0.0844)	Loss CE 0.0183 (0.0183)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6596 (0.6596)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8408], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1243], device='cuda:0', requires_grad=True)
2022-03-24 04:10:55.286296
Epoch: [2][0/16], lr: 0.00100	Time 3.299 (3.299)	Data 1.930 (1.930)	Loss 0.0626 (0.0626)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5911 (0.5911)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8465], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1275], device='cuda:0', requires_grad=True)
2022-03-24 04:11:13.330281
Epoch: [3][0/16], lr: 0.00100	Time 3.699 (3.699)	Data 2.572 (2.572)	Loss 0.1366 (0.1366)	Loss CE 0.0798 (0.0798)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5648 (0.5648)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1248], device='cuda:0', requires_grad=True)
2022-03-24 04:11:31.142864
Epoch: [4][0/16], lr: 0.00100	Time 3.437 (3.437)	Data 1.961 (1.961)	Loss 0.0792 (0.0792)	Loss CE 0.0187 (0.0187)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6030 (0.6030)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8360], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1217], device='cuda:0', requires_grad=True)
2022-03-24 04:11:48.574882
Epoch: [5][0/16], lr: 0.00100	Time 3.180 (3.180)	Data 2.093 (2.093)	Loss 0.1969 (0.1969)	Loss CE 0.1373 (0.1373)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5936 (0.5936)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8319], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1194], device='cuda:0', requires_grad=True)
2022-03-24 04:12:06.335305
Epoch: [6][0/16], lr: 0.00100	Time 3.847 (3.847)	Data 2.239 (2.239)	Loss 0.0665 (0.0665)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6374 (0.6374)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8342], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1203], device='cuda:0', requires_grad=True)
2022-03-24 04:12:23.650128
Epoch: [7][0/16], lr: 0.00100	Time 3.303 (3.303)	Data 2.152 (2.152)	Loss 0.0637 (0.0637)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6221 (0.6221)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8387], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1231], device='cuda:0', requires_grad=True)
2022-03-24 04:12:39.694294
Epoch: [8][0/16], lr: 0.00100	Time 3.357 (3.357)	Data 2.246 (2.246)	Loss 0.0595 (0.0595)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5617 (0.5617)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8432], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1258], device='cuda:0', requires_grad=True)
2022-03-24 04:12:55.751988
Epoch: [9][0/16], lr: 0.00100	Time 3.367 (3.367)	Data 2.414 (2.414)	Loss 0.0622 (0.0622)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5947 (0.5947)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8448], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1266], device='cuda:0', requires_grad=True)
2022-03-24 04:13:11.950042
Epoch: [10][0/16], lr: 0.00100	Time 3.207 (3.207)	Data 1.977 (1.977)	Loss 0.0633 (0.0633)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6237 (0.6237)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8450], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1267], device='cuda:0', requires_grad=True)
2022-03-24 04:13:26.831995
Epoch: [11][0/16], lr: 0.00100	Time 3.249 (3.249)	Data 2.085 (2.085)	Loss 0.0707 (0.0707)	Loss CE 0.0126 (0.0126)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0009 (0.0009)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5780 (0.5780)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8474], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1282], device='cuda:0', requires_grad=True)
2022-03-24 04:13:41.725507
Epoch: [12][0/16], lr: 0.00100	Time 3.352 (3.352)	Data 2.586 (2.586)	Loss 0.0709 (0.0709)	Loss CE 0.0060 (0.0060)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6460 (0.6460)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8461], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1272], device='cuda:0', requires_grad=True)
2022-03-24 04:13:56.535978
Epoch: [13][0/16], lr: 0.00100	Time 3.328 (3.328)	Data 2.585 (2.585)	Loss 0.0687 (0.0687)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6144 (0.6144)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8460], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1268], device='cuda:0', requires_grad=True)
2022-03-24 04:14:11.419306
Epoch: [14][0/16], lr: 0.00100	Time 3.262 (3.262)	Data 2.218 (2.218)	Loss 0.0597 (0.0597)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5886 (0.5886)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8471], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1272], device='cuda:0', requires_grad=True)
2022-03-24 04:14:26.144498
Epoch: [15][0/16], lr: 0.00100	Time 3.229 (3.229)	Data 2.096 (2.096)	Loss 0.0604 (0.0604)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5962 (0.5962)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1276], device='cuda:0', requires_grad=True)
2022-03-24 04:14:40.800831
Epoch: [16][0/16], lr: 0.00100	Time 3.283 (3.283)	Data 2.354 (2.354)	Loss 0.0622 (0.0622)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5987 (0.5987)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8493], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1280], device='cuda:0', requires_grad=True)
2022-03-24 04:14:56.058579
Epoch: [17][0/16], lr: 0.00100	Time 3.624 (3.624)	Data 2.642 (2.642)	Loss 0.0623 (0.0623)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6088 (0.6088)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1282], device='cuda:0', requires_grad=True)
2022-03-24 04:15:11.782136
Epoch: [18][0/16], lr: 0.00100	Time 3.652 (3.652)	Data 2.769 (2.769)	Loss 0.0593 (0.0593)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5653 (0.5653)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8508], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1283], device='cuda:0', requires_grad=True)
2022-03-24 04:15:26.989187
Epoch: [19][0/16], lr: 0.00100	Time 3.192 (3.192)	Data 1.929 (1.929)	Loss 0.0624 (0.0624)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6198 (0.6198)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8517], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:15:42.153258
Epoch: [20][0/16], lr: 0.00010	Time 3.319 (3.319)	Data 2.177 (2.177)	Loss 0.0574 (0.0574)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5637 (0.5637)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:15:57.464144
Epoch: [21][0/16], lr: 0.00010	Time 3.390 (3.390)	Data 2.145 (2.145)	Loss 0.0617 (0.0617)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6120 (0.6120)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1285], device='cuda:0', requires_grad=True)
2022-03-24 04:16:12.542178
Epoch: [22][0/16], lr: 0.00010	Time 3.389 (3.389)	Data 2.378 (2.378)	Loss 0.0616 (0.0616)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5643 (0.5643)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:16:27.477330
Epoch: [23][0/16], lr: 0.00010	Time 3.470 (3.470)	Data 2.556 (2.556)	Loss 0.0583 (0.0583)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5752 (0.5752)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8519], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:16:42.547939
Epoch: [24][0/16], lr: 0.00010	Time 3.260 (3.260)	Data 2.087 (2.087)	Loss 0.0607 (0.0607)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8520], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:16:57.816565
Epoch: [25][0/16], lr: 0.00010	Time 3.311 (3.311)	Data 2.383 (2.383)	Loss 0.0607 (0.0607)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6022 (0.6022)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8521], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1287], device='cuda:0', requires_grad=True)
2022-03-24 04:17:13.218698
Epoch: [26][0/16], lr: 0.00010	Time 3.252 (3.252)	Data 2.361 (2.361)	Loss 0.0588 (0.0588)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5835 (0.5835)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1287], device='cuda:0', requires_grad=True)
2022-03-24 04:17:28.499468
Epoch: [27][0/16], lr: 0.00010	Time 3.357 (3.357)	Data 2.086 (2.086)	Loss 0.0579 (0.0579)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5615 (0.5615)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1287], device='cuda:0', requires_grad=True)
2022-03-24 04:17:43.052831
Epoch: [28][0/16], lr: 0.00010	Time 3.151 (3.151)	Data 1.986 (1.986)	Loss 0.0561 (0.0561)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5539 (0.5539)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:17:57.569580
Epoch: [29][0/16], lr: 0.00010	Time 3.434 (3.434)	Data 2.148 (2.148)	Loss 0.0737 (0.0737)	Loss CE 0.0146 (0.0146)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5882 (0.5882)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:18:15.083664
Epoch: [30][0/16], lr: 0.00001	Time 3.237 (3.237)	Data 2.257 (2.257)	Loss 0.0615 (0.0615)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6064 (0.6064)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:18:32.819325
Epoch: [31][0/16], lr: 0.00001	Time 3.483 (3.483)	Data 1.886 (1.886)	Loss 0.0621 (0.0621)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6092 (0.6092)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:18:50.982296
Epoch: [32][0/16], lr: 0.00001	Time 3.859 (3.859)	Data 2.460 (2.460)	Loss 0.0622 (0.0622)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:19:08.722287
Epoch: [33][0/16], lr: 0.00001	Time 3.585 (3.585)	Data 2.467 (2.467)	Loss 0.0612 (0.0612)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6080 (0.6080)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:19:26.516151
Epoch: [34][0/16], lr: 0.00001	Time 3.406 (3.406)	Data 2.165 (2.165)	Loss 0.0635 (0.0635)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6083 (0.6083)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:19:44.475764
Epoch: [35][0/16], lr: 0.00001	Time 3.568 (3.568)	Data 2.397 (2.397)	Loss 0.0600 (0.0600)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5931 (0.5931)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:20:02.220204
Epoch: [36][0/16], lr: 0.00001	Time 3.257 (3.257)	Data 2.240 (2.240)	Loss 0.0620 (0.0620)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5910 (0.5910)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:20:19.991746
Epoch: [37][0/16], lr: 0.00001	Time 3.633 (3.633)	Data 2.166 (2.166)	Loss 0.0598 (0.0598)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5850 (0.5850)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:20:38.058885
Epoch: [38][0/16], lr: 0.00001	Time 3.610 (3.610)	Data 2.252 (2.252)	Loss 0.0612 (0.0612)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6043 (0.6043)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:20:56.034407
Epoch: [39][0/16], lr: 0.00001	Time 3.567 (3.567)	Data 1.962 (1.962)	Loss 0.0607 (0.0607)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5789 (0.5789)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:21:13.514679
Epoch: [40][0/16], lr: 0.00001	Time 3.252 (3.252)	Data 2.119 (2.119)	Loss 0.0626 (0.0626)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6203 (0.6203)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:21:31.260718
Epoch: [41][0/16], lr: 0.00001	Time 3.558 (3.558)	Data 2.158 (2.158)	Loss 0.0605 (0.0605)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5692 (0.5692)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:21:49.161945
Epoch: [42][0/16], lr: 0.00001	Time 3.513 (3.513)	Data 1.907 (1.907)	Loss 0.0681 (0.0681)	Loss CE 0.0094 (0.0094)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5845 (0.5845)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:22:06.505339
Epoch: [43][0/16], lr: 0.00001	Time 3.176 (3.176)	Data 1.931 (1.931)	Loss 0.0612 (0.0612)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6026 (0.6026)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:22:24.181396
Epoch: [44][0/16], lr: 0.00001	Time 3.488 (3.488)	Data 2.327 (2.327)	Loss 0.0604 (0.0604)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5974 (0.5974)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:22:41.739002
Epoch: [45][0/16], lr: 0.00001	Time 3.227 (3.227)	Data 2.050 (2.050)	Loss 0.0652 (0.0652)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6476 (0.6476)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:22:59.613453
Epoch: [46][0/16], lr: 0.00001	Time 3.596 (3.596)	Data 2.006 (2.006)	Loss 0.0585 (0.0585)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5620 (0.5620)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:23:17.408609
Epoch: [47][0/16], lr: 0.00001	Time 3.439 (3.439)	Data 2.088 (2.088)	Loss 0.0608 (0.0608)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5940 (0.5940)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:23:34.835287
Epoch: [48][0/16], lr: 0.00001	Time 3.365 (3.365)	Data 2.073 (2.073)	Loss 0.0633 (0.0633)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5939 (0.5939)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 04:23:52.549168
Epoch: [49][0/16], lr: 0.00001	Time 3.576 (3.576)	Data 2.158 (2.158)	Loss 0.0582 (0.0582)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0006 (0.0006)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5756 (0.5756)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=207, sigma=tensor([3.8523]), eta=tensor([3.1286])
  (fc1): CosineLinear(input_features=512, output_features=201, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 192
video number + exemplar : 192
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=207, sigma=tensor([3.8523]), eta=tensor([3.1286])
  (fc1): CosineLinear(input_features=512, output_features=201, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 345
DataLoader CBF Constructed : Train 10
Optimizer Constructed
2022-03-24 04:24:25.579282
Epoch: [0][0/10], lr: 0.00050	Time 2.953 (2.953)	Data 1.951 (1.951)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1284], device='cuda:0', requires_grad=True)
2022-03-24 04:24:33.933304
Epoch: [1][0/10], lr: 0.00050	Time 2.912 (2.912)	Data 2.304 (2.304)	Loss 0.0049 (0.0049)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8519], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1281], device='cuda:0', requires_grad=True)
2022-03-24 04:24:42.257075
Epoch: [2][0/10], lr: 0.00050	Time 3.037 (3.037)	Data 2.008 (2.008)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8512], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1276], device='cuda:0', requires_grad=True)
2022-03-24 04:24:50.568923
Epoch: [3][0/10], lr: 0.00050	Time 2.860 (2.860)	Data 1.890 (1.890)	Loss 0.0071 (0.0071)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8516], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1277], device='cuda:0', requires_grad=True)
2022-03-24 04:24:58.879997
Epoch: [4][0/10], lr: 0.00050	Time 3.004 (3.004)	Data 2.040 (2.040)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8512], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1274], device='cuda:0', requires_grad=True)
2022-03-24 04:25:07.490214
Epoch: [5][0/10], lr: 0.00050	Time 3.167 (3.167)	Data 2.208 (2.208)	Loss 0.0121 (0.0121)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1271], device='cuda:0', requires_grad=True)
2022-03-24 04:25:16.202797
Epoch: [6][0/10], lr: 0.00050	Time 3.153 (3.153)	Data 2.225 (2.225)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1270], device='cuda:0', requires_grad=True)
2022-03-24 04:25:24.788299
Epoch: [7][0/10], lr: 0.00050	Time 3.136 (3.136)	Data 2.220 (2.220)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8512], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1270], device='cuda:0', requires_grad=True)
2022-03-24 04:25:33.117561
Epoch: [8][0/10], lr: 0.00050	Time 3.018 (3.018)	Data 2.109 (2.109)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1269], device='cuda:0', requires_grad=True)
2022-03-24 04:25:41.441859
Epoch: [9][0/10], lr: 0.00050	Time 3.056 (3.056)	Data 2.350 (2.350)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8512], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1267], device='cuda:0', requires_grad=True)
2022-03-24 04:25:49.778318
Epoch: [10][0/10], lr: 0.00050	Time 3.032 (3.032)	Data 2.078 (2.078)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8514], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1266], device='cuda:0', requires_grad=True)
2022-03-24 04:25:58.193266
Epoch: [11][0/10], lr: 0.00050	Time 2.822 (2.822)	Data 2.016 (2.016)	Loss 0.0085 (0.0085)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8517], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1266], device='cuda:0', requires_grad=True)
2022-03-24 04:26:06.441658
Epoch: [12][0/10], lr: 0.00050	Time 2.960 (2.960)	Data 2.459 (2.459)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8517], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1264], device='cuda:0', requires_grad=True)
2022-03-24 04:26:14.852830
Epoch: [13][0/10], lr: 0.00050	Time 2.942 (2.942)	Data 2.253 (2.253)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8516], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1262], device='cuda:0', requires_grad=True)
2022-03-24 04:26:23.276728
Epoch: [14][0/10], lr: 0.00050	Time 3.046 (3.046)	Data 2.569 (2.569)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8519], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1261], device='cuda:0', requires_grad=True)
2022-03-24 04:26:32.246718
Epoch: [15][0/10], lr: 0.00050	Time 3.249 (3.249)	Data 2.410 (2.410)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:26:40.896666
Epoch: [16][0/10], lr: 0.00050	Time 3.240 (3.240)	Data 2.492 (2.492)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1258], device='cuda:0', requires_grad=True)
2022-03-24 04:26:49.209080
Epoch: [17][0/10], lr: 0.00050	Time 3.104 (3.104)	Data 2.009 (2.009)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8516], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1255], device='cuda:0', requires_grad=True)
2022-03-24 04:26:57.485124
Epoch: [18][0/10], lr: 0.00050	Time 3.055 (3.055)	Data 2.337 (2.337)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8514], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1252], device='cuda:0', requires_grad=True)
2022-03-24 04:27:05.013091
Epoch: [19][0/10], lr: 0.00050	Time 3.009 (3.009)	Data 2.225 (2.225)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1253], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_009.pth.tar
exemplar : 345
Computing the class mean vectors...
Eval Task 0 for Age 9
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.960 (4.960)	Prec@1 68.750 (68.750)
Test: [100/120]	Time 0.550 (0.487)	Prec@1 93.750 (67.512)
Testing Results: Prec@1 67.760
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (70.606)
Testing Results (NME): Prec@1 70.521
Eval Task 1 for Age 9
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.596 (3.596)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 71.642
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 62.687
Eval Task 2 for Age 9
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.819 (3.819)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 86.076
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 75.949
Eval Task 3 for Age 9
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.586 (3.586)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 82.353
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 84.706
Eval Task 4 for Age 9
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.981 (3.981)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 78.082
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 65.753
Eval Task 5 for Age 9
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.119 (4.119)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 94.872
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 88.462
Eval Task 6 for Age 9
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.146 (4.146)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 59.701
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 68.657
Eval Task 7 for Age 9
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.845 (3.845)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 88.889
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.123
Eval Task 8 for Age 9
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.840 (3.840)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 92.424
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 78.788
Eval Task 9 for Age 9
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.817 (3.817)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.104
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 87.013
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77]
Method : OURS
----AGE 10----
current_task  [41, 87]
current_head  71
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05873670062235365]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=213, sigma=tensor([3.8518]), eta=tensor([3.1253])
  (fc1): CosineLinear(input_features=512, output_features=207, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 208
video number + exemplar : 553
DataLoader Constructed : Train 17
Optimizer Constructed
video number : 208
video number + exemplar : 208
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 04:31:04.665941
Epoch: [0][0/17], lr: 0.00100	Time 3.359 (3.359)	Data 2.013 (2.013)	Loss 0.0587 (0.0587)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5694 (0.5694)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8344], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1147], device='cuda:0', requires_grad=True)
2022-03-24 04:31:20.033025
Epoch: [1][0/17], lr: 0.00100	Time 3.208 (3.208)	Data 2.089 (2.089)	Loss 0.1023 (0.1023)	Loss CE 0.0455 (0.0455)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0004 (0.0004)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5657 (0.5657)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8286], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1111], device='cuda:0', requires_grad=True)
2022-03-24 04:31:35.771352
Epoch: [2][0/17], lr: 0.00100	Time 3.443 (3.443)	Data 2.640 (2.640)	Loss 0.0640 (0.0640)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5791 (0.5791)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8283], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1108], device='cuda:0', requires_grad=True)
2022-03-24 04:31:50.738790
Epoch: [3][0/17], lr: 0.00100	Time 3.202 (3.202)	Data 2.267 (2.267)	Loss 0.0836 (0.0836)	Loss CE 0.0287 (0.0287)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5465 (0.5465)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8351], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1147], device='cuda:0', requires_grad=True)
2022-03-24 04:32:08.540719
Epoch: [4][0/17], lr: 0.00100	Time 3.499 (3.499)	Data 2.055 (2.055)	Loss 0.0587 (0.0587)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5724 (0.5724)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8362], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 04:32:26.877132
Epoch: [5][0/17], lr: 0.00100	Time 3.363 (3.363)	Data 2.133 (2.133)	Loss 0.0938 (0.0938)	Loss CE 0.0385 (0.0385)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5510 (0.5510)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8373], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1166], device='cuda:0', requires_grad=True)
2022-03-24 04:32:45.511569
Epoch: [6][0/17], lr: 0.00100	Time 3.382 (3.382)	Data 2.611 (2.611)	Loss 0.0582 (0.0582)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5543 (0.5543)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1174], device='cuda:0', requires_grad=True)
2022-03-24 04:33:04.233864
Epoch: [7][0/17], lr: 0.00100	Time 3.413 (3.413)	Data 1.903 (1.903)	Loss 0.0636 (0.0636)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6266 (0.6266)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1163], device='cuda:0', requires_grad=True)
2022-03-24 04:33:22.930381
Epoch: [8][0/17], lr: 0.00100	Time 3.721 (3.721)	Data 2.320 (2.320)	Loss 0.0771 (0.0771)	Loss CE 0.0208 (0.0208)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5604 (0.5604)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8388], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1173], device='cuda:0', requires_grad=True)
2022-03-24 04:33:41.818326
Epoch: [9][0/17], lr: 0.00100	Time 3.604 (3.604)	Data 2.301 (2.301)	Loss 0.0703 (0.0703)	Loss CE 0.0124 (0.0124)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5765 (0.5765)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8408], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1184], device='cuda:0', requires_grad=True)
2022-03-24 04:34:00.529741
Epoch: [10][0/17], lr: 0.00100	Time 3.523 (3.523)	Data 2.400 (2.400)	Loss 0.0584 (0.0584)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5782 (0.5782)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1184], device='cuda:0', requires_grad=True)
2022-03-24 04:34:18.888782
Epoch: [11][0/17], lr: 0.00100	Time 3.339 (3.339)	Data 2.152 (2.152)	Loss 0.1211 (0.1211)	Loss CE 0.0616 (0.0616)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5924 (0.5924)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8416], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1175], device='cuda:0', requires_grad=True)
2022-03-24 04:34:37.341419
Epoch: [12][0/17], lr: 0.00100	Time 3.378 (3.378)	Data 1.994 (1.994)	Loss 0.0586 (0.0586)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5802 (0.5802)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8438], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1184], device='cuda:0', requires_grad=True)
2022-03-24 04:34:55.688432
Epoch: [13][0/17], lr: 0.00100	Time 3.449 (3.449)	Data 2.188 (2.188)	Loss 0.0630 (0.0630)	Loss CE 0.0093 (0.0093)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5345 (0.5345)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8463], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1196], device='cuda:0', requires_grad=True)
2022-03-24 04:35:14.109042
Epoch: [14][0/17], lr: 0.00100	Time 3.456 (3.456)	Data 2.203 (2.203)	Loss 0.0581 (0.0581)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5493 (0.5493)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1192], device='cuda:0', requires_grad=True)
2022-03-24 04:35:32.617474
Epoch: [15][0/17], lr: 0.00100	Time 3.443 (3.443)	Data 2.450 (2.450)	Loss 0.0615 (0.0615)	Loss CE 0.0083 (0.0083)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5299 (0.5299)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8450], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1189], device='cuda:0', requires_grad=True)
2022-03-24 04:35:51.572140
Epoch: [16][0/17], lr: 0.00100	Time 3.654 (3.654)	Data 2.694 (2.694)	Loss 0.0589 (0.0589)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5707 (0.5707)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8371], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1134], device='cuda:0', requires_grad=True)
2022-03-24 04:36:10.372662
Epoch: [17][0/17], lr: 0.00100	Time 3.541 (3.541)	Data 2.450 (2.450)	Loss 0.0600 (0.0600)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5738 (0.5738)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8380], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1140], device='cuda:0', requires_grad=True)
2022-03-24 04:36:28.902719
Epoch: [18][0/17], lr: 0.00100	Time 3.256 (3.256)	Data 2.100 (2.100)	Loss 0.0574 (0.0574)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5431 (0.5431)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8399], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1152], device='cuda:0', requires_grad=True)
2022-03-24 04:36:47.519453
Epoch: [19][0/17], lr: 0.00100	Time 3.545 (3.545)	Data 2.313 (2.313)	Loss 0.0587 (0.0587)	Loss CE 0.0054 (0.0054)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5311 (0.5311)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8395], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1148], device='cuda:0', requires_grad=True)
2022-03-24 04:37:06.217198
Epoch: [20][0/17], lr: 0.00010	Time 3.500 (3.500)	Data 2.255 (2.255)	Loss 0.0613 (0.0613)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5488 (0.5488)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8396], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1149], device='cuda:0', requires_grad=True)
2022-03-24 04:37:24.691882
Epoch: [21][0/17], lr: 0.00010	Time 3.472 (3.472)	Data 2.146 (2.146)	Loss 0.0548 (0.0548)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5338 (0.5338)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8398], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1149], device='cuda:0', requires_grad=True)
2022-03-24 04:37:43.018944
Epoch: [22][0/17], lr: 0.00010	Time 3.494 (3.494)	Data 2.051 (2.051)	Loss 0.0635 (0.0635)	Loss CE 0.0060 (0.0060)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5731 (0.5731)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8399], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1150], device='cuda:0', requires_grad=True)
2022-03-24 04:38:01.464568
Epoch: [23][0/17], lr: 0.00010	Time 3.433 (3.433)	Data 2.064 (2.064)	Loss 0.0576 (0.0576)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5678 (0.5678)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8400], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1150], device='cuda:0', requires_grad=True)
2022-03-24 04:38:19.989603
Epoch: [24][0/17], lr: 0.00010	Time 3.479 (3.479)	Data 2.166 (2.166)	Loss 0.0578 (0.0578)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5565 (0.5565)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 04:38:38.586505
Epoch: [25][0/17], lr: 0.00010	Time 3.582 (3.582)	Data 2.618 (2.618)	Loss 0.0561 (0.0561)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5270 (0.5270)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8404], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1152], device='cuda:0', requires_grad=True)
2022-03-24 04:38:56.963818
Epoch: [26][0/17], lr: 0.00010	Time 3.166 (3.166)	Data 1.890 (1.890)	Loss 0.0554 (0.0554)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5502 (0.5502)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8406], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1153], device='cuda:0', requires_grad=True)
2022-03-24 04:39:15.507767
Epoch: [27][0/17], lr: 0.00010	Time 3.360 (3.360)	Data 2.345 (2.345)	Loss 0.0597 (0.0597)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5906 (0.5906)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8407], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1153], device='cuda:0', requires_grad=True)
2022-03-24 04:39:33.911366
Epoch: [28][0/17], lr: 0.00010	Time 3.311 (3.311)	Data 2.075 (2.075)	Loss 0.0689 (0.0689)	Loss CE 0.0143 (0.0143)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5441 (0.5441)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8409], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1154], device='cuda:0', requires_grad=True)
2022-03-24 04:39:52.306971
Epoch: [29][0/17], lr: 0.00010	Time 3.370 (3.370)	Data 2.413 (2.413)	Loss 0.0583 (0.0583)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5736 (0.5736)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:40:11.060077
Epoch: [30][0/17], lr: 0.00001	Time 3.533 (3.533)	Data 2.490 (2.490)	Loss 0.0589 (0.0589)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5634 (0.5634)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:40:30.006382
Epoch: [31][0/17], lr: 0.00001	Time 3.545 (3.545)	Data 2.510 (2.510)	Loss 0.0615 (0.0615)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5986 (0.5986)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:40:48.430850
Epoch: [32][0/17], lr: 0.00001	Time 3.306 (3.306)	Data 2.313 (2.313)	Loss 0.0688 (0.0688)	Loss CE 0.0113 (0.0113)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5726 (0.5726)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:41:07.160317
Epoch: [33][0/17], lr: 0.00001	Time 3.652 (3.652)	Data 2.452 (2.452)	Loss 0.0541 (0.0541)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5286 (0.5286)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:41:24.426671
Epoch: [34][0/17], lr: 0.00001	Time 3.427 (3.427)	Data 2.556 (2.556)	Loss 0.0532 (0.0532)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5225 (0.5225)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:41:41.843273
Epoch: [35][0/17], lr: 0.00001	Time 3.245 (3.245)	Data 2.066 (2.066)	Loss 0.0795 (0.0795)	Loss CE 0.0216 (0.0216)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5769 (0.5769)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:41:59.010860
Epoch: [36][0/17], lr: 0.00001	Time 3.373 (3.373)	Data 2.333 (2.333)	Loss 0.0550 (0.0550)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5373 (0.5373)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:42:14.338042
Epoch: [37][0/17], lr: 0.00001	Time 3.156 (3.156)	Data 2.013 (2.013)	Loss 0.0571 (0.0571)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5608 (0.5608)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:42:30.049861
Epoch: [38][0/17], lr: 0.00001	Time 3.454 (3.454)	Data 2.338 (2.338)	Loss 0.0577 (0.0577)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5674 (0.5674)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:42:45.670964
Epoch: [39][0/17], lr: 0.00001	Time 3.295 (3.295)	Data 2.388 (2.388)	Loss 0.0583 (0.0583)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5748 (0.5748)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:43:00.964557
Epoch: [40][0/17], lr: 0.00001	Time 3.202 (3.202)	Data 2.018 (2.018)	Loss 0.0613 (0.0613)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5727 (0.5727)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:43:16.542833
Epoch: [41][0/17], lr: 0.00001	Time 3.301 (3.301)	Data 2.441 (2.441)	Loss 0.0564 (0.0564)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5396 (0.5396)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:43:31.876902
Epoch: [42][0/17], lr: 0.00001	Time 3.313 (3.313)	Data 2.204 (2.204)	Loss 0.0586 (0.0586)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5556 (0.5556)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:43:47.685462
Epoch: [43][0/17], lr: 0.00001	Time 3.264 (3.264)	Data 2.099 (2.099)	Loss 0.0762 (0.0762)	Loss CE 0.0207 (0.0207)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5516 (0.5516)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:44:03.800161
Epoch: [44][0/17], lr: 0.00001	Time 3.430 (3.430)	Data 2.329 (2.329)	Loss 0.0562 (0.0562)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5529 (0.5529)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:44:19.614360
Epoch: [45][0/17], lr: 0.00001	Time 3.595 (3.595)	Data 2.205 (2.205)	Loss 0.0573 (0.0573)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5412 (0.5412)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:44:35.504178
Epoch: [46][0/17], lr: 0.00001	Time 3.530 (3.530)	Data 2.427 (2.427)	Loss 0.0614 (0.0614)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0006 (0.0006)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6000 (0.6000)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:44:51.408451
Epoch: [47][0/17], lr: 0.00001	Time 3.227 (3.227)	Data 2.267 (2.267)	Loss 0.0615 (0.0615)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6010 (0.6010)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:45:07.327539
Epoch: [48][0/17], lr: 0.00001	Time 3.352 (3.352)	Data 2.167 (2.167)	Loss 0.0657 (0.0657)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5994 (0.5994)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:45:23.390563
Epoch: [49][0/17], lr: 0.00001	Time 3.429 (3.429)	Data 2.546 (2.546)	Loss 0.0589 (0.0589)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0005 (0.0005)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5815 (0.5815)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8412], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=213, sigma=tensor([3.8412]), eta=tensor([3.1155])
  (fc1): CosineLinear(input_features=512, output_features=207, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 208
video number + exemplar : 208
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=213, sigma=tensor([3.8412]), eta=tensor([3.1155])
  (fc1): CosineLinear(input_features=512, output_features=207, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 355
DataLoader CBF Constructed : Train 11
Optimizer Constructed
2022-03-24 04:45:53.915235
Epoch: [0][0/11], lr: 0.00050	Time 2.832 (2.832)	Data 2.275 (2.275)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:46:02.083733
Epoch: [1][0/11], lr: 0.00050	Time 2.933 (2.933)	Data 2.249 (2.249)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8403], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1147], device='cuda:0', requires_grad=True)
2022-03-24 04:46:10.483567
Epoch: [2][0/11], lr: 0.00050	Time 3.065 (3.065)	Data 2.528 (2.528)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8407], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1147], device='cuda:0', requires_grad=True)
2022-03-24 04:46:18.691138
Epoch: [3][0/11], lr: 0.00050	Time 3.019 (3.019)	Data 2.353 (2.353)	Loss 0.0072 (0.0072)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1149], device='cuda:0', requires_grad=True)
2022-03-24 04:46:26.698807
Epoch: [4][0/11], lr: 0.00050	Time 2.862 (2.862)	Data 2.399 (2.399)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8419], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 04:46:34.193986
Epoch: [5][0/11], lr: 0.00050	Time 2.831 (2.831)	Data 2.159 (2.159)	Loss 0.0048 (0.0048)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8429], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:46:41.564105
Epoch: [6][0/11], lr: 0.00050	Time 2.880 (2.880)	Data 2.395 (2.395)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8433], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 04:46:49.676229
Epoch: [7][0/11], lr: 0.00050	Time 2.877 (2.877)	Data 2.016 (2.016)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8438], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1157], device='cuda:0', requires_grad=True)
2022-03-24 04:46:58.819793
Epoch: [8][0/11], lr: 0.00050	Time 3.124 (3.124)	Data 2.272 (2.272)	Loss 0.0046 (0.0046)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8446], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 04:47:07.755665
Epoch: [9][0/11], lr: 0.00050	Time 2.986 (2.986)	Data 2.176 (2.176)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8450], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1160], device='cuda:0', requires_grad=True)
2022-03-24 04:47:16.510184
Epoch: [10][0/11], lr: 0.00050	Time 2.702 (2.702)	Data 1.878 (1.878)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8454], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1160], device='cuda:0', requires_grad=True)
2022-03-24 04:47:25.574494
Epoch: [11][0/11], lr: 0.00050	Time 3.166 (3.166)	Data 2.419 (2.419)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8457], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1160], device='cuda:0', requires_grad=True)
2022-03-24 04:47:34.806185
Epoch: [12][0/11], lr: 0.00050	Time 2.872 (2.872)	Data 2.241 (2.241)	Loss 0.0040 (0.0040)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8465], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1162], device='cuda:0', requires_grad=True)
2022-03-24 04:47:43.896708
Epoch: [13][0/11], lr: 0.00050	Time 3.094 (3.094)	Data 2.383 (2.383)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8472], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1165], device='cuda:0', requires_grad=True)
2022-03-24 04:47:52.645813
Epoch: [14][0/11], lr: 0.00050	Time 2.942 (2.942)	Data 2.200 (2.200)	Loss 0.0092 (0.0092)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8478], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1165], device='cuda:0', requires_grad=True)
2022-03-24 04:48:01.868348
Epoch: [15][0/11], lr: 0.00050	Time 3.191 (3.191)	Data 2.326 (2.326)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8479], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1163], device='cuda:0', requires_grad=True)
2022-03-24 04:48:10.855608
Epoch: [16][0/11], lr: 0.00050	Time 3.065 (3.065)	Data 2.273 (2.273)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8479], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1161], device='cuda:0', requires_grad=True)
2022-03-24 04:48:19.416123
Epoch: [17][0/11], lr: 0.00050	Time 2.925 (2.925)	Data 2.176 (2.176)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8479], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1160], device='cuda:0', requires_grad=True)
2022-03-24 04:48:28.518576
Epoch: [18][0/11], lr: 0.00050	Time 3.099 (3.099)	Data 2.301 (2.301)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8478], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1157], device='cuda:0', requires_grad=True)
2022-03-24 04:48:37.556692
Epoch: [19][0/11], lr: 0.00050	Time 3.043 (3.043)	Data 2.398 (2.398)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8478], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_010.pth.tar
exemplar : 355
Computing the class mean vectors...
Eval Task 0 for Age 10
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.846 (4.846)	Prec@1 50.000 (50.000)
Test: [100/120]	Time 0.505 (0.548)	Prec@1 93.750 (66.399)
Testing Results: Prec@1 66.719
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (70.978)
Testing Results (NME): Prec@1 71.302
Eval Task 1 for Age 10
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.049 (4.049)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 65.672
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 61.194
Eval Task 2 for Age 10
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.019 (4.019)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 84.810
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 78.481
Eval Task 3 for Age 10
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.414 (4.414)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 82.353
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 82.353
Eval Task 4 for Age 10
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.816 (3.816)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 80.822
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 72.603
Eval Task 5 for Age 10
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.064 (4.064)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 88.462
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.615
Eval Task 6 for Age 10
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.096 (4.096)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 68.657
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 61.194
Eval Task 7 for Age 10
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.187 (4.187)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 88.889
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 88.889
Eval Task 8 for Age 10
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.135 (4.135)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 80.303
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 69.697
Eval Task 9 for Age 10
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.175 (4.175)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 90.909
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 87.013
Eval Task 10 for Age 10
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.443 (3.443)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.780
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.122
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82]
Method : OURS
----AGE 11----
current_task  [14, 38]
current_head  73
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.05958187643906492]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=219, sigma=tensor([3.8478]), eta=tensor([3.1155])
  (fc1): CosineLinear(input_features=512, output_features=213, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 188
video number + exemplar : 543
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 188
video number + exemplar : 188
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 04:53:11.055346
Epoch: [0][0/16], lr: 0.00100	Time 3.547 (3.547)	Data 1.874 (1.874)	Loss 0.1987 (0.1987)	Loss CE 0.1242 (0.1242)	Loss KD (Logit) 0.0676 (0.0676)	Loss KD (GCAM) 0.0241 (0.0241)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6326 (0.6326)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8402], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1108], device='cuda:0', requires_grad=True)
2022-03-24 04:53:28.095780
Epoch: [1][0/16], lr: 0.00100	Time 3.140 (3.140)	Data 1.827 (1.827)	Loss 0.0877 (0.0877)	Loss CE 0.0131 (0.0131)	Loss KD (Logit) 0.0708 (0.0708)	Loss KD (GCAM) 0.0315 (0.0315)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6102 (0.6102)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8413], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1115], device='cuda:0', requires_grad=True)
2022-03-24 04:53:45.817320
Epoch: [2][0/16], lr: 0.00100	Time 3.379 (3.379)	Data 2.461 (2.461)	Loss 0.1274 (0.1274)	Loss CE 0.0582 (0.0582)	Loss KD (Logit) 0.0713 (0.0713)	Loss KD (GCAM) 0.0284 (0.0284)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5650 (0.5650)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8392], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1102], device='cuda:0', requires_grad=True)
2022-03-24 04:54:03.506128
Epoch: [3][0/16], lr: 0.00100	Time 3.324 (3.324)	Data 2.206 (2.206)	Loss 0.0787 (0.0787)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0719 (0.0719)	Loss KD (GCAM) 0.0344 (0.0344)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6148 (0.6148)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8426], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1121], device='cuda:0', requires_grad=True)
2022-03-24 04:54:21.160848
Epoch: [4][0/16], lr: 0.00100	Time 3.443 (3.443)	Data 2.267 (2.267)	Loss 0.1169 (0.1169)	Loss CE 0.0367 (0.0367)	Loss KD (Logit) 0.0730 (0.0730)	Loss KD (GCAM) 0.0356 (0.0356)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6514 (0.6514)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8467], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1144], device='cuda:0', requires_grad=True)
2022-03-24 04:54:38.911784
Epoch: [5][0/16], lr: 0.00100	Time 3.659 (3.659)	Data 2.678 (2.678)	Loss 0.1359 (0.1359)	Loss CE 0.0611 (0.0611)	Loss KD (Logit) 0.0729 (0.0729)	Loss KD (GCAM) 0.0337 (0.0337)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6037 (0.6037)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8527], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1181], device='cuda:0', requires_grad=True)
2022-03-24 04:54:56.618327
Epoch: [6][0/16], lr: 0.00100	Time 3.275 (3.275)	Data 1.921 (1.921)	Loss 0.0796 (0.0796)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0709 (0.0709)	Loss KD (GCAM) 0.0363 (0.0363)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6187 (0.6187)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8546], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1198], device='cuda:0', requires_grad=True)
2022-03-24 04:55:14.373574
Epoch: [7][0/16], lr: 0.00100	Time 3.444 (3.444)	Data 2.512 (2.512)	Loss 0.0797 (0.0797)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0726 (0.0726)	Loss KD (GCAM) 0.0370 (0.0370)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5954 (0.5954)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8554], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1205], device='cuda:0', requires_grad=True)
2022-03-24 04:55:31.146024
Epoch: [8][0/16], lr: 0.00100	Time 3.450 (3.450)	Data 2.173 (2.173)	Loss 0.1358 (0.1358)	Loss CE 0.0608 (0.0608)	Loss KD (Logit) 0.0736 (0.0736)	Loss KD (GCAM) 0.0337 (0.0337)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6056 (0.6056)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1213], device='cuda:0', requires_grad=True)
2022-03-24 04:55:47.650522
Epoch: [9][0/16], lr: 0.00100	Time 3.360 (3.360)	Data 2.276 (2.276)	Loss 0.0806 (0.0806)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0728 (0.0728)	Loss KD (GCAM) 0.0328 (0.0328)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6435 (0.6435)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8544], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1193], device='cuda:0', requires_grad=True)
2022-03-24 04:56:04.224255
Epoch: [10][0/16], lr: 0.00100	Time 3.428 (3.428)	Data 2.407 (2.407)	Loss 0.1671 (0.1671)	Loss CE 0.0915 (0.0915)	Loss KD (Logit) 0.0727 (0.0727)	Loss KD (GCAM) 0.0330 (0.0330)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6139 (0.6139)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1197], device='cuda:0', requires_grad=True)
2022-03-24 04:56:19.142161
Epoch: [11][0/16], lr: 0.00100	Time 3.327 (3.327)	Data 2.251 (2.251)	Loss 0.0868 (0.0868)	Loss CE 0.0085 (0.0085)	Loss KD (Logit) 0.0705 (0.0705)	Loss KD (GCAM) 0.0367 (0.0367)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6305 (0.6305)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8605], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1228], device='cuda:0', requires_grad=True)
2022-03-24 04:56:33.809854
Epoch: [12][0/16], lr: 0.00100	Time 3.205 (3.205)	Data 2.090 (2.090)	Loss 0.0826 (0.0826)	Loss CE 0.0093 (0.0093)	Loss KD (Logit) 0.0723 (0.0723)	Loss KD (GCAM) 0.0349 (0.0349)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5851 (0.5851)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8652], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 04:56:48.457431
Epoch: [13][0/16], lr: 0.00100	Time 3.146 (3.146)	Data 1.911 (1.911)	Loss 0.0844 (0.0844)	Loss CE 0.0083 (0.0083)	Loss KD (Logit) 0.0720 (0.0720)	Loss KD (GCAM) 0.0369 (0.0369)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6066 (0.6066)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8680], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1279], device='cuda:0', requires_grad=True)
2022-03-24 04:57:03.788104
Epoch: [14][0/16], lr: 0.00100	Time 3.550 (3.550)	Data 2.614 (2.614)	Loss 0.0801 (0.0801)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0709 (0.0709)	Loss KD (GCAM) 0.0363 (0.0363)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6123 (0.6123)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8685], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1288], device='cuda:0', requires_grad=True)
2022-03-24 04:57:18.463783
Epoch: [15][0/16], lr: 0.00100	Time 3.167 (3.167)	Data 2.042 (2.042)	Loss 0.0761 (0.0761)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0716 (0.0716)	Loss KD (GCAM) 0.0389 (0.0389)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5938 (0.5938)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8685], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1292], device='cuda:0', requires_grad=True)
2022-03-24 04:57:33.179665
Epoch: [16][0/16], lr: 0.00100	Time 3.204 (3.204)	Data 2.219 (2.219)	Loss 0.0775 (0.0775)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0713 (0.0713)	Loss KD (GCAM) 0.0381 (0.0381)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6021 (0.6021)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8707], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1304], device='cuda:0', requires_grad=True)
2022-03-24 04:57:47.893229
Epoch: [17][0/16], lr: 0.00100	Time 3.167 (3.167)	Data 1.884 (1.884)	Loss 0.0791 (0.0791)	Loss CE 0.0086 (0.0086)	Loss KD (Logit) 0.0726 (0.0726)	Loss KD (GCAM) 0.0372 (0.0372)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5505 (0.5505)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8742], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1323], device='cuda:0', requires_grad=True)
2022-03-24 04:58:03.239381
Epoch: [18][0/16], lr: 0.00100	Time 3.503 (3.503)	Data 2.645 (2.645)	Loss 0.0803 (0.0803)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0725 (0.0725)	Loss KD (GCAM) 0.0360 (0.0360)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6464 (0.6464)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8778], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1343], device='cuda:0', requires_grad=True)
2022-03-24 04:58:18.754853
Epoch: [19][0/16], lr: 0.00100	Time 3.452 (3.452)	Data 2.573 (2.573)	Loss 0.0821 (0.0821)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0720 (0.0720)	Loss KD (GCAM) 0.0355 (0.0355)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6348 (0.6348)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8789], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1345], device='cuda:0', requires_grad=True)
2022-03-24 04:58:34.178292
Epoch: [20][0/16], lr: 0.00010	Time 3.325 (3.325)	Data 2.310 (2.310)	Loss 0.1197 (0.1197)	Loss CE 0.0421 (0.0421)	Loss KD (Logit) 0.0724 (0.0724)	Loss KD (GCAM) 0.0373 (0.0373)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6212 (0.6212)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8791], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1346], device='cuda:0', requires_grad=True)
2022-03-24 04:58:49.273289
Epoch: [21][0/16], lr: 0.00010	Time 3.461 (3.461)	Data 2.489 (2.489)	Loss 0.0740 (0.0740)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0735 (0.0735)	Loss KD (GCAM) 0.0347 (0.0347)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5902 (0.5902)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8792], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1346], device='cuda:0', requires_grad=True)
2022-03-24 04:59:04.195852
Epoch: [22][0/16], lr: 0.00010	Time 3.194 (3.194)	Data 2.093 (2.093)	Loss 0.0794 (0.0794)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0703 (0.0703)	Loss KD (GCAM) 0.0324 (0.0324)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6457 (0.6457)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8791], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1345], device='cuda:0', requires_grad=True)
2022-03-24 04:59:19.400239
Epoch: [23][0/16], lr: 0.00010	Time 3.282 (3.282)	Data 2.386 (2.386)	Loss 0.0781 (0.0781)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0715 (0.0715)	Loss KD (GCAM) 0.0352 (0.0352)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6133 (0.6133)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8791], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1345], device='cuda:0', requires_grad=True)
2022-03-24 04:59:34.583702
Epoch: [24][0/16], lr: 0.00010	Time 3.388 (3.388)	Data 2.581 (2.581)	Loss 0.0807 (0.0807)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.0722 (0.0722)	Loss KD (GCAM) 0.0353 (0.0353)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6265 (0.6265)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8793], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1345], device='cuda:0', requires_grad=True)
2022-03-24 04:59:49.967995
Epoch: [25][0/16], lr: 0.00010	Time 3.307 (3.307)	Data 2.247 (2.247)	Loss 0.0736 (0.0736)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0713 (0.0713)	Loss KD (GCAM) 0.0333 (0.0333)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5884 (0.5884)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8795], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1346], device='cuda:0', requires_grad=True)
2022-03-24 05:00:05.181067
Epoch: [26][0/16], lr: 0.00010	Time 3.557 (3.557)	Data 2.531 (2.531)	Loss 0.0779 (0.0779)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0716 (0.0716)	Loss KD (GCAM) 0.0352 (0.0352)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6147 (0.6147)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8797], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:00:20.436660
Epoch: [27][0/16], lr: 0.00010	Time 3.383 (3.383)	Data 2.335 (2.335)	Loss 0.0831 (0.0831)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0717 (0.0717)	Loss KD (GCAM) 0.0348 (0.0348)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6146 (0.6146)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8797], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:00:35.758129
Epoch: [28][0/16], lr: 0.00010	Time 3.140 (3.140)	Data 2.466 (2.466)	Loss 0.0789 (0.0789)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0714 (0.0714)	Loss KD (GCAM) 0.0359 (0.0359)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6094 (0.6094)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8798], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:00:50.055672
Epoch: [29][0/16], lr: 0.00010	Time 3.476 (3.476)	Data 1.970 (1.970)	Loss 0.0773 (0.0773)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0731 (0.0731)	Loss KD (GCAM) 0.0331 (0.0331)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6097 (0.6097)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:01:07.875448
Epoch: [30][0/16], lr: 0.00001	Time 3.721 (3.721)	Data 2.514 (2.514)	Loss 0.0770 (0.0770)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0722 (0.0722)	Loss KD (GCAM) 0.0348 (0.0348)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5779 (0.5779)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:01:25.965452
Epoch: [31][0/16], lr: 0.00001	Time 3.532 (3.532)	Data 2.334 (2.334)	Loss 0.0779 (0.0779)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0722 (0.0722)	Loss KD (GCAM) 0.0336 (0.0336)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6174 (0.6174)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:01:44.004351
Epoch: [32][0/16], lr: 0.00001	Time 3.602 (3.602)	Data 1.989 (1.989)	Loss 0.0989 (0.0989)	Loss CE 0.0260 (0.0260)	Loss KD (Logit) 0.0698 (0.0698)	Loss KD (GCAM) 0.0363 (0.0363)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5786 (0.5786)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:02:02.111379
Epoch: [33][0/16], lr: 0.00001	Time 3.647 (3.647)	Data 2.607 (2.607)	Loss 0.0760 (0.0760)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0709 (0.0709)	Loss KD (GCAM) 0.0343 (0.0343)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6054 (0.6054)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:02:20.013765
Epoch: [34][0/16], lr: 0.00001	Time 3.572 (3.572)	Data 2.529 (2.529)	Loss 0.0761 (0.0761)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0725 (0.0725)	Loss KD (GCAM) 0.0338 (0.0338)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6154 (0.6154)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:02:38.159890
Epoch: [35][0/16], lr: 0.00001	Time 3.747 (3.747)	Data 2.648 (2.648)	Loss 0.0876 (0.0876)	Loss CE 0.0129 (0.0129)	Loss KD (Logit) 0.0706 (0.0706)	Loss KD (GCAM) 0.0340 (0.0340)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6031 (0.6031)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:02:55.982222
Epoch: [36][0/16], lr: 0.00001	Time 3.474 (3.474)	Data 2.089 (2.089)	Loss 0.0815 (0.0815)	Loss CE 0.0044 (0.0044)	Loss KD (Logit) 0.0717 (0.0717)	Loss KD (GCAM) 0.0349 (0.0349)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6242 (0.6242)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:03:13.339754
Epoch: [37][0/16], lr: 0.00001	Time 3.047 (3.047)	Data 1.912 (1.912)	Loss 0.1003 (0.1003)	Loss CE 0.0271 (0.0271)	Loss KD (Logit) 0.0728 (0.0728)	Loss KD (GCAM) 0.0319 (0.0319)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5927 (0.5927)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:03:30.710285
Epoch: [38][0/16], lr: 0.00001	Time 3.118 (3.118)	Data 1.828 (1.828)	Loss 0.0782 (0.0782)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0718 (0.0718)	Loss KD (GCAM) 0.0346 (0.0346)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6272 (0.6272)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:03:48.472020
Epoch: [39][0/16], lr: 0.00001	Time 3.574 (3.574)	Data 2.089 (2.089)	Loss 0.0718 (0.0718)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0715 (0.0715)	Loss KD (GCAM) 0.0336 (0.0336)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5716 (0.5716)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:04:06.437979
Epoch: [40][0/16], lr: 0.00001	Time 3.521 (3.521)	Data 2.027 (2.027)	Loss 0.0865 (0.0865)	Loss CE 0.0089 (0.0089)	Loss KD (Logit) 0.0713 (0.0713)	Loss KD (GCAM) 0.0360 (0.0360)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6254 (0.6254)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8799], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:04:24.439462
Epoch: [41][0/16], lr: 0.00001	Time 3.546 (3.546)	Data 2.047 (2.047)	Loss 0.0773 (0.0773)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0711 (0.0711)	Loss KD (GCAM) 0.0333 (0.0333)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6290 (0.6290)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:04:42.372811
Epoch: [42][0/16], lr: 0.00001	Time 3.607 (3.607)	Data 2.505 (2.505)	Loss 0.0811 (0.0811)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0711 (0.0711)	Loss KD (GCAM) 0.0343 (0.0343)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6484 (0.6484)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:04:59.976016
Epoch: [43][0/16], lr: 0.00001	Time 3.291 (3.291)	Data 2.187 (2.187)	Loss 0.0711 (0.0711)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0715 (0.0715)	Loss KD (GCAM) 0.0346 (0.0346)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5612 (0.5612)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:05:17.685142
Epoch: [44][0/16], lr: 0.00001	Time 3.523 (3.523)	Data 2.313 (2.313)	Loss 0.0755 (0.0755)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0720 (0.0720)	Loss KD (GCAM) 0.0360 (0.0360)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5694 (0.5694)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 05:05:35.772329
Epoch: [45][0/16], lr: 0.00001	Time 3.534 (3.534)	Data 2.566 (2.566)	Loss 0.0772 (0.0772)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0719 (0.0719)	Loss KD (GCAM) 0.0348 (0.0348)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6077 (0.6077)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 05:05:53.629903
Epoch: [46][0/16], lr: 0.00001	Time 3.600 (3.600)	Data 2.043 (2.043)	Loss 0.0753 (0.0753)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0721 (0.0721)	Loss KD (GCAM) 0.0335 (0.0335)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6062 (0.6062)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 05:06:11.507222
Epoch: [47][0/16], lr: 0.00001	Time 3.466 (3.466)	Data 1.955 (1.955)	Loss 0.0769 (0.0769)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0723 (0.0723)	Loss KD (GCAM) 0.0360 (0.0360)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6145 (0.6145)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 05:06:29.302702
Epoch: [48][0/16], lr: 0.00001	Time 3.522 (3.522)	Data 2.076 (2.076)	Loss 0.0742 (0.0742)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0720 (0.0720)	Loss KD (GCAM) 0.0315 (0.0315)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5778 (0.5778)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 05:06:47.549345
Epoch: [49][0/16], lr: 0.00001	Time 3.776 (3.776)	Data 2.618 (2.618)	Loss 0.0710 (0.0710)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0697 (0.0697)	Loss KD (GCAM) 0.0297 (0.0297)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5698 (0.5698)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=219, sigma=tensor([3.8800]), eta=tensor([3.1348])
  (fc1): CosineLinear(input_features=512, output_features=213, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 188
video number + exemplar : 188
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=219, sigma=tensor([3.8800]), eta=tensor([3.1348])
  (fc1): CosineLinear(input_features=512, output_features=213, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 365
DataLoader CBF Constructed : Train 11
2022-03-24 05:07:20.808297
Epoch: [0][0/11], lr: 0.00050	Time 2.995 (2.995)	Data 1.929 (1.929)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8804], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1349], device='cuda:0', requires_grad=True)
2022-03-24 05:07:30.266669
Epoch: [1][0/11], lr: 0.00050	Time 3.312 (3.312)	Data 2.189 (2.189)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 05:07:38.950163
Epoch: [2][0/11], lr: 0.00050	Time 2.918 (2.918)	Data 1.869 (1.869)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8814], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1352], device='cuda:0', requires_grad=True)
2022-03-24 05:07:47.524971
Epoch: [3][0/11], lr: 0.00050	Time 2.887 (2.887)	Data 1.852 (1.852)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8819], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1353], device='cuda:0', requires_grad=True)
2022-03-24 05:07:56.446543
Epoch: [4][0/11], lr: 0.00050	Time 2.854 (2.854)	Data 2.223 (2.223)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8822], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1353], device='cuda:0', requires_grad=True)
2022-03-24 05:08:05.686769
Epoch: [5][0/11], lr: 0.00050	Time 3.173 (3.173)	Data 2.293 (2.293)	Loss 0.0054 (0.0054)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8822], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1350], device='cuda:0', requires_grad=True)
2022-03-24 05:08:15.161086
Epoch: [6][0/11], lr: 0.00050	Time 3.314 (3.314)	Data 2.589 (2.589)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8820], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:08:24.054349
Epoch: [7][0/11], lr: 0.00050	Time 3.004 (3.004)	Data 2.237 (2.237)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8823], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 05:08:32.718530
Epoch: [8][0/11], lr: 0.00050	Time 2.630 (2.630)	Data 1.896 (1.896)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8822], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1346], device='cuda:0', requires_grad=True)
2022-03-24 05:08:41.294099
Epoch: [9][0/11], lr: 0.00050	Time 2.968 (2.968)	Data 2.132 (2.132)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8821], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1344], device='cuda:0', requires_grad=True)
2022-03-24 05:08:50.704008
Epoch: [10][0/11], lr: 0.00050	Time 3.408 (3.408)	Data 1.994 (1.994)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8813], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 05:08:59.426100
Epoch: [11][0/11], lr: 0.00050	Time 2.886 (2.886)	Data 1.913 (1.913)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1338], device='cuda:0', requires_grad=True)
2022-03-24 05:09:08.008894
Epoch: [12][0/11], lr: 0.00050	Time 2.895 (2.895)	Data 1.866 (1.866)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1336], device='cuda:0', requires_grad=True)
2022-03-24 05:09:16.798192
Epoch: [13][0/11], lr: 0.00050	Time 3.080 (3.080)	Data 2.109 (2.109)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1334], device='cuda:0', requires_grad=True)
2022-03-24 05:09:26.024304
Epoch: [14][0/11], lr: 0.00050	Time 3.364 (3.364)	Data 2.574 (2.574)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8811], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
2022-03-24 05:09:34.914317
Epoch: [15][0/11], lr: 0.00050	Time 2.963 (2.963)	Data 2.113 (2.113)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8811], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1331], device='cuda:0', requires_grad=True)
2022-03-24 05:09:43.848243
Epoch: [16][0/11], lr: 0.00050	Time 2.864 (2.864)	Data 1.812 (1.812)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8812], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1331], device='cuda:0', requires_grad=True)
2022-03-24 05:09:52.805954
Epoch: [17][0/11], lr: 0.00050	Time 2.880 (2.880)	Data 2.213 (2.213)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8817], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
2022-03-24 05:10:00.810256
Epoch: [18][0/11], lr: 0.00050	Time 3.043 (3.043)	Data 2.129 (2.129)	Loss 0.0082 (0.0082)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8822], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1334], device='cuda:0', requires_grad=True)
2022-03-24 05:10:08.780463
Epoch: [19][0/11], lr: 0.00050	Time 2.861 (2.861)	Data 1.998 (1.998)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8823], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_011.pth.tar
exemplar : 365
Computing the class mean vectors...
Eval Task 0 for Age 11
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.683 (4.683)	Prec@1 56.250 (56.250)
Test: [100/120]	Time 0.358 (0.493)	Prec@1 81.250 (63.119)
Testing Results: Prec@1 63.802
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (71.163)
Testing Results (NME): Prec@1 71.406
Eval Task 1 for Age 11
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.705 (3.705)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 49.254
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 55.224
Eval Task 2 for Age 11
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.983 (3.983)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 88.608
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 77.215
Eval Task 3 for Age 11
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.145 (4.145)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 76.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 83.529
Eval Task 4 for Age 11
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.400 (3.400)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 71.233
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 64.384
Eval Task 5 for Age 11
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.114 (4.114)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 88.462
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.615
Eval Task 6 for Age 11
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.957 (3.957)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 53.731
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 47.761
Eval Task 7 for Age 11
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.196 (3.196)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 91.358
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 85.185
Eval Task 8 for Age 11
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.869 (3.869)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 72.727
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 63.636
Eval Task 9 for Age 11
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.639 (3.639)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 89.610
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 89.610
Eval Task 10 for Age 11
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.283 (4.283)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 97.561
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 90.244
Eval Task 11 for Age 11
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.953 (3.953)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 91.549
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 77.465
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71]
Method : OURS
----AGE 12----
current_task  [79, 5]
current_head  75
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06041522986797286]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=225, sigma=tensor([3.8823]), eta=tensor([3.1333])
  (fc1): CosineLinear(input_features=512, output_features=219, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 200
video number + exemplar : 565
DataLoader Constructed : Train 17
Optimizer Constructed
video number : 200
video number + exemplar : 200
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 05:14:34.340491
Epoch: [0][0/17], lr: 0.00100	Time 3.656 (3.656)	Data 2.680 (2.680)	Loss 0.0638 (0.0638)	Loss CE 0.0051 (0.0051)	Loss KD (Logit) 0.0054 (0.0054)	Loss KD (GCAM) 0.0041 (0.0041)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5721 (0.5721)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1326], device='cuda:0', requires_grad=True)
2022-03-24 05:14:49.341710
Epoch: [1][0/17], lr: 0.00100	Time 3.260 (3.260)	Data 1.887 (1.887)	Loss 0.0603 (0.0603)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5472 (0.5472)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8787], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1313], device='cuda:0', requires_grad=True)
2022-03-24 05:15:07.571246
Epoch: [2][0/17], lr: 0.00100	Time 3.509 (3.509)	Data 2.259 (2.259)	Loss 0.1250 (0.1250)	Loss CE 0.0685 (0.0685)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5396 (0.5396)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8818], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1331], device='cuda:0', requires_grad=True)
2022-03-24 05:15:26.172858
Epoch: [3][0/17], lr: 0.00100	Time 3.252 (3.252)	Data 2.438 (2.438)	Loss 0.0777 (0.0777)	Loss CE 0.0154 (0.0154)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0063 (0.0063)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6007 (0.6007)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1325], device='cuda:0', requires_grad=True)
2022-03-24 05:15:44.403008
Epoch: [4][0/17], lr: 0.00100	Time 3.574 (3.574)	Data 2.487 (2.487)	Loss 0.0768 (0.0768)	Loss CE 0.0190 (0.0190)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5537 (0.5537)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8788], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1319], device='cuda:0', requires_grad=True)
2022-03-24 05:16:03.217736
Epoch: [5][0/17], lr: 0.00100	Time 3.663 (3.663)	Data 2.060 (2.060)	Loss 0.1303 (0.1303)	Loss CE 0.0674 (0.0674)	Loss KD (Logit) 0.0055 (0.0055)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8831], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1346], device='cuda:0', requires_grad=True)
2022-03-24 05:16:21.931948
Epoch: [6][0/17], lr: 0.00100	Time 3.421 (3.421)	Data 2.032 (2.032)	Loss 0.0604 (0.0604)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5600 (0.5600)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8854], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1361], device='cuda:0', requires_grad=True)
2022-03-24 05:16:40.502493
Epoch: [7][0/17], lr: 0.00100	Time 3.680 (3.680)	Data 2.420 (2.420)	Loss 0.1237 (0.1237)	Loss CE 0.0658 (0.0658)	Loss KD (Logit) 0.0060 (0.0060)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5531 (0.5531)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8846], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1360], device='cuda:0', requires_grad=True)
2022-03-24 05:16:59.396459
Epoch: [8][0/17], lr: 0.00100	Time 3.645 (3.645)	Data 2.533 (2.533)	Loss 0.0619 (0.0619)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0059 (0.0059)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5800 (0.5800)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8867], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1374], device='cuda:0', requires_grad=True)
2022-03-24 05:17:18.219247
Epoch: [9][0/17], lr: 0.00100	Time 3.541 (3.541)	Data 2.481 (2.481)	Loss 0.0620 (0.0620)	Loss CE 0.0037 (0.0037)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5562 (0.5562)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8901], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1396], device='cuda:0', requires_grad=True)
2022-03-24 05:17:36.714245
Epoch: [10][0/17], lr: 0.00100	Time 3.423 (3.423)	Data 2.478 (2.478)	Loss 0.0598 (0.0598)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0059 (0.0059)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5611 (0.5611)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8911], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1402], device='cuda:0', requires_grad=True)
2022-03-24 05:17:55.042947
Epoch: [11][0/17], lr: 0.00100	Time 3.417 (3.417)	Data 2.426 (2.426)	Loss 0.0694 (0.0694)	Loss CE 0.0081 (0.0081)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5837 (0.5837)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8900], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1392], device='cuda:0', requires_grad=True)
2022-03-24 05:18:13.281255
Epoch: [12][0/17], lr: 0.00100	Time 3.378 (3.378)	Data 2.158 (2.158)	Loss 0.0904 (0.0904)	Loss CE 0.0273 (0.0273)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6051 (0.6051)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8913], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1398], device='cuda:0', requires_grad=True)
2022-03-24 05:18:31.575411
Epoch: [13][0/17], lr: 0.00100	Time 3.368 (3.368)	Data 2.446 (2.446)	Loss 0.0719 (0.0719)	Loss CE 0.0147 (0.0147)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5459 (0.5459)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8931], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1409], device='cuda:0', requires_grad=True)
2022-03-24 05:18:50.122590
Epoch: [14][0/17], lr: 0.00100	Time 3.570 (3.570)	Data 2.556 (2.556)	Loss 0.0601 (0.0601)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0059 (0.0059)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5654 (0.5654)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8920], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1404], device='cuda:0', requires_grad=True)
2022-03-24 05:19:08.569399
Epoch: [15][0/17], lr: 0.00100	Time 3.194 (3.194)	Data 1.922 (1.922)	Loss 0.0602 (0.0602)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5559 (0.5559)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8894], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1388], device='cuda:0', requires_grad=True)
2022-03-24 05:19:26.943286
Epoch: [16][0/17], lr: 0.00100	Time 3.501 (3.501)	Data 2.150 (2.150)	Loss 0.0591 (0.0591)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0089 (0.0089)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5478 (0.5478)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8868], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1370], device='cuda:0', requires_grad=True)
2022-03-24 05:19:45.134500
Epoch: [17][0/17], lr: 0.00100	Time 3.237 (3.237)	Data 1.933 (1.933)	Loss 0.0629 (0.0629)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0089 (0.0089)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5952 (0.5952)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8875], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1372], device='cuda:0', requires_grad=True)
2022-03-24 05:20:03.645906
Epoch: [18][0/17], lr: 0.00100	Time 3.347 (3.347)	Data 2.301 (2.301)	Loss 0.0815 (0.0815)	Loss CE 0.0228 (0.0228)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5579 (0.5579)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8889], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1379], device='cuda:0', requires_grad=True)
2022-03-24 05:20:21.945497
Epoch: [19][0/17], lr: 0.00100	Time 3.414 (3.414)	Data 2.557 (2.557)	Loss 0.0624 (0.0624)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0083 (0.0083)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5761 (0.5761)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8881], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1373], device='cuda:0', requires_grad=True)
2022-03-24 05:20:40.462373
Epoch: [20][0/17], lr: 0.00010	Time 3.412 (3.412)	Data 2.023 (2.023)	Loss 0.0658 (0.0658)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0059 (0.0059)	Loss KD (GCAM) 0.0081 (0.0081)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5808 (0.5808)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8883], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1374], device='cuda:0', requires_grad=True)
2022-03-24 05:20:58.841629
Epoch: [21][0/17], lr: 0.00010	Time 3.372 (3.372)	Data 2.278 (2.278)	Loss 0.0815 (0.0815)	Loss CE 0.0249 (0.0249)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5398 (0.5398)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8887], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1376], device='cuda:0', requires_grad=True)
2022-03-24 05:21:17.155237
Epoch: [22][0/17], lr: 0.00010	Time 3.447 (3.447)	Data 1.899 (1.899)	Loss 0.0596 (0.0596)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0086 (0.0086)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5582 (0.5582)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8890], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1378], device='cuda:0', requires_grad=True)
2022-03-24 05:21:35.541551
Epoch: [23][0/17], lr: 0.00010	Time 3.370 (3.370)	Data 1.947 (1.947)	Loss 0.0667 (0.0667)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0081 (0.0081)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5919 (0.5919)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1379], device='cuda:0', requires_grad=True)
2022-03-24 05:21:53.982619
Epoch: [24][0/17], lr: 0.00010	Time 3.517 (3.517)	Data 2.554 (2.554)	Loss 0.0722 (0.0722)	Loss CE 0.0132 (0.0132)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5614 (0.5614)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8895], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1380], device='cuda:0', requires_grad=True)
2022-03-24 05:22:12.105465
Epoch: [25][0/17], lr: 0.00010	Time 3.145 (3.145)	Data 1.813 (1.813)	Loss 0.0582 (0.0582)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5519 (0.5519)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8896], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1381], device='cuda:0', requires_grad=True)
2022-03-24 05:22:30.634846
Epoch: [26][0/17], lr: 0.00010	Time 3.548 (3.548)	Data 2.553 (2.553)	Loss 0.0630 (0.0630)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5876 (0.5876)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8898], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1382], device='cuda:0', requires_grad=True)
2022-03-24 05:22:49.392591
Epoch: [27][0/17], lr: 0.00010	Time 3.625 (3.625)	Data 2.399 (2.399)	Loss 0.0597 (0.0597)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0054 (0.0054)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5606 (0.5606)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8899], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1382], device='cuda:0', requires_grad=True)
2022-03-24 05:23:07.950941
Epoch: [28][0/17], lr: 0.00010	Time 3.299 (3.299)	Data 2.203 (2.203)	Loss 0.0661 (0.0661)	Loss CE 0.0073 (0.0073)	Loss KD (Logit) 0.0055 (0.0055)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5614 (0.5614)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8901], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1383], device='cuda:0', requires_grad=True)
2022-03-24 05:23:26.261839
Epoch: [29][0/17], lr: 0.00010	Time 3.147 (3.147)	Data 1.899 (1.899)	Loss 0.0554 (0.0554)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0059 (0.0059)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5231 (0.5231)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:23:45.140737
Epoch: [30][0/17], lr: 0.00001	Time 3.373 (3.373)	Data 2.162 (2.162)	Loss 0.0654 (0.0654)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6085 (0.6085)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:24:03.335603
Epoch: [31][0/17], lr: 0.00001	Time 3.287 (3.287)	Data 2.095 (2.095)	Loss 0.0599 (0.0599)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5615 (0.5615)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:24:20.272285
Epoch: [32][0/17], lr: 0.00001	Time 3.409 (3.409)	Data 2.071 (2.071)	Loss 0.0611 (0.0611)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5792 (0.5792)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:24:37.079496
Epoch: [33][0/17], lr: 0.00001	Time 3.260 (3.260)	Data 1.895 (1.895)	Loss 0.0631 (0.0631)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:24:53.573743
Epoch: [34][0/17], lr: 0.00001	Time 3.359 (3.359)	Data 2.262 (2.262)	Loss 0.0629 (0.0629)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5905 (0.5905)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:25:09.068311
Epoch: [35][0/17], lr: 0.00001	Time 3.255 (3.255)	Data 1.896 (1.896)	Loss 0.0588 (0.0588)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5530 (0.5530)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:25:24.592071
Epoch: [36][0/17], lr: 0.00001	Time 3.347 (3.347)	Data 2.251 (2.251)	Loss 0.0591 (0.0591)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0083 (0.0083)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5604 (0.5604)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:25:39.757218
Epoch: [37][0/17], lr: 0.00001	Time 3.220 (3.220)	Data 2.134 (2.134)	Loss 0.0590 (0.0590)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5581 (0.5581)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:25:55.218111
Epoch: [38][0/17], lr: 0.00001	Time 3.251 (3.251)	Data 1.858 (1.858)	Loss 0.0586 (0.0586)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5491 (0.5491)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:26:10.285827
Epoch: [39][0/17], lr: 0.00001	Time 3.175 (3.175)	Data 1.937 (1.937)	Loss 0.0574 (0.0574)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5425 (0.5425)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:26:25.781085
Epoch: [40][0/17], lr: 0.00001	Time 3.335 (3.335)	Data 2.362 (2.362)	Loss 0.0573 (0.0573)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5324 (0.5324)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:26:41.478466
Epoch: [41][0/17], lr: 0.00001	Time 3.423 (3.423)	Data 2.245 (2.245)	Loss 0.0614 (0.0614)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0059 (0.0059)	Loss KD (GCAM) 0.0085 (0.0085)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5827 (0.5827)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:26:57.194476
Epoch: [42][0/17], lr: 0.00001	Time 3.281 (3.281)	Data 2.036 (2.036)	Loss 0.0616 (0.0616)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0055 (0.0055)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5879 (0.5879)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:27:13.308491
Epoch: [43][0/17], lr: 0.00001	Time 3.296 (3.296)	Data 2.411 (2.411)	Loss 0.0628 (0.0628)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5978 (0.5978)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:27:29.054325
Epoch: [44][0/17], lr: 0.00001	Time 3.292 (3.292)	Data 2.094 (2.094)	Loss 0.0626 (0.0626)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5958 (0.5958)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:27:44.751543
Epoch: [45][0/17], lr: 0.00001	Time 3.184 (3.184)	Data 1.880 (1.880)	Loss 0.0601 (0.0601)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0058 (0.0058)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5699 (0.5699)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:28:00.437511
Epoch: [46][0/17], lr: 0.00001	Time 3.194 (3.194)	Data 2.192 (2.192)	Loss 0.0570 (0.0570)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5413 (0.5413)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:28:16.105051
Epoch: [47][0/17], lr: 0.00001	Time 3.383 (3.383)	Data 2.390 (2.390)	Loss 0.0594 (0.0594)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0057 (0.0057)	Loss KD (GCAM) 0.0083 (0.0083)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5595 (0.5595)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:28:31.847074
Epoch: [48][0/17], lr: 0.00001	Time 3.267 (3.267)	Data 2.099 (2.099)	Loss 0.0643 (0.0643)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0059 (0.0059)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6125 (0.6125)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
2022-03-24 05:28:47.736667
Epoch: [49][0/17], lr: 0.00001	Time 3.148 (3.148)	Data 2.097 (2.097)	Loss 0.0849 (0.0849)	Loss CE 0.0250 (0.0250)	Loss KD (Logit) 0.0056 (0.0056)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5720 (0.5720)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8903], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1384], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=225, sigma=tensor([3.8903]), eta=tensor([3.1384])
  (fc1): CosineLinear(input_features=512, output_features=219, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 200
video number + exemplar : 200
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=225, sigma=tensor([3.8903]), eta=tensor([3.1384])
  (fc1): CosineLinear(input_features=512, output_features=219, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 375
DataLoader CBF Constructed : Train 11
Optimizer Constructed
2022-03-24 05:29:18.243139
Epoch: [0][0/11], lr: 0.00050	Time 2.751 (2.751)	Data 1.834 (1.834)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8902], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1382], device='cuda:0', requires_grad=True)
2022-03-24 05:29:26.074310
Epoch: [1][0/11], lr: 0.00050	Time 2.727 (2.727)	Data 2.172 (2.172)	Loss 0.0176 (0.0176)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8900], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1381], device='cuda:0', requires_grad=True)
2022-03-24 05:29:33.393264
Epoch: [2][0/11], lr: 0.00050	Time 2.834 (2.834)	Data 2.328 (2.328)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8901], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1380], device='cuda:0', requires_grad=True)
2022-03-24 05:29:40.859980
Epoch: [3][0/11], lr: 0.00050	Time 3.009 (3.009)	Data 2.001 (2.001)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8904], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1381], device='cuda:0', requires_grad=True)
2022-03-24 05:29:49.679253
Epoch: [4][0/11], lr: 0.00050	Time 3.134 (3.134)	Data 2.231 (2.231)	Loss 0.0029 (0.0029)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8908], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1381], device='cuda:0', requires_grad=True)
2022-03-24 05:29:58.864414
Epoch: [5][0/11], lr: 0.00050	Time 3.099 (3.099)	Data 2.102 (2.102)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8910], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1381], device='cuda:0', requires_grad=True)
2022-03-24 05:30:07.794715
Epoch: [6][0/11], lr: 0.00050	Time 2.835 (2.835)	Data 1.872 (1.872)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8910], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1379], device='cuda:0', requires_grad=True)
2022-03-24 05:30:16.609513
Epoch: [7][0/11], lr: 0.00050	Time 3.083 (3.083)	Data 2.198 (2.198)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8909], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1376], device='cuda:0', requires_grad=True)
2022-03-24 05:30:25.967338
Epoch: [8][0/11], lr: 0.00050	Time 3.214 (3.214)	Data 1.974 (1.974)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8906], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1373], device='cuda:0', requires_grad=True)
2022-03-24 05:30:34.424765
Epoch: [9][0/11], lr: 0.00050	Time 2.799 (2.799)	Data 1.843 (1.843)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8909], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1373], device='cuda:0', requires_grad=True)
2022-03-24 05:30:43.283726
Epoch: [10][0/11], lr: 0.00050	Time 2.939 (2.939)	Data 2.046 (2.046)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8911], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1373], device='cuda:0', requires_grad=True)
2022-03-24 05:30:52.389882
Epoch: [11][0/11], lr: 0.00050	Time 3.115 (3.115)	Data 2.168 (2.168)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1374], device='cuda:0', requires_grad=True)
2022-03-24 05:31:01.118236
Epoch: [12][0/11], lr: 0.00050	Time 2.748 (2.748)	Data 1.899 (1.899)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1373], device='cuda:0', requires_grad=True)
2022-03-24 05:31:09.973104
Epoch: [13][0/11], lr: 0.00050	Time 3.051 (3.051)	Data 2.235 (2.235)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1370], device='cuda:0', requires_grad=True)
2022-03-24 05:31:18.894373
Epoch: [14][0/11], lr: 0.00050	Time 2.904 (2.904)	Data 2.167 (2.167)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1368], device='cuda:0', requires_grad=True)
2022-03-24 05:31:27.835106
Epoch: [15][0/11], lr: 0.00050	Time 2.890 (2.890)	Data 1.831 (1.831)	Loss 0.0031 (0.0031)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 05:31:36.679764
Epoch: [16][0/11], lr: 0.00050	Time 2.982 (2.982)	Data 2.062 (2.062)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1364], device='cuda:0', requires_grad=True)
2022-03-24 05:31:45.903114
Epoch: [17][0/11], lr: 0.00050	Time 3.063 (3.063)	Data 1.826 (1.826)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8918], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1364], device='cuda:0', requires_grad=True)
2022-03-24 05:31:54.848611
Epoch: [18][0/11], lr: 0.00050	Time 2.989 (2.989)	Data 2.040 (2.040)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1362], device='cuda:0', requires_grad=True)
2022-03-24 05:32:03.778696
Epoch: [19][0/11], lr: 0.00050	Time 2.862 (2.862)	Data 2.102 (2.102)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8917], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1360], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_012.pth.tar
exemplar : 375
Computing the class mean vectors...
Eval Task 0 for Age 12
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.071 (5.071)	Prec@1 56.250 (56.250)
Test: [100/120]	Time 0.459 (0.562)	Prec@1 87.500 (63.800)
Testing Results: Prec@1 63.906
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (70.297)
Testing Results (NME): Prec@1 70.365
Eval Task 1 for Age 12
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.969 (3.969)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 53.731
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 59.701
Eval Task 2 for Age 12
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.316 (4.316)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 83.544
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 78.481
Eval Task 3 for Age 12
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.001 (4.001)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 81.176
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 83.529
Eval Task 4 for Age 12
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 4.212 (4.212)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 71.233
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 60.274
Eval Task 5 for Age 12
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.557 (3.557)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 87.179
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 85.897
Eval Task 6 for Age 12
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.325 (4.325)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 49.254
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 55.224
Eval Task 7 for Age 12
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.221 (4.221)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.358
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 82.716
Eval Task 8 for Age 12
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.280 (4.280)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 62.121
Eval Task 9 for Age 12
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.190 (4.190)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 85.714
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 85.714
Eval Task 10 for Age 12
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.130 (4.130)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 95.122
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 93.902
Eval Task 11 for Age 12
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.231 (4.231)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 85.915
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 83.099
Eval Task 12 for Age 12
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.209 (4.209)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 94.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.667
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75]
Method : OURS
----AGE 13----
current_task  [52, 54]
current_head  77
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06123724356957945]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=231, sigma=tensor([3.8917]), eta=tensor([3.1360])
  (fc1): CosineLinear(input_features=512, output_features=225, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 168
video number + exemplar : 543
DataLoader Constructed : Train 16
Optimizer Constructed
video number : 168
video number + exemplar : 168
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 05:37:05.023722
Epoch: [0][0/16], lr: 0.00100	Time 3.543 (3.543)	Data 2.187 (2.187)	Loss 0.1484 (0.1484)	Loss CE 0.0900 (0.0900)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5817 (0.5817)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8793], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1284], device='cuda:0', requires_grad=True)
2022-03-24 05:37:22.532952
Epoch: [1][0/16], lr: 0.00100	Time 3.525 (3.525)	Data 2.020 (2.020)	Loss 0.4783 (0.4783)	Loss CE 0.4231 (0.4231)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0011 (0.0011)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5481 (0.5481)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8704], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1232], device='cuda:0', requires_grad=True)
2022-03-24 05:37:40.239339
Epoch: [2][0/16], lr: 0.00100	Time 3.549 (3.549)	Data 1.924 (1.924)	Loss 0.0995 (0.0995)	Loss CE 0.0390 (0.0390)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5997 (0.5997)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8698], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1231], device='cuda:0', requires_grad=True)
2022-03-24 05:37:57.983708
Epoch: [3][0/16], lr: 0.00100	Time 3.283 (3.283)	Data 1.895 (1.895)	Loss 0.1746 (0.1746)	Loss CE 0.1203 (0.1203)	Loss KD (Logit) 0.0018 (0.0018)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5387 (0.5387)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8643], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1202], device='cuda:0', requires_grad=True)
2022-03-24 05:38:13.963524
Epoch: [4][0/16], lr: 0.00100	Time 3.179 (3.179)	Data 2.222 (2.222)	Loss 0.0653 (0.0653)	Loss CE 0.0078 (0.0078)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5690 (0.5690)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8631], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1193], device='cuda:0', requires_grad=True)
2022-03-24 05:38:29.489690
Epoch: [5][0/16], lr: 0.00100	Time 3.250 (3.250)	Data 1.912 (1.912)	Loss 0.0632 (0.0632)	Loss CE 0.0056 (0.0056)	Loss KD (Logit) 0.0018 (0.0018)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5704 (0.5704)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8637], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1193], device='cuda:0', requires_grad=True)
2022-03-24 05:38:45.674158
Epoch: [6][0/16], lr: 0.00100	Time 3.495 (3.495)	Data 1.828 (1.828)	Loss 0.0682 (0.0682)	Loss CE 0.0155 (0.0155)	Loss KD (Logit) 0.0018 (0.0018)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5217 (0.5217)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8720], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1243], device='cuda:0', requires_grad=True)
2022-03-24 05:39:00.918845
Epoch: [7][0/16], lr: 0.00100	Time 3.351 (3.351)	Data 2.542 (2.542)	Loss 0.0617 (0.0617)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0018 (0.0018)	Loss KD (GCAM) 0.0016 (0.0016)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5411 (0.5411)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8790], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1284], device='cuda:0', requires_grad=True)
2022-03-24 05:39:15.937406
Epoch: [8][0/16], lr: 0.00100	Time 3.426 (3.426)	Data 2.589 (2.589)	Loss 0.0536 (0.0536)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5186 (0.5186)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8858], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1324], device='cuda:0', requires_grad=True)
2022-03-24 05:39:30.888269
Epoch: [9][0/16], lr: 0.00100	Time 3.399 (3.399)	Data 2.178 (2.178)	Loss 0.0588 (0.0588)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5658 (0.5658)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8911], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1353], device='cuda:0', requires_grad=True)
2022-03-24 05:39:45.897815
Epoch: [10][0/16], lr: 0.00100	Time 3.475 (3.475)	Data 2.307 (2.307)	Loss 0.1436 (0.1436)	Loss CE 0.0813 (0.0813)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6177 (0.6177)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8954], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1377], device='cuda:0', requires_grad=True)
2022-03-24 05:40:00.567990
Epoch: [11][0/16], lr: 0.00100	Time 3.255 (3.255)	Data 2.120 (2.120)	Loss 0.0585 (0.0585)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0018 (0.0018)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5628 (0.5628)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9016], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1409], device='cuda:0', requires_grad=True)
2022-03-24 05:40:15.608410
Epoch: [12][0/16], lr: 0.00100	Time 3.547 (3.547)	Data 2.837 (2.837)	Loss 0.0684 (0.0684)	Loss CE 0.0124 (0.0124)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5549 (0.5549)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9053], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1428], device='cuda:0', requires_grad=True)
2022-03-24 05:40:30.863486
Epoch: [13][0/16], lr: 0.00100	Time 3.324 (3.324)	Data 2.105 (2.105)	Loss 0.0643 (0.0643)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5925 (0.5925)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9082], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1444], device='cuda:0', requires_grad=True)
2022-03-24 05:40:45.985607
Epoch: [14][0/16], lr: 0.00100	Time 3.204 (3.204)	Data 2.034 (2.034)	Loss 0.0678 (0.0678)	Loss CE 0.0081 (0.0081)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5926 (0.5926)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9114], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1463], device='cuda:0', requires_grad=True)
2022-03-24 05:41:01.038026
Epoch: [15][0/16], lr: 0.00100	Time 3.457 (3.457)	Data 2.435 (2.435)	Loss 0.0601 (0.0601)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5525 (0.5525)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9129], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1472], device='cuda:0', requires_grad=True)
2022-03-24 05:41:16.103436
Epoch: [16][0/16], lr: 0.00100	Time 3.305 (3.305)	Data 2.126 (2.126)	Loss 0.0587 (0.0587)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5656 (0.5656)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9152], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1485], device='cuda:0', requires_grad=True)
2022-03-24 05:41:31.327236
Epoch: [17][0/16], lr: 0.00100	Time 3.323 (3.323)	Data 2.295 (2.295)	Loss 0.0618 (0.0618)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5990 (0.5990)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9170], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1494], device='cuda:0', requires_grad=True)
2022-03-24 05:41:46.628090
Epoch: [18][0/16], lr: 0.00100	Time 3.401 (3.401)	Data 2.506 (2.506)	Loss 0.0585 (0.0585)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5753 (0.5753)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1502], device='cuda:0', requires_grad=True)
2022-03-24 05:42:01.469396
Epoch: [19][0/16], lr: 0.00100	Time 3.142 (3.142)	Data 2.194 (2.194)	Loss 0.0587 (0.0587)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0018 (0.0018)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5635 (0.5635)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9200], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1508], device='cuda:0', requires_grad=True)
2022-03-24 05:42:16.522524
Epoch: [20][0/16], lr: 0.00010	Time 3.166 (3.166)	Data 2.235 (2.235)	Loss 0.0589 (0.0589)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5738 (0.5738)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9201], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1508], device='cuda:0', requires_grad=True)
2022-03-24 05:42:31.787716
Epoch: [21][0/16], lr: 0.00010	Time 3.286 (3.286)	Data 2.266 (2.266)	Loss 0.0664 (0.0664)	Loss CE 0.0075 (0.0075)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5835 (0.5835)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9202], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1509], device='cuda:0', requires_grad=True)
2022-03-24 05:42:46.933172
Epoch: [22][0/16], lr: 0.00010	Time 3.267 (3.267)	Data 2.455 (2.455)	Loss 0.0636 (0.0636)	Loss CE 0.0052 (0.0052)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5791 (0.5791)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9199], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1507], device='cuda:0', requires_grad=True)
2022-03-24 05:43:01.902323
Epoch: [23][0/16], lr: 0.00010	Time 3.326 (3.326)	Data 2.175 (2.175)	Loss 0.0669 (0.0669)	Loss CE 0.0088 (0.0088)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5765 (0.5765)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9200], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1508], device='cuda:0', requires_grad=True)
2022-03-24 05:43:17.094191
Epoch: [24][0/16], lr: 0.00010	Time 3.452 (3.452)	Data 2.373 (2.373)	Loss 0.0620 (0.0620)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5694 (0.5694)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9201], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1508], device='cuda:0', requires_grad=True)
2022-03-24 05:43:31.380902
Epoch: [25][0/16], lr: 0.00010	Time 3.279 (3.279)	Data 1.939 (1.939)	Loss 0.0608 (0.0608)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6000 (0.6000)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9203], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1509], device='cuda:0', requires_grad=True)
2022-03-24 05:43:48.255998
Epoch: [26][0/16], lr: 0.00010	Time 3.577 (3.577)	Data 1.972 (1.972)	Loss 0.0575 (0.0575)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5668 (0.5668)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1509], device='cuda:0', requires_grad=True)
2022-03-24 05:44:06.035446
Epoch: [27][0/16], lr: 0.00010	Time 3.463 (3.463)	Data 2.296 (2.296)	Loss 0.0596 (0.0596)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5853 (0.5853)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:44:23.472120
Epoch: [28][0/16], lr: 0.00010	Time 3.161 (3.161)	Data 1.877 (1.877)	Loss 0.0582 (0.0582)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5701 (0.5701)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:44:41.366217
Epoch: [29][0/16], lr: 0.00010	Time 3.489 (3.489)	Data 1.941 (1.941)	Loss 0.0557 (0.0557)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5408 (0.5408)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:44:58.650171
Epoch: [30][0/16], lr: 0.00001	Time 3.220 (3.220)	Data 2.016 (2.016)	Loss 0.0573 (0.0573)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5632 (0.5632)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:45:16.344672
Epoch: [31][0/16], lr: 0.00001	Time 3.529 (3.529)	Data 2.033 (2.033)	Loss 0.0614 (0.0614)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6048 (0.6048)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:45:34.033670
Epoch: [32][0/16], lr: 0.00001	Time 3.443 (3.443)	Data 2.221 (2.221)	Loss 0.0689 (0.0689)	Loss CE 0.0088 (0.0088)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5956 (0.5956)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:45:51.733388
Epoch: [33][0/16], lr: 0.00001	Time 3.461 (3.461)	Data 2.490 (2.490)	Loss 0.0575 (0.0575)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5668 (0.5668)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:46:09.603729
Epoch: [34][0/16], lr: 0.00001	Time 3.624 (3.624)	Data 2.459 (2.459)	Loss 0.1420 (0.1420)	Loss CE 0.0867 (0.0867)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5480 (0.5480)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:46:26.954473
Epoch: [35][0/16], lr: 0.00001	Time 3.242 (3.242)	Data 1.886 (1.886)	Loss 0.0600 (0.0600)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5879 (0.5879)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:46:44.715033
Epoch: [36][0/16], lr: 0.00001	Time 3.574 (3.574)	Data 2.243 (2.243)	Loss 0.0569 (0.0569)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5502 (0.5502)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:47:02.635456
Epoch: [37][0/16], lr: 0.00001	Time 3.430 (3.430)	Data 2.339 (2.339)	Loss 0.0612 (0.0612)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5997 (0.5997)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:47:20.211040
Epoch: [38][0/16], lr: 0.00001	Time 3.061 (3.061)	Data 1.905 (1.905)	Loss 0.0857 (0.0857)	Loss CE 0.0233 (0.0233)	Loss KD (Logit) 0.0016 (0.0016)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6192 (0.6192)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:47:38.040791
Epoch: [39][0/16], lr: 0.00001	Time 3.460 (3.460)	Data 2.219 (2.219)	Loss 0.0549 (0.0549)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5388 (0.5388)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:47:55.179797
Epoch: [40][0/16], lr: 0.00001	Time 2.993 (2.993)	Data 1.900 (1.900)	Loss 0.0538 (0.0538)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0018 (0.0018)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5248 (0.5248)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:48:13.152317
Epoch: [41][0/16], lr: 0.00001	Time 3.778 (3.778)	Data 2.596 (2.596)	Loss 0.0576 (0.0576)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5694 (0.5694)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:48:31.204545
Epoch: [42][0/16], lr: 0.00001	Time 3.619 (3.619)	Data 2.306 (2.306)	Loss 0.0600 (0.0600)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5540 (0.5540)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:48:49.185887
Epoch: [43][0/16], lr: 0.00001	Time 3.602 (3.602)	Data 2.492 (2.492)	Loss 0.0637 (0.0637)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6099 (0.6099)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:49:07.111461
Epoch: [44][0/16], lr: 0.00001	Time 3.621 (3.621)	Data 2.109 (2.109)	Loss 0.1138 (0.1138)	Loss CE 0.0504 (0.0504)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6281 (0.6281)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:49:24.902922
Epoch: [45][0/16], lr: 0.00001	Time 3.295 (3.295)	Data 2.079 (2.079)	Loss 0.0595 (0.0595)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5841 (0.5841)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:49:42.448674
Epoch: [46][0/16], lr: 0.00001	Time 3.179 (3.179)	Data 1.887 (1.887)	Loss 0.0571 (0.0571)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5460 (0.5460)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:49:59.997205
Epoch: [47][0/16], lr: 0.00001	Time 3.303 (3.303)	Data 2.402 (2.402)	Loss 0.0587 (0.0587)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0014 (0.0014)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5798 (0.5798)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:50:17.394132
Epoch: [48][0/16], lr: 0.00001	Time 3.015 (3.015)	Data 1.893 (1.893)	Loss 0.0550 (0.0550)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0015 (0.0015)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5365 (0.5365)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
2022-03-24 05:50:34.725330
Epoch: [49][0/16], lr: 0.00001	Time 3.301 (3.301)	Data 2.060 (2.060)	Loss 0.0686 (0.0686)	Loss CE 0.0098 (0.0098)	Loss KD (Logit) 0.0017 (0.0017)	Loss KD (GCAM) 0.0013 (0.0013)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5835 (0.5835)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1511], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=231, sigma=tensor([3.9209]), eta=tensor([3.1511])
  (fc1): CosineLinear(input_features=512, output_features=225, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 168
video number + exemplar : 168
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=231, sigma=tensor([3.9209]), eta=tensor([3.1511])
  (fc1): CosineLinear(input_features=512, output_features=225, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 385
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-24 05:51:08.390056
Epoch: [0][0/12], lr: 0.00050	Time 3.173 (3.173)	Data 2.100 (2.100)	Loss 0.0050 (0.0050)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1510], device='cuda:0', requires_grad=True)
2022-03-24 05:51:18.202359
Epoch: [1][0/12], lr: 0.00050	Time 3.146 (3.146)	Data 1.971 (1.971)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9202], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1502], device='cuda:0', requires_grad=True)
2022-03-24 05:51:27.990426
Epoch: [2][0/12], lr: 0.00050	Time 3.167 (3.167)	Data 2.126 (2.126)	Loss 0.0127 (0.0127)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9200], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1499], device='cuda:0', requires_grad=True)
2022-03-24 05:51:37.771870
Epoch: [3][0/12], lr: 0.00050	Time 3.066 (3.066)	Data 2.211 (2.211)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9198], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1495], device='cuda:0', requires_grad=True)
2022-03-24 05:51:46.913069
Epoch: [4][0/12], lr: 0.00050	Time 2.760 (2.760)	Data 1.876 (1.876)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9196], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1493], device='cuda:0', requires_grad=True)
2022-03-24 05:51:56.520639
Epoch: [5][0/12], lr: 0.00050	Time 2.987 (2.987)	Data 2.304 (2.304)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9193], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1490], device='cuda:0', requires_grad=True)
2022-03-24 05:52:06.354396
Epoch: [6][0/12], lr: 0.00050	Time 3.515 (3.515)	Data 2.496 (2.496)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9188], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1485], device='cuda:0', requires_grad=True)
2022-03-24 05:52:16.154813
Epoch: [7][0/12], lr: 0.00050	Time 3.141 (3.141)	Data 2.186 (2.186)	Loss 0.0031 (0.0031)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9188], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1482], device='cuda:0', requires_grad=True)
2022-03-24 05:52:25.934459
Epoch: [8][0/12], lr: 0.00050	Time 3.130 (3.130)	Data 2.085 (2.085)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9191], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1480], device='cuda:0', requires_grad=True)
2022-03-24 05:52:35.686294
Epoch: [9][0/12], lr: 0.00050	Time 3.101 (3.101)	Data 2.235 (2.235)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9196], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1481], device='cuda:0', requires_grad=True)
2022-03-24 05:52:44.853341
Epoch: [10][0/12], lr: 0.00050	Time 2.747 (2.747)	Data 1.894 (1.894)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9199], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1480], device='cuda:0', requires_grad=True)
2022-03-24 05:52:53.506480
Epoch: [11][0/12], lr: 0.00050	Time 2.916 (2.916)	Data 2.037 (2.037)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9194], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1477], device='cuda:0', requires_grad=True)
2022-03-24 05:53:01.814028
Epoch: [12][0/12], lr: 0.00050	Time 2.964 (2.964)	Data 1.938 (1.938)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9191], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1474], device='cuda:0', requires_grad=True)
2022-03-24 05:53:10.339000
Epoch: [13][0/12], lr: 0.00050	Time 3.011 (3.011)	Data 2.269 (2.269)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9191], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1472], device='cuda:0', requires_grad=True)
2022-03-24 05:53:18.729588
Epoch: [14][0/12], lr: 0.00050	Time 2.700 (2.700)	Data 1.907 (1.907)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9193], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1471], device='cuda:0', requires_grad=True)
2022-03-24 05:53:27.376485
Epoch: [15][0/12], lr: 0.00050	Time 2.928 (2.928)	Data 2.347 (2.347)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9193], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1469], device='cuda:0', requires_grad=True)
2022-03-24 05:53:35.813206
Epoch: [16][0/12], lr: 0.00050	Time 2.877 (2.877)	Data 2.291 (2.291)	Loss 0.0032 (0.0032)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9193], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1467], device='cuda:0', requires_grad=True)
2022-03-24 05:53:44.232326
Epoch: [17][0/12], lr: 0.00050	Time 3.011 (3.011)	Data 1.973 (1.973)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9191], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1464], device='cuda:0', requires_grad=True)
2022-03-24 05:53:52.735906
Epoch: [18][0/12], lr: 0.00050	Time 3.004 (3.004)	Data 2.227 (2.227)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9189], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1461], device='cuda:0', requires_grad=True)
2022-03-24 05:54:01.447875
Epoch: [19][0/12], lr: 0.00050	Time 3.020 (3.020)	Data 2.239 (2.239)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9189], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1459], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_013.pth.tar
exemplar : 385
Computing the class mean vectors...
Eval Task 0 for Age 13
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.006 (5.006)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.415 (0.491)	Prec@1 68.750 (62.438)
Testing Results: Prec@1 62.969
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (68.936)
Testing Results (NME): Prec@1 68.854
Eval Task 1 for Age 13
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.952 (3.952)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 29.851
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 50.746
Eval Task 2 for Age 13
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.832 (3.832)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 82.278
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 75.949
Eval Task 3 for Age 13
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.508 (3.508)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 81.176
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 85.882
Eval Task 4 for Age 13
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.728 (3.728)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 69.863
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 64.384
Eval Task 5 for Age 13
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.898 (3.898)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 84.615
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 87.179
Eval Task 6 for Age 13
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.843 (3.843)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 70.149
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 61.194
Eval Task 7 for Age 13
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.474 (3.474)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 90.123
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 86.420
Eval Task 8 for Age 13
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.867 (3.867)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 68.182
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 63.636
Eval Task 9 for Age 13
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.287 (3.287)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 87.013
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 85.714
Eval Task 10 for Age 13
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.123 (4.123)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.780
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 97.561
Eval Task 11 for Age 13
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.015 (4.015)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 53.521
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 71.831
Eval Task 12 for Age 13
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.130 (4.130)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 56.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 72.000
Eval Task 13 for Age 13
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.511 (3.511)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 85.075
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67]
Method : OURS
----AGE 14----
current_task  [50, 16]
current_head  79
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.062048368229954284]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=237, sigma=tensor([3.9189]), eta=tensor([3.1459])
  (fc1): CosineLinear(input_features=512, output_features=231, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 206
video number + exemplar : 591
DataLoader Constructed : Train 18
Optimizer Constructed
video number : 206
video number + exemplar : 206
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 05:58:50.512695
Epoch: [0][0/18], lr: 0.00100	Time 4.057 (4.057)	Data 2.708 (2.708)	Loss 0.2026 (0.2026)	Loss CE 0.1191 (0.1191)	Loss KD (Logit) 0.2590 (0.2590)	Loss KD (GCAM) 0.0369 (0.0369)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5629 (0.5629)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9000], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 05:59:09.793018
Epoch: [1][0/18], lr: 0.00100	Time 3.713 (3.713)	Data 2.109 (2.109)	Loss 0.2967 (0.2967)	Loss CE 0.2110 (0.2110)	Loss KD (Logit) 0.2631 (0.2631)	Loss KD (GCAM) 0.0407 (0.0407)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5720 (0.5720)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8847], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 05:59:29.457208
Epoch: [2][0/18], lr: 0.00100	Time 3.356 (3.356)	Data 1.990 (1.990)	Loss 0.2412 (0.2412)	Loss CE 0.1555 (0.1555)	Loss KD (Logit) 0.2735 (0.2735)	Loss KD (GCAM) 0.0430 (0.0430)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5586 (0.5586)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8786], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1215], device='cuda:0', requires_grad=True)
2022-03-24 05:59:48.820130
Epoch: [3][0/18], lr: 0.00100	Time 3.257 (3.257)	Data 2.456 (2.456)	Loss 0.1212 (0.1212)	Loss CE 0.0342 (0.0342)	Loss KD (Logit) 0.2654 (0.2654)	Loss KD (GCAM) 0.0500 (0.0500)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5560 (0.5560)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8669], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1152], device='cuda:0', requires_grad=True)
2022-03-24 06:00:08.407880
Epoch: [4][0/18], lr: 0.00100	Time 3.626 (3.626)	Data 2.262 (2.262)	Loss 0.3071 (0.3071)	Loss CE 0.2160 (0.2160)	Loss KD (Logit) 0.2813 (0.2813)	Loss KD (GCAM) 0.0575 (0.0575)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5644 (0.5644)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8642], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1140], device='cuda:0', requires_grad=True)
2022-03-24 06:00:28.136335
Epoch: [5][0/18], lr: 0.00100	Time 3.668 (3.668)	Data 2.527 (2.527)	Loss 0.1147 (0.1147)	Loss CE 0.0270 (0.0270)	Loss KD (Logit) 0.2677 (0.2677)	Loss KD (GCAM) 0.0532 (0.0532)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5514 (0.5514)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8649], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1149], device='cuda:0', requires_grad=True)
2022-03-24 06:00:47.694209
Epoch: [6][0/18], lr: 0.00100	Time 3.698 (3.698)	Data 2.692 (2.692)	Loss 0.1103 (0.1103)	Loss CE 0.0180 (0.0180)	Loss KD (Logit) 0.2748 (0.2748)	Loss KD (GCAM) 0.0552 (0.0552)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5865 (0.5865)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8703], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1185], device='cuda:0', requires_grad=True)
2022-03-24 06:01:07.359746
Epoch: [7][0/18], lr: 0.00100	Time 3.552 (3.552)	Data 2.202 (2.202)	Loss 0.1849 (0.1849)	Loss CE 0.0943 (0.0943)	Loss KD (Logit) 0.2665 (0.2665)	Loss KD (GCAM) 0.0518 (0.0518)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5853 (0.5853)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8745], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1209], device='cuda:0', requires_grad=True)
2022-03-24 06:01:26.877213
Epoch: [8][0/18], lr: 0.00100	Time 3.353 (3.353)	Data 1.907 (1.907)	Loss 0.0926 (0.0926)	Loss CE 0.0040 (0.0040)	Loss KD (Logit) 0.2782 (0.2782)	Loss KD (GCAM) 0.0506 (0.0506)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5616 (0.5616)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8785], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1236], device='cuda:0', requires_grad=True)
2022-03-24 06:01:46.042504
Epoch: [9][0/18], lr: 0.00100	Time 3.267 (3.267)	Data 2.275 (2.275)	Loss 0.0902 (0.0902)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.2694 (0.2694)	Loss KD (GCAM) 0.0507 (0.0507)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5536 (0.5536)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8811], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1250], device='cuda:0', requires_grad=True)
2022-03-24 06:02:05.572551
Epoch: [10][0/18], lr: 0.00100	Time 3.420 (3.420)	Data 1.944 (1.944)	Loss 0.1426 (0.1426)	Loss CE 0.0540 (0.0540)	Loss KD (Logit) 0.2737 (0.2737)	Loss KD (GCAM) 0.0504 (0.0504)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5643 (0.5643)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8867], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1281], device='cuda:0', requires_grad=True)
2022-03-24 06:02:25.344511
Epoch: [11][0/18], lr: 0.00100	Time 3.733 (3.733)	Data 2.648 (2.648)	Loss 0.0887 (0.0887)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.2575 (0.2575)	Loss KD (GCAM) 0.0431 (0.0431)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5854 (0.5854)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 06:02:44.718607
Epoch: [12][0/18], lr: 0.00100	Time 3.453 (3.453)	Data 2.501 (2.501)	Loss 0.0879 (0.0879)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.2878 (0.2878)	Loss KD (GCAM) 0.0506 (0.0506)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5384 (0.5384)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8900], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1299], device='cuda:0', requires_grad=True)
2022-03-24 06:03:04.443143
Epoch: [13][0/18], lr: 0.00100	Time 3.373 (3.373)	Data 2.101 (2.101)	Loss 0.0874 (0.0874)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.2554 (0.2554)	Loss KD (GCAM) 0.0475 (0.0475)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5393 (0.5393)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8916], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1308], device='cuda:0', requires_grad=True)
2022-03-24 06:03:23.858858
Epoch: [14][0/18], lr: 0.00100	Time 3.154 (3.154)	Data 1.824 (1.824)	Loss 0.0866 (0.0866)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.2687 (0.2687)	Loss KD (GCAM) 0.0438 (0.0438)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5584 (0.5584)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8949], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1325], device='cuda:0', requires_grad=True)
2022-03-24 06:03:43.213175
Epoch: [15][0/18], lr: 0.00100	Time 3.466 (3.466)	Data 2.377 (2.377)	Loss 0.0959 (0.0959)	Loss CE 0.0085 (0.0085)	Loss KD (Logit) 0.2678 (0.2678)	Loss KD (GCAM) 0.0439 (0.0439)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5767 (0.5767)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8976], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1341], device='cuda:0', requires_grad=True)
2022-03-24 06:04:02.399320
Epoch: [16][0/18], lr: 0.00100	Time 3.497 (3.497)	Data 2.461 (2.461)	Loss 0.0857 (0.0857)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.2748 (0.2748)	Loss KD (GCAM) 0.0469 (0.0469)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5328 (0.5328)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8982], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1344], device='cuda:0', requires_grad=True)
2022-03-24 06:04:21.710127
Epoch: [17][0/18], lr: 0.00100	Time 2.860 (2.860)	Data 1.836 (1.836)	Loss 0.0881 (0.0881)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.2747 (0.2747)	Loss KD (GCAM) 0.0433 (0.0433)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5645 (0.5645)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8987], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 06:04:41.288349
Epoch: [18][0/18], lr: 0.00100	Time 3.447 (3.447)	Data 2.550 (2.550)	Loss 0.0915 (0.0915)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.2679 (0.2679)	Loss KD (GCAM) 0.0423 (0.0423)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5897 (0.5897)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9000], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1352], device='cuda:0', requires_grad=True)
2022-03-24 06:05:00.638971
Epoch: [19][0/18], lr: 0.00100	Time 3.495 (3.495)	Data 2.333 (2.333)	Loss 0.0929 (0.0929)	Loss CE 0.0081 (0.0081)	Loss KD (Logit) 0.2607 (0.2607)	Loss KD (GCAM) 0.0429 (0.0429)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5584 (0.5584)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9015], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1359], device='cuda:0', requires_grad=True)
2022-03-24 06:05:20.390327
Epoch: [20][0/18], lr: 0.00010	Time 3.370 (3.370)	Data 2.240 (2.240)	Loss 0.0826 (0.0826)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.2644 (0.2644)	Loss KD (GCAM) 0.0380 (0.0380)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5381 (0.5381)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9016], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1359], device='cuda:0', requires_grad=True)
2022-03-24 06:05:39.508904
Epoch: [21][0/18], lr: 0.00010	Time 3.192 (3.192)	Data 2.143 (2.143)	Loss 0.0832 (0.0832)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.2642 (0.2642)	Loss KD (GCAM) 0.0402 (0.0402)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5424 (0.5424)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9017], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1360], device='cuda:0', requires_grad=True)
2022-03-24 06:05:58.944924
Epoch: [22][0/18], lr: 0.00010	Time 3.432 (3.432)	Data 1.995 (1.995)	Loss 0.0932 (0.0932)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.2689 (0.2689)	Loss KD (GCAM) 0.0427 (0.0427)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5825 (0.5825)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9019], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1361], device='cuda:0', requires_grad=True)
2022-03-24 06:06:18.480128
Epoch: [23][0/18], lr: 0.00010	Time 3.451 (3.451)	Data 1.990 (1.990)	Loss 0.0824 (0.0824)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.2650 (0.2650)	Loss KD (GCAM) 0.0417 (0.0417)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5205 (0.5205)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9021], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1362], device='cuda:0', requires_grad=True)
2022-03-24 06:06:37.627991
Epoch: [24][0/18], lr: 0.00010	Time 3.229 (3.229)	Data 1.907 (1.907)	Loss 0.0801 (0.0801)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.2642 (0.2642)	Loss KD (GCAM) 0.0367 (0.0367)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5190 (0.5190)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9024], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1363], device='cuda:0', requires_grad=True)
2022-03-24 06:06:55.962728
Epoch: [25][0/18], lr: 0.00010	Time 3.376 (3.376)	Data 1.908 (1.908)	Loss 0.0887 (0.0887)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.2593 (0.2593)	Loss KD (GCAM) 0.0405 (0.0405)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5771 (0.5771)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9024], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1363], device='cuda:0', requires_grad=True)
2022-03-24 06:07:13.239447
Epoch: [26][0/18], lr: 0.00010	Time 3.126 (3.126)	Data 1.990 (1.990)	Loss 0.0803 (0.0803)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.2617 (0.2617)	Loss KD (GCAM) 0.0367 (0.0367)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5240 (0.5240)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9026], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1364], device='cuda:0', requires_grad=True)
2022-03-24 06:07:30.632241
Epoch: [27][0/18], lr: 0.00010	Time 3.239 (3.239)	Data 2.170 (2.170)	Loss 0.0870 (0.0870)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.2610 (0.2610)	Loss KD (GCAM) 0.0363 (0.0363)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5701 (0.5701)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9027], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:07:47.003701
Epoch: [28][0/18], lr: 0.00010	Time 3.325 (3.325)	Data 2.618 (2.618)	Loss 0.0842 (0.0842)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.2688 (0.2688)	Loss KD (GCAM) 0.0396 (0.0396)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5531 (0.5531)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9027], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:08:03.557969
Epoch: [29][0/18], lr: 0.00010	Time 3.670 (3.670)	Data 2.271 (2.271)	Loss 0.0850 (0.0850)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.2734 (0.2734)	Loss KD (GCAM) 0.0353 (0.0353)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5720 (0.5720)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9028], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:08:19.695817
Epoch: [30][0/18], lr: 0.00001	Time 3.356 (3.356)	Data 2.504 (2.504)	Loss 0.0967 (0.0967)	Loss CE 0.0120 (0.0120)	Loss KD (Logit) 0.2514 (0.2514)	Loss KD (GCAM) 0.0382 (0.0382)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5770 (0.5770)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:08:35.944621
Epoch: [31][0/18], lr: 0.00001	Time 3.327 (3.327)	Data 2.084 (2.084)	Loss 0.0900 (0.0900)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.2644 (0.2644)	Loss KD (GCAM) 0.0464 (0.0464)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5894 (0.5894)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:08:52.249284
Epoch: [32][0/18], lr: 0.00001	Time 3.253 (3.253)	Data 1.974 (1.974)	Loss 0.0781 (0.0781)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.2505 (0.2505)	Loss KD (GCAM) 0.0371 (0.0371)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5094 (0.5094)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:09:08.779871
Epoch: [33][0/18], lr: 0.00001	Time 3.383 (3.383)	Data 2.193 (2.193)	Loss 0.0823 (0.0823)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.2604 (0.2604)	Loss KD (GCAM) 0.0442 (0.0442)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5183 (0.5183)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:09:25.397807
Epoch: [34][0/18], lr: 0.00001	Time 3.331 (3.331)	Data 2.187 (2.187)	Loss 0.0830 (0.0830)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.2543 (0.2543)	Loss KD (GCAM) 0.0392 (0.0392)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5389 (0.5389)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:09:41.629046
Epoch: [35][0/18], lr: 0.00001	Time 3.171 (3.171)	Data 2.295 (2.295)	Loss 0.0809 (0.0809)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.2539 (0.2539)	Loss KD (GCAM) 0.0375 (0.0375)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5367 (0.5367)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:09:58.358433
Epoch: [36][0/18], lr: 0.00001	Time 3.327 (3.327)	Data 2.004 (2.004)	Loss 0.0888 (0.0888)	Loss CE 0.0082 (0.0082)	Loss KD (Logit) 0.2625 (0.2625)	Loss KD (GCAM) 0.0432 (0.0432)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5137 (0.5137)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:10:15.115089
Epoch: [37][0/18], lr: 0.00001	Time 3.315 (3.315)	Data 2.426 (2.426)	Loss 0.0877 (0.0877)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.2588 (0.2588)	Loss KD (GCAM) 0.0424 (0.0424)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5800 (0.5800)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:10:31.882738
Epoch: [38][0/18], lr: 0.00001	Time 3.238 (3.238)	Data 2.033 (2.033)	Loss 0.0836 (0.0836)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.2558 (0.2558)	Loss KD (GCAM) 0.0416 (0.0416)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5314 (0.5314)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9029], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:10:48.480348
Epoch: [39][0/18], lr: 0.00001	Time 3.213 (3.213)	Data 2.112 (2.112)	Loss 0.0875 (0.0875)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.2655 (0.2655)	Loss KD (GCAM) 0.0438 (0.0438)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5596 (0.5596)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:11:05.190577
Epoch: [40][0/18], lr: 0.00001	Time 3.242 (3.242)	Data 2.223 (2.223)	Loss 0.0853 (0.0853)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.2604 (0.2604)	Loss KD (GCAM) 0.0406 (0.0406)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5690 (0.5690)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:11:21.411749
Epoch: [41][0/18], lr: 0.00001	Time 3.326 (3.326)	Data 2.322 (2.322)	Loss 0.0857 (0.0857)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.2594 (0.2594)	Loss KD (GCAM) 0.0391 (0.0391)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5647 (0.5647)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:11:37.968042
Epoch: [42][0/18], lr: 0.00001	Time 3.436 (3.436)	Data 2.240 (2.240)	Loss 0.0774 (0.0774)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.2521 (0.2521)	Loss KD (GCAM) 0.0368 (0.0368)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5052 (0.5052)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:11:54.545029
Epoch: [43][0/18], lr: 0.00001	Time 3.173 (3.173)	Data 2.372 (2.372)	Loss 0.0814 (0.0814)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.2588 (0.2588)	Loss KD (GCAM) 0.0374 (0.0374)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5250 (0.5250)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:12:10.877565
Epoch: [44][0/18], lr: 0.00001	Time 3.093 (3.093)	Data 2.344 (2.344)	Loss 0.0871 (0.0871)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.2626 (0.2626)	Loss KD (GCAM) 0.0387 (0.0387)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5919 (0.5919)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:12:26.658963
Epoch: [45][0/18], lr: 0.00001	Time 3.627 (3.627)	Data 2.542 (2.542)	Loss 0.0891 (0.0891)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.2684 (0.2684)	Loss KD (GCAM) 0.0367 (0.0367)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6003 (0.6003)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:12:45.624737
Epoch: [46][0/18], lr: 0.00001	Time 3.089 (3.089)	Data 2.104 (2.104)	Loss 0.0863 (0.0863)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.2658 (0.2658)	Loss KD (GCAM) 0.0380 (0.0380)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5776 (0.5776)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:13:04.978052
Epoch: [47][0/18], lr: 0.00001	Time 3.432 (3.432)	Data 2.527 (2.527)	Loss 0.0847 (0.0847)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.2594 (0.2594)	Loss KD (GCAM) 0.0427 (0.0427)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5287 (0.5287)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:13:24.670581
Epoch: [48][0/18], lr: 0.00001	Time 3.676 (3.676)	Data 2.632 (2.632)	Loss 0.0838 (0.0838)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.2667 (0.2667)	Loss KD (GCAM) 0.0381 (0.0381)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5272 (0.5272)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9031], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:13:44.151744
Epoch: [49][0/18], lr: 0.00001	Time 3.561 (3.561)	Data 2.085 (2.085)	Loss 0.0875 (0.0875)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.2678 (0.2678)	Loss KD (GCAM) 0.0421 (0.0421)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5683 (0.5683)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9031], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=237, sigma=tensor([3.9031]), eta=tensor([3.1366])
  (fc1): CosineLinear(input_features=512, output_features=231, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 206
video number + exemplar : 206
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=237, sigma=tensor([3.9031]), eta=tensor([3.1366])
  (fc1): CosineLinear(input_features=512, output_features=231, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 395
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-24 06:14:20.591987
Epoch: [0][0/12], lr: 0.00050	Time 2.977 (2.977)	Data 2.087 (2.087)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1365], device='cuda:0', requires_grad=True)
2022-03-24 06:14:30.264347
Epoch: [1][0/12], lr: 0.00050	Time 3.187 (3.187)	Data 2.330 (2.330)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9034], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1366], device='cuda:0', requires_grad=True)
2022-03-24 06:14:39.886316
Epoch: [2][0/12], lr: 0.00050	Time 2.968 (2.968)	Data 1.792 (1.792)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9027], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1361], device='cuda:0', requires_grad=True)
2022-03-24 06:14:49.560925
Epoch: [3][0/12], lr: 0.00050	Time 3.086 (3.086)	Data 1.870 (1.870)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9028], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1360], device='cuda:0', requires_grad=True)
2022-03-24 06:14:58.904734
Epoch: [4][0/12], lr: 0.00050	Time 2.942 (2.942)	Data 2.447 (2.447)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9028], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1359], device='cuda:0', requires_grad=True)
2022-03-24 06:15:08.645277
Epoch: [5][0/12], lr: 0.00050	Time 3.187 (3.187)	Data 2.073 (2.073)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9035], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1361], device='cuda:0', requires_grad=True)
2022-03-24 06:15:18.475866
Epoch: [6][0/12], lr: 0.00050	Time 3.170 (3.170)	Data 2.557 (2.557)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9043], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1363], device='cuda:0', requires_grad=True)
2022-03-24 06:15:28.267412
Epoch: [7][0/12], lr: 0.00050	Time 3.068 (3.068)	Data 2.295 (2.295)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9046], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1363], device='cuda:0', requires_grad=True)
2022-03-24 06:15:38.075669
Epoch: [8][0/12], lr: 0.00050	Time 3.133 (3.133)	Data 2.217 (2.217)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9048], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1362], device='cuda:0', requires_grad=True)
2022-03-24 06:15:47.694402
Epoch: [9][0/12], lr: 0.00050	Time 3.015 (3.015)	Data 1.950 (1.950)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9053], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1363], device='cuda:0', requires_grad=True)
2022-03-24 06:15:57.066860
Epoch: [10][0/12], lr: 0.00050	Time 2.875 (2.875)	Data 2.328 (2.328)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9057], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1364], device='cuda:0', requires_grad=True)
2022-03-24 06:16:06.554132
Epoch: [11][0/12], lr: 0.00050	Time 2.891 (2.891)	Data 1.898 (1.898)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9055], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1360], device='cuda:0', requires_grad=True)
2022-03-24 06:16:16.349752
Epoch: [12][0/12], lr: 0.00050	Time 3.184 (3.184)	Data 2.423 (2.423)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9054], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1358], device='cuda:0', requires_grad=True)
2022-03-24 06:16:26.037789
Epoch: [13][0/12], lr: 0.00050	Time 3.239 (3.239)	Data 2.353 (2.353)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9053], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1355], device='cuda:0', requires_grad=True)
2022-03-24 06:16:35.358066
Epoch: [14][0/12], lr: 0.00050	Time 2.952 (2.952)	Data 2.084 (2.084)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9053], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1353], device='cuda:0', requires_grad=True)
2022-03-24 06:16:44.971900
Epoch: [15][0/12], lr: 0.00050	Time 3.090 (3.090)	Data 2.510 (2.510)	Loss 0.0189 (0.0189)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9055], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 06:16:54.570082
Epoch: [16][0/12], lr: 0.00050	Time 2.947 (2.947)	Data 1.928 (1.928)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9053], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 06:17:04.079605
Epoch: [17][0/12], lr: 0.00050	Time 2.956 (2.956)	Data 2.348 (2.348)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9045], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 06:17:13.463581
Epoch: [18][0/12], lr: 0.00050	Time 2.924 (2.924)	Data 2.066 (2.066)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9040], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1334], device='cuda:0', requires_grad=True)
2022-03-24 06:17:23.273971
Epoch: [19][0/12], lr: 0.00050	Time 3.032 (3.032)	Data 2.328 (2.328)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9041], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_014.pth.tar
exemplar : 395
Computing the class mean vectors...
Eval Task 0 for Age 14
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 3.722 (3.722)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.551 (0.545)	Prec@1 75.000 (63.552)
Testing Results: Prec@1 63.542
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (69.616)
Testing Results (NME): Prec@1 69.531
Eval Task 1 for Age 14
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.148 (4.148)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 32.836
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 52.239
Eval Task 2 for Age 14
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.145 (4.145)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 83.544
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 74.684
Eval Task 3 for Age 14
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.198 (4.198)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 87.059
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 82.353
Eval Task 4 for Age 14
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 4.091 (4.091)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 69.863
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 64.384
Eval Task 5 for Age 14
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.113 (4.113)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 85.897
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 89.744
Eval Task 6 for Age 14
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.967 (3.967)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 47.761
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 62.687
Eval Task 7 for Age 14
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.831 (3.831)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 90.123
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 85.185
Eval Task 8 for Age 14
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.109 (4.109)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 65.152
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 62.121
Eval Task 9 for Age 14
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.837 (3.837)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 85.714
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.416
Eval Task 10 for Age 14
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.345 (4.345)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.341
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 93.902
Eval Task 11 for Age 14
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.149 (4.149)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 38.028
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 59.155
Eval Task 12 for Age 14
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.217 (4.217)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 57.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 73.333
Eval Task 13 for Age 14
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.393 (3.393)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 91.045
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 80.597
Eval Task 14 for Age 14
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.237 (4.237)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 96.591
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 80.682
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88]
Method : OURS
----AGE 15----
current_task  [49, 63]
current_head  81
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06284902544988268]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=243, sigma=tensor([3.9041]), eta=tensor([3.1333])
  (fc1): CosineLinear(input_features=512, output_features=237, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 166
video number + exemplar : 561
DataLoader Constructed : Train 17
Optimizer Constructed
video number : 166
video number + exemplar : 166
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 06:22:41.681135
Epoch: [0][0/17], lr: 0.00100	Time 3.472 (3.472)	Data 2.413 (2.413)	Loss 0.0697 (0.0697)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0495 (0.0495)	Loss KD (GCAM) 0.0194 (0.0194)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5842 (0.5842)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9050], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1336], device='cuda:0', requires_grad=True)
2022-03-24 06:22:56.986491
Epoch: [1][0/17], lr: 0.00100	Time 3.326 (3.326)	Data 1.896 (1.896)	Loss 0.0759 (0.0759)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.0512 (0.0512)	Loss KD (GCAM) 0.0167 (0.0167)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6150 (0.6150)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9053], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1338], device='cuda:0', requires_grad=True)
2022-03-24 06:23:12.756887
Epoch: [2][0/17], lr: 0.00100	Time 3.217 (3.217)	Data 2.149 (2.149)	Loss 0.0670 (0.0670)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0498 (0.0498)	Loss KD (GCAM) 0.0167 (0.0167)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5861 (0.5861)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9067], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1343], device='cuda:0', requires_grad=True)
2022-03-24 06:23:28.355633
Epoch: [3][0/17], lr: 0.00100	Time 3.276 (3.276)	Data 2.497 (2.497)	Loss 0.0661 (0.0661)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0505 (0.0505)	Loss KD (GCAM) 0.0211 (0.0211)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5640 (0.5640)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9054], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1329], device='cuda:0', requires_grad=True)
2022-03-24 06:23:44.075700
Epoch: [4][0/17], lr: 0.00100	Time 3.182 (3.182)	Data 2.021 (2.021)	Loss 0.0741 (0.0741)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0528 (0.0528)	Loss KD (GCAM) 0.0227 (0.0227)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5813 (0.5813)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9055], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1329], device='cuda:0', requires_grad=True)
2022-03-24 06:23:59.797673
Epoch: [5][0/17], lr: 0.00100	Time 3.162 (3.162)	Data 1.979 (1.979)	Loss 0.0675 (0.0675)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0538 (0.0538)	Loss KD (GCAM) 0.0240 (0.0240)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5654 (0.5654)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9066], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
2022-03-24 06:24:15.906872
Epoch: [6][0/17], lr: 0.00100	Time 3.535 (3.535)	Data 2.529 (2.529)	Loss 0.0756 (0.0756)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0534 (0.0534)	Loss KD (GCAM) 0.0234 (0.0234)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5942 (0.5942)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9049], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1320], device='cuda:0', requires_grad=True)
2022-03-24 06:24:31.545500
Epoch: [7][0/17], lr: 0.00100	Time 3.398 (3.398)	Data 2.460 (2.460)	Loss 0.1028 (0.1028)	Loss CE 0.0304 (0.0304)	Loss KD (Logit) 0.0548 (0.0548)	Loss KD (GCAM) 0.0287 (0.0287)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6040 (0.6040)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9046], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1321], device='cuda:0', requires_grad=True)
2022-03-24 06:24:47.128093
Epoch: [8][0/17], lr: 0.00100	Time 3.022 (3.022)	Data 1.807 (1.807)	Loss 0.0772 (0.0772)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0507 (0.0507)	Loss KD (GCAM) 0.0226 (0.0226)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6638 (0.6638)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9061], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1331], device='cuda:0', requires_grad=True)
2022-03-24 06:25:03.168926
Epoch: [9][0/17], lr: 0.00100	Time 3.364 (3.364)	Data 2.500 (2.500)	Loss 0.0745 (0.0745)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0526 (0.0526)	Loss KD (GCAM) 0.0237 (0.0237)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6054 (0.6054)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9082], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1343], device='cuda:0', requires_grad=True)
2022-03-24 06:25:19.115106
Epoch: [10][0/17], lr: 0.00100	Time 3.411 (3.411)	Data 2.321 (2.321)	Loss 0.0718 (0.0718)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0505 (0.0505)	Loss KD (GCAM) 0.0268 (0.0268)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6012 (0.6012)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9106], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1357], device='cuda:0', requires_grad=True)
2022-03-24 06:25:35.001087
Epoch: [11][0/17], lr: 0.00100	Time 3.395 (3.395)	Data 2.111 (2.111)	Loss 0.0718 (0.0718)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0530 (0.0530)	Loss KD (GCAM) 0.0249 (0.0249)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6079 (0.6079)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9081], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 06:25:50.664777
Epoch: [12][0/17], lr: 0.00100	Time 3.220 (3.220)	Data 2.285 (2.285)	Loss 0.0645 (0.0645)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0542 (0.0542)	Loss KD (GCAM) 0.0234 (0.0234)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5341 (0.5341)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9083], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1338], device='cuda:0', requires_grad=True)
2022-03-24 06:26:06.392892
Epoch: [13][0/17], lr: 0.00100	Time 3.090 (3.090)	Data 1.885 (1.885)	Loss 0.0728 (0.0728)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0531 (0.0531)	Loss KD (GCAM) 0.0260 (0.0260)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6074 (0.6074)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9088], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 06:26:21.349226
Epoch: [14][0/17], lr: 0.00100	Time 3.291 (3.291)	Data 2.043 (2.043)	Loss 0.0704 (0.0704)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0539 (0.0539)	Loss KD (GCAM) 0.0263 (0.0263)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5866 (0.5866)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9102], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1344], device='cuda:0', requires_grad=True)
2022-03-24 06:26:40.305135
Epoch: [15][0/17], lr: 0.00100	Time 3.573 (3.573)	Data 2.691 (2.691)	Loss 0.0771 (0.0771)	Loss CE 0.0084 (0.0084)	Loss KD (Logit) 0.0519 (0.0519)	Loss KD (GCAM) 0.0254 (0.0254)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5784 (0.5784)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9116], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1350], device='cuda:0', requires_grad=True)
2022-03-24 06:26:58.772777
Epoch: [16][0/17], lr: 0.00100	Time 3.406 (3.406)	Data 2.201 (2.201)	Loss 0.0700 (0.0700)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0509 (0.0509)	Loss KD (GCAM) 0.0254 (0.0254)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5712 (0.5712)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9126], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1354], device='cuda:0', requires_grad=True)
2022-03-24 06:27:17.431114
Epoch: [17][0/17], lr: 0.00100	Time 3.286 (3.286)	Data 2.478 (2.478)	Loss 0.0756 (0.0756)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0526 (0.0526)	Loss KD (GCAM) 0.0244 (0.0244)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6219 (0.6219)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9131], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1354], device='cuda:0', requires_grad=True)
2022-03-24 06:27:35.839296
Epoch: [18][0/17], lr: 0.00100	Time 3.304 (3.304)	Data 2.316 (2.316)	Loss 0.0719 (0.0719)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0521 (0.0521)	Loss KD (GCAM) 0.0206 (0.0206)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6229 (0.6229)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9133], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1353], device='cuda:0', requires_grad=True)
2022-03-24 06:27:54.542106
Epoch: [19][0/17], lr: 0.00100	Time 3.557 (3.557)	Data 2.546 (2.546)	Loss 0.0682 (0.0682)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0507 (0.0507)	Loss KD (GCAM) 0.0214 (0.0214)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5819 (0.5819)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 06:28:13.362056
Epoch: [20][0/17], lr: 0.00010	Time 3.415 (3.415)	Data 2.173 (2.173)	Loss 0.0697 (0.0697)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0528 (0.0528)	Loss KD (GCAM) 0.0228 (0.0228)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5941 (0.5941)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 06:28:31.772321
Epoch: [21][0/17], lr: 0.00010	Time 3.401 (3.401)	Data 1.863 (1.863)	Loss 0.0723 (0.0723)	Loss CE 0.0000 (0.0000)	Loss KD (Logit) 0.0521 (0.0521)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6299 (0.6299)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 06:28:50.393028
Epoch: [22][0/17], lr: 0.00010	Time 3.483 (3.483)	Data 2.537 (2.537)	Loss 0.0692 (0.0692)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0504 (0.0504)	Loss KD (GCAM) 0.0195 (0.0195)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5989 (0.5989)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 06:29:08.846031
Sigma : Parameter containing:
tensor([3.9135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1351], device='cuda:0', requires_grad=True)
2022-03-24 06:29:27.185599
Epoch: [24][0/17], lr: 0.00010	Time 3.400 (3.400)	Data 1.969 (1.969)	Loss 0.0660 (0.0660)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0524 (0.0524)	Loss KD (GCAM) 0.0220 (0.0220)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5599 (0.5599)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1350], device='cuda:0', requires_grad=True)
2022-03-24 06:29:45.557397
Epoch: [25][0/17], lr: 0.00010	Time 3.368 (3.368)	Data 2.087 (2.087)	Loss 0.1108 (0.1108)	Loss CE 0.0465 (0.0465)	Loss KD (Logit) 0.0535 (0.0535)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5492 (0.5492)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9135], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1350], device='cuda:0', requires_grad=True)
2022-03-24 06:30:03.960665
Epoch: [26][0/17], lr: 0.00010	Time 3.551 (3.551)	Data 2.570 (2.570)	Loss 0.0720 (0.0720)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0522 (0.0522)	Loss KD (GCAM) 0.0228 (0.0228)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6161 (0.6161)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1349], device='cuda:0', requires_grad=True)
2022-03-24 06:30:22.474667
Epoch: [27][0/17], lr: 0.00010	Time 3.279 (3.279)	Data 1.973 (1.973)	Loss 0.0716 (0.0716)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0515 (0.0515)	Loss KD (GCAM) 0.0215 (0.0215)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6145 (0.6145)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1349], device='cuda:0', requires_grad=True)
2022-03-24 06:30:40.639738
Epoch: [28][0/17], lr: 0.00010	Time 3.241 (3.241)	Data 1.876 (1.876)	Loss 0.0702 (0.0702)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0522 (0.0522)	Loss KD (GCAM) 0.0213 (0.0213)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6046 (0.6046)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1349], device='cuda:0', requires_grad=True)
2022-03-24 06:30:59.157773
Epoch: [29][0/17], lr: 0.00010	Time 3.423 (3.423)	Data 2.145 (2.145)	Loss 0.0690 (0.0690)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0501 (0.0501)	Loss KD (GCAM) 0.0215 (0.0215)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5918 (0.5918)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1349], device='cuda:0', requires_grad=True)
2022-03-24 06:31:17.321776
Epoch: [30][0/17], lr: 0.00001	Time 3.286 (3.286)	Data 1.832 (1.832)	Loss 0.0701 (0.0701)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0528 (0.0528)	Loss KD (GCAM) 0.0251 (0.0251)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5902 (0.5902)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:31:35.770933
Epoch: [31][0/17], lr: 0.00001	Time 3.298 (3.298)	Data 1.874 (1.874)	Loss 0.0681 (0.0681)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0514 (0.0514)	Loss KD (GCAM) 0.0224 (0.0224)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5736 (0.5736)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:31:54.139988
Epoch: [32][0/17], lr: 0.00001	Time 3.434 (3.434)	Data 1.889 (1.889)	Loss 0.0735 (0.0735)	Loss CE 0.0000 (0.0000)	Loss KD (Logit) 0.0514 (0.0514)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6424 (0.6424)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:32:12.517137
Epoch: [33][0/17], lr: 0.00001	Time 3.380 (3.380)	Data 1.927 (1.927)	Loss 0.0761 (0.0761)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0515 (0.0515)	Loss KD (GCAM) 0.0236 (0.0236)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6244 (0.6244)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:32:30.915025
Epoch: [34][0/17], lr: 0.00001	Time 3.393 (3.393)	Data 2.243 (2.243)	Loss 0.0667 (0.0667)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0516 (0.0516)	Loss KD (GCAM) 0.0185 (0.0185)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5777 (0.5777)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:32:49.411920
Epoch: [35][0/17], lr: 0.00001	Time 3.377 (3.377)	Data 2.251 (2.251)	Loss 0.0722 (0.0722)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0526 (0.0526)	Loss KD (GCAM) 0.0209 (0.0209)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6218 (0.6218)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:33:07.852374
Epoch: [36][0/17], lr: 0.00001	Time 3.200 (3.200)	Data 2.076 (2.076)	Loss 0.0711 (0.0711)	Loss CE 0.0050 (0.0050)	Loss KD (Logit) 0.0517 (0.0517)	Loss KD (GCAM) 0.0216 (0.0216)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5642 (0.5642)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:33:26.074136
Epoch: [37][0/17], lr: 0.00001	Time 3.375 (3.375)	Data 2.515 (2.515)	Loss 0.0682 (0.0682)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0508 (0.0508)	Loss KD (GCAM) 0.0200 (0.0200)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5879 (0.5879)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:33:44.565051
Epoch: [38][0/17], lr: 0.00001	Time 3.531 (3.531)	Data 2.466 (2.466)	Loss 0.0696 (0.0696)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0512 (0.0512)	Loss KD (GCAM) 0.0217 (0.0217)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5963 (0.5963)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:34:02.958922
Epoch: [39][0/17], lr: 0.00001	Time 3.406 (3.406)	Data 2.191 (2.191)	Loss 0.0701 (0.0701)	Loss CE 0.0000 (0.0000)	Loss KD (Logit) 0.0523 (0.0523)	Loss KD (GCAM) 0.0202 (0.0202)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6067 (0.6067)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:34:21.249839
Epoch: [40][0/17], lr: 0.00001	Time 3.273 (3.273)	Data 2.281 (2.281)	Loss 0.0674 (0.0674)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0521 (0.0521)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5789 (0.5789)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:34:39.788328
Epoch: [41][0/17], lr: 0.00001	Time 3.650 (3.650)	Data 2.373 (2.373)	Loss 0.0704 (0.0704)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0514 (0.0514)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6105 (0.6105)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:34:58.264540
Epoch: [42][0/17], lr: 0.00001	Time 3.265 (3.265)	Data 2.048 (2.048)	Loss 0.0702 (0.0702)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0527 (0.0527)	Loss KD (GCAM) 0.0220 (0.0220)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6012 (0.6012)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:35:16.462665
Epoch: [43][0/17], lr: 0.00001	Time 3.319 (3.319)	Data 2.072 (2.072)	Loss 0.0720 (0.0720)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0529 (0.0529)	Loss KD (GCAM) 0.0245 (0.0245)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6111 (0.6111)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:35:35.097059
Epoch: [44][0/17], lr: 0.00001	Time 3.379 (3.379)	Data 2.657 (2.657)	Loss 0.0745 (0.0745)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0522 (0.0522)	Loss KD (GCAM) 0.0257 (0.0257)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6240 (0.6240)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:35:52.013499
Epoch: [45][0/17], lr: 0.00001	Time 3.467 (3.467)	Data 2.438 (2.438)	Loss 0.0698 (0.0698)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0519 (0.0519)	Loss KD (GCAM) 0.0206 (0.0206)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6025 (0.6025)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:36:08.816359
Epoch: [46][0/17], lr: 0.00001	Time 3.174 (3.174)	Data 2.396 (2.396)	Loss 0.0729 (0.0729)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0528 (0.0528)	Loss KD (GCAM) 0.0243 (0.0243)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6215 (0.6215)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:36:26.034435
Epoch: [47][0/17], lr: 0.00001	Time 3.305 (3.305)	Data 2.012 (2.012)	Loss 0.0772 (0.0772)	Loss CE 0.0137 (0.0137)	Loss KD (Logit) 0.0510 (0.0510)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5428 (0.5428)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:36:41.669156
Epoch: [48][0/17], lr: 0.00001	Time 3.217 (3.217)	Data 2.086 (2.086)	Loss 0.0702 (0.0702)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0529 (0.0529)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6060 (0.6060)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
2022-03-24 06:36:57.290083
Epoch: [49][0/17], lr: 0.00001	Time 3.461 (3.461)	Data 2.188 (2.188)	Loss 0.0740 (0.0740)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0509 (0.0509)	Loss KD (GCAM) 0.0232 (0.0232)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6368 (0.6368)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9134], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1348], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=243, sigma=tensor([3.9134]), eta=tensor([3.1348])
  (fc1): CosineLinear(input_features=512, output_features=237, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 166
video number + exemplar : 166
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=243, sigma=tensor([3.9134]), eta=tensor([3.1348])
  (fc1): CosineLinear(input_features=512, output_features=237, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 405
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-24 06:37:27.222891
Epoch: [0][0/12], lr: 0.00050	Time 2.812 (2.812)	Data 1.953 (1.953)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9133], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1346], device='cuda:0', requires_grad=True)
2022-03-24 06:37:35.809245
Epoch: [1][0/12], lr: 0.00050	Time 2.972 (2.972)	Data 1.946 (1.946)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9130], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1343], device='cuda:0', requires_grad=True)
2022-03-24 06:37:44.160188
Epoch: [2][0/12], lr: 0.00050	Time 2.991 (2.991)	Data 2.038 (2.038)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 06:37:52.628336
Epoch: [3][0/12], lr: 0.00050	Time 2.973 (2.973)	Data 2.060 (2.060)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9127], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1337], device='cuda:0', requires_grad=True)
2022-03-24 06:38:01.424967
Epoch: [4][0/12], lr: 0.00050	Time 3.062 (3.062)	Data 2.393 (2.393)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1336], device='cuda:0', requires_grad=True)
2022-03-24 06:38:10.062651
Epoch: [5][0/12], lr: 0.00050	Time 2.975 (2.975)	Data 2.097 (2.097)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1335], device='cuda:0', requires_grad=True)
2022-03-24 06:38:18.680442
Epoch: [6][0/12], lr: 0.00050	Time 2.991 (2.991)	Data 2.216 (2.216)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
2022-03-24 06:38:27.123717
Epoch: [7][0/12], lr: 0.00050	Time 2.933 (2.933)	Data 2.150 (2.150)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9130], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1333], device='cuda:0', requires_grad=True)
2022-03-24 06:38:35.825073
Epoch: [8][0/12], lr: 0.00050	Time 3.000 (3.000)	Data 1.871 (1.871)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9129], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1330], device='cuda:0', requires_grad=True)
2022-03-24 06:38:44.500151
Epoch: [9][0/12], lr: 0.00050	Time 2.937 (2.937)	Data 2.382 (2.382)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9129], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1328], device='cuda:0', requires_grad=True)
2022-03-24 06:38:53.130806
Epoch: [10][0/12], lr: 0.00050	Time 3.015 (3.015)	Data 2.504 (2.504)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1325], device='cuda:0', requires_grad=True)
2022-03-24 06:39:01.734023
Epoch: [11][0/12], lr: 0.00050	Time 3.035 (3.035)	Data 1.970 (1.970)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9129], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1324], device='cuda:0', requires_grad=True)
2022-03-24 06:39:10.044466
Epoch: [12][0/12], lr: 0.00050	Time 2.856 (2.856)	Data 1.943 (1.943)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9130], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1322], device='cuda:0', requires_grad=True)
2022-03-24 06:39:18.548871
Epoch: [13][0/12], lr: 0.00050	Time 2.918 (2.918)	Data 1.894 (1.894)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9129], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1320], device='cuda:0', requires_grad=True)
2022-03-24 06:39:26.965162
Epoch: [14][0/12], lr: 0.00050	Time 2.960 (2.960)	Data 2.059 (2.059)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9127], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1317], device='cuda:0', requires_grad=True)
2022-03-24 06:39:35.324750
Epoch: [15][0/12], lr: 0.00050	Time 2.960 (2.960)	Data 2.288 (2.288)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1315], device='cuda:0', requires_grad=True)
2022-03-24 06:39:43.967205
Epoch: [16][0/12], lr: 0.00050	Time 3.088 (3.088)	Data 2.480 (2.480)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1314], device='cuda:0', requires_grad=True)
2022-03-24 06:39:52.819929
Epoch: [17][0/12], lr: 0.00050	Time 2.901 (2.901)	Data 2.358 (2.358)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1311], device='cuda:0', requires_grad=True)
2022-03-24 06:40:01.318378
Epoch: [18][0/12], lr: 0.00050	Time 2.922 (2.922)	Data 2.076 (2.076)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1309], device='cuda:0', requires_grad=True)
2022-03-24 06:40:09.780843
Epoch: [19][0/12], lr: 0.00050	Time 2.747 (2.747)	Data 1.886 (1.886)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9128], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1307], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_015.pth.tar
exemplar : 405
Computing the class mean vectors...
Eval Task 0 for Age 15
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 3.777 (3.777)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.565 (0.494)	Prec@1 87.500 (63.119)
Testing Results: Prec@1 63.594
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 93.750 (70.545)
Testing Results (NME): Prec@1 70.469
Eval Task 1 for Age 15
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.407 (3.407)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 49.254
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 61.194
Eval Task 2 for Age 15
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.894 (3.894)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 78.481
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 75.949
Eval Task 3 for Age 15
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.785 (3.785)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 87.059
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 84.706
Eval Task 4 for Age 15
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.595 (3.595)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 75.342
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 61.644
Eval Task 5 for Age 15
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.054 (4.054)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 88.462
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 89.744
Eval Task 6 for Age 15
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.018 (4.018)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 56.716
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 56.716
Eval Task 7 for Age 15
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.270 (4.270)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.296
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 88.889
Eval Task 8 for Age 15
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.905 (3.905)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 62.121
Eval Task 9 for Age 15
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.489 (3.489)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 85.714
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 83.117
Eval Task 10 for Age 15
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.918 (3.918)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.341
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.683
Eval Task 11 for Age 15
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.351 (3.351)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 57.746
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 59.155
Eval Task 12 for Age 15
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.134 (4.134)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 69.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 72.000
Eval Task 13 for Age 15
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.707 (3.707)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 86.567
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 77.612
Eval Task 14 for Age 15
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.188 (4.188)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 88.636
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 78.409
Eval Task 15 for Age 15
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 4.041 (4.041)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 98.387
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62]
Method : OURS
----AGE 16----
current_task  [48, 66]
current_head  83
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06363961030678927]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=249, sigma=tensor([3.9128]), eta=tensor([3.1307])
  (fc1): CosineLinear(input_features=512, output_features=243, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 177
video number + exemplar : 582
DataLoader Constructed : Train 18
Optimizer Constructed
video number : 177
video number + exemplar : 177
Initialize Cosine Classifier
Computing the class mean vectors...
2022-03-24 06:45:33.139833
Epoch: [0][0/18], lr: 0.00100	Time 3.695 (3.695)	Data 1.980 (1.980)	Loss 0.1847 (0.1847)	Loss CE 0.1333 (0.1333)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5114 (0.5114)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Sigma : Parameter containing:
tensor([3.8952], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1209], device='cuda:0', requires_grad=True)
2022-03-24 06:45:52.173107
Epoch: [1][0/18], lr: 0.00100	Time 3.341 (3.341)	Data 2.108 (2.108)	Loss 0.0746 (0.0746)	Loss CE 0.0162 (0.0162)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0005 (0.0005)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5815 (0.5815)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8846], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 06:46:11.585707
Epoch: [2][0/18], lr: 0.00100	Time 3.290 (3.290)	Data 2.218 (2.218)	Loss 0.1053 (0.1053)	Loss CE 0.0479 (0.0479)	Loss KD (Logit) 0.0013 (0.0013)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5710 (0.5710)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8781], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1114], device='cuda:0', requires_grad=True)
2022-03-24 06:46:31.299886
Epoch: [3][0/18], lr: 0.00100	Time 3.573 (3.573)	Data 2.377 (2.377)	Loss 0.0919 (0.0919)	Loss CE 0.0371 (0.0371)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5447 (0.5447)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8665], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1037], device='cuda:0', requires_grad=True)
2022-03-24 06:46:50.909956
Epoch: [4][0/18], lr: 0.00100	Time 3.471 (3.471)	Data 2.547 (2.547)	Loss 0.5179 (0.5179)	Loss CE 0.4549 (0.4549)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6262 (0.6262)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0960], device='cuda:0', requires_grad=True)
2022-03-24 06:47:10.282418
Epoch: [5][0/18], lr: 0.00100	Time 3.296 (3.296)	Data 1.872 (1.872)	Loss 0.0600 (0.0600)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5702 (0.5702)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0941], device='cuda:0', requires_grad=True)
2022-03-24 06:47:30.249125
Epoch: [6][0/18], lr: 0.00100	Time 3.701 (3.701)	Data 2.524 (2.524)	Loss 0.0733 (0.0733)	Loss CE 0.0149 (0.0149)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5809 (0.5809)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8490], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0918], device='cuda:0', requires_grad=True)
2022-03-24 06:47:49.881106
Epoch: [7][0/18], lr: 0.00100	Time 3.542 (3.542)	Data 2.350 (2.350)	Loss 0.0869 (0.0869)	Loss CE 0.0289 (0.0289)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5764 (0.5764)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0936], device='cuda:0', requires_grad=True)
2022-03-24 06:48:09.489699
Epoch: [8][0/18], lr: 0.00100	Time 3.500 (3.500)	Data 2.286 (2.286)	Loss 0.0628 (0.0628)	Loss CE 0.0084 (0.0084)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5408 (0.5408)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8560], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0957], device='cuda:0', requires_grad=True)
2022-03-24 06:48:28.978321
Epoch: [9][0/18], lr: 0.00100	Time 3.377 (3.377)	Data 2.391 (2.391)	Loss 0.0638 (0.0638)	Loss CE 0.0109 (0.0109)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5257 (0.5257)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8571], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 06:48:48.820364
Epoch: [10][0/18], lr: 0.00100	Time 3.633 (3.633)	Data 2.480 (2.480)	Loss 0.0787 (0.0787)	Loss CE 0.0203 (0.0203)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5806 (0.5806)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8523], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0940], device='cuda:0', requires_grad=True)
2022-03-24 06:49:08.751636
Epoch: [11][0/18], lr: 0.00100	Time 3.508 (3.508)	Data 2.536 (2.536)	Loss 0.0577 (0.0577)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5702 (0.5702)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 06:49:27.540360
Epoch: [12][0/18], lr: 0.00100	Time 3.233 (3.233)	Data 1.942 (1.942)	Loss 0.0589 (0.0589)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5527 (0.5527)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8545], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0956], device='cuda:0', requires_grad=True)
2022-03-24 06:49:45.112551
Epoch: [13][0/18], lr: 0.00100	Time 3.138 (3.138)	Data 1.874 (1.874)	Loss 0.0604 (0.0604)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5696 (0.5696)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8577], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0971], device='cuda:0', requires_grad=True)
2022-03-24 06:50:03.436706
Epoch: [14][0/18], lr: 0.00100	Time 3.515 (3.515)	Data 2.150 (2.150)	Loss 0.0644 (0.0644)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6169 (0.6169)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 06:50:20.564093
Epoch: [15][0/18], lr: 0.00100	Time 3.472 (3.472)	Data 2.291 (2.291)	Loss 0.0554 (0.0554)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5446 (0.5446)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8546], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0943], device='cuda:0', requires_grad=True)
2022-03-24 06:50:36.791391
Epoch: [16][0/18], lr: 0.00100	Time 3.206 (3.206)	Data 1.904 (1.904)	Loss 0.0637 (0.0637)	Loss CE 0.0079 (0.0079)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5548 (0.5548)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8550], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0941], device='cuda:0', requires_grad=True)
2022-03-24 06:50:53.214849
Epoch: [17][0/18], lr: 0.00100	Time 3.236 (3.236)	Data 2.281 (2.281)	Loss 0.0594 (0.0594)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5680 (0.5680)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0916], device='cuda:0', requires_grad=True)
2022-03-24 06:51:09.528316
Epoch: [18][0/18], lr: 0.00100	Time 3.389 (3.389)	Data 2.188 (2.188)	Loss 0.0648 (0.0648)	Loss CE 0.0109 (0.0109)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5357 (0.5357)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8505], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0908], device='cuda:0', requires_grad=True)
2022-03-24 06:51:25.788215
Epoch: [19][0/18], lr: 0.00100	Time 3.357 (3.357)	Data 2.136 (2.136)	Loss 0.0677 (0.0677)	Loss CE 0.0115 (0.0115)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5581 (0.5581)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8534], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0919], device='cuda:0', requires_grad=True)
2022-03-24 06:51:42.183732
Epoch: [20][0/18], lr: 0.00010	Time 3.238 (3.238)	Data 2.394 (2.394)	Loss 0.0546 (0.0546)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5382 (0.5382)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8537], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0920], device='cuda:0', requires_grad=True)
2022-03-24 06:51:58.562092
Epoch: [21][0/18], lr: 0.00010	Time 3.319 (3.319)	Data 2.495 (2.495)	Loss 0.0558 (0.0558)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5432 (0.5432)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8540], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0922], device='cuda:0', requires_grad=True)
2022-03-24 06:52:14.996504
Epoch: [22][0/18], lr: 0.00010	Time 3.295 (3.295)	Data 2.544 (2.544)	Loss 0.0552 (0.0552)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5416 (0.5416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8542], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0923], device='cuda:0', requires_grad=True)
2022-03-24 06:52:31.433428
Epoch: [23][0/18], lr: 0.00010	Time 3.223 (3.223)	Data 1.926 (1.926)	Loss 0.0556 (0.0556)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5416 (0.5416)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8544], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0923], device='cuda:0', requires_grad=True)
2022-03-24 06:52:47.955263
Epoch: [24][0/18], lr: 0.00010	Time 3.172 (3.172)	Data 2.044 (2.044)	Loss 0.0574 (0.0574)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5487 (0.5487)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8545], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0924], device='cuda:0', requires_grad=True)
2022-03-24 06:53:04.629468
Epoch: [25][0/18], lr: 0.00010	Time 3.263 (3.263)	Data 2.434 (2.434)	Loss 0.0571 (0.0571)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5537 (0.5537)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8546], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0924], device='cuda:0', requires_grad=True)
2022-03-24 06:53:21.104375
Epoch: [26][0/18], lr: 0.00010	Time 3.233 (3.233)	Data 1.857 (1.857)	Loss 0.0630 (0.0630)	Loss CE 0.0066 (0.0066)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5609 (0.5609)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8547], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0925], device='cuda:0', requires_grad=True)
2022-03-24 06:53:37.551414
Epoch: [27][0/18], lr: 0.00010	Time 3.181 (3.181)	Data 2.066 (2.066)	Loss 0.0565 (0.0565)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5581 (0.5581)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8548], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0926], device='cuda:0', requires_grad=True)
2022-03-24 06:53:53.959112
Epoch: [28][0/18], lr: 0.00010	Time 3.382 (3.382)	Data 2.447 (2.447)	Loss 0.0572 (0.0572)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5660 (0.5660)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8550], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0926], device='cuda:0', requires_grad=True)
2022-03-24 06:54:10.615578
Epoch: [29][0/18], lr: 0.00010	Time 3.391 (3.391)	Data 2.562 (2.562)	Loss 0.0656 (0.0656)	Loss CE 0.0077 (0.0077)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5756 (0.5756)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:54:27.091027
Epoch: [30][0/18], lr: 0.00001	Time 3.181 (3.181)	Data 1.949 (1.949)	Loss 0.0561 (0.0561)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5521 (0.5521)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:54:43.527290
Epoch: [31][0/18], lr: 0.00001	Time 3.351 (3.351)	Data 2.288 (2.288)	Loss 0.0601 (0.0601)	Loss CE 0.0023 (0.0023)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5742 (0.5742)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:54:59.712874
Epoch: [32][0/18], lr: 0.00001	Time 3.240 (3.240)	Data 2.174 (2.174)	Loss 0.0568 (0.0568)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5530 (0.5530)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:55:16.683314
Epoch: [33][0/18], lr: 0.00001	Time 3.421 (3.421)	Data 1.990 (1.990)	Loss 0.0578 (0.0578)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5719 (0.5719)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:55:36.251623
Epoch: [34][0/18], lr: 0.00001	Time 3.598 (3.598)	Data 2.259 (2.259)	Loss 0.0544 (0.0544)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5374 (0.5374)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:55:55.930558
Epoch: [35][0/18], lr: 0.00001	Time 3.627 (3.627)	Data 2.512 (2.512)	Loss 0.0565 (0.0565)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5354 (0.5354)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:56:15.695380
Epoch: [36][0/18], lr: 0.00001	Time 3.671 (3.671)	Data 2.596 (2.596)	Loss 0.0602 (0.0602)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5893 (0.5893)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:56:35.171534
Epoch: [37][0/18], lr: 0.00001	Time 3.508 (3.508)	Data 2.071 (2.071)	Loss 0.0585 (0.0585)	Loss CE 0.0089 (0.0089)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4934 (0.4934)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:56:54.458253
Epoch: [38][0/18], lr: 0.00001	Time 3.262 (3.262)	Data 2.033 (2.033)	Loss 0.0579 (0.0579)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5736 (0.5736)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:57:13.628466
Epoch: [39][0/18], lr: 0.00001	Time 3.373 (3.373)	Data 2.178 (2.178)	Loss 0.0595 (0.0595)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5665 (0.5665)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:57:33.099386
Epoch: [40][0/18], lr: 0.00001	Time 3.327 (3.327)	Data 2.444 (2.444)	Loss 0.0614 (0.0614)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5524 (0.5524)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:57:52.470052
Epoch: [41][0/18], lr: 0.00001	Time 3.452 (3.452)	Data 2.024 (2.024)	Loss 0.0488 (0.0488)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4774 (0.4774)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:58:11.970066
Epoch: [42][0/18], lr: 0.00001	Time 3.434 (3.434)	Data 1.969 (1.969)	Loss 0.0564 (0.0564)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0015 (0.0015)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5564 (0.5564)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:58:31.734534
Epoch: [43][0/18], lr: 0.00001	Time 3.418 (3.418)	Data 2.038 (2.038)	Loss 0.0565 (0.0565)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5468 (0.5468)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8552], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 06:58:51.570298
Epoch: [44][0/18], lr: 0.00001	Time 3.549 (3.549)	Data 2.459 (2.459)	Loss 0.0585 (0.0585)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5757 (0.5757)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
2022-03-24 06:59:11.168575
Epoch: [45][0/18], lr: 0.00001	Time 3.506 (3.506)	Data 2.418 (2.418)	Loss 0.0597 (0.0597)	Loss CE 0.0034 (0.0034)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5594 (0.5594)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
2022-03-24 06:59:30.861601
Epoch: [46][0/18], lr: 0.00001	Time 3.341 (3.341)	Data 2.164 (2.164)	Loss 0.0561 (0.0561)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5436 (0.5436)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
2022-03-24 06:59:49.842579
Epoch: [47][0/18], lr: 0.00001	Time 3.276 (3.276)	Data 2.260 (2.260)	Loss 0.0562 (0.0562)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5542 (0.5542)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0927], device='cuda:0', requires_grad=True)
2022-03-24 07:00:09.235249
Epoch: [48][0/18], lr: 0.00001	Time 3.471 (3.471)	Data 2.316 (2.316)	Loss 0.0582 (0.0582)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0007 (0.0007)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5721 (0.5721)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
2022-03-24 07:00:28.879778
Epoch: [49][0/18], lr: 0.00001	Time 3.374 (3.374)	Data 1.929 (1.929)	Loss 0.0542 (0.0542)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0014 (0.0014)	Loss KD (GCAM) 0.0008 (0.0008)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5330 (0.5330)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=249, sigma=tensor([3.8553]), eta=tensor([3.0928])
  (fc1): CosineLinear(input_features=512, output_features=243, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 177
video number + exemplar : 177
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=249, sigma=tensor([3.8553]), eta=tensor([3.0928])
  (fc1): CosineLinear(input_features=512, output_features=243, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 415
DataLoader CBF Constructed : Train 12
Optimizer Constructed
2022-03-24 07:01:05.754724
Epoch: [0][0/12], lr: 0.00050	Time 3.212 (3.212)	Data 2.324 (2.324)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8559], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0930], device='cuda:0', requires_grad=True)
2022-03-24 07:01:14.999542
Epoch: [1][0/12], lr: 0.00050	Time 2.837 (2.837)	Data 2.039 (2.039)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8569], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0935], device='cuda:0', requires_grad=True)
2022-03-24 07:01:24.797397
Epoch: [2][0/12], lr: 0.00050	Time 3.105 (3.105)	Data 2.115 (2.115)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8576], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 07:01:34.563542
Epoch: [3][0/12], lr: 0.00050	Time 3.108 (3.108)	Data 2.081 (2.081)	Loss 0.0331 (0.0331)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8576], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 07:01:44.424158
Epoch: [4][0/12], lr: 0.00050	Time 3.179 (3.179)	Data 2.406 (2.406)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8572], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0934], device='cuda:0', requires_grad=True)
2022-03-24 07:01:53.875282
Epoch: [5][0/12], lr: 0.00050	Time 2.805 (2.805)	Data 1.942 (1.942)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8574], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0934], device='cuda:0', requires_grad=True)
2022-03-24 07:02:04.079887
Epoch: [6][0/12], lr: 0.00050	Time 3.480 (3.480)	Data 2.820 (2.820)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8579], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0935], device='cuda:0', requires_grad=True)
2022-03-24 07:02:13.886934
Epoch: [7][0/12], lr: 0.00050	Time 3.120 (3.120)	Data 2.232 (2.232)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0936], device='cuda:0', requires_grad=True)
2022-03-24 07:02:23.663689
Epoch: [8][0/12], lr: 0.00050	Time 3.061 (3.061)	Data 1.988 (1.988)	Loss 0.0058 (0.0058)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8590], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0939], device='cuda:0', requires_grad=True)
2022-03-24 07:02:33.618818
Epoch: [9][0/12], lr: 0.00050	Time 3.231 (3.231)	Data 2.531 (2.531)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8594], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0940], device='cuda:0', requires_grad=True)
2022-03-24 07:02:43.144362
Epoch: [10][0/12], lr: 0.00050	Time 3.218 (3.218)	Data 2.380 (2.380)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8590], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 07:02:52.581970
Epoch: [11][0/12], lr: 0.00050	Time 2.822 (2.822)	Data 2.036 (2.036)	Loss 0.0159 (0.0159)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8592], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0940], device='cuda:0', requires_grad=True)
2022-03-24 07:03:02.260693
Epoch: [12][0/12], lr: 0.00050	Time 3.012 (3.012)	Data 2.347 (2.347)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8589], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0937], device='cuda:0', requires_grad=True)
2022-03-24 07:03:11.970432
Epoch: [13][0/12], lr: 0.00050	Time 3.165 (3.165)	Data 2.050 (2.050)	Loss 0.0023 (0.0023)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8589], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0937], device='cuda:0', requires_grad=True)
2022-03-24 07:03:21.774753
Epoch: [14][0/12], lr: 0.00050	Time 3.183 (3.183)	Data 2.407 (2.407)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8592], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 07:03:31.563116
Epoch: [15][0/12], lr: 0.00050	Time 3.126 (3.126)	Data 2.532 (2.532)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8595], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 07:03:41.381034
Epoch: [16][0/12], lr: 0.00050	Time 3.191 (3.191)	Data 2.143 (2.143)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8601], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0939], device='cuda:0', requires_grad=True)
2022-03-24 07:03:51.219644
Epoch: [17][0/12], lr: 0.00050	Time 3.152 (3.152)	Data 2.280 (2.280)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8604], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0939], device='cuda:0', requires_grad=True)
2022-03-24 07:04:01.013734
Epoch: [18][0/12], lr: 0.00050	Time 3.132 (3.132)	Data 2.258 (2.258)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8605], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 07:04:10.476994
Epoch: [19][0/12], lr: 0.00050	Time 3.099 (3.099)	Data 2.234 (2.234)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8603], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0935], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_016.pth.tar
exemplar : 415
Computing the class mean vectors...
Eval Task 0 for Age 16
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 3.802 (3.802)	Prec@1 68.750 (68.750)
Test: [100/120]	Time 0.367 (0.485)	Prec@1 81.250 (62.067)
Testing Results: Prec@1 61.823
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (68.069)
Testing Results (NME): Prec@1 68.021
Eval Task 1 for Age 16
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.798 (3.798)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 40.299
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 25.000 (25.000)
Testing Results (NME): Prec@1 41.791
Eval Task 2 for Age 16
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.007 (4.007)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 82.278
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 75.949
Eval Task 3 for Age 16
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.185 (4.185)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 84.706
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 82.353
Eval Task 4 for Age 16
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.928 (3.928)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 75.342
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 56.164
Eval Task 5 for Age 16
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.289 (3.289)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 91.026
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 88.462
Eval Task 6 for Age 16
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.936 (3.936)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 62.687
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 53.731
Eval Task 7 for Age 16
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.517 (3.517)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.358
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 95.062
Eval Task 8 for Age 16
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.442 (3.442)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 62.121
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 62.121
Eval Task 9 for Age 16
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.460 (3.460)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 87.013
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 81.818
Eval Task 10 for Age 16
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.335 (4.335)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 90.244
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.683
Eval Task 11 for Age 16
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.646 (3.646)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 53.521
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 63.380
Eval Task 12 for Age 16
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.127 (4.127)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 80.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 76.000
Eval Task 13 for Age 16
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.132 (4.132)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.597
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 71.642
Eval Task 14 for Age 16
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 3.987 (3.987)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 84.091
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 62.500
Eval Task 15 for Age 16
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 4.173 (4.173)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.935
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 95.161
Eval Task 16 for Age 16
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.960 (3.960)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.875
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 78.125
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64]
Method : OURS
----AGE 17----
current_task  [26, 1]
current_head  85
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06442049363362563]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=255, sigma=tensor([3.8603]), eta=tensor([3.0935])
  (fc1): CosineLinear(input_features=512, output_features=249, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 198
video number + exemplar : 613
DataLoader Constructed : Train 19
Optimizer Constructed
video number : 198
video number + exemplar : 198
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 07:09:33.592918
Epoch: [0][0/19], lr: 0.00100	Time 3.683 (3.683)	Data 2.570 (2.570)	Loss 0.0628 (0.0628)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0040 (0.0040)	Loss KD (GCAM) 0.0020 (0.0020)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6096 (0.6096)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8553], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0900], device='cuda:0', requires_grad=True)
2022-03-24 07:09:53.837603
Epoch: [1][0/19], lr: 0.00100	Time 3.465 (3.465)	Data 2.317 (2.317)	Loss 0.0670 (0.0670)	Loss CE 0.0091 (0.0091)	Loss KD (Logit) 0.0041 (0.0041)	Loss KD (GCAM) 0.0023 (0.0023)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5688 (0.5688)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0868], device='cuda:0', requires_grad=True)
2022-03-24 07:10:14.198624
Epoch: [2][0/19], lr: 0.00100	Time 3.378 (3.378)	Data 2.079 (2.079)	Loss 0.0812 (0.0812)	Loss CE 0.0236 (0.0236)	Loss KD (Logit) 0.0041 (0.0041)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5640 (0.5640)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8472], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0853], device='cuda:0', requires_grad=True)
2022-03-24 07:10:34.275478
Epoch: [3][0/19], lr: 0.00100	Time 3.437 (3.437)	Data 2.140 (2.140)	Loss 0.0702 (0.0702)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0041 (0.0041)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6511 (0.6511)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8397], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0819], device='cuda:0', requires_grad=True)
2022-03-24 07:10:54.389385
Epoch: [4][0/19], lr: 0.00100	Time 3.230 (3.230)	Data 1.894 (1.894)	Loss 0.0690 (0.0690)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6285 (0.6285)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8418], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0833], device='cuda:0', requires_grad=True)
2022-03-24 07:11:14.358355
Epoch: [5][0/19], lr: 0.00100	Time 3.374 (3.374)	Data 2.079 (2.079)	Loss 0.1113 (0.1113)	Loss CE 0.0458 (0.0458)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0044 (0.0044)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6398 (0.6398)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8444], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0848], device='cuda:0', requires_grad=True)
2022-03-24 07:11:34.457315
Epoch: [6][0/19], lr: 0.00100	Time 3.437 (3.437)	Data 2.191 (2.191)	Loss 0.0916 (0.0916)	Loss CE 0.0268 (0.0268)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6304 (0.6304)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8475], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0866], device='cuda:0', requires_grad=True)
2022-03-24 07:11:54.631463
Epoch: [7][0/19], lr: 0.00100	Time 3.481 (3.481)	Data 2.242 (2.242)	Loss 0.0793 (0.0793)	Loss CE 0.0126 (0.0126)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6532 (0.6532)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8522], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0890], device='cuda:0', requires_grad=True)
2022-03-24 07:12:14.880373
Epoch: [8][0/19], lr: 0.00100	Time 3.356 (3.356)	Data 2.064 (2.064)	Loss 0.0645 (0.0645)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6223 (0.6223)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8560], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0907], device='cuda:0', requires_grad=True)
2022-03-24 07:12:34.832333
Epoch: [9][0/19], lr: 0.00100	Time 3.105 (3.105)	Data 1.884 (1.884)	Loss 0.0654 (0.0654)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6359 (0.6359)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8560], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0905], device='cuda:0', requires_grad=True)
2022-03-24 07:12:55.278580
Epoch: [10][0/19], lr: 0.00100	Time 3.549 (3.549)	Data 2.539 (2.539)	Loss 0.0697 (0.0697)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6358 (0.6358)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8564], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0909], device='cuda:0', requires_grad=True)
2022-03-24 07:13:15.694541
Epoch: [11][0/19], lr: 0.00100	Time 3.332 (3.332)	Data 2.049 (2.049)	Loss 0.0632 (0.0632)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5995 (0.5995)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8592], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0923], device='cuda:0', requires_grad=True)
2022-03-24 07:13:35.768892
Epoch: [12][0/19], lr: 0.00100	Time 3.453 (3.453)	Data 2.188 (2.188)	Loss 0.0663 (0.0663)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6392 (0.6392)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8606], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0928], device='cuda:0', requires_grad=True)
2022-03-24 07:13:55.834802
Epoch: [13][0/19], lr: 0.00100	Time 3.418 (3.418)	Data 2.427 (2.427)	Loss 0.0642 (0.0642)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6209 (0.6209)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8614], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0931], device='cuda:0', requires_grad=True)
2022-03-24 07:14:16.076951
Epoch: [14][0/19], lr: 0.00100	Time 3.448 (3.448)	Data 2.481 (2.481)	Loss 0.0650 (0.0650)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6121 (0.6121)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8638], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0941], device='cuda:0', requires_grad=True)
2022-03-24 07:14:36.808709
Epoch: [15][0/19], lr: 0.00100	Time 3.475 (3.475)	Data 2.384 (2.384)	Loss 0.0683 (0.0683)	Loss CE 0.0070 (0.0070)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5990 (0.5990)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8605], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0920], device='cuda:0', requires_grad=True)
2022-03-24 07:14:56.854518
Epoch: [16][0/19], lr: 0.00100	Time 3.274 (3.274)	Data 2.223 (2.223)	Loss 0.0642 (0.0642)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5800 (0.5800)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8628], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0930], device='cuda:0', requires_grad=True)
2022-03-24 07:15:17.020175
Epoch: [17][0/19], lr: 0.00100	Time 3.437 (3.437)	Data 1.981 (1.981)	Loss 0.0650 (0.0650)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6327 (0.6327)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8646], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0940], device='cuda:0', requires_grad=True)
2022-03-24 07:15:37.077427
Epoch: [18][0/19], lr: 0.00100	Time 3.436 (3.436)	Data 2.540 (2.540)	Loss 0.0629 (0.0629)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6090 (0.6090)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8664], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0948], device='cuda:0', requires_grad=True)
2022-03-24 07:15:57.131598
Epoch: [19][0/19], lr: 0.00100	Time 3.571 (3.571)	Data 2.063 (2.063)	Loss 0.0988 (0.0988)	Loss CE 0.0336 (0.0336)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6373 (0.6373)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8693], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0961], device='cuda:0', requires_grad=True)
2022-03-24 07:16:17.087974
Epoch: [20][0/19], lr: 0.00010	Time 3.363 (3.363)	Data 2.415 (2.415)	Loss 0.0704 (0.0704)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0045 (0.0045)	Loss KD (GCAM) 0.0043 (0.0043)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6394 (0.6394)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8696], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0962], device='cuda:0', requires_grad=True)
2022-03-24 07:16:36.999788
Epoch: [21][0/19], lr: 0.00010	Time 3.301 (3.301)	Data 1.966 (1.966)	Loss 0.0655 (0.0655)	Loss CE 0.0054 (0.0054)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5872 (0.5872)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8699], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 07:16:57.122131
Epoch: [22][0/19], lr: 0.00010	Time 3.424 (3.424)	Data 2.362 (2.362)	Loss 0.0663 (0.0663)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6474 (0.6474)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8700], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 07:17:17.203657
Epoch: [23][0/19], lr: 0.00010	Time 3.348 (3.348)	Data 2.108 (2.108)	Loss 0.0649 (0.0649)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0031 (0.0031)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6200 (0.6200)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8702], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0966], device='cuda:0', requires_grad=True)
2022-03-24 07:17:37.371468
Epoch: [24][0/19], lr: 0.00010	Time 3.328 (3.328)	Data 2.092 (2.092)	Loss 0.0640 (0.0640)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6137 (0.6137)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8704], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0967], device='cuda:0', requires_grad=True)
2022-03-24 07:17:57.519702
Epoch: [25][0/19], lr: 0.00010	Time 3.203 (3.203)	Data 2.302 (2.302)	Loss 0.0656 (0.0656)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6409 (0.6409)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8707], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0967], device='cuda:0', requires_grad=True)
2022-03-24 07:18:17.704212
Epoch: [26][0/19], lr: 0.00010	Time 3.363 (3.363)	Data 1.924 (1.924)	Loss 0.0628 (0.0628)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6121 (0.6121)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8708], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0968], device='cuda:0', requires_grad=True)
2022-03-24 07:18:36.064788
Epoch: [27][0/19], lr: 0.00010	Time 3.570 (3.570)	Data 2.099 (2.099)	Loss 0.0670 (0.0670)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6378 (0.6378)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8709], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0968], device='cuda:0', requires_grad=True)
2022-03-24 07:18:54.721114
Epoch: [28][0/19], lr: 0.00010	Time 3.353 (3.353)	Data 2.406 (2.406)	Loss 0.0651 (0.0651)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6315 (0.6315)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8710], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:19:12.304761
Epoch: [29][0/19], lr: 0.00010	Time 3.157 (3.157)	Data 1.916 (1.916)	Loss 0.0651 (0.0651)	Loss CE 0.0000 (0.0000)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6367 (0.6367)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:19:29.525158
Epoch: [30][0/19], lr: 0.00001	Time 3.321 (3.321)	Data 2.301 (2.301)	Loss 0.0697 (0.0697)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0034 (0.0034)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6408 (0.6408)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:19:46.541311
Epoch: [31][0/19], lr: 0.00001	Time 3.387 (3.387)	Data 2.466 (2.466)	Loss 0.0688 (0.0688)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6672 (0.6672)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:20:03.644873
Epoch: [32][0/19], lr: 0.00001	Time 3.407 (3.407)	Data 2.464 (2.464)	Loss 0.0651 (0.0651)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6367 (0.6367)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:20:20.372774
Epoch: [33][0/19], lr: 0.00001	Time 3.235 (3.235)	Data 2.062 (2.062)	Loss 0.0699 (0.0699)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6446 (0.6446)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:20:37.342171
Epoch: [34][0/19], lr: 0.00001	Time 3.468 (3.468)	Data 2.282 (2.282)	Loss 0.0619 (0.0619)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0038 (0.0038)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5825 (0.5825)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:20:54.571255
Epoch: [35][0/19], lr: 0.00001	Time 3.279 (3.279)	Data 2.423 (2.423)	Loss 0.0612 (0.0612)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5946 (0.5946)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:21:12.004940
Epoch: [36][0/19], lr: 0.00001	Time 3.342 (3.342)	Data 2.185 (2.185)	Loss 0.0640 (0.0640)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6148 (0.6148)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:21:29.679102
Epoch: [37][0/19], lr: 0.00001	Time 3.595 (3.595)	Data 2.753 (2.753)	Loss 0.0669 (0.0669)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6480 (0.6480)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:21:46.972833
Epoch: [38][0/19], lr: 0.00001	Time 3.255 (3.255)	Data 2.132 (2.132)	Loss 0.0712 (0.0712)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0044 (0.0044)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6413 (0.6413)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:22:04.593515
Epoch: [39][0/19], lr: 0.00001	Time 3.504 (3.504)	Data 2.656 (2.656)	Loss 0.0672 (0.0672)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0036 (0.0036)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6387 (0.6387)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8712], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:22:22.219296
Epoch: [40][0/19], lr: 0.00001	Time 3.709 (3.709)	Data 2.497 (2.497)	Loss 0.0636 (0.0636)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6178 (0.6178)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:22:39.462344
Epoch: [41][0/19], lr: 0.00001	Time 3.345 (3.345)	Data 2.589 (2.589)	Loss 0.0652 (0.0652)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6385 (0.6385)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:22:56.818919
Epoch: [42][0/19], lr: 0.00001	Time 3.348 (3.348)	Data 2.443 (2.443)	Loss 0.0607 (0.0607)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5864 (0.5864)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:23:13.999426
Epoch: [43][0/19], lr: 0.00001	Time 3.291 (3.291)	Data 2.154 (2.154)	Loss 0.0596 (0.0596)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0034 (0.0034)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5778 (0.5778)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:23:31.201936
Epoch: [44][0/19], lr: 0.00001	Time 3.299 (3.299)	Data 2.140 (2.140)	Loss 0.0623 (0.0623)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6070 (0.6070)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:23:48.451299
Epoch: [45][0/19], lr: 0.00001	Time 3.121 (3.121)	Data 2.253 (2.253)	Loss 0.0597 (0.0597)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5824 (0.5824)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:24:05.079990
Epoch: [46][0/19], lr: 0.00001	Time 3.373 (3.373)	Data 2.111 (2.111)	Loss 0.0603 (0.0603)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5876 (0.5876)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:24:25.367257
Epoch: [47][0/19], lr: 0.00001	Time 3.331 (3.331)	Data 2.010 (2.010)	Loss 0.0621 (0.0621)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0042 (0.0042)	Loss KD (GCAM) 0.0035 (0.0035)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6040 (0.6040)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8713], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:24:45.381528
Epoch: [48][0/19], lr: 0.00001	Time 3.287 (3.287)	Data 1.948 (1.948)	Loss 0.0777 (0.0777)	Loss CE 0.0139 (0.0139)	Loss KD (Logit) 0.0041 (0.0041)	Loss KD (GCAM) 0.0037 (0.0037)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6243 (0.6243)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8714], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:25:05.380114
Epoch: [49][0/19], lr: 0.00001	Time 3.258 (3.258)	Data 2.006 (2.006)	Loss 0.0645 (0.0645)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0043 (0.0043)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6134 (0.6134)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8714], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=255, sigma=tensor([3.8714]), eta=tensor([3.0970])
  (fc1): CosineLinear(input_features=512, output_features=249, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 198
video number + exemplar : 198
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=255, sigma=tensor([3.8714]), eta=tensor([3.0970])
  (fc1): CosineLinear(input_features=512, output_features=249, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 425
DataLoader CBF Constructed : Train 13
Optimizer Constructed
2022-03-24 07:25:43.074300
Epoch: [0][0/13], lr: 0.00050	Time 3.067 (3.067)	Data 2.089 (2.089)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8714], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:25:53.245127
Epoch: [1][0/13], lr: 0.00050	Time 2.992 (2.992)	Data 2.302 (2.302)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8717], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0969], device='cuda:0', requires_grad=True)
2022-03-24 07:26:03.286657
Epoch: [2][0/13], lr: 0.00050	Time 3.022 (3.022)	Data 2.027 (2.027)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8723], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0971], device='cuda:0', requires_grad=True)
2022-03-24 07:26:13.441464
Epoch: [3][0/13], lr: 0.00050	Time 3.074 (3.074)	Data 2.400 (2.400)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8725], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0971], device='cuda:0', requires_grad=True)
2022-03-24 07:26:23.506782
Epoch: [4][0/13], lr: 0.00050	Time 3.036 (3.036)	Data 2.097 (2.097)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8729], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:26:33.568936
Epoch: [5][0/13], lr: 0.00050	Time 2.977 (2.977)	Data 2.238 (2.238)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8734], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0970], device='cuda:0', requires_grad=True)
2022-03-24 07:26:43.698899
Epoch: [6][0/13], lr: 0.00050	Time 3.064 (3.064)	Data 2.474 (2.474)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8735], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0968], device='cuda:0', requires_grad=True)
2022-03-24 07:26:53.711218
Epoch: [7][0/13], lr: 0.00050	Time 2.986 (2.986)	Data 2.357 (2.357)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8738], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0968], device='cuda:0', requires_grad=True)
2022-03-24 07:27:03.885888
Epoch: [8][0/13], lr: 0.00050	Time 3.053 (3.053)	Data 2.494 (2.494)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8738], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0966], device='cuda:0', requires_grad=True)
2022-03-24 07:27:13.909190
Epoch: [9][0/13], lr: 0.00050	Time 3.011 (3.011)	Data 2.369 (2.369)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8740], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0965], device='cuda:0', requires_grad=True)
2022-03-24 07:27:23.998537
Epoch: [10][0/13], lr: 0.00050	Time 2.933 (2.933)	Data 2.139 (2.139)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8744], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0966], device='cuda:0', requires_grad=True)
2022-03-24 07:27:34.077010
Epoch: [11][0/13], lr: 0.00050	Time 2.971 (2.971)	Data 1.941 (1.941)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8745], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0965], device='cuda:0', requires_grad=True)
2022-03-24 07:27:44.141706
Epoch: [12][0/13], lr: 0.00050	Time 2.976 (2.976)	Data 2.346 (2.346)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8747], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0964], device='cuda:0', requires_grad=True)
2022-03-24 07:27:54.206682
Epoch: [13][0/13], lr: 0.00050	Time 3.020 (3.020)	Data 2.158 (2.158)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8747], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0962], device='cuda:0', requires_grad=True)
2022-03-24 07:28:04.361459
Epoch: [14][0/13], lr: 0.00050	Time 3.014 (3.014)	Data 2.552 (2.552)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8747], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0960], device='cuda:0', requires_grad=True)
2022-03-24 07:28:14.290666
Epoch: [15][0/13], lr: 0.00050	Time 2.863 (2.863)	Data 1.869 (1.869)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8748], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0959], device='cuda:0', requires_grad=True)
2022-03-24 07:28:24.395174
Epoch: [16][0/13], lr: 0.00050	Time 3.116 (3.116)	Data 2.058 (2.058)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8753], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0959], device='cuda:0', requires_grad=True)
2022-03-24 07:28:34.694342
Epoch: [17][0/13], lr: 0.00050	Time 3.063 (3.063)	Data 2.428 (2.428)	Loss 0.0281 (0.0281)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8759], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0961], device='cuda:0', requires_grad=True)
2022-03-24 07:28:44.980326
Epoch: [18][0/13], lr: 0.00050	Time 3.127 (3.127)	Data 2.562 (2.562)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8757], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0958], device='cuda:0', requires_grad=True)
2022-03-24 07:28:55.012262
Epoch: [19][0/13], lr: 0.00050	Time 3.073 (3.073)	Data 2.158 (2.158)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8756], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0955], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_017.pth.tar
exemplar : 425
Computing the class mean vectors...
Eval Task 0 for Age 17
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.808 (4.808)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.353 (0.555)	Prec@1 62.500 (60.644)
Testing Results: Prec@1 60.573
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 75.000 (67.760)
Testing Results (NME): Prec@1 68.021
Eval Task 1 for Age 17
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.519 (3.519)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 38.806
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 18.750 (18.750)
Testing Results (NME): Prec@1 35.821
Eval Task 2 for Age 17
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.231 (4.231)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 86.076
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 77.215
Eval Task 3 for Age 17
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.889 (3.889)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 82.353
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 82.353
Eval Task 4 for Age 17
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.733 (3.733)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 71.233
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 60.274
Eval Task 5 for Age 17
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.047 (4.047)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 88.462
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 87.179
Eval Task 6 for Age 17
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.427 (3.427)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 76.119
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 68.657
Eval Task 7 for Age 17
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.159 (4.159)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 60.494
Eval Task 8 for Age 17
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.940 (3.940)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 62.121
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 57.576
Eval Task 9 for Age 17
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.056 (4.056)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 85.714
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 81.818
Eval Task 10 for Age 17
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.878 (3.878)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.463
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 90.244
Eval Task 11 for Age 17
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.999 (3.999)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 42.254
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 54.930
Eval Task 12 for Age 17
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.017 (4.017)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 73.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 73.333
Eval Task 13 for Age 17
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.032 (4.032)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 85.075
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.627
Eval Task 14 for Age 17
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 3.358 (3.358)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 84.091
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 64.773
Eval Task 15 for Age 17
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.286 (3.286)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 93.548
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.323
Eval Task 16 for Age 17
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.646 (3.646)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 87.500
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 73.438
Eval Task 17 for Age 17
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.224 (4.224)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.104
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 85.714
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77]
Method : OURS
----AGE 18----
current_task  [7, 33]
current_head  87
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.0651920240520265]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=261, sigma=tensor([3.8756]), eta=tensor([3.0955])
  (fc1): CosineLinear(input_features=512, output_features=255, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 196
video number + exemplar : 621
DataLoader Constructed : Train 19
Optimizer Constructed
video number : 196
video number + exemplar : 196
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 07:34:46.813685
Epoch: [0][0/19], lr: 0.00100	Time 3.487 (3.487)	Data 2.156 (2.156)	Loss 0.1357 (0.1357)	Loss CE 0.0735 (0.0735)	Loss KD (Logit) 0.0228 (0.0228)	Loss KD (GCAM) 0.0109 (0.0109)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5743 (0.5743)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8619], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0875], device='cuda:0', requires_grad=True)
2022-03-24 07:35:03.833916
Epoch: [1][0/19], lr: 0.00100	Time 3.272 (3.272)	Data 2.490 (2.490)	Loss 0.1414 (0.1414)	Loss CE 0.0785 (0.0785)	Loss KD (Logit) 0.0249 (0.0249)	Loss KD (GCAM) 0.0154 (0.0154)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5669 (0.5669)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8602], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0882], device='cuda:0', requires_grad=True)
2022-03-24 07:35:21.314790
Epoch: [2][0/19], lr: 0.00100	Time 3.334 (3.334)	Data 2.410 (2.410)	Loss 0.1480 (0.1480)	Loss CE 0.0864 (0.0864)	Loss KD (Logit) 0.0242 (0.0242)	Loss KD (GCAM) 0.0172 (0.0172)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5480 (0.5480)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8551], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0866], device='cuda:0', requires_grad=True)
2022-03-24 07:35:38.600683
Epoch: [3][0/19], lr: 0.00100	Time 3.401 (3.401)	Data 2.146 (2.146)	Loss 0.1444 (0.1444)	Loss CE 0.0781 (0.0781)	Loss KD (Logit) 0.0256 (0.0256)	Loss KD (GCAM) 0.0213 (0.0213)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5820 (0.5820)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8630], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0915], device='cuda:0', requires_grad=True)
2022-03-24 07:35:55.828900
Epoch: [4][0/19], lr: 0.00100	Time 3.201 (3.201)	Data 2.429 (2.429)	Loss 0.0909 (0.0909)	Loss CE 0.0229 (0.0229)	Loss KD (Logit) 0.0250 (0.0250)	Loss KD (GCAM) 0.0175 (0.0175)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6106 (0.6106)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8699], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0961], device='cuda:0', requires_grad=True)
2022-03-24 07:36:13.319192
Epoch: [5][0/19], lr: 0.00100	Time 3.293 (3.293)	Data 2.294 (2.294)	Loss 0.1373 (0.1373)	Loss CE 0.0707 (0.0707)	Loss KD (Logit) 0.0244 (0.0244)	Loss KD (GCAM) 0.0174 (0.0174)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5973 (0.5973)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8742], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0989], device='cuda:0', requires_grad=True)
2022-03-24 07:36:29.905868
Epoch: [6][0/19], lr: 0.00100	Time 3.060 (3.060)	Data 1.900 (1.900)	Loss 0.0715 (0.0715)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0257 (0.0257)	Loss KD (GCAM) 0.0187 (0.0187)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6017 (0.6017)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8819], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1034], device='cuda:0', requires_grad=True)
2022-03-24 07:36:47.192208
Epoch: [7][0/19], lr: 0.00100	Time 3.341 (3.341)	Data 2.264 (2.264)	Loss 0.1656 (0.1656)	Loss CE 0.0956 (0.0956)	Loss KD (Logit) 0.0257 (0.0257)	Loss KD (GCAM) 0.0192 (0.0192)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6252 (0.6252)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8849], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1053], device='cuda:0', requires_grad=True)
2022-03-24 07:37:04.514472
Epoch: [8][0/19], lr: 0.00100	Time 3.354 (3.354)	Data 2.311 (2.311)	Loss 0.0805 (0.0805)	Loss CE 0.0134 (0.0134)	Loss KD (Logit) 0.0246 (0.0246)	Loss KD (GCAM) 0.0209 (0.0209)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5922 (0.5922)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8892], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1078], device='cuda:0', requires_grad=True)
2022-03-24 07:37:21.789092
Epoch: [9][0/19], lr: 0.00100	Time 3.179 (3.179)	Data 1.922 (1.922)	Loss 0.0687 (0.0687)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.0239 (0.0239)	Loss KD (GCAM) 0.0195 (0.0195)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5650 (0.5650)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8937], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1103], device='cuda:0', requires_grad=True)
2022-03-24 07:37:38.346162
Epoch: [10][0/19], lr: 0.00100	Time 3.811 (3.811)	Data 2.703 (2.703)	Loss 0.0721 (0.0721)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0253 (0.0253)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6294 (0.6294)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8970], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1125], device='cuda:0', requires_grad=True)
2022-03-24 07:37:58.520668
Epoch: [11][0/19], lr: 0.00100	Time 3.403 (3.403)	Data 2.565 (2.565)	Loss 0.0691 (0.0691)	Loss CE 0.0042 (0.0042)	Loss KD (Logit) 0.0245 (0.0245)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5782 (0.5782)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8980], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1129], device='cuda:0', requires_grad=True)
2022-03-24 07:38:18.971297
Epoch: [12][0/19], lr: 0.00100	Time 3.462 (3.462)	Data 2.249 (2.249)	Loss 0.0651 (0.0651)	Loss CE 0.0025 (0.0025)	Loss KD (Logit) 0.0253 (0.0253)	Loss KD (GCAM) 0.0183 (0.0183)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5552 (0.5552)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8981], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1128], device='cuda:0', requires_grad=True)
2022-03-24 07:38:39.453869
Epoch: [13][0/19], lr: 0.00100	Time 3.493 (3.493)	Data 2.100 (2.100)	Loss 0.0675 (0.0675)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0242 (0.0242)	Loss KD (GCAM) 0.0170 (0.0170)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5957 (0.5957)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9006], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1140], device='cuda:0', requires_grad=True)
2022-03-24 07:38:59.564262
Epoch: [14][0/19], lr: 0.00100	Time 3.268 (3.268)	Data 1.852 (1.852)	Loss 0.0733 (0.0733)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0245 (0.0245)	Loss KD (GCAM) 0.0174 (0.0174)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6570 (0.6570)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9025], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1150], device='cuda:0', requires_grad=True)
2022-03-24 07:39:19.984179
Epoch: [15][0/19], lr: 0.00100	Time 3.536 (3.536)	Data 1.958 (1.958)	Loss 0.1115 (0.1115)	Loss CE 0.0422 (0.0422)	Loss KD (Logit) 0.0260 (0.0260)	Loss KD (GCAM) 0.0168 (0.0168)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6251 (0.6251)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9027], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1147], device='cuda:0', requires_grad=True)
2022-03-24 07:39:40.553921
Epoch: [16][0/19], lr: 0.00100	Time 3.544 (3.544)	Data 2.582 (2.582)	Loss 0.0811 (0.0811)	Loss CE 0.0129 (0.0129)	Loss KD (Logit) 0.0271 (0.0271)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6073 (0.6073)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9076], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1173], device='cuda:0', requires_grad=True)
2022-03-24 07:40:01.171060
Epoch: [17][0/19], lr: 0.00100	Time 3.619 (3.619)	Data 2.484 (2.484)	Loss 0.0719 (0.0719)	Loss CE 0.0071 (0.0071)	Loss KD (Logit) 0.0249 (0.0249)	Loss KD (GCAM) 0.0200 (0.0200)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5716 (0.5716)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9140], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1210], device='cuda:0', requires_grad=True)
2022-03-24 07:40:22.085303
Sigma : Parameter containing:
tensor([3.9181], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1232], device='cuda:0', requires_grad=True)
2022-03-24 07:40:42.522210
Epoch: [19][0/19], lr: 0.00100	Time 3.501 (3.501)	Data 2.178 (2.178)	Loss 0.0641 (0.0641)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0262 (0.0262)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5647 (0.5647)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9199], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
2022-03-24 07:41:02.684550
Epoch: [20][0/19], lr: 0.00010	Time 3.455 (3.455)	Data 2.405 (2.405)	Loss 0.0694 (0.0694)	Loss CE 0.0041 (0.0041)	Loss KD (Logit) 0.0258 (0.0258)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5830 (0.5830)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9201], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1241], device='cuda:0', requires_grad=True)
2022-03-24 07:41:22.719764
Epoch: [21][0/19], lr: 0.00010	Time 3.488 (3.488)	Data 2.448 (2.448)	Loss 0.0686 (0.0686)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0251 (0.0251)	Loss KD (GCAM) 0.0165 (0.0165)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6007 (0.6007)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9202], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1242], device='cuda:0', requires_grad=True)
2022-03-24 07:41:42.744257
Epoch: [22][0/19], lr: 0.00010	Time 3.346 (3.346)	Data 1.934 (1.934)	Loss 0.0698 (0.0698)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0265 (0.0265)	Loss KD (GCAM) 0.0163 (0.0163)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6117 (0.6117)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1243], device='cuda:0', requires_grad=True)
2022-03-24 07:42:02.772050
Epoch: [23][0/19], lr: 0.00010	Time 3.325 (3.325)	Data 1.987 (1.987)	Loss 0.0656 (0.0656)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0241 (0.0241)	Loss KD (GCAM) 0.0175 (0.0175)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5528 (0.5528)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1244], device='cuda:0', requires_grad=True)
2022-03-24 07:42:22.873826
Epoch: [24][0/19], lr: 0.00010	Time 3.470 (3.470)	Data 2.552 (2.552)	Loss 0.0659 (0.0659)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0245 (0.0245)	Loss KD (GCAM) 0.0182 (0.0182)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5827 (0.5827)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1245], device='cuda:0', requires_grad=True)
2022-03-24 07:42:43.037874
Epoch: [25][0/19], lr: 0.00010	Time 3.275 (3.275)	Data 1.972 (1.972)	Loss 0.0635 (0.0635)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0263 (0.0263)	Loss KD (GCAM) 0.0181 (0.0181)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5559 (0.5559)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9211], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1245], device='cuda:0', requires_grad=True)
2022-03-24 07:43:03.466256
Epoch: [26][0/19], lr: 0.00010	Time 3.549 (3.549)	Data 2.282 (2.282)	Loss 0.0742 (0.0742)	Loss CE 0.0069 (0.0069)	Loss KD (Logit) 0.0251 (0.0251)	Loss KD (GCAM) 0.0174 (0.0174)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6047 (0.6047)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:43:24.069429
Epoch: [27][0/19], lr: 0.00010	Time 3.553 (3.553)	Data 2.508 (2.508)	Loss 0.0661 (0.0661)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0262 (0.0262)	Loss KD (GCAM) 0.0183 (0.0183)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5606 (0.5606)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:43:44.755529
Epoch: [28][0/19], lr: 0.00010	Time 3.457 (3.457)	Data 2.069 (2.069)	Loss 0.0672 (0.0672)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0256 (0.0256)	Loss KD (GCAM) 0.0164 (0.0164)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5786 (0.5786)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:44:04.908079
Epoch: [29][0/19], lr: 0.00010	Time 3.334 (3.334)	Data 1.888 (1.888)	Loss 0.0740 (0.0740)	Loss CE 0.0094 (0.0094)	Loss KD (Logit) 0.0254 (0.0254)	Loss KD (GCAM) 0.0182 (0.0182)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5751 (0.5751)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9213], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:44:25.096362
Epoch: [30][0/19], lr: 0.00001	Time 3.444 (3.444)	Data 2.348 (2.348)	Loss 0.0719 (0.0719)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0259 (0.0259)	Loss KD (GCAM) 0.0163 (0.0163)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6145 (0.6145)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9213], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:44:44.948690
Epoch: [31][0/19], lr: 0.00001	Time 3.315 (3.315)	Data 1.954 (1.954)	Loss 0.0899 (0.0899)	Loss CE 0.0246 (0.0246)	Loss KD (Logit) 0.0251 (0.0251)	Loss KD (GCAM) 0.0173 (0.0173)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5852 (0.5852)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9213], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:45:04.992116
Epoch: [32][0/19], lr: 0.00001	Time 3.333 (3.333)	Data 1.960 (1.960)	Loss 0.0687 (0.0687)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0265 (0.0265)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6085 (0.6085)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:45:25.208689
Epoch: [33][0/19], lr: 0.00001	Time 3.341 (3.341)	Data 2.322 (2.322)	Loss 0.0650 (0.0650)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0247 (0.0247)	Loss KD (GCAM) 0.0159 (0.0159)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5627 (0.5627)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9213], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:45:45.391679
Epoch: [34][0/19], lr: 0.00001	Time 3.248 (3.248)	Data 2.256 (2.256)	Loss 0.0670 (0.0670)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0258 (0.0258)	Loss KD (GCAM) 0.0175 (0.0175)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5718 (0.5718)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:46:05.975432
Epoch: [35][0/19], lr: 0.00001	Time 3.460 (3.460)	Data 2.054 (2.054)	Loss 0.0645 (0.0645)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0243 (0.0243)	Loss KD (GCAM) 0.0182 (0.0182)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5450 (0.5450)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:46:26.190963
Epoch: [36][0/19], lr: 0.00001	Time 3.431 (3.431)	Data 2.500 (2.500)	Loss 0.0643 (0.0643)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0256 (0.0256)	Loss KD (GCAM) 0.0175 (0.0175)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5644 (0.5644)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:46:46.511752
Epoch: [37][0/19], lr: 0.00001	Time 3.621 (3.621)	Data 2.299 (2.299)	Loss 0.0717 (0.0717)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0259 (0.0259)	Loss KD (GCAM) 0.0178 (0.0178)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6397 (0.6397)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:47:06.071355
Epoch: [38][0/19], lr: 0.00001	Time 3.566 (3.566)	Data 2.576 (2.576)	Loss 0.0705 (0.0705)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0246 (0.0246)	Loss KD (GCAM) 0.0176 (0.0176)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6080 (0.6080)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:47:24.856034
Epoch: [39][0/19], lr: 0.00001	Time 3.207 (3.207)	Data 2.014 (2.014)	Loss 0.0650 (0.0650)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0250 (0.0250)	Loss KD (GCAM) 0.0169 (0.0169)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5729 (0.5729)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:47:44.080032
Epoch: [40][0/19], lr: 0.00001	Time 3.328 (3.328)	Data 2.059 (2.059)	Loss 0.0691 (0.0691)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0254 (0.0254)	Loss KD (GCAM) 0.0176 (0.0176)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6105 (0.6105)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:48:01.084875
Epoch: [41][0/19], lr: 0.00001	Time 3.401 (3.401)	Data 2.146 (2.146)	Loss 0.0664 (0.0664)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0264 (0.0264)	Loss KD (GCAM) 0.0182 (0.0182)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5840 (0.5840)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:48:18.274916
Epoch: [42][0/19], lr: 0.00001	Time 3.400 (3.400)	Data 2.441 (2.441)	Loss 0.0635 (0.0635)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0236 (0.0236)	Loss KD (GCAM) 0.0168 (0.0168)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5635 (0.5635)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:48:35.271721
Epoch: [43][0/19], lr: 0.00001	Time 3.321 (3.321)	Data 2.381 (2.381)	Loss 0.0633 (0.0633)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0250 (0.0250)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5516 (0.5516)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:48:52.714725
Epoch: [44][0/19], lr: 0.00001	Time 3.709 (3.709)	Data 2.343 (2.343)	Loss 0.0670 (0.0670)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0250 (0.0250)	Loss KD (GCAM) 0.0166 (0.0166)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6019 (0.6019)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:49:09.375477
Epoch: [45][0/19], lr: 0.00001	Time 3.431 (3.431)	Data 2.599 (2.599)	Loss 0.1293 (0.1293)	Loss CE 0.0631 (0.0631)	Loss KD (Logit) 0.0262 (0.0262)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5899 (0.5899)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:49:26.440971
Epoch: [46][0/19], lr: 0.00001	Time 3.291 (3.291)	Data 2.390 (2.390)	Loss 0.0708 (0.0708)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0247 (0.0247)	Loss KD (GCAM) 0.0175 (0.0175)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6310 (0.6310)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:49:43.847890
Epoch: [47][0/19], lr: 0.00001	Time 3.416 (3.416)	Data 2.553 (2.553)	Loss 0.0699 (0.0699)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0257 (0.0257)	Loss KD (GCAM) 0.0163 (0.0163)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6271 (0.6271)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:50:01.137041
Epoch: [48][0/19], lr: 0.00001	Time 3.251 (3.251)	Data 2.371 (2.371)	Loss 0.0666 (0.0666)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0242 (0.0242)	Loss KD (GCAM) 0.0170 (0.0170)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5920 (0.5920)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
2022-03-24 07:50:18.338159
Epoch: [49][0/19], lr: 0.00001	Time 3.280 (3.280)	Data 2.045 (2.045)	Loss 0.0636 (0.0636)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0246 (0.0246)	Loss KD (GCAM) 0.0177 (0.0177)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5630 (0.5630)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1247], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=261, sigma=tensor([3.9216]), eta=tensor([3.1247])
  (fc1): CosineLinear(input_features=512, output_features=255, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 196
video number + exemplar : 196
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=261, sigma=tensor([3.9216]), eta=tensor([3.1247])
  (fc1): CosineLinear(input_features=512, output_features=255, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 435
DataLoader CBF Constructed : Train 13
Optimizer Constructed
2022-03-24 07:50:51.948555
Epoch: [0][0/13], lr: 0.00050	Time 3.267 (3.267)	Data 2.670 (2.670)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 07:51:01.162500
Epoch: [1][0/13], lr: 0.00050	Time 2.960 (2.960)	Data 2.255 (2.255)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1244], device='cuda:0', requires_grad=True)
2022-03-24 07:51:10.121340
Epoch: [2][0/13], lr: 0.00050	Time 2.928 (2.928)	Data 2.330 (2.330)	Loss 0.0046 (0.0046)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1244], device='cuda:0', requires_grad=True)
2022-03-24 07:51:19.303023
Epoch: [3][0/13], lr: 0.00050	Time 2.975 (2.975)	Data 2.147 (2.147)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9216], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1242], device='cuda:0', requires_grad=True)
2022-03-24 07:51:28.798172
Epoch: [4][0/13], lr: 0.00050	Time 3.276 (3.276)	Data 2.106 (2.106)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1238], device='cuda:0', requires_grad=True)
2022-03-24 07:51:37.862484
Epoch: [5][0/13], lr: 0.00050	Time 2.997 (2.997)	Data 1.890 (1.890)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9215], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 07:51:46.949012
Epoch: [6][0/13], lr: 0.00050	Time 2.942 (2.942)	Data 2.073 (2.073)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1241], device='cuda:0', requires_grad=True)
2022-03-24 07:51:55.735925
Epoch: [7][0/13], lr: 0.00050	Time 2.870 (2.870)	Data 1.888 (1.888)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 07:52:04.597109
Epoch: [8][0/13], lr: 0.00050	Time 2.953 (2.953)	Data 2.066 (2.066)	Loss 0.0910 (0.0910)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1231], device='cuda:0', requires_grad=True)
2022-03-24 07:52:13.360922
Epoch: [9][0/13], lr: 0.00050	Time 2.914 (2.914)	Data 2.019 (2.019)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1229], device='cuda:0', requires_grad=True)
2022-03-24 07:52:22.267513
Epoch: [10][0/13], lr: 0.00050	Time 2.984 (2.984)	Data 2.048 (2.048)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1228], device='cuda:0', requires_grad=True)
2022-03-24 07:52:30.687502
Epoch: [11][0/13], lr: 0.00050	Time 3.138 (3.138)	Data 2.385 (2.385)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1224], device='cuda:0', requires_grad=True)
2022-03-24 07:52:39.554119
Epoch: [12][0/13], lr: 0.00050	Time 3.301 (3.301)	Data 2.490 (2.490)	Loss 0.0023 (0.0023)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9210], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1221], device='cuda:0', requires_grad=True)
2022-03-24 07:52:49.794801
Epoch: [13][0/13], lr: 0.00050	Time 3.103 (3.103)	Data 2.078 (2.078)	Loss 0.0049 (0.0049)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9210], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1219], device='cuda:0', requires_grad=True)
2022-03-24 07:52:59.837990
Epoch: [14][0/13], lr: 0.00050	Time 3.004 (3.004)	Data 2.126 (2.126)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9210], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1217], device='cuda:0', requires_grad=True)
2022-03-24 07:53:09.982581
Epoch: [15][0/13], lr: 0.00050	Time 3.107 (3.107)	Data 2.379 (2.379)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1217], device='cuda:0', requires_grad=True)
2022-03-24 07:53:20.102602
Epoch: [16][0/13], lr: 0.00050	Time 3.028 (3.028)	Data 2.225 (2.225)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1214], device='cuda:0', requires_grad=True)
2022-03-24 07:53:30.241238
Epoch: [17][0/13], lr: 0.00050	Time 2.983 (2.983)	Data 2.079 (2.079)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9207], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1210], device='cuda:0', requires_grad=True)
2022-03-24 07:53:40.261699
Epoch: [18][0/13], lr: 0.00050	Time 2.998 (2.998)	Data 2.323 (2.323)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1208], device='cuda:0', requires_grad=True)
2022-03-24 07:53:50.372783
Epoch: [19][0/13], lr: 0.00050	Time 3.080 (3.080)	Data 2.096 (2.096)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1206], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_018.pth.tar
exemplar : 435
Computing the class mean vectors...
Eval Task 0 for Age 18
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.087 (4.087)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.399 (0.546)	Prec@1 68.750 (60.087)
Testing Results: Prec@1 60.208
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (66.708)
Testing Results (NME): Prec@1 66.979
Eval Task 1 for Age 18
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.030 (4.030)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 37.313
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 50.746
Eval Task 2 for Age 18
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.583 (3.583)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 75.949
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 70.886
Eval Task 3 for Age 18
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.279 (4.279)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 78.824
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 82.353
Eval Task 4 for Age 18
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 4.158 (4.158)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 68.493
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 56.164
Eval Task 5 for Age 18
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.947 (3.947)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 85.897
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 83.333
Eval Task 6 for Age 18
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.105 (4.105)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 58.209
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 53.731
Eval Task 7 for Age 18
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.949 (3.949)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 54.321
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 48.148
Eval Task 8 for Age 18
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.939 (3.939)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 54.545
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 60.606
Eval Task 9 for Age 18
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.431 (4.431)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 81.818
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 79.221
Eval Task 10 for Age 18
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.001 (4.001)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 92.683
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 91.463
Eval Task 11 for Age 18
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.016 (4.016)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 33.803
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 52.113
Eval Task 12 for Age 18
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.638 (3.638)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 69.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 70.667
Eval Task 13 for Age 18
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.077 (4.077)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 82.090
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 76.119
Eval Task 14 for Age 18
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.333 (4.333)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 61.364
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 69.318
Eval Task 15 for Age 18
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.521 (3.521)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 58.065
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 80.645
Eval Task 16 for Age 18
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.360 (3.360)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 84.375
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 75.000
Eval Task 17 for Age 18
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.960 (3.960)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 97.403
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 84.416
Eval Task 18 for Age 18
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.965 (3.965)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 98.529
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 85.294
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77, 68]
Method : OURS
----AGE 19----
current_task  [88, 70]
current_head  89
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.0659545297913646]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=267, sigma=tensor([3.9205]), eta=tensor([3.1206])
  (fc1): CosineLinear(input_features=512, output_features=261, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 210
video number + exemplar : 645
DataLoader Constructed : Train 20
Optimizer Constructed
video number : 210
video number + exemplar : 210
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 08:00:00.789174
Epoch: [0][0/20], lr: 0.00100	Time 3.839 (3.839)	Data 2.413 (2.413)	Loss 0.0796 (0.0796)	Loss CE 0.0258 (0.0258)	Loss KD (Logit) 0.0223 (0.0223)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5116 (0.5116)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9202], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1204], device='cuda:0', requires_grad=True)
2022-03-24 08:00:21.383289
Epoch: [1][0/20], lr: 0.00100	Time 3.186 (3.186)	Data 1.990 (1.990)	Loss 0.1239 (0.1239)	Loss CE 0.0697 (0.0697)	Loss KD (Logit) 0.0213 (0.0213)	Loss KD (GCAM) 0.0055 (0.0055)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5116 (0.5116)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1211], device='cuda:0', requires_grad=True)
2022-03-24 08:00:42.238911
Epoch: [2][0/20], lr: 0.00100	Time 3.305 (3.305)	Data 2.126 (2.126)	Loss 0.1787 (0.1787)	Loss CE 0.1225 (0.1225)	Loss KD (Logit) 0.0221 (0.0221)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5267 (0.5267)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9127], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1156], device='cuda:0', requires_grad=True)
2022-03-24 08:01:01.763490
Epoch: [3][0/20], lr: 0.00100	Time 3.394 (3.394)	Data 2.558 (2.558)	Loss 0.0657 (0.0657)	Loss CE 0.0060 (0.0060)	Loss KD (Logit) 0.0224 (0.0224)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5614 (0.5614)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9092], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1137], device='cuda:0', requires_grad=True)
2022-03-24 08:01:21.110266
Epoch: [4][0/20], lr: 0.00100	Time 3.409 (3.409)	Data 1.918 (1.918)	Loss 0.0712 (0.0712)	Loss CE 0.0143 (0.0143)	Loss KD (Logit) 0.0220 (0.0220)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5318 (0.5318)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9086], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1136], device='cuda:0', requires_grad=True)
2022-03-24 08:01:38.968231
Epoch: [5][0/20], lr: 0.00100	Time 3.379 (3.379)	Data 2.136 (2.136)	Loss 0.2948 (0.2948)	Loss CE 0.2334 (0.2334)	Loss KD (Logit) 0.0221 (0.0221)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5772 (0.5772)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.9095], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1142], device='cuda:0', requires_grad=True)
2022-03-24 08:01:56.897389
Epoch: [6][0/20], lr: 0.00100	Time 3.599 (3.599)	Data 2.606 (2.606)	Loss 0.0865 (0.0865)	Loss CE 0.0258 (0.0258)	Loss KD (Logit) 0.0217 (0.0217)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5721 (0.5721)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9151], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1174], device='cuda:0', requires_grad=True)
2022-03-24 08:02:14.681180
Epoch: [7][0/20], lr: 0.00100	Time 3.169 (3.169)	Data 1.977 (1.977)	Loss 0.0624 (0.0624)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0215 (0.0215)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5812 (0.5812)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9179], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1194], device='cuda:0', requires_grad=True)
2022-03-24 08:02:32.447336
Epoch: [8][0/20], lr: 0.00100	Time 3.277 (3.277)	Data 2.168 (2.168)	Loss 0.0558 (0.0558)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.0218 (0.0218)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5061 (0.5061)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9182], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1193], device='cuda:0', requires_grad=True)
2022-03-24 08:02:50.342413
Epoch: [9][0/20], lr: 0.00100	Time 3.312 (3.312)	Data 2.052 (2.052)	Loss 0.0600 (0.0600)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0223 (0.0223)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5345 (0.5345)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9190], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1196], device='cuda:0', requires_grad=True)
2022-03-24 08:03:08.415480
Epoch: [10][0/20], lr: 0.00100	Time 3.626 (3.626)	Data 2.134 (2.134)	Loss 0.0677 (0.0677)	Loss CE 0.0083 (0.0083)	Loss KD (Logit) 0.0223 (0.0223)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5588 (0.5588)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1202], device='cuda:0', requires_grad=True)
2022-03-24 08:03:26.289849
Epoch: [11][0/20], lr: 0.00100	Time 3.229 (3.229)	Data 2.373 (2.373)	Loss 0.0548 (0.0548)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0223 (0.0223)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5034 (0.5034)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1210], device='cuda:0', requires_grad=True)
2022-03-24 08:03:44.268973
Epoch: [12][0/20], lr: 0.00100	Time 3.292 (3.292)	Data 2.159 (2.159)	Loss 0.0581 (0.0581)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0215 (0.0215)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5145 (0.5145)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9244], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1221], device='cuda:0', requires_grad=True)
2022-03-24 08:04:02.191599
Epoch: [13][0/20], lr: 0.00100	Time 3.262 (3.262)	Data 2.352 (2.352)	Loss 0.0576 (0.0576)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0222 (0.0222)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5257 (0.5257)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9226], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1208], device='cuda:0', requires_grad=True)
2022-03-24 08:04:20.113028
Epoch: [14][0/20], lr: 0.00100	Time 3.266 (3.266)	Data 2.361 (2.361)	Loss 0.0594 (0.0594)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0223 (0.0223)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5485 (0.5485)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9235], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1212], device='cuda:0', requires_grad=True)
2022-03-24 08:04:38.176409
Epoch: [15][0/20], lr: 0.00100	Time 3.251 (3.251)	Data 2.311 (2.311)	Loss 0.0599 (0.0599)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0216 (0.0216)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5615 (0.5615)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9251], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1220], device='cuda:0', requires_grad=True)
2022-03-24 08:04:56.061137
Epoch: [16][0/20], lr: 0.00100	Time 3.305 (3.305)	Data 2.215 (2.215)	Loss 0.0644 (0.0644)	Loss CE 0.0095 (0.0095)	Loss KD (Logit) 0.0225 (0.0225)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5124 (0.5124)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9277], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1233], device='cuda:0', requires_grad=True)
2022-03-24 08:05:14.075223
Epoch: [17][0/20], lr: 0.00100	Time 3.229 (3.229)	Data 2.002 (2.002)	Loss 0.0579 (0.0579)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0223 (0.0223)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5384 (0.5384)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9295], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1242], device='cuda:0', requires_grad=True)
2022-03-24 08:05:32.035323
Epoch: [18][0/20], lr: 0.00100	Time 3.115 (3.115)	Data 1.965 (1.965)	Loss 0.0742 (0.0742)	Loss CE 0.0177 (0.0177)	Loss KD (Logit) 0.0220 (0.0220)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5300 (0.5300)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9318], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1256], device='cuda:0', requires_grad=True)
2022-03-24 08:05:49.886715
Epoch: [19][0/20], lr: 0.00100	Time 3.377 (3.377)	Data 2.342 (2.342)	Loss 0.0586 (0.0586)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0211 (0.0211)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5487 (0.5487)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9294], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1235], device='cuda:0', requires_grad=True)
2022-03-24 08:06:07.608299
Epoch: [20][0/20], lr: 0.00010	Time 3.235 (3.235)	Data 2.136 (2.136)	Loss 0.0596 (0.0596)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0221 (0.0221)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5487 (0.5487)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9294], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1235], device='cuda:0', requires_grad=True)
2022-03-24 08:06:24.925140
Epoch: [21][0/20], lr: 0.00010	Time 3.496 (3.496)	Data 2.227 (2.227)	Loss 0.0532 (0.0532)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0216 (0.0216)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4793 (0.4793)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9297], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1236], device='cuda:0', requires_grad=True)
2022-03-24 08:06:46.326288
Epoch: [22][0/20], lr: 0.00010	Time 3.676 (3.676)	Data 2.573 (2.573)	Loss 0.0568 (0.0568)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0216 (0.0216)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5303 (0.5303)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9298], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1237], device='cuda:0', requires_grad=True)
2022-03-24 08:07:07.510837
Epoch: [23][0/20], lr: 0.00010	Time 3.519 (3.519)	Data 1.959 (1.959)	Loss 0.0593 (0.0593)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0217 (0.0217)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5539 (0.5539)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9299], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1237], device='cuda:0', requires_grad=True)
2022-03-24 08:07:28.282275
Epoch: [24][0/20], lr: 0.00010	Time 3.307 (3.307)	Data 2.138 (2.138)	Loss 0.0538 (0.0538)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0224 (0.0224)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4952 (0.4952)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9301], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1238], device='cuda:0', requires_grad=True)
2022-03-24 08:07:49.251916
Epoch: [25][0/20], lr: 0.00010	Time 3.424 (3.424)	Data 2.140 (2.140)	Loss 0.0612 (0.0612)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0218 (0.0218)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5556 (0.5556)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9303], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:08:10.417161
Epoch: [26][0/20], lr: 0.00010	Time 3.539 (3.539)	Data 2.277 (2.277)	Loss 0.0543 (0.0543)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0222 (0.0222)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4999 (0.4999)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9304], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:08:31.335827
Epoch: [27][0/20], lr: 0.00010	Time 3.200 (3.200)	Data 1.873 (1.873)	Loss 0.0611 (0.0611)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0221 (0.0221)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5568 (0.5568)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9304], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:08:52.483884
Epoch: [28][0/20], lr: 0.00010	Time 3.397 (3.397)	Data 2.068 (2.068)	Loss 0.0605 (0.0605)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0216 (0.0216)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5579 (0.5579)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9305], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:09:13.607757
Epoch: [29][0/20], lr: 0.00010	Time 3.638 (3.638)	Data 2.551 (2.551)	Loss 0.0580 (0.0580)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0222 (0.0222)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5397 (0.5397)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:09:34.531108
Epoch: [30][0/20], lr: 0.00001	Time 3.236 (3.236)	Data 1.925 (1.925)	Loss 0.0604 (0.0604)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0211 (0.0211)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5642 (0.5642)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:09:55.728458
Epoch: [31][0/20], lr: 0.00001	Time 3.410 (3.410)	Data 2.278 (2.278)	Loss 0.0626 (0.0626)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0220 (0.0220)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5733 (0.5733)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:10:16.760369
Epoch: [32][0/20], lr: 0.00001	Time 3.480 (3.480)	Data 2.101 (2.101)	Loss 0.0575 (0.0575)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0217 (0.0217)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5219 (0.5219)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:10:37.676102
Epoch: [33][0/20], lr: 0.00001	Time 3.266 (3.266)	Data 1.919 (1.919)	Loss 0.0553 (0.0553)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0217 (0.0217)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5049 (0.5049)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
2022-03-24 08:10:58.723882
Epoch: [34][0/20], lr: 0.00001	Time 3.287 (3.287)	Data 1.957 (1.957)	Loss 0.0616 (0.0616)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0214 (0.0214)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5775 (0.5775)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
2022-03-24 08:11:19.688893
Epoch: [35][0/20], lr: 0.00001	Time 3.532 (3.532)	Data 2.216 (2.216)	Loss 0.0563 (0.0563)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0223 (0.0223)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5106 (0.5106)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
2022-03-24 08:11:41.160502
Epoch: [36][0/20], lr: 0.00001	Time 3.702 (3.702)	Data 2.645 (2.645)	Loss 0.0620 (0.0620)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0211 (0.0211)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5593 (0.5593)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
2022-03-24 08:12:02.729161
Epoch: [37][0/20], lr: 0.00001	Time 3.503 (3.503)	Data 2.262 (2.262)	Loss 0.0573 (0.0573)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0221 (0.0221)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5341 (0.5341)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:12:23.817475
Epoch: [38][0/20], lr: 0.00001	Time 3.460 (3.460)	Data 2.170 (2.170)	Loss 0.0553 (0.0553)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0215 (0.0215)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5175 (0.5175)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:12:44.947636
Epoch: [39][0/20], lr: 0.00001	Time 3.424 (3.424)	Data 2.378 (2.378)	Loss 0.0561 (0.0561)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0215 (0.0215)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5209 (0.5209)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9306], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:13:05.945958
Epoch: [40][0/20], lr: 0.00001	Time 3.522 (3.522)	Data 2.271 (2.271)	Loss 0.0608 (0.0608)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0218 (0.0218)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5727 (0.5727)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:13:26.820023
Epoch: [41][0/20], lr: 0.00001	Time 3.438 (3.438)	Data 1.909 (1.909)	Loss 0.0604 (0.0604)	Loss CE 0.0046 (0.0046)	Loss KD (Logit) 0.0230 (0.0230)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5216 (0.5216)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:13:48.240975
Epoch: [42][0/20], lr: 0.00001	Time 3.416 (3.416)	Data 2.103 (2.103)	Loss 0.0588 (0.0588)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0213 (0.0213)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5528 (0.5528)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:14:09.892065
Epoch: [43][0/20], lr: 0.00001	Time 3.698 (3.698)	Data 2.270 (2.270)	Loss 0.0563 (0.0563)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0219 (0.0219)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5238 (0.5238)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:14:31.090233
Epoch: [44][0/20], lr: 0.00001	Time 3.433 (3.433)	Data 2.400 (2.400)	Loss 0.0572 (0.0572)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0220 (0.0220)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5327 (0.5327)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:14:52.435359
Epoch: [45][0/20], lr: 0.00001	Time 3.460 (3.460)	Data 2.560 (2.560)	Loss 0.0593 (0.0593)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0214 (0.0214)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5483 (0.5483)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:15:13.661197
Epoch: [46][0/20], lr: 0.00001	Time 3.453 (3.453)	Data 2.109 (2.109)	Loss 0.0589 (0.0589)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0220 (0.0220)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5522 (0.5522)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:15:35.135567
Epoch: [47][0/20], lr: 0.00001	Time 3.597 (3.597)	Data 2.237 (2.237)	Loss 0.0545 (0.0545)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0215 (0.0215)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5031 (0.5031)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:15:54.972095
Epoch: [48][0/20], lr: 0.00001	Time 3.400 (3.400)	Data 2.487 (2.487)	Loss 0.0598 (0.0598)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0209 (0.0209)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5611 (0.5611)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:16:14.709762
Epoch: [49][0/20], lr: 0.00001	Time 3.413 (3.413)	Data 2.245 (2.245)	Loss 0.0587 (0.0587)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0215 (0.0215)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5445 (0.5445)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=267, sigma=tensor([3.9307]), eta=tensor([3.1240])
  (fc1): CosineLinear(input_features=512, output_features=261, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 210
video number + exemplar : 210
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=267, sigma=tensor([3.9307]), eta=tensor([3.1240])
  (fc1): CosineLinear(input_features=512, output_features=261, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 445
DataLoader CBF Constructed : Train 13
Optimizer Constructed
2022-03-24 08:16:51.265943
Epoch: [0][0/13], lr: 0.00050	Time 2.889 (2.889)	Data 1.831 (1.831)	Loss 0.0039 (0.0039)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9308], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1239], device='cuda:0', requires_grad=True)
2022-03-24 08:17:00.660601
Epoch: [1][0/13], lr: 0.00050	Time 3.223 (3.223)	Data 2.313 (2.313)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9309], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1238], device='cuda:0', requires_grad=True)
2022-03-24 08:17:09.593471
Epoch: [2][0/13], lr: 0.00050	Time 3.030 (3.030)	Data 2.330 (2.330)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1237], device='cuda:0', requires_grad=True)
2022-03-24 08:17:18.627913
Epoch: [3][0/13], lr: 0.00050	Time 3.156 (3.156)	Data 2.067 (2.067)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9310], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1235], device='cuda:0', requires_grad=True)
2022-03-24 08:17:27.507530
Epoch: [4][0/13], lr: 0.00050	Time 2.991 (2.991)	Data 2.239 (2.239)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9307], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1231], device='cuda:0', requires_grad=True)
2022-03-24 08:17:36.466983
Epoch: [5][0/13], lr: 0.00050	Time 2.816 (2.816)	Data 2.041 (2.041)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9299], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1225], device='cuda:0', requires_grad=True)
2022-03-24 08:17:45.402404
Epoch: [6][0/13], lr: 0.00050	Time 2.965 (2.965)	Data 2.361 (2.361)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9294], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1220], device='cuda:0', requires_grad=True)
2022-03-24 08:17:54.234988
Epoch: [7][0/13], lr: 0.00050	Time 2.920 (2.920)	Data 2.309 (2.309)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9296], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1220], device='cuda:0', requires_grad=True)
2022-03-24 08:18:03.119475
Epoch: [8][0/13], lr: 0.00050	Time 3.068 (3.068)	Data 2.207 (2.207)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9297], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1219], device='cuda:0', requires_grad=True)
2022-03-24 08:18:12.418138
Epoch: [9][0/13], lr: 0.00050	Time 2.918 (2.918)	Data 2.120 (2.120)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9295], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1216], device='cuda:0', requires_grad=True)
2022-03-24 08:18:21.146502
Epoch: [10][0/13], lr: 0.00050	Time 2.696 (2.696)	Data 1.887 (1.887)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9292], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1212], device='cuda:0', requires_grad=True)
2022-03-24 08:18:30.196458
Epoch: [11][0/13], lr: 0.00050	Time 3.008 (3.008)	Data 2.316 (2.316)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9294], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1212], device='cuda:0', requires_grad=True)
2022-03-24 08:18:39.368277
Epoch: [12][0/13], lr: 0.00050	Time 3.083 (3.083)	Data 2.158 (2.158)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9295], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1211], device='cuda:0', requires_grad=True)
2022-03-24 08:18:48.575264
Epoch: [13][0/13], lr: 0.00050	Time 3.082 (3.082)	Data 2.322 (2.322)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9296], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1208], device='cuda:0', requires_grad=True)
2022-03-24 08:18:57.664436
Epoch: [14][0/13], lr: 0.00050	Time 2.897 (2.897)	Data 2.065 (2.065)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9296], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1206], device='cuda:0', requires_grad=True)
2022-03-24 08:19:06.634784
Epoch: [15][0/13], lr: 0.00050	Time 3.007 (3.007)	Data 2.064 (2.064)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9295], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1204], device='cuda:0', requires_grad=True)
2022-03-24 08:19:15.519733
Epoch: [16][0/13], lr: 0.00050	Time 2.797 (2.797)	Data 1.850 (1.850)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9295], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1202], device='cuda:0', requires_grad=True)
2022-03-24 08:19:24.595005
Epoch: [17][0/13], lr: 0.00050	Time 3.008 (3.008)	Data 1.896 (1.896)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9298], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1201], device='cuda:0', requires_grad=True)
2022-03-24 08:19:33.731855
Epoch: [18][0/13], lr: 0.00050	Time 3.124 (3.124)	Data 2.555 (2.555)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9300], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1200], device='cuda:0', requires_grad=True)
2022-03-24 08:19:42.691608
Epoch: [19][0/13], lr: 0.00050	Time 2.837 (2.837)	Data 1.874 (1.874)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9292], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1195], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_019.pth.tar
exemplar : 445
Computing the class mean vectors...
Eval Task 0 for Age 19
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.771 (4.771)	Prec@1 43.750 (43.750)
Test: [100/120]	Time 0.450 (0.509)	Prec@1 87.500 (58.601)
Testing Results: Prec@1 58.854
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 81.250 (65.842)
Testing Results (NME): Prec@1 65.885
Eval Task 1 for Age 19
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.018 (4.018)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 52.239
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 31.250 (31.250)
Testing Results (NME): Prec@1 47.761
Eval Task 2 for Age 19
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.640 (3.640)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 79.747
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 69.620
Eval Task 3 for Age 19
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.176 (4.176)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 85.882
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 83.529
Eval Task 4 for Age 19
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.535 (3.535)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 68.493
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 61.644
Eval Task 5 for Age 19
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.890 (3.890)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 83.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 82.051
Eval Task 6 for Age 19
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.216 (4.216)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 59.701
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 56.716
Eval Task 7 for Age 19
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.118 (4.118)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 58.025
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 55.556
Eval Task 8 for Age 19
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.057 (4.057)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 59.091
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 62.121
Eval Task 9 for Age 19
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.080 (4.080)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 72.727
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 70.130
Eval Task 10 for Age 19
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.372 (4.372)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 92.683
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 91.463
Eval Task 11 for Age 19
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.037 (4.037)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 50.704
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 59.155
Eval Task 12 for Age 19
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.198 (4.198)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 62.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 69.333
Eval Task 13 for Age 19
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.828 (3.828)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 91.045
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 76.119
Eval Task 14 for Age 19
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.330 (4.330)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 73.864
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 73.864
Eval Task 15 for Age 19
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.697 (3.697)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 80.645
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 82.258
Eval Task 16 for Age 19
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 4.165 (4.165)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 81.250
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 67.188
Eval Task 17 for Age 19
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.071 (4.071)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.104
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 83.117
Eval Task 18 for Age 19
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.494 (3.494)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 89.706
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 82.353
Eval Task 19 for Age 19
Current Task : [88, 70]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.179 (4.179)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 95.062
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 85.185
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77, 68, 81]
Method : OURS
----AGE 20----
current_task  [12, 24]
current_head  91
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06670832032063168]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=273, sigma=tensor([3.9292]), eta=tensor([3.1195])
  (fc1): CosineLinear(input_features=512, output_features=267, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 170
video number + exemplar : 615
DataLoader Constructed : Train 19
Optimizer Constructed
video number : 170
video number + exemplar : 170
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 08:25:55.510580
Epoch: [0][0/19], lr: 0.00100	Time 3.762 (3.762)	Data 2.656 (2.656)	Loss 0.1195 (0.1195)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.6552 (0.6552)	Loss KD (GCAM) 0.0357 (0.0357)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5956 (0.5956)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9248], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1161], device='cuda:0', requires_grad=True)
2022-03-24 08:26:15.077724
Epoch: [1][0/19], lr: 0.00100	Time 3.469 (3.469)	Data 2.384 (2.384)	Loss 0.1349 (0.1349)	Loss CE 0.0217 (0.0217)	Loss KD (Logit) 0.6565 (0.6565)	Loss KD (GCAM) 0.0471 (0.0471)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5527 (0.5527)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9188], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1132], device='cuda:0', requires_grad=True)
2022-03-24 08:26:35.422197
Epoch: [2][0/19], lr: 0.00100	Time 3.347 (3.347)	Data 2.092 (2.092)	Loss 0.1394 (0.1394)	Loss CE 0.0197 (0.0197)	Loss KD (Logit) 0.6518 (0.6518)	Loss KD (GCAM) 0.0540 (0.0540)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6001 (0.6001)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9110], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1088], device='cuda:0', requires_grad=True)
2022-03-24 08:26:56.023930
Epoch: [3][0/19], lr: 0.00100	Time 3.611 (3.611)	Data 2.335 (2.335)	Loss 0.1816 (0.1816)	Loss CE 0.0621 (0.0621)	Loss KD (Logit) 0.6651 (0.6651)	Loss KD (GCAM) 0.0618 (0.0618)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5663 (0.5663)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8936], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0978], device='cuda:0', requires_grad=True)
2022-03-24 08:27:16.399885
Epoch: [4][0/19], lr: 0.00100	Time 3.399 (3.399)	Data 1.880 (1.880)	Loss 0.2433 (0.2433)	Loss CE 0.1207 (0.1207)	Loss KD (Logit) 0.6694 (0.6694)	Loss KD (GCAM) 0.0639 (0.0639)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5878 (0.5878)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8908], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0961], device='cuda:0', requires_grad=True)
2022-03-24 08:27:36.662560
Epoch: [5][0/19], lr: 0.00100	Time 3.394 (3.394)	Data 2.091 (2.091)	Loss 0.1227 (0.1227)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.6725 (0.6725)	Loss KD (GCAM) 0.0573 (0.0573)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6022 (0.6022)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8941], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0983], device='cuda:0', requires_grad=True)
2022-03-24 08:27:56.588249
Epoch: [6][0/19], lr: 0.00100	Time 3.425 (3.425)	Data 2.459 (2.459)	Loss 0.1292 (0.1292)	Loss CE 0.0103 (0.0103)	Loss KD (Logit) 0.6807 (0.6807)	Loss KD (GCAM) 0.0555 (0.0555)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5679 (0.5679)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8973], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1003], device='cuda:0', requires_grad=True)
2022-03-24 08:28:16.850052
Epoch: [7][0/19], lr: 0.00100	Time 3.204 (3.204)	Data 1.920 (1.920)	Loss 0.1277 (0.1277)	Loss CE 0.0099 (0.0099)	Loss KD (Logit) 0.6841 (0.6841)	Loss KD (GCAM) 0.0543 (0.0543)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5590 (0.5590)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9006], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1022], device='cuda:0', requires_grad=True)
2022-03-24 08:28:36.880118
Epoch: [8][0/19], lr: 0.00100	Time 3.422 (3.422)	Data 2.351 (2.351)	Loss 0.1241 (0.1241)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.6887 (0.6887)	Loss KD (GCAM) 0.0546 (0.0546)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5869 (0.5869)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9016], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1026], device='cuda:0', requires_grad=True)
2022-03-24 08:28:56.858252
Epoch: [9][0/19], lr: 0.00100	Time 3.337 (3.337)	Data 2.106 (2.106)	Loss 0.1257 (0.1257)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.6632 (0.6632)	Loss KD (GCAM) 0.0560 (0.0560)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6023 (0.6023)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9049], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1046], device='cuda:0', requires_grad=True)
2022-03-24 08:29:16.997560
Epoch: [10][0/19], lr: 0.00100	Time 3.400 (3.400)	Data 2.194 (2.194)	Loss 0.1161 (0.1161)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.6700 (0.6700)	Loss KD (GCAM) 0.0481 (0.0481)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5581 (0.5581)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9062], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1056], device='cuda:0', requires_grad=True)
2022-03-24 08:29:35.884017
Epoch: [11][0/19], lr: 0.00100	Time 3.192 (3.192)	Data 2.109 (2.109)	Loss 0.1763 (0.1763)	Loss CE 0.0593 (0.0593)	Loss KD (Logit) 0.6781 (0.6781)	Loss KD (GCAM) 0.0514 (0.0514)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5631 (0.5631)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9087], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1075], device='cuda:0', requires_grad=True)
2022-03-24 08:29:54.458159
Epoch: [12][0/19], lr: 0.00100	Time 3.226 (3.226)	Data 2.225 (2.225)	Loss 0.1312 (0.1312)	Loss CE 0.0114 (0.0114)	Loss KD (Logit) 0.6394 (0.6394)	Loss KD (GCAM) 0.0540 (0.0540)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6089 (0.6089)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9093], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1086], device='cuda:0', requires_grad=True)
2022-03-24 08:30:12.957721
Epoch: [13][0/19], lr: 0.00100	Time 3.313 (3.313)	Data 1.931 (1.931)	Loss 0.1537 (0.1537)	Loss CE 0.0336 (0.0336)	Loss KD (Logit) 0.6530 (0.6530)	Loss KD (GCAM) 0.0550 (0.0550)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5998 (0.5998)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9139], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1120], device='cuda:0', requires_grad=True)
2022-03-24 08:30:29.914143
Epoch: [14][0/19], lr: 0.00100	Time 3.192 (3.192)	Data 2.069 (2.069)	Loss 0.1252 (0.1252)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6985 (0.6985)	Loss KD (GCAM) 0.0503 (0.0503)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6266 (0.6266)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9174], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1141], device='cuda:0', requires_grad=True)
2022-03-24 08:30:46.858340
Epoch: [15][0/19], lr: 0.00100	Time 3.367 (3.367)	Data 2.380 (2.380)	Loss 0.1243 (0.1243)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.6731 (0.6731)	Loss KD (GCAM) 0.0566 (0.0566)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6183 (0.6183)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9189], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1150], device='cuda:0', requires_grad=True)
2022-03-24 08:31:03.962384
Epoch: [16][0/19], lr: 0.00100	Time 3.331 (3.331)	Data 2.490 (2.490)	Loss 0.1811 (0.1811)	Loss CE 0.0619 (0.0619)	Loss KD (Logit) 0.6867 (0.6867)	Loss KD (GCAM) 0.0592 (0.0592)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5570 (0.5570)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9194], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1154], device='cuda:0', requires_grad=True)
2022-03-24 08:31:20.904088
Epoch: [17][0/19], lr: 0.00100	Time 3.359 (3.359)	Data 2.566 (2.566)	Loss 0.1332 (0.1332)	Loss CE 0.0141 (0.0141)	Loss KD (Logit) 0.6919 (0.6919)	Loss KD (GCAM) 0.0597 (0.0597)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5508 (0.5508)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9196], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1153], device='cuda:0', requires_grad=True)
2022-03-24 08:31:37.694585
Epoch: [18][0/19], lr: 0.00100	Time 3.212 (3.212)	Data 2.204 (2.204)	Loss 0.1240 (0.1240)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.6860 (0.6860)	Loss KD (GCAM) 0.0613 (0.0613)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5873 (0.5873)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9190], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1144], device='cuda:0', requires_grad=True)
2022-03-24 08:31:54.425551
Epoch: [19][0/19], lr: 0.00100	Time 3.218 (3.218)	Data 2.027 (2.027)	Loss 0.1227 (0.1227)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.6629 (0.6629)	Loss KD (GCAM) 0.0601 (0.0601)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6004 (0.6004)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9205], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 08:32:11.560801
Epoch: [20][0/19], lr: 0.00010	Time 3.255 (3.255)	Data 2.098 (2.098)	Loss 0.1184 (0.1184)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.6586 (0.6586)	Loss KD (GCAM) 0.0620 (0.0620)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5529 (0.5529)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9206], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 08:32:28.907619
Epoch: [21][0/19], lr: 0.00010	Time 3.282 (3.282)	Data 2.395 (2.395)	Loss 0.1630 (0.1630)	Loss CE 0.0477 (0.0477)	Loss KD (Logit) 0.6545 (0.6545)	Loss KD (GCAM) 0.0508 (0.0508)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5641 (0.5641)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1152], device='cuda:0', requires_grad=True)
2022-03-24 08:32:46.749202
Epoch: [22][0/19], lr: 0.00010	Time 3.462 (3.462)	Data 2.452 (2.452)	Loss 0.1170 (0.1170)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.6702 (0.6702)	Loss KD (GCAM) 0.0543 (0.0543)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5564 (0.5564)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 08:33:04.009164
Epoch: [23][0/19], lr: 0.00010	Time 3.300 (3.300)	Data 2.342 (2.342)	Loss 0.1202 (0.1202)	Loss CE 0.0080 (0.0080)	Loss KD (Logit) 0.6565 (0.6565)	Loss KD (GCAM) 0.0540 (0.0540)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5218 (0.5218)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1152], device='cuda:0', requires_grad=True)
2022-03-24 08:33:21.399378
Epoch: [24][0/19], lr: 0.00010	Time 3.192 (3.192)	Data 2.220 (2.220)	Loss 0.1238 (0.1238)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.6546 (0.6546)	Loss KD (GCAM) 0.0515 (0.0515)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6248 (0.6248)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9209], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1152], device='cuda:0', requires_grad=True)
2022-03-24 08:33:38.396084
Epoch: [25][0/19], lr: 0.00010	Time 3.204 (3.204)	Data 2.396 (2.396)	Loss 0.1438 (0.1438)	Loss CE 0.0241 (0.0241)	Loss KD (Logit) 0.6821 (0.6821)	Loss KD (GCAM) 0.0523 (0.0523)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5860 (0.5860)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9211], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1153], device='cuda:0', requires_grad=True)
2022-03-24 08:33:55.640568
Epoch: [26][0/19], lr: 0.00010	Time 3.319 (3.319)	Data 2.229 (2.229)	Loss 0.1179 (0.1179)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.6539 (0.6539)	Loss KD (GCAM) 0.0543 (0.0543)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5736 (0.5736)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9212], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1154], device='cuda:0', requires_grad=True)
2022-03-24 08:34:12.821894
Epoch: [27][0/19], lr: 0.00010	Time 3.242 (3.242)	Data 2.005 (2.005)	Loss 0.1175 (0.1175)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.6588 (0.6588)	Loss KD (GCAM) 0.0506 (0.0506)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5689 (0.5689)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9214], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 08:34:30.049194
Epoch: [28][0/19], lr: 0.00010	Time 3.311 (3.311)	Data 2.041 (2.041)	Loss 0.1271 (0.1271)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.6834 (0.6834)	Loss KD (GCAM) 0.0551 (0.0551)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6046 (0.6046)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9217], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1157], device='cuda:0', requires_grad=True)
2022-03-24 08:34:47.220927
Epoch: [29][0/19], lr: 0.00010	Time 3.429 (3.429)	Data 2.249 (2.249)	Loss 0.1153 (0.1153)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6592 (0.6592)	Loss KD (GCAM) 0.0493 (0.0493)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5620 (0.5620)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:35:03.865465
Epoch: [30][0/19], lr: 0.00001	Time 3.186 (3.186)	Data 1.907 (1.907)	Loss 0.1226 (0.1226)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.6692 (0.6692)	Loss KD (GCAM) 0.0496 (0.0496)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6097 (0.6097)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:35:21.454579
Epoch: [31][0/19], lr: 0.00001	Time 3.346 (3.346)	Data 2.120 (2.120)	Loss 0.1163 (0.1163)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.6696 (0.6696)	Loss KD (GCAM) 0.0544 (0.0544)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5433 (0.5433)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:35:41.666119
Epoch: [32][0/19], lr: 0.00001	Time 3.451 (3.451)	Data 1.927 (1.927)	Loss 0.1198 (0.1198)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.6421 (0.6421)	Loss KD (GCAM) 0.0526 (0.0526)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5947 (0.5947)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9219], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:36:02.007458
Epoch: [33][0/19], lr: 0.00001	Time 3.471 (3.471)	Data 2.317 (2.317)	Loss 0.1165 (0.1165)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.6408 (0.6408)	Loss KD (GCAM) 0.0515 (0.0515)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5762 (0.5762)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:36:22.237085
Epoch: [34][0/19], lr: 0.00001	Time 3.347 (3.347)	Data 1.921 (1.921)	Loss 0.1155 (0.1155)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.6446 (0.6446)	Loss KD (GCAM) 0.0513 (0.0513)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5656 (0.5656)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:36:42.335869
Epoch: [35][0/19], lr: 0.00001	Time 3.367 (3.367)	Data 2.308 (2.308)	Loss 0.1419 (0.1419)	Loss CE 0.0222 (0.0222)	Loss KD (Logit) 0.6561 (0.6561)	Loss KD (GCAM) 0.0530 (0.0530)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6006 (0.6006)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:37:02.092412
Epoch: [36][0/19], lr: 0.00001	Time 3.023 (3.023)	Data 1.836 (1.836)	Loss 0.1192 (0.1192)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.6748 (0.6748)	Loss KD (GCAM) 0.0565 (0.0565)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5642 (0.5642)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:37:22.360320
Epoch: [37][0/19], lr: 0.00001	Time 3.239 (3.239)	Data 2.476 (2.476)	Loss 0.1435 (0.1435)	Loss CE 0.0257 (0.0257)	Loss KD (Logit) 0.6629 (0.6629)	Loss KD (GCAM) 0.0569 (0.0569)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5647 (0.5647)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:37:42.184628
Epoch: [38][0/19], lr: 0.00001	Time 3.454 (3.454)	Data 2.091 (2.091)	Loss 0.1152 (0.1152)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6724 (0.6724)	Loss KD (GCAM) 0.0476 (0.0476)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5573 (0.5573)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:38:02.292967
Epoch: [39][0/19], lr: 0.00001	Time 3.494 (3.494)	Data 2.304 (2.304)	Loss 0.1182 (0.1182)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.6591 (0.6591)	Loss KD (GCAM) 0.0486 (0.0486)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5686 (0.5686)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:38:22.440089
Epoch: [40][0/19], lr: 0.00001	Time 3.427 (3.427)	Data 2.211 (2.211)	Loss 0.1143 (0.1143)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.6424 (0.6424)	Loss KD (GCAM) 0.0451 (0.0451)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5779 (0.5779)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:38:42.595222
Epoch: [41][0/19], lr: 0.00001	Time 3.630 (3.630)	Data 2.064 (2.064)	Loss 0.1173 (0.1173)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.6593 (0.6593)	Loss KD (GCAM) 0.0501 (0.0501)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5802 (0.5802)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:39:02.792255
Epoch: [42][0/19], lr: 0.00001	Time 3.447 (3.447)	Data 2.042 (2.042)	Loss 0.1229 (0.1229)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.6698 (0.6698)	Loss KD (GCAM) 0.0515 (0.0515)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5881 (0.5881)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:39:22.734834
Epoch: [43][0/19], lr: 0.00001	Time 3.259 (3.259)	Data 2.289 (2.289)	Loss 0.1205 (0.1205)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.6605 (0.6605)	Loss KD (GCAM) 0.0473 (0.0473)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5873 (0.5873)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:39:43.479333
Epoch: [44][0/19], lr: 0.00001	Time 3.741 (3.741)	Data 1.959 (1.959)	Loss 0.1211 (0.1211)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.6758 (0.6758)	Loss KD (GCAM) 0.0574 (0.0574)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5785 (0.5785)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:40:03.780345
Epoch: [45][0/19], lr: 0.00001	Time 3.532 (3.532)	Data 2.630 (2.630)	Loss 0.1230 (0.1230)	Loss CE 0.0048 (0.0048)	Loss KD (Logit) 0.6495 (0.6495)	Loss KD (GCAM) 0.0532 (0.0532)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5896 (0.5896)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9221], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:40:23.608917
Epoch: [46][0/19], lr: 0.00001	Time 3.362 (3.362)	Data 2.158 (2.158)	Loss 0.1155 (0.1155)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.6669 (0.6669)	Loss KD (GCAM) 0.0471 (0.0471)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5619 (0.5619)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9222], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:40:43.793481
Epoch: [47][0/19], lr: 0.00001	Time 3.466 (3.466)	Data 2.434 (2.434)	Loss 0.1202 (0.1202)	Loss CE 0.0060 (0.0060)	Loss KD (Logit) 0.6521 (0.6521)	Loss KD (GCAM) 0.0487 (0.0487)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5617 (0.5617)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9222], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:41:03.788408
Epoch: [48][0/19], lr: 0.00001	Time 3.471 (3.471)	Data 2.170 (2.170)	Loss 0.1182 (0.1182)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.6666 (0.6666)	Loss KD (GCAM) 0.0490 (0.0490)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5729 (0.5729)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9222], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:41:23.970432
Epoch: [49][0/19], lr: 0.00001	Time 3.324 (3.324)	Data 2.324 (2.324)	Loss 0.1184 (0.1184)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.6592 (0.6592)	Loss KD (GCAM) 0.0558 (0.0558)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5708 (0.5708)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9222], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=273, sigma=tensor([3.9222]), eta=tensor([3.1159])
  (fc1): CosineLinear(input_features=512, output_features=267, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 170
video number + exemplar : 170
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=273, sigma=tensor([3.9222]), eta=tensor([3.1159])
  (fc1): CosineLinear(input_features=512, output_features=267, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 455
DataLoader CBF Constructed : Train 14
Optimizer Constructed
2022-03-24 08:42:01.219315
Epoch: [0][0/14], lr: 0.00050	Time 3.132 (3.132)	Data 2.208 (2.208)	Loss 0.0171 (0.0171)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1159], device='cuda:0', requires_grad=True)
2022-03-24 08:42:11.857856
Epoch: [1][0/14], lr: 0.00050	Time 2.995 (2.995)	Data 2.188 (2.188)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1158], device='cuda:0', requires_grad=True)
2022-03-24 08:42:22.260031
Epoch: [2][0/14], lr: 0.00050	Time 2.922 (2.922)	Data 2.066 (2.066)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9224], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1156], device='cuda:0', requires_grad=True)
2022-03-24 08:42:32.609828
Epoch: [3][0/14], lr: 0.00050	Time 2.964 (2.964)	Data 2.012 (2.012)	Loss 0.0043 (0.0043)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9226], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 08:42:42.978133
Epoch: [4][0/14], lr: 0.00050	Time 2.919 (2.919)	Data 2.230 (2.230)	Loss 0.0044 (0.0044)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9229], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 08:42:53.643080
Epoch: [5][0/14], lr: 0.00050	Time 3.234 (3.234)	Data 2.675 (2.675)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9232], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1155], device='cuda:0', requires_grad=True)
2022-03-24 08:43:04.676106
Epoch: [6][0/14], lr: 0.00050	Time 3.164 (3.164)	Data 2.463 (2.463)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9231], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1153], device='cuda:0', requires_grad=True)
2022-03-24 08:43:15.262148
Epoch: [7][0/14], lr: 0.00050	Time 3.105 (3.105)	Data 2.423 (2.423)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9234], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1152], device='cuda:0', requires_grad=True)
2022-03-24 08:43:26.081738
Epoch: [8][0/14], lr: 0.00050	Time 3.135 (3.135)	Data 2.417 (2.417)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9240], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1153], device='cuda:0', requires_grad=True)
2022-03-24 08:43:36.385081
Epoch: [9][0/14], lr: 0.00050	Time 2.817 (2.817)	Data 1.877 (1.877)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9244], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1154], device='cuda:0', requires_grad=True)
2022-03-24 08:43:47.735641
Epoch: [10][0/14], lr: 0.00050	Time 3.179 (3.179)	Data 1.957 (1.957)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9248], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1154], device='cuda:0', requires_grad=True)
2022-03-24 08:43:58.417829
Epoch: [11][0/14], lr: 0.00050	Time 3.054 (3.054)	Data 1.912 (1.912)	Loss 0.0041 (0.0041)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9251], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1153], device='cuda:0', requires_grad=True)
2022-03-24 08:44:08.946292
Epoch: [12][0/14], lr: 0.00050	Time 3.092 (3.092)	Data 2.433 (2.433)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9255], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1151], device='cuda:0', requires_grad=True)
2022-03-24 08:44:19.408812
Epoch: [13][0/14], lr: 0.00050	Time 3.087 (3.087)	Data 2.060 (2.060)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9258], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1149], device='cuda:0', requires_grad=True)
2022-03-24 08:44:29.910408
Epoch: [14][0/14], lr: 0.00050	Time 3.197 (3.197)	Data 2.683 (2.683)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9259], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1148], device='cuda:0', requires_grad=True)
2022-03-24 08:44:39.680106
Epoch: [15][0/14], lr: 0.00050	Time 2.978 (2.978)	Data 2.123 (2.123)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9262], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1147], device='cuda:0', requires_grad=True)
2022-03-24 08:44:49.098743
Epoch: [16][0/14], lr: 0.00050	Time 2.955 (2.955)	Data 2.042 (2.042)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9265], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1147], device='cuda:0', requires_grad=True)
2022-03-24 08:44:58.501235
Epoch: [17][0/14], lr: 0.00050	Time 2.942 (2.942)	Data 1.864 (1.864)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9265], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1145], device='cuda:0', requires_grad=True)
2022-03-24 08:45:08.004015
Epoch: [18][0/14], lr: 0.00050	Time 2.864 (2.864)	Data 1.901 (1.901)	Loss 0.0033 (0.0033)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9266], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1144], device='cuda:0', requires_grad=True)
2022-03-24 08:45:18.000587
Epoch: [19][0/14], lr: 0.00050	Time 3.376 (3.376)	Data 2.719 (2.719)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9267], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1143], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_020.pth.tar
exemplar : 455
Computing the class mean vectors...
Eval Task 0 for Age 20
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.833 (4.833)	Prec@1 50.000 (50.000)
Test: [100/120]	Time 0.380 (0.487)	Prec@1 81.250 (57.302)
Testing Results: Prec@1 57.760
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 75.000 (64.356)
Testing Results (NME): Prec@1 64.479
Eval Task 1 for Age 20
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.105 (4.105)	Prec@1 18.750 (18.750)
Testing Results: Prec@1 23.881
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 49.254
Eval Task 2 for Age 20
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.797 (3.797)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 84.810
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 68.354
Eval Task 3 for Age 20
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.918 (3.918)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 76.471
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 78.824
Eval Task 4 for Age 20
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.859 (3.859)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 67.123
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 61.644
Eval Task 5 for Age 20
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.861 (3.861)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 88.462
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 83.333
Eval Task 6 for Age 20
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.984 (3.984)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 55.224
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 31.250 (31.250)
Testing Results (NME): Prec@1 49.254
Eval Task 7 for Age 20
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.083 (4.083)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 56.790
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 60.494
Eval Task 8 for Age 20
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.088 (4.088)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 62.121
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 59.091
Eval Task 9 for Age 20
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.323 (3.323)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 75.325
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 72.727
Eval Task 10 for Age 20
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.740 (3.740)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 89.024
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 92.683
Eval Task 11 for Age 20
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.784 (3.784)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 33.803
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 31.250 (31.250)
Testing Results (NME): Prec@1 36.620
Eval Task 12 for Age 20
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.762 (3.762)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 74.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 68.000
Eval Task 13 for Age 20
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.007 (4.007)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 77.612
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 74.627
Eval Task 14 for Age 20
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.304 (4.304)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 43.182
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 61.364
Eval Task 15 for Age 20
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.774 (3.774)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 74.194
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 66.129
Eval Task 16 for Age 20
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 4.079 (4.079)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 76.562
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 68.750
Eval Task 17 for Age 20
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.133 (4.133)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 88.312
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 77.922
Eval Task 18 for Age 20
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.628 (3.628)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 51.471
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 52.941
Eval Task 19 for Age 20
Current Task : [88, 70]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.448 (3.448)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 88.889
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 79.012
Eval Task 20 for Age 20
Current Task : [12, 24]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.203 (4.203)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 83.099
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Method : OURS
----AGE 21----
current_task  [21, 29]
current_head  93
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06745368781616021]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=279, sigma=tensor([3.9267]), eta=tensor([3.1143])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 188
video number + exemplar : 643
DataLoader Constructed : Train 20
Optimizer Constructed
video number : 188
video number + exemplar : 188
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 08:51:31.887120
Epoch: [0][0/20], lr: 0.00100	Time 3.635 (3.635)	Data 2.370 (2.370)	Loss 0.2500 (0.2500)	Loss CE 0.1711 (0.1711)	Loss KD (Logit) 0.2456 (0.2456)	Loss KD (GCAM) 0.0283 (0.0283)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5381 (0.5381)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.9112], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 08:51:53.098349
Epoch: [1][0/20], lr: 0.00100	Time 3.822 (3.822)	Data 2.167 (2.167)	Loss 0.1683 (0.1683)	Loss CE 0.0856 (0.0856)	Loss KD (Logit) 0.2657 (0.2657)	Loss KD (GCAM) 0.0426 (0.0426)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5196 (0.5196)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.8989], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0987], device='cuda:0', requires_grad=True)
2022-03-24 08:52:14.328976
Epoch: [2][0/20], lr: 0.00100	Time 3.427 (3.427)	Data 2.171 (2.171)	Loss 0.0984 (0.0984)	Loss CE 0.0099 (0.0099)	Loss KD (Logit) 0.2667 (0.2667)	Loss KD (GCAM) 0.0461 (0.0461)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5668 (0.5668)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8933], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0960], device='cuda:0', requires_grad=True)
2022-03-24 08:52:35.819015
Epoch: [3][0/20], lr: 0.00100	Time 3.565 (3.565)	Data 2.088 (2.088)	Loss 0.1218 (0.1218)	Loss CE 0.0344 (0.0344)	Loss KD (Logit) 0.2584 (0.2584)	Loss KD (GCAM) 0.0455 (0.0455)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5632 (0.5632)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8883], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0934], device='cuda:0', requires_grad=True)
2022-03-24 08:52:57.102258
Epoch: [4][0/20], lr: 0.00100	Time 3.520 (3.520)	Data 1.880 (1.880)	Loss 0.0922 (0.0922)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.2614 (0.2614)	Loss KD (GCAM) 0.0447 (0.0447)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6016 (0.6016)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8882], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0938], device='cuda:0', requires_grad=True)
2022-03-24 08:53:18.343630
Epoch: [5][0/20], lr: 0.00100	Time 3.400 (3.400)	Data 2.287 (2.287)	Loss 0.1075 (0.1075)	Loss CE 0.0236 (0.0236)	Loss KD (Logit) 0.2648 (0.2648)	Loss KD (GCAM) 0.0448 (0.0448)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5263 (0.5263)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8931], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0971], device='cuda:0', requires_grad=True)
2022-03-24 08:53:39.182045
Epoch: [6][0/20], lr: 0.00100	Time 3.171 (3.171)	Data 1.843 (1.843)	Loss 0.2431 (0.2431)	Loss CE 0.1570 (0.1570)	Loss KD (Logit) 0.2680 (0.2680)	Loss KD (GCAM) 0.0423 (0.0423)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5531 (0.5531)	Loss REG 0.0000 (0.0000)	Prec@1 93.750 (93.750)
Sigma : Parameter containing:
tensor([3.8935], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0975], device='cuda:0', requires_grad=True)
2022-03-24 08:54:00.339727
Epoch: [7][0/20], lr: 0.00100	Time 3.664 (3.664)	Data 2.674 (2.674)	Loss 0.0860 (0.0860)	Loss CE 0.0064 (0.0064)	Loss KD (Logit) 0.2534 (0.2534)	Loss KD (GCAM) 0.0457 (0.0457)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4879 (0.4879)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.8962], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0984], device='cuda:0', requires_grad=True)
2022-03-24 08:54:21.532452
Epoch: [8][0/20], lr: 0.00100	Time 3.521 (3.521)	Data 2.529 (2.529)	Loss 0.1009 (0.1009)	Loss CE 0.0154 (0.0154)	Loss KD (Logit) 0.2620 (0.2620)	Loss KD (GCAM) 0.0494 (0.0494)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5307 (0.5307)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9020], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1017], device='cuda:0', requires_grad=True)
2022-03-24 08:54:43.010170
Epoch: [9][0/20], lr: 0.00100	Time 3.611 (3.611)	Data 2.538 (2.538)	Loss 0.0921 (0.0921)	Loss CE 0.0038 (0.0038)	Loss KD (Logit) 0.2625 (0.2625)	Loss KD (GCAM) 0.0460 (0.0460)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5681 (0.5681)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9030], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1025], device='cuda:0', requires_grad=True)
2022-03-24 08:55:04.430852
Epoch: [10][0/20], lr: 0.00100	Time 3.596 (3.596)	Data 2.537 (2.537)	Loss 0.0885 (0.0885)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.2624 (0.2624)	Loss KD (GCAM) 0.0443 (0.0443)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5424 (0.5424)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9053], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1040], device='cuda:0', requires_grad=True)
2022-03-24 08:55:25.530669
Epoch: [11][0/20], lr: 0.00100	Time 3.495 (3.495)	Data 2.293 (2.293)	Loss 0.1095 (0.1095)	Loss CE 0.0242 (0.0242)	Loss KD (Logit) 0.2521 (0.2521)	Loss KD (GCAM) 0.0436 (0.0436)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5526 (0.5526)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9080], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1058], device='cuda:0', requires_grad=True)
2022-03-24 08:55:46.395095
Epoch: [12][0/20], lr: 0.00100	Time 3.151 (3.151)	Data 2.207 (2.207)	Loss 0.0841 (0.0841)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.2588 (0.2588)	Loss KD (GCAM) 0.0469 (0.0469)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5187 (0.5187)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9107], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1068], device='cuda:0', requires_grad=True)
2022-03-24 08:56:07.349854
Epoch: [13][0/20], lr: 0.00100	Time 3.646 (3.646)	Data 2.591 (2.591)	Loss 0.0872 (0.0872)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.2582 (0.2582)	Loss KD (GCAM) 0.0451 (0.0451)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5470 (0.5470)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9132], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1077], device='cuda:0', requires_grad=True)
2022-03-24 08:56:28.373926
Epoch: [14][0/20], lr: 0.00100	Time 3.036 (3.036)	Data 1.844 (1.844)	Loss 0.0923 (0.0923)	Loss CE 0.0087 (0.0087)	Loss KD (Logit) 0.2482 (0.2482)	Loss KD (GCAM) 0.0489 (0.0489)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5213 (0.5213)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9154], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1085], device='cuda:0', requires_grad=True)
2022-03-24 08:56:49.709910
Epoch: [15][0/20], lr: 0.00100	Time 3.332 (3.332)	Data 2.314 (2.314)	Loss 0.0880 (0.0880)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.2551 (0.2551)	Loss KD (GCAM) 0.0469 (0.0469)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5637 (0.5637)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9159], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1088], device='cuda:0', requires_grad=True)
2022-03-24 08:57:10.789525
Epoch: [16][0/20], lr: 0.00100	Time 3.285 (3.285)	Data 2.163 (2.163)	Loss 0.0837 (0.0837)	Loss CE 0.0032 (0.0032)	Loss KD (Logit) 0.2628 (0.2628)	Loss KD (GCAM) 0.0420 (0.0420)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5017 (0.5017)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9144], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1078], device='cuda:0', requires_grad=True)
2022-03-24 08:57:32.136474
Epoch: [17][0/20], lr: 0.00100	Time 3.624 (3.624)	Data 2.367 (2.367)	Loss 0.2950 (0.2950)	Loss CE 0.2064 (0.2064)	Loss KD (Logit) 0.2694 (0.2694)	Loss KD (GCAM) 0.0471 (0.0471)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5634 (0.5634)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9123], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1065], device='cuda:0', requires_grad=True)
2022-03-24 08:57:52.881761
Epoch: [18][0/20], lr: 0.00100	Time 3.016 (3.016)	Data 1.869 (1.869)	Loss 0.0894 (0.0894)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.2739 (0.2739)	Loss KD (GCAM) 0.0496 (0.0496)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5367 (0.5367)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9127], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1070], device='cuda:0', requires_grad=True)
2022-03-24 08:58:13.958114
Epoch: [19][0/20], lr: 0.00100	Time 3.513 (3.513)	Data 2.653 (2.653)	Loss 0.2003 (0.2003)	Loss CE 0.1141 (0.1141)	Loss KD (Logit) 0.2655 (0.2655)	Loss KD (GCAM) 0.0468 (0.0468)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5434 (0.5434)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9139], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1073], device='cuda:0', requires_grad=True)
2022-03-24 08:58:33.597723
Epoch: [20][0/20], lr: 0.00010	Time 3.537 (3.537)	Data 2.539 (2.539)	Loss 0.0873 (0.0873)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.2639 (0.2639)	Loss KD (GCAM) 0.0508 (0.0508)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5353 (0.5353)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9142], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1074], device='cuda:0', requires_grad=True)
2022-03-24 08:58:53.464770
Epoch: [21][0/20], lr: 0.00010	Time 3.405 (3.405)	Data 2.616 (2.616)	Loss 0.1063 (0.1063)	Loss CE 0.0192 (0.0192)	Loss KD (Logit) 0.2638 (0.2638)	Loss KD (GCAM) 0.0495 (0.0495)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5439 (0.5439)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9145], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1076], device='cuda:0', requires_grad=True)
2022-03-24 08:59:12.717879
Epoch: [22][0/20], lr: 0.00010	Time 3.231 (3.231)	Data 2.159 (2.159)	Loss 0.0887 (0.0887)	Loss CE 0.0079 (0.0079)	Loss KD (Logit) 0.2659 (0.2659)	Loss KD (GCAM) 0.0460 (0.0460)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4907 (0.4907)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9148], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1078], device='cuda:0', requires_grad=True)
2022-03-24 08:59:30.793071
Epoch: [23][0/20], lr: 0.00010	Time 3.508 (3.508)	Data 2.402 (2.402)	Loss 0.0868 (0.0868)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.2622 (0.2622)	Loss KD (GCAM) 0.0476 (0.0476)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5424 (0.5424)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9152], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1080], device='cuda:0', requires_grad=True)
2022-03-24 08:59:48.562739
Epoch: [24][0/20], lr: 0.00010	Time 3.383 (3.383)	Data 2.506 (2.506)	Loss 0.0862 (0.0862)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.2641 (0.2641)	Loss KD (GCAM) 0.0462 (0.0462)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5427 (0.5427)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9155], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1082], device='cuda:0', requires_grad=True)
2022-03-24 09:00:06.183330
Epoch: [25][0/20], lr: 0.00010	Time 3.434 (3.434)	Data 2.256 (2.256)	Loss 0.0920 (0.0920)	Loss CE 0.0088 (0.0088)	Loss KD (Logit) 0.2548 (0.2548)	Loss KD (GCAM) 0.0509 (0.0509)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5077 (0.5077)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9158], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1083], device='cuda:0', requires_grad=True)
2022-03-24 09:00:24.196836
Epoch: [26][0/20], lr: 0.00010	Time 3.501 (3.501)	Data 2.703 (2.703)	Loss 0.0841 (0.0841)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.2557 (0.2557)	Loss KD (GCAM) 0.0457 (0.0457)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5269 (0.5269)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9161], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1085], device='cuda:0', requires_grad=True)
2022-03-24 09:00:41.946914
Epoch: [27][0/20], lr: 0.00010	Time 3.511 (3.511)	Data 2.560 (2.560)	Loss 0.0870 (0.0870)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.2576 (0.2576)	Loss KD (GCAM) 0.0406 (0.0406)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5714 (0.5714)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9164], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 09:01:00.230165
Epoch: [28][0/20], lr: 0.00010	Time 3.295 (3.295)	Data 2.116 (2.116)	Loss 0.0878 (0.0878)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.2621 (0.2621)	Loss KD (GCAM) 0.0477 (0.0477)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5564 (0.5564)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9166], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1088], device='cuda:0', requires_grad=True)
2022-03-24 09:01:18.227350
Epoch: [29][0/20], lr: 0.00010	Time 3.405 (3.405)	Data 2.157 (2.157)	Loss 0.0950 (0.0950)	Loss CE 0.0121 (0.0121)	Loss KD (Logit) 0.2614 (0.2614)	Loss KD (GCAM) 0.0446 (0.0446)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5187 (0.5187)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9169], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:01:36.259098
Epoch: [30][0/20], lr: 0.00001	Time 3.303 (3.303)	Data 2.252 (2.252)	Loss 0.0889 (0.0889)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.2604 (0.2604)	Loss KD (GCAM) 0.0443 (0.0443)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5528 (0.5528)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9169], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:01:54.156679
Epoch: [31][0/20], lr: 0.00001	Time 3.253 (3.253)	Data 2.365 (2.365)	Loss 0.0837 (0.0837)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.2639 (0.2639)	Loss KD (GCAM) 0.0445 (0.0445)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5206 (0.5206)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9170], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:02:12.080481
Epoch: [32][0/20], lr: 0.00001	Time 3.260 (3.260)	Data 2.203 (2.203)	Loss 0.0788 (0.0788)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.2596 (0.2596)	Loss KD (GCAM) 0.0407 (0.0407)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4829 (0.4829)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9170], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:02:30.083131
Epoch: [33][0/20], lr: 0.00001	Time 3.206 (3.206)	Data 2.307 (2.307)	Loss 0.0840 (0.0840)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.2552 (0.2552)	Loss KD (GCAM) 0.0443 (0.0443)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5279 (0.5279)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9170], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:02:47.805341
Epoch: [34][0/20], lr: 0.00001	Time 3.181 (3.181)	Data 2.356 (2.356)	Loss 0.0881 (0.0881)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.2602 (0.2602)	Loss KD (GCAM) 0.0399 (0.0399)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5366 (0.5366)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9170], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:03:05.552844
Epoch: [35][0/20], lr: 0.00001	Time 3.230 (3.230)	Data 2.138 (2.138)	Loss 0.0786 (0.0786)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.2553 (0.2553)	Loss KD (GCAM) 0.0414 (0.0414)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4797 (0.4797)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9170], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:03:23.737801
Epoch: [36][0/20], lr: 0.00001	Time 3.462 (3.462)	Data 2.609 (2.609)	Loss 0.0859 (0.0859)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.2601 (0.2601)	Loss KD (GCAM) 0.0430 (0.0430)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5077 (0.5077)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:03:41.578769
Epoch: [37][0/20], lr: 0.00001	Time 3.209 (3.209)	Data 2.386 (2.386)	Loss 0.0803 (0.0803)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.2577 (0.2577)	Loss KD (GCAM) 0.0434 (0.0434)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4923 (0.4923)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:03:58.824320
Epoch: [38][0/20], lr: 0.00001	Time 3.523 (3.523)	Data 2.155 (2.155)	Loss 0.0875 (0.0875)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.2530 (0.2530)	Loss KD (GCAM) 0.0387 (0.0387)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5666 (0.5666)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:04:19.092846
Epoch: [39][0/20], lr: 0.00001	Time 3.470 (3.470)	Data 2.150 (2.150)	Loss 0.0872 (0.0872)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.2616 (0.2616)	Loss KD (GCAM) 0.0441 (0.0441)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5545 (0.5545)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:04:40.507810
Epoch: [40][0/20], lr: 0.00001	Time 3.508 (3.508)	Data 2.217 (2.217)	Loss 0.1117 (0.1117)	Loss CE 0.0263 (0.0263)	Loss KD (Logit) 0.2596 (0.2596)	Loss KD (GCAM) 0.0429 (0.0429)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5503 (0.5503)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:05:01.840890
Epoch: [41][0/20], lr: 0.00001	Time 3.497 (3.497)	Data 2.136 (2.136)	Loss 0.0811 (0.0811)	Loss CE 0.0016 (0.0016)	Loss KD (Logit) 0.2586 (0.2586)	Loss KD (GCAM) 0.0439 (0.0439)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4892 (0.4892)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9171], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:05:23.266132
Epoch: [42][0/20], lr: 0.00001	Time 3.708 (3.708)	Data 2.554 (2.554)	Loss 0.0806 (0.0806)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.2591 (0.2591)	Loss KD (GCAM) 0.0399 (0.0399)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4896 (0.4896)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9172], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:05:44.284142
Epoch: [43][0/20], lr: 0.00001	Time 3.421 (3.421)	Data 2.510 (2.510)	Loss 0.0884 (0.0884)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.2574 (0.2574)	Loss KD (GCAM) 0.0413 (0.0413)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5793 (0.5793)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9172], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:06:05.821593
Epoch: [44][0/20], lr: 0.00001	Time 3.822 (3.822)	Data 2.192 (2.192)	Loss 0.0829 (0.0829)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.2555 (0.2555)	Loss KD (GCAM) 0.0424 (0.0424)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5217 (0.5217)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9172], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:06:27.220688
Epoch: [45][0/20], lr: 0.00001	Time 3.548 (3.548)	Data 2.115 (2.115)	Loss 0.0879 (0.0879)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.2601 (0.2601)	Loss KD (GCAM) 0.0462 (0.0462)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5163 (0.5163)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:06:48.553436
Epoch: [46][0/20], lr: 0.00001	Time 3.397 (3.397)	Data 2.047 (2.047)	Loss 0.0850 (0.0850)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.2578 (0.2578)	Loss KD (GCAM) 0.0407 (0.0407)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5415 (0.5415)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1092], device='cuda:0', requires_grad=True)
2022-03-24 09:07:09.865684
Epoch: [47][0/20], lr: 0.00001	Time 3.631 (3.631)	Data 2.157 (2.157)	Loss 0.0948 (0.0948)	Loss CE 0.0112 (0.0112)	Loss KD (Logit) 0.2642 (0.2642)	Loss KD (GCAM) 0.0434 (0.0434)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5277 (0.5277)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1092], device='cuda:0', requires_grad=True)
2022-03-24 09:07:31.000249
Epoch: [48][0/20], lr: 0.00001	Time 3.228 (3.228)	Data 1.873 (1.873)	Loss 0.0858 (0.0858)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.2539 (0.2539)	Loss KD (GCAM) 0.0426 (0.0426)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5505 (0.5505)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9173], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1092], device='cuda:0', requires_grad=True)
2022-03-24 09:07:52.014131
Epoch: [49][0/20], lr: 0.00001	Time 3.317 (3.317)	Data 2.015 (2.015)	Loss 0.0887 (0.0887)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.2546 (0.2546)	Loss KD (GCAM) 0.0417 (0.0417)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5681 (0.5681)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9174], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1092], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=279, sigma=tensor([3.9174]), eta=tensor([3.1092])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 188
video number + exemplar : 188
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=279, sigma=tensor([3.9174]), eta=tensor([3.1092])
  (fc1): CosineLinear(input_features=512, output_features=273, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 465
DataLoader CBF Constructed : Train 14
Optimizer Constructed
2022-03-24 09:08:31.261996
Epoch: [0][0/14], lr: 0.00050	Time 3.067 (3.067)	Data 2.250 (2.250)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9175], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 09:08:42.280345
Epoch: [1][0/14], lr: 0.00050	Time 3.101 (3.101)	Data 2.467 (2.467)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9180], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 09:08:53.475708
Epoch: [2][0/14], lr: 0.00050	Time 3.504 (3.504)	Data 2.761 (2.761)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9187], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1094], device='cuda:0', requires_grad=True)
2022-03-24 09:09:04.027013
Epoch: [3][0/14], lr: 0.00050	Time 2.928 (2.928)	Data 1.870 (1.870)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9189], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1094], device='cuda:0', requires_grad=True)
2022-03-24 09:09:14.406283
Epoch: [4][0/14], lr: 0.00050	Time 2.914 (2.914)	Data 1.911 (1.911)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9192], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1094], device='cuda:0', requires_grad=True)
2022-03-24 09:09:24.957161
Epoch: [5][0/14], lr: 0.00050	Time 3.092 (3.092)	Data 2.554 (2.554)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9197], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1097], device='cuda:0', requires_grad=True)
2022-03-24 09:09:35.440068
Epoch: [6][0/14], lr: 0.00050	Time 3.196 (3.196)	Data 2.071 (2.071)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9201], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1098], device='cuda:0', requires_grad=True)
2022-03-24 09:09:46.480937
Epoch: [7][0/14], lr: 0.00050	Time 3.199 (3.199)	Data 2.593 (2.593)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9210], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1101], device='cuda:0', requires_grad=True)
2022-03-24 09:09:56.852957
Epoch: [8][0/14], lr: 0.00050	Time 2.898 (2.898)	Data 1.946 (1.946)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9217], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1102], device='cuda:0', requires_grad=True)
2022-03-24 09:10:07.265910
Epoch: [9][0/14], lr: 0.00050	Time 2.954 (2.954)	Data 2.458 (2.458)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9220], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1103], device='cuda:0', requires_grad=True)
2022-03-24 09:10:17.675029
Epoch: [10][0/14], lr: 0.00050	Time 2.973 (2.973)	Data 1.902 (1.902)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9223], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1105], device='cuda:0', requires_grad=True)
2022-03-24 09:10:28.120462
Epoch: [11][0/14], lr: 0.00050	Time 2.944 (2.944)	Data 2.319 (2.319)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9226], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1105], device='cuda:0', requires_grad=True)
2022-03-24 09:10:38.534415
Epoch: [12][0/14], lr: 0.00050	Time 2.960 (2.960)	Data 2.034 (2.034)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9227], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1104], device='cuda:0', requires_grad=True)
2022-03-24 09:10:49.091735
Epoch: [13][0/14], lr: 0.00050	Time 3.011 (3.011)	Data 2.023 (2.023)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9230], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1104], device='cuda:0', requires_grad=True)
2022-03-24 09:11:00.130746
Epoch: [14][0/14], lr: 0.00050	Time 3.244 (3.244)	Data 2.557 (2.557)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9234], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1105], device='cuda:0', requires_grad=True)
2022-03-24 09:11:11.264656
Epoch: [15][0/14], lr: 0.00050	Time 3.655 (3.655)	Data 2.537 (2.537)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9234], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1102], device='cuda:0', requires_grad=True)
2022-03-24 09:11:21.967611
Epoch: [16][0/14], lr: 0.00050	Time 3.071 (3.071)	Data 2.276 (2.276)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9233], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1100], device='cuda:0', requires_grad=True)
2022-03-24 09:11:32.136064
Epoch: [17][0/14], lr: 0.00050	Time 2.912 (2.912)	Data 2.039 (2.039)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9235], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1098], device='cuda:0', requires_grad=True)
2022-03-24 09:11:42.683228
Epoch: [18][0/14], lr: 0.00050	Time 3.084 (3.084)	Data 1.889 (1.889)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9237], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1097], device='cuda:0', requires_grad=True)
2022-03-24 09:11:53.603207
Epoch: [19][0/14], lr: 0.00050	Time 3.578 (3.578)	Data 2.179 (2.179)	Loss 0.0042 (0.0042)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9239], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1097], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_021.pth.tar
exemplar : 465
Computing the class mean vectors...
Eval Task 0 for Age 21
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.283 (5.283)	Prec@1 56.250 (56.250)
Test: [100/120]	Time 0.393 (0.554)	Prec@1 68.750 (61.696)
Testing Results: Prec@1 61.719
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (66.151)
Testing Results (NME): Prec@1 66.458
Eval Task 1 for Age 21
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.326 (3.326)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 37.313
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 31.250 (31.250)
Testing Results (NME): Prec@1 49.254
Eval Task 2 for Age 21
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.243 (3.243)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 84.810
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 75.949
Eval Task 3 for Age 21
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.370 (4.370)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 77.647
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 81.176
Eval Task 4 for Age 21
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 4.069 (4.069)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 71.233
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 61.644
Eval Task 5 for Age 21
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.247 (3.247)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 87.179
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.615
Eval Task 6 for Age 21
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.166 (4.166)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 53.731
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 49.254
Eval Task 7 for Age 21
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.070 (4.070)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 65.432
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 65.432
Eval Task 8 for Age 21
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.613 (3.613)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 59.091
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 54.545
Eval Task 9 for Age 21
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.917 (3.917)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.519
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 80.519
Eval Task 10 for Age 21
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.435 (3.435)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 91.463
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 92.683
Eval Task 11 for Age 21
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.421 (4.421)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 40.845
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 59.155
Eval Task 12 for Age 21
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.971 (3.971)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 73.333
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 73.333
Eval Task 13 for Age 21
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.437 (3.437)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 67.164
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 70.149
Eval Task 14 for Age 21
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.339 (4.339)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 47.727
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 61.364
Eval Task 15 for Age 21
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 4.076 (4.076)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 74.194
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 82.258
Eval Task 16 for Age 21
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.805 (3.805)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 75.000
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 65.625
Eval Task 17 for Age 21
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.078 (4.078)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 87.013
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 75.325
Eval Task 18 for Age 21
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.740 (3.740)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 61.765
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 58.824
Eval Task 19 for Age 21
Current Task : [88, 70]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.337 (4.337)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 79.012
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 74.074
Eval Task 20 for Age 21
Current Task : [12, 24]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.562 (3.562)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 71.831
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 73.239
Eval Task 21 for Age 21
Current Task : [21, 29]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.219 (4.219)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 100.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.000
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77, 68, 81, 71, 75]
Method : OURS
----AGE 22----
current_task  [91, 62]
current_head  95
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06819090848492927]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=285, sigma=tensor([3.9239]), eta=tensor([3.1097])
  (fc1): CosineLinear(input_features=512, output_features=279, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 234
video number + exemplar : 699
DataLoader Constructed : Train 21
Optimizer Constructed
video number : 234
video number + exemplar : 234
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 09:18:22.030845
Epoch: [0][0/21], lr: 0.00100	Time 3.382 (3.382)	Data 2.117 (2.117)	Loss 0.0855 (0.0855)	Loss CE 0.0201 (0.0201)	Loss KD (Logit) 0.0642 (0.0642)	Loss KD (GCAM) 0.0106 (0.0106)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5782 (0.5782)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9208], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1074], device='cuda:0', requires_grad=True)
2022-03-24 09:18:43.423575
Epoch: [1][0/21], lr: 0.00100	Time 3.491 (3.491)	Data 2.191 (2.191)	Loss 0.0794 (0.0794)	Loss CE 0.0132 (0.0132)	Loss KD (Logit) 0.0668 (0.0668)	Loss KD (GCAM) 0.0142 (0.0142)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5740 (0.5740)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9124], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1038], device='cuda:0', requires_grad=True)
2022-03-24 09:19:05.272332
Epoch: [2][0/21], lr: 0.00100	Time 3.536 (3.536)	Data 2.428 (2.428)	Loss 0.0788 (0.0788)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0689 (0.0689)	Loss KD (GCAM) 0.0207 (0.0207)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6578 (0.6578)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9194], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 09:19:26.778224
Epoch: [3][0/21], lr: 0.00100	Time 3.337 (3.337)	Data 2.073 (2.073)	Loss 0.0830 (0.0830)	Loss CE 0.0077 (0.0077)	Loss KD (Logit) 0.0693 (0.0693)	Loss KD (GCAM) 0.0215 (0.0215)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6410 (0.6410)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9247], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1123], device='cuda:0', requires_grad=True)
2022-03-24 09:19:48.486036
Epoch: [4][0/21], lr: 0.00100	Time 3.443 (3.443)	Data 1.966 (1.966)	Loss 0.0892 (0.0892)	Loss CE 0.0196 (0.0196)	Loss KD (Logit) 0.0675 (0.0675)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5929 (0.5929)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9304], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1157], device='cuda:0', requires_grad=True)
2022-03-24 09:20:10.116493
Epoch: [5][0/21], lr: 0.00100	Time 3.297 (3.297)	Data 1.873 (1.873)	Loss 0.0813 (0.0813)	Loss CE 0.0053 (0.0053)	Loss KD (Logit) 0.0687 (0.0687)	Loss KD (GCAM) 0.0211 (0.0211)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6498 (0.6498)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9363], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1195], device='cuda:0', requires_grad=True)
2022-03-24 09:20:31.939168
Epoch: [6][0/21], lr: 0.00100	Time 3.535 (3.535)	Data 2.552 (2.552)	Loss 0.0746 (0.0746)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0697 (0.0697)	Loss KD (GCAM) 0.0194 (0.0194)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6304 (0.6304)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9401], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1218], device='cuda:0', requires_grad=True)
2022-03-24 09:20:53.778740
Epoch: [7][0/21], lr: 0.00100	Time 3.253 (3.253)	Data 1.902 (1.902)	Loss 0.0719 (0.0719)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0705 (0.0705)	Loss KD (GCAM) 0.0216 (0.0216)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6011 (0.6011)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9407], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1216], device='cuda:0', requires_grad=True)
2022-03-24 09:21:15.581928
Epoch: [8][0/21], lr: 0.00100	Time 3.533 (3.533)	Data 2.046 (2.046)	Loss 0.1187 (0.1187)	Loss CE 0.0495 (0.0495)	Loss KD (Logit) 0.0691 (0.0691)	Loss KD (GCAM) 0.0227 (0.0227)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5766 (0.5766)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9430], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1228], device='cuda:0', requires_grad=True)
2022-03-24 09:21:37.346632
Epoch: [9][0/21], lr: 0.00100	Time 3.230 (3.230)	Data 2.231 (2.231)	Loss 0.0784 (0.0784)	Loss CE 0.0045 (0.0045)	Loss KD (Logit) 0.0714 (0.0714)	Loss KD (GCAM) 0.0227 (0.0227)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6224 (0.6224)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9457], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1242], device='cuda:0', requires_grad=True)
2022-03-24 09:21:59.802785
Epoch: [10][0/21], lr: 0.00100	Time 3.484 (3.484)	Data 2.489 (2.489)	Loss 0.0754 (0.0754)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0674 (0.0674)	Loss KD (GCAM) 0.0199 (0.0199)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6405 (0.6405)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9458], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1241], device='cuda:0', requires_grad=True)
2022-03-24 09:22:21.778200
Epoch: [11][0/21], lr: 0.00100	Time 3.211 (3.211)	Data 2.362 (2.362)	Loss 0.0731 (0.0731)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0676 (0.0676)	Loss KD (GCAM) 0.0194 (0.0194)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5989 (0.5989)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9465], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1244], device='cuda:0', requires_grad=True)
2022-03-24 09:22:44.150453
Epoch: [12][0/21], lr: 0.00100	Time 3.511 (3.511)	Data 2.010 (2.010)	Loss 0.0919 (0.0919)	Loss CE 0.0188 (0.0188)	Loss KD (Logit) 0.0693 (0.0693)	Loss KD (GCAM) 0.0202 (0.0202)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6232 (0.6232)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9486], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1254], device='cuda:0', requires_grad=True)
2022-03-24 09:23:06.251251
Epoch: [13][0/21], lr: 0.00100	Time 3.350 (3.350)	Data 2.598 (2.598)	Loss 0.0719 (0.0719)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0681 (0.0681)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6151 (0.6151)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9505], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1263], device='cuda:0', requires_grad=True)
2022-03-24 09:23:27.905593
Epoch: [14][0/21], lr: 0.00100	Time 3.527 (3.527)	Data 2.603 (2.603)	Loss 0.0777 (0.0777)	Loss CE 0.0044 (0.0044)	Loss KD (Logit) 0.0681 (0.0681)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6275 (0.6275)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9524], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1272], device='cuda:0', requires_grad=True)
2022-03-24 09:23:50.364001
Epoch: [15][0/21], lr: 0.00100	Time 3.644 (3.644)	Data 2.700 (2.700)	Loss 0.0759 (0.0759)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0675 (0.0675)	Loss KD (GCAM) 0.0180 (0.0180)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6404 (0.6404)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9548], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1283], device='cuda:0', requires_grad=True)
2022-03-24 09:24:12.282894
Epoch: [16][0/21], lr: 0.00100	Time 3.250 (3.250)	Data 1.926 (1.926)	Loss 0.0705 (0.0705)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0673 (0.0673)	Loss KD (GCAM) 0.0203 (0.0203)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5876 (0.5876)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9566], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1292], device='cuda:0', requires_grad=True)
2022-03-24 09:24:34.152420
Epoch: [17][0/21], lr: 0.00100	Time 3.318 (3.318)	Data 2.556 (2.556)	Loss 0.0789 (0.0789)	Loss CE 0.0097 (0.0097)	Loss KD (Logit) 0.0653 (0.0653)	Loss KD (GCAM) 0.0191 (0.0191)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5897 (0.5897)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9581], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1298], device='cuda:0', requires_grad=True)
2022-03-24 09:24:56.426730
Epoch: [18][0/21], lr: 0.00100	Time 3.755 (3.755)	Data 2.188 (2.188)	Loss 0.0724 (0.0724)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0657 (0.0657)	Loss KD (GCAM) 0.0142 (0.0142)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6345 (0.6345)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9578], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1295], device='cuda:0', requires_grad=True)
2022-03-24 09:25:18.451249
Epoch: [19][0/21], lr: 0.00100	Time 3.513 (3.513)	Data 2.609 (2.609)	Loss 0.0699 (0.0699)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0651 (0.0651)	Loss KD (GCAM) 0.0157 (0.0157)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6034 (0.6034)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 09:25:40.990270
Epoch: [20][0/21], lr: 0.00010	Time 3.725 (3.725)	Data 2.294 (2.294)	Loss 0.0695 (0.0695)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0679 (0.0679)	Loss KD (GCAM) 0.0165 (0.0165)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5919 (0.5919)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9583], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 09:26:02.737181
Epoch: [21][0/21], lr: 0.00010	Time 3.497 (3.497)	Data 2.373 (2.373)	Loss 0.0690 (0.0690)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0681 (0.0681)	Loss KD (GCAM) 0.0191 (0.0191)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5811 (0.5811)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 09:26:24.362228
Epoch: [22][0/21], lr: 0.00010	Time 3.391 (3.391)	Data 2.041 (2.041)	Loss 0.0729 (0.0729)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0662 (0.0662)	Loss KD (GCAM) 0.0155 (0.0155)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6273 (0.6273)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9585], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 09:26:46.080713
Epoch: [23][0/21], lr: 0.00010	Time 3.447 (3.447)	Data 2.282 (2.282)	Loss 0.0821 (0.0821)	Loss CE 0.0106 (0.0106)	Loss KD (Logit) 0.0690 (0.0690)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6143 (0.6143)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9585], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 09:27:07.240449
Epoch: [24][0/21], lr: 0.00010	Time 3.327 (3.327)	Data 2.067 (2.067)	Loss 0.0861 (0.0861)	Loss CE 0.0143 (0.0143)	Loss KD (Logit) 0.0673 (0.0673)	Loss KD (GCAM) 0.0176 (0.0176)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6191 (0.6191)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9584], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1293], device='cuda:0', requires_grad=True)
2022-03-24 09:27:27.389316
Epoch: [25][0/21], lr: 0.00010	Time 3.398 (3.398)	Data 2.507 (2.507)	Loss 0.0722 (0.0722)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0661 (0.0661)	Loss KD (GCAM) 0.0162 (0.0162)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6247 (0.6247)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9581], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:27:47.146538
Epoch: [26][0/21], lr: 0.00010	Time 3.246 (3.246)	Data 2.108 (2.108)	Loss 0.0673 (0.0673)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0660 (0.0660)	Loss KD (GCAM) 0.0156 (0.0156)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5758 (0.5758)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9581], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:28:05.270738
Epoch: [27][0/21], lr: 0.00010	Time 3.264 (3.264)	Data 1.965 (1.965)	Loss 0.0713 (0.0713)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0690 (0.0690)	Loss KD (GCAM) 0.0213 (0.0213)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6003 (0.6003)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:28:23.712411
Epoch: [28][0/21], lr: 0.00010	Time 3.300 (3.300)	Data 2.224 (2.224)	Loss 0.0738 (0.0738)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0655 (0.0655)	Loss KD (GCAM) 0.0179 (0.0179)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6244 (0.6244)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9581], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:28:41.890441
Epoch: [29][0/21], lr: 0.00010	Time 3.261 (3.261)	Data 1.976 (1.976)	Loss 0.0715 (0.0715)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0681 (0.0681)	Loss KD (GCAM) 0.0164 (0.0164)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6121 (0.6121)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:29:00.436718
Epoch: [30][0/21], lr: 0.00001	Time 3.476 (3.476)	Data 2.709 (2.709)	Loss 0.0686 (0.0686)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0703 (0.0703)	Loss KD (GCAM) 0.0198 (0.0198)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5673 (0.5673)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:29:19.034938
Epoch: [31][0/21], lr: 0.00001	Time 3.233 (3.233)	Data 2.253 (2.253)	Loss 0.0713 (0.0713)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0685 (0.0685)	Loss KD (GCAM) 0.0186 (0.0186)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6068 (0.6068)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:29:37.549670
Epoch: [32][0/21], lr: 0.00001	Time 3.184 (3.184)	Data 1.879 (1.879)	Loss 0.0714 (0.0714)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0684 (0.0684)	Loss KD (GCAM) 0.0171 (0.0171)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6148 (0.6148)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:29:56.185235
Epoch: [33][0/21], lr: 0.00001	Time 3.122 (3.122)	Data 1.806 (1.806)	Loss 0.0698 (0.0698)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0677 (0.0677)	Loss KD (GCAM) 0.0201 (0.0201)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5633 (0.5633)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:30:14.534993
Epoch: [34][0/21], lr: 0.00001	Time 3.315 (3.315)	Data 2.328 (2.328)	Loss 0.0744 (0.0744)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0688 (0.0688)	Loss KD (GCAM) 0.0195 (0.0195)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6209 (0.6209)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:30:32.691777
Epoch: [35][0/21], lr: 0.00001	Time 3.065 (3.065)	Data 1.867 (1.867)	Loss 0.0699 (0.0699)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0655 (0.0655)	Loss KD (GCAM) 0.0196 (0.0196)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5904 (0.5904)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:30:51.445598
Epoch: [36][0/21], lr: 0.00001	Time 3.242 (3.242)	Data 2.036 (2.036)	Loss 0.0707 (0.0707)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0677 (0.0677)	Loss KD (GCAM) 0.0171 (0.0171)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5783 (0.5783)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:31:10.284254
Epoch: [37][0/21], lr: 0.00001	Time 3.393 (3.393)	Data 2.540 (2.540)	Loss 0.0685 (0.0685)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0682 (0.0682)	Loss KD (GCAM) 0.0193 (0.0193)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5752 (0.5752)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:31:29.224151
Epoch: [38][0/21], lr: 0.00001	Time 3.309 (3.309)	Data 2.119 (2.119)	Loss 0.0736 (0.0736)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0690 (0.0690)	Loss KD (GCAM) 0.0168 (0.0168)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6364 (0.6364)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:31:47.572373
Epoch: [39][0/21], lr: 0.00001	Time 3.167 (3.167)	Data 2.201 (2.201)	Loss 0.0710 (0.0710)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0692 (0.0692)	Loss KD (GCAM) 0.0157 (0.0157)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6016 (0.6016)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:32:06.005766
Epoch: [40][0/21], lr: 0.00001	Time 3.105 (3.105)	Data 1.960 (1.960)	Loss 0.0759 (0.0759)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0670 (0.0670)	Loss KD (GCAM) 0.0149 (0.0149)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6677 (0.6677)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:32:24.497625
Epoch: [41][0/21], lr: 0.00001	Time 3.186 (3.186)	Data 1.915 (1.915)	Loss 0.0748 (0.0748)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0660 (0.0660)	Loss KD (GCAM) 0.0164 (0.0164)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6519 (0.6519)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:32:42.529972
Epoch: [42][0/21], lr: 0.00001	Time 3.369 (3.369)	Data 2.299 (2.299)	Loss 0.0904 (0.0904)	Loss CE 0.0171 (0.0171)	Loss KD (Logit) 0.0679 (0.0679)	Loss KD (GCAM) 0.0177 (0.0177)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6332 (0.6332)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:33:02.049896
Epoch: [43][0/21], lr: 0.00001	Time 3.450 (3.450)	Data 1.928 (1.928)	Loss 0.0722 (0.0722)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0652 (0.0652)	Loss KD (GCAM) 0.0162 (0.0162)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6116 (0.6116)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:33:24.103290
Epoch: [44][0/21], lr: 0.00001	Time 3.162 (3.162)	Data 2.002 (2.002)	Loss 0.0721 (0.0721)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0670 (0.0670)	Loss KD (GCAM) 0.0191 (0.0191)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6155 (0.6155)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:33:46.504978
Epoch: [45][0/21], lr: 0.00001	Time 3.655 (3.655)	Data 2.370 (2.370)	Loss 0.0718 (0.0718)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0688 (0.0688)	Loss KD (GCAM) 0.0155 (0.0155)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6235 (0.6235)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:34:08.583397
Epoch: [46][0/21], lr: 0.00001	Time 3.680 (3.680)	Data 2.709 (2.709)	Loss 0.0726 (0.0726)	Loss CE 0.0040 (0.0040)	Loss KD (Logit) 0.0685 (0.0685)	Loss KD (GCAM) 0.0190 (0.0190)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5826 (0.5826)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:34:30.682907
Epoch: [47][0/21], lr: 0.00001	Time 3.297 (3.297)	Data 1.957 (1.957)	Loss 0.0698 (0.0698)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0683 (0.0683)	Loss KD (GCAM) 0.0164 (0.0164)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6007 (0.6007)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:34:52.697787
Epoch: [48][0/21], lr: 0.00001	Time 3.316 (3.316)	Data 1.900 (1.900)	Loss 0.0663 (0.0663)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0658 (0.0658)	Loss KD (GCAM) 0.0176 (0.0176)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5641 (0.5641)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
2022-03-24 09:35:14.536533
Epoch: [49][0/21], lr: 0.00001	Time 3.379 (3.379)	Data 2.362 (2.362)	Loss 0.0732 (0.0732)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0673 (0.0673)	Loss KD (GCAM) 0.0170 (0.0170)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6173 (0.6173)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9582], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1291], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=285, sigma=tensor([3.9582]), eta=tensor([3.1291])
  (fc1): CosineLinear(input_features=512, output_features=279, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 234
video number + exemplar : 234
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=285, sigma=tensor([3.9582]), eta=tensor([3.1291])
  (fc1): CosineLinear(input_features=512, output_features=279, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 475
DataLoader CBF Constructed : Train 14
Optimizer Constructed
2022-03-24 09:35:55.566020
Epoch: [0][0/14], lr: 0.00050	Time 2.931 (2.931)	Data 1.829 (1.829)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9586], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1292], device='cuda:0', requires_grad=True)
2022-03-24 09:36:06.029116
Epoch: [1][0/14], lr: 0.00050	Time 3.107 (3.107)	Data 2.562 (2.562)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9589], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1292], device='cuda:0', requires_grad=True)
2022-03-24 09:36:16.927895
Epoch: [2][0/14], lr: 0.00050	Time 3.233 (3.233)	Data 2.304 (2.304)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9595], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 09:36:27.588172
Epoch: [3][0/14], lr: 0.00050	Time 3.033 (3.033)	Data 2.372 (2.372)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9602], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1297], device='cuda:0', requires_grad=True)
2022-03-24 09:36:38.057134
Epoch: [4][0/14], lr: 0.00050	Time 2.820 (2.820)	Data 1.889 (1.889)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9599], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 09:36:48.506903
Epoch: [5][0/14], lr: 0.00050	Time 2.817 (2.817)	Data 1.973 (1.973)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9585], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 09:36:59.508164
Epoch: [6][0/14], lr: 0.00050	Time 3.136 (3.136)	Data 2.162 (2.162)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9579], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1280], device='cuda:0', requires_grad=True)
2022-03-24 09:37:10.134699
Epoch: [7][0/14], lr: 0.00050	Time 3.064 (3.064)	Data 2.047 (2.047)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9576], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1276], device='cuda:0', requires_grad=True)
2022-03-24 09:37:21.160543
Epoch: [8][0/14], lr: 0.00050	Time 3.380 (3.380)	Data 2.139 (2.139)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9573], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1273], device='cuda:0', requires_grad=True)
2022-03-24 09:37:31.654991
Epoch: [9][0/14], lr: 0.00050	Time 2.977 (2.977)	Data 2.187 (2.187)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9570], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1268], device='cuda:0', requires_grad=True)
2022-03-24 09:37:42.100043
Epoch: [10][0/14], lr: 0.00050	Time 3.046 (3.046)	Data 2.486 (2.486)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9565], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1263], device='cuda:0', requires_grad=True)
2022-03-24 09:37:52.456270
Epoch: [11][0/14], lr: 0.00050	Time 2.663 (2.663)	Data 1.864 (1.864)	Loss 0.0187 (0.0187)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1260], device='cuda:0', requires_grad=True)
2022-03-24 09:38:03.700109
Epoch: [12][0/14], lr: 0.00050	Time 3.551 (3.551)	Data 2.689 (2.689)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9561], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1257], device='cuda:0', requires_grad=True)
2022-03-24 09:38:14.312124
Epoch: [13][0/14], lr: 0.00050	Time 3.135 (3.135)	Data 2.627 (2.627)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9564], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1257], device='cuda:0', requires_grad=True)
2022-03-24 09:38:25.263420
Epoch: [14][0/14], lr: 0.00050	Time 3.321 (3.321)	Data 2.509 (2.509)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1254], device='cuda:0', requires_grad=True)
2022-03-24 09:38:35.775701
Epoch: [15][0/14], lr: 0.00050	Time 3.002 (3.002)	Data 2.130 (2.130)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1251], device='cuda:0', requires_grad=True)
2022-03-24 09:38:46.198569
Epoch: [16][0/14], lr: 0.00050	Time 2.888 (2.888)	Data 2.049 (2.049)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9562], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1250], device='cuda:0', requires_grad=True)
2022-03-24 09:38:56.566699
Epoch: [17][0/14], lr: 0.00050	Time 2.964 (2.964)	Data 2.207 (2.207)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9559], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1246], device='cuda:0', requires_grad=True)
2022-03-24 09:39:07.089325
Epoch: [18][0/14], lr: 0.00050	Time 3.083 (3.083)	Data 1.915 (1.915)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9559], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1243], device='cuda:0', requires_grad=True)
2022-03-24 09:39:17.520232
Epoch: [19][0/14], lr: 0.00050	Time 3.076 (3.076)	Data 2.091 (2.091)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9556], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1240], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_022.pth.tar
exemplar : 475
Computing the class mean vectors...
Eval Task 0 for Age 22
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.859 (4.859)	Prec@1 62.500 (62.500)
Test: [100/120]	Time 0.504 (0.558)	Prec@1 75.000 (59.282)
Testing Results: Prec@1 59.115
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (66.708)
Testing Results (NME): Prec@1 67.188
Eval Task 1 for Age 22
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.597 (3.597)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 41.791
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 52.239
Eval Task 2 for Age 22
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.915 (3.915)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 68.354
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 73.418
Eval Task 3 for Age 22
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.533 (3.533)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 78.824
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 78.824
Eval Task 4 for Age 22
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.872 (3.872)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 73.973
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 58.904
Eval Task 5 for Age 22
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.906 (3.906)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 79.487
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 85.897
Eval Task 6 for Age 22
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.288 (3.288)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 41.791
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 47.761
Eval Task 7 for Age 22
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.321 (4.321)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 64.198
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 61.728
Eval Task 8 for Age 22
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.030 (4.030)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 62.121
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 57.576
Eval Task 9 for Age 22
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.643 (3.643)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 77.922
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 75.325
Eval Task 10 for Age 22
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.139 (4.139)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 91.463
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 90.244
Eval Task 11 for Age 22
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.739 (3.739)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 30.986
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 50.704
Eval Task 12 for Age 22
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.149 (4.149)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 72.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 74.667
Eval Task 13 for Age 22
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.749 (3.749)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 80.597
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 77.612
Eval Task 14 for Age 22
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.071 (4.071)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 42.045
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 62.500
Eval Task 15 for Age 22
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 4.039 (4.039)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 70.968
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Test: [0/4]	Time 4.194 (4.194)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 67.188
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 65.625
Eval Task 17 for Age 22
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.228 (4.228)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 84.416
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 76.623
Eval Task 18 for Age 22
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.859 (3.859)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 44.118
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 58.824
Eval Task 19 for Age 22
Current Task : [88, 70]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.945 (3.945)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 76.543
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 69.136
Eval Task 20 for Age 22
Current Task : [12, 24]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.390 (3.390)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 73.239
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 76.056
Eval Task 21 for Age 22
Current Task : [21, 29]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.055 (4.055)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 88.000
Eval Task 22 for Age 22
Current Task : [91, 62]
video number : 92
video number + exemplar : 92
DataLoader Constructed
Test: [0/6]	Time 4.201 (4.201)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 96.739
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 59.783
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77, 68, 81, 71, 75, 92]
Method : OURS
----AGE 23----
current_task  [44, 86]
current_head  97
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.06892024376045111]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=291, sigma=tensor([3.9556]), eta=tensor([3.1240])
  (fc1): CosineLinear(input_features=512, output_features=285, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 168
video number + exemplar : 643
DataLoader Constructed : Train 20
Optimizer Constructed
video number : 168
video number + exemplar : 168
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 09:46:05.487214
Epoch: [0][0/20], lr: 0.00100	Time 3.469 (3.469)	Data 2.502 (2.502)	Loss 0.0877 (0.0877)	Loss CE 0.0346 (0.0346)	Loss KD (Logit) 0.0118 (0.0118)	Loss KD (GCAM) 0.0030 (0.0030)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5145 (0.5145)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9535], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1222], device='cuda:0', requires_grad=True)
2022-03-24 09:46:24.609708
Epoch: [1][0/20], lr: 0.00100	Time 3.618 (3.618)	Data 1.950 (1.950)	Loss 0.1687 (0.1687)	Loss CE 0.1127 (0.1127)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5358 (0.5358)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9563], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1245], device='cuda:0', requires_grad=True)
2022-03-24 09:46:46.174664
Epoch: [2][0/20], lr: 0.00100	Time 4.007 (4.007)	Data 2.782 (2.782)	Loss 0.0758 (0.0758)	Loss CE 0.0165 (0.0165)	Loss KD (Logit) 0.0126 (0.0126)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5698 (0.5698)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9616], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1278], device='cuda:0', requires_grad=True)
2022-03-24 09:47:07.340051
Epoch: [3][0/20], lr: 0.00100	Time 3.349 (3.349)	Data 2.116 (2.116)	Loss 0.1743 (0.1743)	Loss CE 0.1169 (0.1169)	Loss KD (Logit) 0.0126 (0.0126)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5466 (0.5466)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9638], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1277], device='cuda:0', requires_grad=True)
2022-03-24 09:47:28.119596
Epoch: [4][0/20], lr: 0.00100	Time 3.320 (3.320)	Data 2.140 (2.140)	Loss 0.2840 (0.2840)	Loss CE 0.2293 (0.2293)	Loss KD (Logit) 0.0128 (0.0128)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5189 (0.5189)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9646], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1273], device='cuda:0', requires_grad=True)
2022-03-24 09:47:49.068765
Epoch: [5][0/20], lr: 0.00100	Time 3.415 (3.415)	Data 2.110 (2.110)	Loss 0.0752 (0.0752)	Loss CE 0.0149 (0.0149)	Loss KD (Logit) 0.0123 (0.0123)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5748 (0.5748)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9637], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1263], device='cuda:0', requires_grad=True)
2022-03-24 09:48:09.947953
Epoch: [6][0/20], lr: 0.00100	Time 3.100 (3.100)	Data 1.856 (1.856)	Loss 0.1713 (0.1713)	Loss CE 0.1166 (0.1166)	Loss KD (Logit) 0.0133 (0.0133)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5186 (0.5186)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9586], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1225], device='cuda:0', requires_grad=True)
2022-03-24 09:48:31.647030
Epoch: [7][0/20], lr: 0.00100	Time 3.692 (3.692)	Data 2.652 (2.652)	Loss 0.0636 (0.0636)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0129 (0.0129)	Loss KD (GCAM) 0.0061 (0.0061)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5911 (0.5911)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9606], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1237], device='cuda:0', requires_grad=True)
2022-03-24 09:48:52.946763
Epoch: [8][0/20], lr: 0.00100	Time 3.583 (3.583)	Data 2.106 (2.106)	Loss 0.0576 (0.0576)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0130 (0.0130)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5321 (0.5321)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9630], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1253], device='cuda:0', requires_grad=True)
2022-03-24 09:49:14.174149
Epoch: [9][0/20], lr: 0.00100	Time 3.476 (3.476)	Data 1.989 (1.989)	Loss 0.0654 (0.0654)	Loss CE 0.0089 (0.0089)	Loss KD (Logit) 0.0129 (0.0129)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5363 (0.5363)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9634], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1253], device='cuda:0', requires_grad=True)
2022-03-24 09:49:35.938430
Epoch: [10][0/20], lr: 0.00100	Time 3.629 (3.629)	Data 2.498 (2.498)	Loss 0.0576 (0.0576)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0129 (0.0129)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5254 (0.5254)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9671], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1273], device='cuda:0', requires_grad=True)
2022-03-24 09:49:57.330860
Epoch: [11][0/20], lr: 0.00100	Time 3.500 (3.500)	Data 2.394 (2.394)	Loss 0.0751 (0.0751)	Loss CE 0.0151 (0.0151)	Loss KD (Logit) 0.0134 (0.0134)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5691 (0.5691)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9719], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1303], device='cuda:0', requires_grad=True)
2022-03-24 09:50:18.679552
Epoch: [12][0/20], lr: 0.00100	Time 3.484 (3.484)	Data 2.077 (2.077)	Loss 0.0616 (0.0616)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0133 (0.0133)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5498 (0.5498)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9732], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1310], device='cuda:0', requires_grad=True)
2022-03-24 09:50:39.918679
Epoch: [13][0/20], lr: 0.00100	Time 3.591 (3.591)	Data 2.548 (2.548)	Loss 0.0712 (0.0712)	Loss CE 0.0123 (0.0123)	Loss KD (Logit) 0.0132 (0.0132)	Loss KD (GCAM) 0.0077 (0.0077)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5567 (0.5567)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9762], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1327], device='cuda:0', requires_grad=True)
2022-03-24 09:51:01.390230
Epoch: [14][0/20], lr: 0.00100	Time 3.661 (3.661)	Data 2.219 (2.219)	Loss 0.0677 (0.0677)	Loss CE 0.0087 (0.0087)	Loss KD (Logit) 0.0127 (0.0127)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5601 (0.5601)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9783], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1338], device='cuda:0', requires_grad=True)
2022-03-24 09:51:22.372677
Epoch: [15][0/20], lr: 0.00100	Time 3.219 (3.219)	Data 1.975 (1.975)	Loss 0.0609 (0.0609)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0126 (0.0126)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5788 (0.5788)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9789], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:51:43.440371
Epoch: [16][0/20], lr: 0.00100	Time 3.550 (3.550)	Data 2.612 (2.612)	Loss 0.0575 (0.0575)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0127 (0.0127)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5395 (0.5395)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9795], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:52:04.765510
Epoch: [17][0/20], lr: 0.00100	Time 3.523 (3.523)	Data 2.369 (2.369)	Loss 0.0717 (0.0717)	Loss CE 0.0139 (0.0139)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5494 (0.5494)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9808], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1347], device='cuda:0', requires_grad=True)
2022-03-24 09:52:25.638652
Epoch: [18][0/20], lr: 0.00100	Time 3.303 (3.303)	Data 1.899 (1.899)	Loss 0.0564 (0.0564)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0130 (0.0130)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5318 (0.5318)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9795], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1336], device='cuda:0', requires_grad=True)
2022-03-24 09:52:46.587930
Epoch: [19][0/20], lr: 0.00100	Time 3.468 (3.468)	Data 2.284 (2.284)	Loss 0.0622 (0.0622)	Loss CE 0.0061 (0.0061)	Loss KD (Logit) 0.0128 (0.0128)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5311 (0.5311)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9801], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1337], device='cuda:0', requires_grad=True)
2022-03-24 09:53:07.755625
Epoch: [20][0/20], lr: 0.00010	Time 3.385 (3.385)	Data 2.547 (2.547)	Loss 0.0570 (0.0570)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0126 (0.0126)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5309 (0.5309)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9802], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1338], device='cuda:0', requires_grad=True)
2022-03-24 09:53:29.000059
Epoch: [21][0/20], lr: 0.00010	Time 3.600 (3.600)	Data 2.020 (2.020)	Loss 0.0658 (0.0658)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0129 (0.0129)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6142 (0.6142)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9803], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1338], device='cuda:0', requires_grad=True)
2022-03-24 09:53:50.610879
Epoch: [22][0/20], lr: 0.00010	Time 3.608 (3.608)	Data 2.446 (2.446)	Loss 0.0570 (0.0570)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0128 (0.0128)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5338 (0.5338)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9804], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 09:54:12.077786
Epoch: [23][0/20], lr: 0.00010	Time 3.476 (3.476)	Data 2.388 (2.388)	Loss 0.0609 (0.0609)	Loss CE 0.0039 (0.0039)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5414 (0.5414)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9805], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 09:54:33.195364
Epoch: [24][0/20], lr: 0.00010	Time 3.572 (3.572)	Data 2.273 (2.273)	Loss 0.0585 (0.0585)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0131 (0.0131)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5370 (0.5370)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9806], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 09:54:54.590992
Epoch: [25][0/20], lr: 0.00010	Time 3.608 (3.608)	Data 2.388 (2.388)	Loss 0.0585 (0.0585)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0128 (0.0128)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5520 (0.5520)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9807], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:55:15.949160
Epoch: [26][0/20], lr: 0.00010	Time 3.588 (3.588)	Data 1.949 (1.949)	Loss 0.0631 (0.0631)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6000 (0.6000)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9807], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:55:36.713444
Epoch: [27][0/20], lr: 0.00010	Time 3.259 (3.259)	Data 1.990 (1.990)	Loss 0.0596 (0.0596)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0128 (0.0128)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5668 (0.5668)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9808], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:55:56.173180
Epoch: [28][0/20], lr: 0.00010	Time 3.447 (3.447)	Data 2.562 (2.562)	Loss 0.0593 (0.0593)	Loss CE 0.0024 (0.0024)	Loss KD (Logit) 0.0128 (0.0128)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5388 (0.5388)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9808], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 09:56:15.220468
Epoch: [29][0/20], lr: 0.00010	Time 3.680 (3.680)	Data 2.076 (2.076)	Loss 0.0613 (0.0613)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0132 (0.0132)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5794 (0.5794)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:56:33.247641
Epoch: [30][0/20], lr: 0.00001	Time 3.338 (3.338)	Data 2.290 (2.290)	Loss 0.0603 (0.0603)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0127 (0.0127)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5432 (0.5432)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:56:50.658448
Epoch: [31][0/20], lr: 0.00001	Time 3.325 (3.325)	Data 2.135 (2.135)	Loss 0.0619 (0.0619)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0129 (0.0129)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5874 (0.5874)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:57:08.326956
Epoch: [32][0/20], lr: 0.00001	Time 3.103 (3.103)	Data 1.965 (1.965)	Loss 0.0603 (0.0603)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5701 (0.5701)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:57:25.872592
Epoch: [33][0/20], lr: 0.00001	Time 3.236 (3.236)	Data 2.301 (2.301)	Loss 0.0527 (0.0527)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0126 (0.0126)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4931 (0.4931)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:57:43.537333
Epoch: [34][0/20], lr: 0.00001	Time 3.494 (3.494)	Data 2.349 (2.349)	Loss 0.0595 (0.0595)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0127 (0.0127)	Loss KD (GCAM) 0.0062 (0.0062)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5554 (0.5554)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:58:01.105961
Epoch: [35][0/20], lr: 0.00001	Time 3.356 (3.356)	Data 2.213 (2.213)	Loss 0.0693 (0.0693)	Loss CE 0.0144 (0.0144)	Loss KD (Logit) 0.0124 (0.0124)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5202 (0.5202)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:58:19.160688
Epoch: [36][0/20], lr: 0.00001	Time 3.462 (3.462)	Data 2.424 (2.424)	Loss 0.0662 (0.0662)	Loss CE 0.0062 (0.0062)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5720 (0.5720)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:58:36.918330
Epoch: [37][0/20], lr: 0.00001	Time 3.279 (3.279)	Data 2.260 (2.260)	Loss 0.0676 (0.0676)	Loss CE 0.0066 (0.0066)	Loss KD (Logit) 0.0122 (0.0122)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5817 (0.5817)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:58:54.706033
Epoch: [38][0/20], lr: 0.00001	Time 3.228 (3.228)	Data 2.318 (2.318)	Loss 0.0646 (0.0646)	Loss CE 0.0063 (0.0063)	Loss KD (Logit) 0.0126 (0.0126)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5544 (0.5544)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:59:12.450462
Epoch: [39][0/20], lr: 0.00001	Time 3.272 (3.272)	Data 2.130 (2.130)	Loss 0.0888 (0.0888)	Loss CE 0.0361 (0.0361)	Loss KD (Logit) 0.0126 (0.0126)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4972 (0.4972)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:59:30.585156
Epoch: [40][0/20], lr: 0.00001	Time 3.340 (3.340)	Data 2.175 (2.175)	Loss 0.0557 (0.0557)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0124 (0.0124)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5231 (0.5231)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 09:59:48.754635
Epoch: [41][0/20], lr: 0.00001	Time 3.394 (3.394)	Data 2.236 (2.236)	Loss 0.0556 (0.0556)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5194 (0.5194)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:00:06.625285
Epoch: [42][0/20], lr: 0.00001	Time 3.180 (3.180)	Data 2.000 (2.000)	Loss 0.0596 (0.0596)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0134 (0.0134)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5664 (0.5664)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:00:24.140869
Epoch: [43][0/20], lr: 0.00001	Time 3.094 (3.094)	Data 1.874 (1.874)	Loss 0.0577 (0.0577)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0127 (0.0127)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5469 (0.5469)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:00:42.097794
Epoch: [44][0/20], lr: 0.00001	Time 3.425 (3.425)	Data 2.397 (2.397)	Loss 0.0597 (0.0597)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0125 (0.0125)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5662 (0.5662)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:00:59.989023
Epoch: [45][0/20], lr: 0.00001	Time 3.249 (3.249)	Data 1.903 (1.903)	Loss 0.0578 (0.0578)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0127 (0.0127)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5454 (0.5454)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:01:17.138142
Epoch: [46][0/20], lr: 0.00001	Time 3.333 (3.333)	Data 1.944 (1.944)	Loss 0.0565 (0.0565)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0132 (0.0132)	Loss KD (GCAM) 0.0065 (0.0065)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5328 (0.5328)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:01:37.030742
Epoch: [47][0/20], lr: 0.00001	Time 3.547 (3.547)	Data 2.056 (2.056)	Loss 0.0572 (0.0572)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0127 (0.0127)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5353 (0.5353)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:01:58.315114
Epoch: [48][0/20], lr: 0.00001	Time 3.599 (3.599)	Data 2.277 (2.277)	Loss 0.0539 (0.0539)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0124 (0.0124)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.4984 (0.4984)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
2022-03-24 10:02:19.630684
Epoch: [49][0/20], lr: 0.00001	Time 3.658 (3.658)	Data 2.543 (2.543)	Loss 0.0595 (0.0595)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0123 (0.0123)	Loss KD (GCAM) 0.0064 (0.0064)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5631 (0.5631)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1340], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=291, sigma=tensor([3.9809]), eta=tensor([3.1340])
  (fc1): CosineLinear(input_features=512, output_features=285, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 168
video number + exemplar : 168
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=291, sigma=tensor([3.9809]), eta=tensor([3.1340])
  (fc1): CosineLinear(input_features=512, output_features=285, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 485
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-24 10:02:58.449941
Epoch: [0][0/15], lr: 0.00050	Time 2.978 (2.978)	Data 2.030 (2.030)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9810], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1339], device='cuda:0', requires_grad=True)
2022-03-24 10:03:09.914101
Epoch: [1][0/15], lr: 0.00050	Time 3.146 (3.146)	Data 2.300 (2.300)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9810], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1337], device='cuda:0', requires_grad=True)
2022-03-24 10:03:21.288155
Epoch: [2][0/15], lr: 0.00050	Time 2.963 (2.963)	Data 1.875 (1.875)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9807], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1334], device='cuda:0', requires_grad=True)
2022-03-24 10:03:32.259367
Epoch: [3][0/15], lr: 0.00050	Time 2.913 (2.913)	Data 2.034 (2.034)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9804], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1331], device='cuda:0', requires_grad=True)
2022-03-24 10:03:43.606912
Epoch: [4][0/15], lr: 0.00050	Time 3.058 (3.058)	Data 2.278 (2.278)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9805], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1330], device='cuda:0', requires_grad=True)
2022-03-24 10:03:55.118668
Epoch: [5][0/15], lr: 0.00050	Time 3.208 (3.208)	Data 2.506 (2.506)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1330], device='cuda:0', requires_grad=True)
2022-03-24 10:04:06.751345
Epoch: [6][0/15], lr: 0.00050	Time 3.243 (3.243)	Data 2.579 (2.579)	Loss 0.0052 (0.0052)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9809], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1328], device='cuda:0', requires_grad=True)
2022-03-24 10:04:18.125006
Epoch: [7][0/15], lr: 0.00050	Time 3.269 (3.269)	Data 2.347 (2.347)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9808], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1325], device='cuda:0', requires_grad=True)
2022-03-24 10:04:29.777435
Epoch: [8][0/15], lr: 0.00050	Time 3.325 (3.325)	Data 2.555 (2.555)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9805], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1321], device='cuda:0', requires_grad=True)
2022-03-24 10:04:40.816604
Epoch: [9][0/15], lr: 0.00050	Time 2.744 (2.744)	Data 1.856 (1.856)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9804], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1318], device='cuda:0', requires_grad=True)
2022-03-24 10:04:52.243998
Epoch: [10][0/15], lr: 0.00050	Time 3.073 (3.073)	Data 2.449 (2.449)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9804], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1315], device='cuda:0', requires_grad=True)
2022-03-24 10:05:03.128353
Epoch: [11][0/15], lr: 0.00050	Time 2.823 (2.823)	Data 1.874 (1.874)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1311], device='cuda:0', requires_grad=True)
2022-03-24 10:05:14.421753
Epoch: [12][0/15], lr: 0.00050	Time 3.038 (3.038)	Data 2.072 (2.072)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9800], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1308], device='cuda:0', requires_grad=True)
2022-03-24 10:05:25.953105
Epoch: [13][0/15], lr: 0.00050	Time 3.395 (3.395)	Data 2.578 (2.578)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9798], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1305], device='cuda:0', requires_grad=True)
2022-03-24 10:05:37.632523
Epoch: [14][0/15], lr: 0.00050	Time 3.216 (3.216)	Data 2.299 (2.299)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9793], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1299], device='cuda:0', requires_grad=True)
2022-03-24 10:05:49.244222
Epoch: [15][0/15], lr: 0.00050	Time 3.222 (3.222)	Data 2.442 (2.442)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9788], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1294], device='cuda:0', requires_grad=True)
2022-03-24 10:06:00.616713
Epoch: [16][0/15], lr: 0.00050	Time 3.301 (3.301)	Data 2.525 (2.525)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9784], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1290], device='cuda:0', requires_grad=True)
2022-03-24 10:06:12.210386
Epoch: [17][0/15], lr: 0.00050	Time 3.602 (3.602)	Data 2.213 (2.213)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9781], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1286], device='cuda:0', requires_grad=True)
2022-03-24 10:06:23.291060
Epoch: [18][0/15], lr: 0.00050	Time 3.110 (3.110)	Data 2.635 (2.635)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9775], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1280], device='cuda:0', requires_grad=True)
2022-03-24 10:06:34.603163
Epoch: [19][0/15], lr: 0.00050	Time 3.183 (3.183)	Data 2.067 (2.067)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9769], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1275], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_023.pth.tar
exemplar : 485
Computing the class mean vectors...
Eval Task 0 for Age 23
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 4.976 (4.976)	Prec@1 43.750 (43.750)
Test: [100/120]	Time 0.564 (0.570)	Prec@1 75.000 (58.106)
Testing Results: Prec@1 58.177
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 81.250 (65.347)
Testing Results (NME): Prec@1 65.677
Eval Task 1 for Age 23
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.045 (4.045)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 34.328
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 31.250 (31.250)
Testing Results (NME): Prec@1 44.776
Eval Task 2 for Age 23
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 4.132 (4.132)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 67.089
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 73.418
Eval Task 3 for Age 23
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 4.034 (4.034)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 84.706
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 83.529
Eval Task 4 for Age 23
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 4.117 (4.117)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 67.123
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 65.753
Eval Task 5 for Age 23
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 3.473 (3.473)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 89.744
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 85.897
Eval Task 6 for Age 23
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.072 (4.072)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 44.776
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 44.776
Eval Task 7 for Age 23
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.403 (3.403)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 66.667
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 58.025
Eval Task 8 for Age 23
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 4.172 (4.172)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 65.152
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 57.576
Eval Task 9 for Age 23
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.442 (3.442)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 84.416
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 83.117
Eval Task 10 for Age 23
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.142 (4.142)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.683
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.683
Eval Task 11 for Age 23
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.392 (3.392)	Prec@1 50.000 (50.000)
Testing Results: Prec@1 50.704
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 56.338
Eval Task 12 for Age 23
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.675 (3.675)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 74.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 76.000
Eval Task 13 for Age 23
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.008 (4.008)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 77.612
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 79.104
Eval Task 14 for Age 23
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.164 (4.164)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 37.500
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 57.955
Eval Task 15 for Age 23
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.842 (3.842)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 91.935
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 82.258
Eval Task 16 for Age 23
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.119 (3.119)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 70.312
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 60.938
Eval Task 17 for Age 23
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.246 (3.246)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 88.312
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 76.623
Eval Task 18 for Age 23
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.902 (3.902)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 45.588
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 58.824
Eval Task 19 for Age 23
Current Task : [88, 70]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.167 (4.167)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 83.951
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 74.074
Eval Task 20 for Age 23
Current Task : [12, 24]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 4.031 (4.031)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 70.423
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 69.014
Eval Task 21 for Age 23
Current Task : [21, 29]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.082 (4.082)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 76.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 82.667
Eval Task 22 for Age 23
Current Task : [91, 62]
video number : 92
video number + exemplar : 92
DataLoader Constructed
Test: [0/6]	Time 3.909 (3.909)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 76.087
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 53.261
Eval Task 23 for Age 23
Current Task : [44, 86]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.649 (3.649)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 86.154
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 73.846
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77, 68, 81, 71, 75, 92, 65]
Method : OURS
----AGE 24----
current_task  [94, 0]
current_head  99
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.0696419413859206]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=297, sigma=tensor([3.9769]), eta=tensor([3.1275])
  (fc1): CosineLinear(input_features=512, output_features=291, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 194
video number + exemplar : 679
DataLoader Constructed : Train 21
Optimizer Constructed
video number : 194
video number + exemplar : 194
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 10:13:37.449846
Epoch: [0][0/21], lr: 0.00100	Time 3.659 (3.659)	Data 2.451 (2.451)	Loss 0.1273 (0.1273)	Loss CE 0.0578 (0.0578)	Loss KD (Logit) 0.0063 (0.0063)	Loss KD (GCAM) 0.0022 (0.0022)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6839 (0.6839)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9685], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1218], device='cuda:0', requires_grad=True)
2022-03-24 10:13:55.734664
Epoch: [1][0/21], lr: 0.00100	Time 3.289 (3.289)	Data 2.222 (2.222)	Loss 0.2941 (0.2941)	Loss CE 0.2322 (0.2322)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0039 (0.0039)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6024 (0.6024)	Loss REG 0.0000 (0.0000)	Prec@1 90.625 (90.625)
Sigma : Parameter containing:
tensor([3.9565], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1144], device='cuda:0', requires_grad=True)
2022-03-24 10:14:14.395716
Epoch: [2][0/21], lr: 0.00100	Time 3.235 (3.235)	Data 2.080 (2.080)	Loss 0.1240 (0.1240)	Loss CE 0.0584 (0.0584)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6372 (0.6372)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9481], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1093], device='cuda:0', requires_grad=True)
2022-03-24 10:14:32.026227
Epoch: [3][0/21], lr: 0.00100	Time 3.175 (3.175)	Data 2.386 (2.386)	Loss 0.0796 (0.0796)	Loss CE 0.0163 (0.0163)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6126 (0.6126)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9484], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1098], device='cuda:0', requires_grad=True)
2022-03-24 10:14:53.056066
Epoch: [4][0/21], lr: 0.00100	Time 3.570 (3.570)	Data 2.393 (2.393)	Loss 0.0961 (0.0961)	Loss CE 0.0353 (0.0353)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5894 (0.5894)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1117], device='cuda:0', requires_grad=True)
2022-03-24 10:15:14.751913
Epoch: [5][0/21], lr: 0.00100	Time 3.169 (3.169)	Data 2.141 (2.141)	Loss 0.0784 (0.0784)	Loss CE 0.0104 (0.0104)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6599 (0.6599)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9485], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1102], device='cuda:0', requires_grad=True)
2022-03-24 10:15:36.910420
Epoch: [6][0/21], lr: 0.00100	Time 3.379 (3.379)	Data 1.939 (1.939)	Loss 0.0637 (0.0637)	Loss CE 0.0021 (0.0021)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5963 (0.5963)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1115], device='cuda:0', requires_grad=True)
2022-03-24 10:15:58.885043
Epoch: [7][0/21], lr: 0.00100	Time 3.462 (3.462)	Data 1.894 (1.894)	Loss 0.0719 (0.0719)	Loss CE 0.0059 (0.0059)	Loss KD (Logit) 0.0066 (0.0066)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6420 (0.6420)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9533], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1129], device='cuda:0', requires_grad=True)
2022-03-24 10:16:21.207838
Epoch: [8][0/21], lr: 0.00100	Time 3.610 (3.610)	Data 2.476 (2.476)	Loss 0.0694 (0.0694)	Loss CE 0.0035 (0.0035)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0059 (0.0059)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6359 (0.6359)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9496], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1106], device='cuda:0', requires_grad=True)
2022-03-24 10:16:43.290188
Epoch: [9][0/21], lr: 0.00100	Time 3.442 (3.442)	Data 2.281 (2.281)	Loss 0.0975 (0.0975)	Loss CE 0.0343 (0.0343)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6107 (0.6107)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9514], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1118], device='cuda:0', requires_grad=True)
2022-03-24 10:17:05.345780
Epoch: [10][0/21], lr: 0.00100	Time 3.338 (3.338)	Data 2.117 (2.117)	Loss 0.0636 (0.0636)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0054 (0.0054)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6098 (0.6098)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9519], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1117], device='cuda:0', requires_grad=True)
2022-03-24 10:17:27.706758
Epoch: [11][0/21], lr: 0.00100	Time 3.540 (3.540)	Data 2.555 (2.555)	Loss 0.0708 (0.0708)	Loss CE 0.0031 (0.0031)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0054 (0.0054)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6560 (0.6560)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9496], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1098], device='cuda:0', requires_grad=True)
2022-03-24 10:17:49.593049
Epoch: [12][0/21], lr: 0.00100	Time 3.398 (3.398)	Data 2.317 (2.317)	Loss 0.1658 (0.1658)	Loss CE 0.1030 (0.1030)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0056 (0.0056)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6072 (0.6072)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9487], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 10:18:11.410192
Epoch: [13][0/21], lr: 0.00100	Time 3.424 (3.424)	Data 2.343 (2.343)	Loss 0.0690 (0.0690)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0055 (0.0055)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6542 (0.6542)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9488], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 10:18:33.264918
Epoch: [14][0/21], lr: 0.00100	Time 3.284 (3.284)	Data 2.089 (2.089)	Loss 0.0850 (0.0850)	Loss CE 0.0229 (0.0229)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0054 (0.0054)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6002 (0.6002)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9486], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1088], device='cuda:0', requires_grad=True)
2022-03-24 10:18:54.908800
Epoch: [15][0/21], lr: 0.00100	Time 3.551 (3.551)	Data 2.158 (2.158)	Loss 0.0761 (0.0761)	Loss CE 0.0107 (0.0107)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6332 (0.6332)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9508], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1098], device='cuda:0', requires_grad=True)
2022-03-24 10:19:16.706364
Epoch: [16][0/21], lr: 0.00100	Time 3.442 (3.442)	Data 2.617 (2.617)	Loss 0.0664 (0.0664)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6390 (0.6390)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9531], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1111], device='cuda:0', requires_grad=True)
2022-03-24 10:19:38.391037
Sigma : Parameter containing:
tensor([3.9493], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:20:00.276594
Epoch: [18][0/21], lr: 0.00100	Time 3.303 (3.303)	Data 2.181 (2.181)	Loss 0.0658 (0.0658)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0053 (0.0053)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5943 (0.5943)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9479], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1076], device='cuda:0', requires_grad=True)
2022-03-24 10:20:21.963344
Epoch: [19][0/21], lr: 0.00100	Time 3.541 (3.541)	Data 2.597 (2.597)	Loss 0.0601 (0.0601)	Loss CE 0.0006 (0.0006)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5751 (0.5751)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9487], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1081], device='cuda:0', requires_grad=True)
2022-03-24 10:20:43.393421
Epoch: [20][0/21], lr: 0.00010	Time 3.382 (3.382)	Data 2.140 (2.140)	Loss 0.0687 (0.0687)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6401 (0.6401)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9487], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1082], device='cuda:0', requires_grad=True)
2022-03-24 10:21:05.131067
Epoch: [21][0/21], lr: 0.00010	Time 3.328 (3.328)	Data 2.111 (2.111)	Loss 0.0578 (0.0578)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5537 (0.5537)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9490], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1083], device='cuda:0', requires_grad=True)
2022-03-24 10:21:27.104001
Epoch: [22][0/21], lr: 0.00010	Time 3.357 (3.357)	Data 2.308 (2.308)	Loss 0.0606 (0.0606)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0056 (0.0056)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5794 (0.5794)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9492], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1084], device='cuda:0', requires_grad=True)
2022-03-24 10:21:49.205255
Epoch: [23][0/21], lr: 0.00010	Time 3.411 (3.411)	Data 1.927 (1.927)	Loss 0.0678 (0.0678)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0045 (0.0045)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6487 (0.6487)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9492], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1083], device='cuda:0', requires_grad=True)
2022-03-24 10:22:11.133480
Epoch: [24][0/21], lr: 0.00010	Time 3.404 (3.404)	Data 1.943 (1.943)	Loss 0.0626 (0.0626)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0052 (0.0052)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5952 (0.5952)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9494], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1084], device='cuda:0', requires_grad=True)
2022-03-24 10:22:33.056467
Epoch: [25][0/21], lr: 0.00010	Time 3.528 (3.528)	Data 2.376 (2.376)	Loss 0.0646 (0.0646)	Loss CE 0.0009 (0.0009)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6173 (0.6173)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9495], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1084], device='cuda:0', requires_grad=True)
2022-03-24 10:22:55.351147
Epoch: [26][0/21], lr: 0.00010	Time 3.451 (3.451)	Data 1.907 (1.907)	Loss 0.0644 (0.0644)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6236 (0.6236)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9496], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1084], device='cuda:0', requires_grad=True)
2022-03-24 10:23:17.144869
Epoch: [27][0/21], lr: 0.00010	Time 3.315 (3.315)	Data 1.914 (1.914)	Loss 0.0634 (0.0634)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5974 (0.5974)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1085], device='cuda:0', requires_grad=True)
2022-03-24 10:23:39.006151
Epoch: [28][0/21], lr: 0.00010	Time 3.460 (3.460)	Data 2.429 (2.429)	Loss 0.0602 (0.0602)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5727 (0.5727)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9499], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1086], device='cuda:0', requires_grad=True)
2022-03-24 10:24:00.742024
Epoch: [29][0/21], lr: 0.00010	Time 3.377 (3.377)	Data 2.294 (2.294)	Loss 0.0635 (0.0635)	Loss CE 0.0060 (0.0060)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5556 (0.5556)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9500], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1086], device='cuda:0', requires_grad=True)
2022-03-24 10:24:21.104911
Epoch: [30][0/21], lr: 0.00001	Time 3.431 (3.431)	Data 2.317 (2.317)	Loss 0.0657 (0.0657)	Loss CE 0.0017 (0.0017)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6207 (0.6207)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9500], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1086], device='cuda:0', requires_grad=True)
2022-03-24 10:24:41.703791
Epoch: [31][0/21], lr: 0.00001	Time 3.673 (3.673)	Data 2.560 (2.560)	Loss 0.0675 (0.0675)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6517 (0.6517)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9500], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1086], device='cuda:0', requires_grad=True)
2022-03-24 10:25:01.411934
Epoch: [32][0/21], lr: 0.00001	Time 3.452 (3.452)	Data 2.420 (2.420)	Loss 0.0768 (0.0768)	Loss CE 0.0122 (0.0122)	Loss KD (Logit) 0.0067 (0.0067)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6274 (0.6274)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1086], device='cuda:0', requires_grad=True)
2022-03-24 10:25:19.717340
Epoch: [33][0/21], lr: 0.00001	Time 3.266 (3.266)	Data 2.101 (2.101)	Loss 0.0624 (0.0624)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0050 (0.0050)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6025 (0.6025)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:25:38.007015
Epoch: [34][0/21], lr: 0.00001	Time 3.331 (3.331)	Data 2.453 (2.453)	Loss 0.0648 (0.0648)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0051 (0.0051)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6242 (0.6242)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:25:56.524150
Epoch: [35][0/21], lr: 0.00001	Time 3.406 (3.406)	Data 2.561 (2.561)	Loss 0.0699 (0.0699)	Loss CE 0.0076 (0.0076)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6045 (0.6045)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:26:14.656366
Epoch: [36][0/21], lr: 0.00001	Time 3.169 (3.169)	Data 2.064 (2.064)	Loss 0.0611 (0.0611)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5903 (0.5903)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:26:32.744394
Epoch: [37][0/21], lr: 0.00001	Time 3.111 (3.111)	Data 1.893 (1.893)	Loss 0.0667 (0.0667)	Loss CE 0.0018 (0.0018)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6289 (0.6289)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:26:51.477234
Epoch: [38][0/21], lr: 0.00001	Time 3.460 (3.460)	Data 2.661 (2.661)	Loss 0.0560 (0.0560)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5326 (0.5326)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:27:10.285694
Epoch: [39][0/21], lr: 0.00001	Time 3.311 (3.311)	Data 2.279 (2.279)	Loss 0.0714 (0.0714)	Loss CE 0.0058 (0.0058)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6377 (0.6377)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:27:29.035335
Epoch: [40][0/21], lr: 0.00001	Time 3.286 (3.286)	Data 2.071 (2.071)	Loss 0.0667 (0.0667)	Loss CE 0.0010 (0.0010)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0046 (0.0046)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6388 (0.6388)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:27:48.023427
Epoch: [41][0/21], lr: 0.00001	Time 3.570 (3.570)	Data 2.742 (2.742)	Loss 0.0661 (0.0661)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6400 (0.6400)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:28:06.890102
Epoch: [42][0/21], lr: 0.00001	Time 3.407 (3.407)	Data 2.254 (2.254)	Loss 0.1390 (0.1390)	Loss CE 0.0755 (0.0755)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6155 (0.6155)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:28:25.525710
Epoch: [43][0/21], lr: 0.00001	Time 3.218 (3.218)	Data 2.101 (2.101)	Loss 0.0657 (0.0657)	Loss CE 0.0027 (0.0027)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6107 (0.6107)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:28:43.925247
Epoch: [44][0/21], lr: 0.00001	Time 3.175 (3.175)	Data 1.877 (1.877)	Loss 0.0649 (0.0649)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6226 (0.6226)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:29:02.771275
Epoch: [45][0/21], lr: 0.00001	Time 3.574 (3.574)	Data 2.126 (2.126)	Loss 0.0630 (0.0630)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0048 (0.0048)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6078 (0.6078)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:29:21.017779
Epoch: [46][0/21], lr: 0.00001	Time 3.187 (3.187)	Data 2.184 (2.184)	Loss 0.0638 (0.0638)	Loss CE 0.0014 (0.0014)	Loss KD (Logit) 0.0070 (0.0070)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6045 (0.6045)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:29:39.334268
Epoch: [47][0/21], lr: 0.00001	Time 3.045 (3.045)	Data 2.067 (2.067)	Loss 0.0683 (0.0683)	Loss CE 0.0055 (0.0055)	Loss KD (Logit) 0.0069 (0.0069)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6096 (0.6096)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:29:56.943961
Epoch: [48][0/21], lr: 0.00001	Time 3.474 (3.474)	Data 2.038 (2.038)	Loss 0.0631 (0.0631)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0068 (0.0068)	Loss KD (GCAM) 0.0049 (0.0049)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5921 (0.5921)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
2022-03-24 10:30:19.073803
Epoch: [49][0/21], lr: 0.00001	Time 3.394 (3.394)	Data 2.273 (2.273)	Loss 0.0723 (0.0723)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0071 (0.0071)	Loss KD (GCAM) 0.0047 (0.0047)	Loss MR 0.0000 (0.0000)	Loss DIV 0.7000 (0.7000)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9502], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1087], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=297, sigma=tensor([3.9502]), eta=tensor([3.1087])
  (fc1): CosineLinear(input_features=512, output_features=291, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 194
video number + exemplar : 194
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=297, sigma=tensor([3.9502]), eta=tensor([3.1087])
  (fc1): CosineLinear(input_features=512, output_features=291, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 495
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-24 10:30:59.207487
Epoch: [0][0/15], lr: 0.00050	Time 2.949 (2.949)	Data 2.105 (2.105)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1083], device='cuda:0', requires_grad=True)
2022-03-24 10:31:10.496319
Epoch: [1][0/15], lr: 0.00050	Time 3.031 (3.031)	Data 2.232 (2.232)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9496], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1081], device='cuda:0', requires_grad=True)
2022-03-24 10:31:21.919826
Epoch: [2][0/15], lr: 0.00050	Time 3.315 (3.315)	Data 2.211 (2.211)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9506], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1086], device='cuda:0', requires_grad=True)
2022-03-24 10:31:32.894809
Epoch: [3][0/15], lr: 0.00050	Time 2.760 (2.760)	Data 1.930 (1.930)	Loss 0.0037 (0.0037)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1089], device='cuda:0', requires_grad=True)
2022-03-24 10:31:44.152944
Epoch: [4][0/15], lr: 0.00050	Time 3.073 (3.073)	Data 1.919 (1.919)	Loss 0.0033 (0.0033)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9518], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 10:31:55.242640
Epoch: [5][0/15], lr: 0.00050	Time 2.899 (2.899)	Data 2.368 (2.368)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9521], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1090], device='cuda:0', requires_grad=True)
2022-03-24 10:32:06.557121
Epoch: [6][0/15], lr: 0.00050	Time 3.058 (3.058)	Data 2.481 (2.481)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9525], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1091], device='cuda:0', requires_grad=True)
2022-03-24 10:32:17.716226
Epoch: [7][0/15], lr: 0.00050	Time 3.134 (3.134)	Data 2.049 (2.049)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1083], device='cuda:0', requires_grad=True)
2022-03-24 10:32:29.487537
Epoch: [8][0/15], lr: 0.00050	Time 3.171 (3.171)	Data 2.045 (2.045)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9501], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1074], device='cuda:0', requires_grad=True)
2022-03-24 10:32:40.967281
Epoch: [9][0/15], lr: 0.00050	Time 3.142 (3.142)	Data 1.967 (1.967)	Loss 0.0037 (0.0037)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9506], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1075], device='cuda:0', requires_grad=True)
2022-03-24 10:32:52.235604
Epoch: [10][0/15], lr: 0.00050	Time 2.844 (2.844)	Data 1.849 (1.849)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9509], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1075], device='cuda:0', requires_grad=True)
2022-03-24 10:33:03.603645
Epoch: [11][0/15], lr: 0.00050	Time 3.097 (3.097)	Data 2.251 (2.251)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9512], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1075], device='cuda:0', requires_grad=True)
2022-03-24 10:33:15.214530
Epoch: [12][0/15], lr: 0.00050	Time 3.238 (3.238)	Data 2.224 (2.224)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9513], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1075], device='cuda:0', requires_grad=True)
2022-03-24 10:33:26.771466
Epoch: [13][0/15], lr: 0.00050	Time 3.195 (3.195)	Data 2.207 (2.207)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9514], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1074], device='cuda:0', requires_grad=True)
2022-03-24 10:33:37.632519
Epoch: [14][0/15], lr: 0.00050	Time 3.001 (3.001)	Data 2.489 (2.489)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9516], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1074], device='cuda:0', requires_grad=True)
2022-03-24 10:33:49.042012
Epoch: [15][0/15], lr: 0.00050	Time 3.117 (3.117)	Data 2.166 (2.166)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9515], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1071], device='cuda:0', requires_grad=True)
2022-03-24 10:34:00.037610
Epoch: [16][0/15], lr: 0.00050	Time 2.759 (2.759)	Data 2.010 (2.010)	Loss 0.0028 (0.0028)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9514], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1068], device='cuda:0', requires_grad=True)
2022-03-24 10:34:11.317484
Epoch: [17][0/15], lr: 0.00050	Time 3.133 (3.133)	Data 2.076 (2.076)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9512], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1064], device='cuda:0', requires_grad=True)
2022-03-24 10:34:22.374240
Epoch: [18][0/15], lr: 0.00050	Time 2.867 (2.867)	Data 1.992 (1.992)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9511], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1061], device='cuda:0', requires_grad=True)
2022-03-24 10:34:33.676181
Epoch: [19][0/15], lr: 0.00050	Time 2.944 (2.944)	Data 1.862 (1.862)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9508], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1057], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_024.pth.tar
exemplar : 495
Computing the class mean vectors...
Eval Task 0 for Age 24
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.525 (5.525)	Prec@1 50.000 (50.000)
Test: [100/120]	Time 0.689 (0.561)	Prec@1 81.250 (61.386)
Testing Results: Prec@1 61.615
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 87.500 (65.470)
Testing Results (NME): Prec@1 65.625
Eval Task 1 for Age 24
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.737 (3.737)	Prec@1 31.250 (31.250)
Testing Results: Prec@1 41.791
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 25.000 (25.000)
Testing Results (NME): Prec@1 53.731
Eval Task 2 for Age 24
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.385 (3.385)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 75.949
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 69.620
Eval Task 3 for Age 24
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.616 (3.616)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 83.529
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 84.706
Eval Task 4 for Age 24
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.433 (3.433)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 72.603
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 60.274
Eval Task 5 for Age 24
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.143 (4.143)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 87.179
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 87.179
Eval Task 6 for Age 24
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.287 (3.287)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 47.761
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 44.776
Eval Task 7 for Age 24
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.226 (4.226)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 55.556
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 58.025
Eval Task 8 for Age 24
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.557 (3.557)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 56.061
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 60.606
Eval Task 9 for Age 24
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.933 (3.933)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.519
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 83.117
Eval Task 10 for Age 24
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 4.276 (4.276)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 89.024
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 90.244
Eval Task 11 for Age 24
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.842 (3.842)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 39.437
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 50.000 (50.000)
Testing Results (NME): Prec@1 46.479
Eval Task 12 for Age 24
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.272 (4.272)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 62.667
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 74.667
Eval Task 13 for Age 24
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.406 (3.406)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 80.597
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.627
Eval Task 14 for Age 24
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.280 (4.280)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 60.227
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 56.818
Eval Task 15 for Age 24
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.603 (3.603)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.645
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 88.710
Eval Task 16 for Age 24
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 4.033 (4.033)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 78.125
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 71.875
Eval Task 17 for Age 24
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 4.249 (4.249)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 87.013
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 72.727
Eval Task 18 for Age 24
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 3.831 (3.831)	Prec@1 18.750 (18.750)
Testing Results: Prec@1 30.882
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 45.588
Eval Task 19 for Age 24
Current Task : [88, 70]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.489 (3.489)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 91.358
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 71.605
Eval Task 20 for Age 24
Current Task : [12, 24]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.961 (3.961)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 64.789
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 71.831
Eval Task 21 for Age 24
Current Task : [21, 29]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 3.546 (3.546)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 76.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 78.667
Eval Task 22 for Age 24
Current Task : [91, 62]
video number : 92
video number + exemplar : 92
DataLoader Constructed
Test: [0/6]	Time 3.685 (3.685)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 78.261
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 57.609
Eval Task 23 for Age 24
Current Task : [44, 86]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.811 (3.811)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 86.154
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 73.846
Eval Task 24 for Age 24
Current Task : [94, 0]
video number : 87
video number + exemplar : 87
DataLoader Constructed
Test: [0/6]	Time 3.722 (3.722)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 89.655
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 83.908
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77, 68, 81, 71, 75, 92, 65, 87]
Method : OURS
----AGE 25----
current_task  [57, 85]
current_head  101
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.07035623639735145]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([3.9508]), eta=tensor([3.1057])
  (fc1): CosineLinear(input_features=512, output_features=297, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 160
video number + exemplar : 655
DataLoader Constructed : Train 20
Optimizer Constructed
video number : 160
video number + exemplar : 160
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-24 10:41:48.415639
Epoch: [0][0/20], lr: 0.00100	Time 3.552 (3.552)	Data 2.154 (2.154)	Loss 0.0690 (0.0690)	Loss CE 0.0085 (0.0085)	Loss KD (Logit) 0.0161 (0.0161)	Loss KD (GCAM) 0.0033 (0.0033)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5835 (0.5835)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9414], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1004], device='cuda:0', requires_grad=True)
2022-03-24 10:42:05.716326
Epoch: [1][0/20], lr: 0.00100	Time 3.090 (3.090)	Data 2.327 (2.327)	Loss 0.1400 (0.1400)	Loss CE 0.0852 (0.0852)	Loss KD (Logit) 0.0171 (0.0171)	Loss KD (GCAM) 0.0063 (0.0063)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5171 (0.5171)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9319], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0952], device='cuda:0', requires_grad=True)
2022-03-24 10:42:23.141085
Epoch: [2][0/20], lr: 0.00100	Time 3.215 (3.215)	Data 1.927 (1.927)	Loss 0.1282 (0.1282)	Loss CE 0.0712 (0.0712)	Loss KD (Logit) 0.0180 (0.0180)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5358 (0.5358)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9272], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0926], device='cuda:0', requires_grad=True)
2022-03-24 10:42:41.193159
Epoch: [3][0/20], lr: 0.00100	Time 3.266 (3.266)	Data 2.123 (2.123)	Loss 0.0891 (0.0891)	Loss CE 0.0318 (0.0318)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5384 (0.5384)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9155], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0850], device='cuda:0', requires_grad=True)
2022-03-24 10:42:59.169626
Epoch: [4][0/20], lr: 0.00100	Time 3.300 (3.300)	Data 2.474 (2.474)	Loss 0.0632 (0.0632)	Loss CE 0.0033 (0.0033)	Loss KD (Logit) 0.0177 (0.0177)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5636 (0.5636)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9090], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0805], device='cuda:0', requires_grad=True)
2022-03-24 10:43:16.176689
Epoch: [5][0/20], lr: 0.00100	Time 3.673 (3.673)	Data 1.954 (1.954)	Loss 0.1394 (0.1394)	Loss CE 0.0812 (0.0812)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5485 (0.5485)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9084], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0799], device='cuda:0', requires_grad=True)
2022-03-24 10:43:37.570335
Epoch: [6][0/20], lr: 0.00100	Time 3.543 (3.543)	Data 2.159 (2.159)	Loss 0.3159 (0.3159)	Loss CE 0.2609 (0.2609)	Loss KD (Logit) 0.0183 (0.0183)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5140 (0.5140)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9051], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0785], device='cuda:0', requires_grad=True)
2022-03-24 10:43:59.216841
Epoch: [7][0/20], lr: 0.00100	Time 3.789 (3.789)	Data 2.679 (2.679)	Loss 0.0713 (0.0713)	Loss CE 0.0096 (0.0096)	Loss KD (Logit) 0.0181 (0.0181)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5790 (0.5790)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9127], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0828], device='cuda:0', requires_grad=True)
2022-03-24 10:44:20.430010
Epoch: [8][0/20], lr: 0.00100	Time 3.499 (3.499)	Data 2.357 (2.357)	Loss 0.0611 (0.0611)	Loss CE 0.0028 (0.0028)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0081 (0.0081)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5468 (0.5468)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9166], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0849], device='cuda:0', requires_grad=True)
2022-03-24 10:44:41.693601
Epoch: [9][0/20], lr: 0.00100	Time 3.566 (3.566)	Data 2.280 (2.280)	Loss 0.0579 (0.0579)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0181 (0.0181)	Loss KD (GCAM) 0.0082 (0.0082)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5110 (0.5110)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9197], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0866], device='cuda:0', requires_grad=True)
2022-03-24 10:45:02.784078
Epoch: [10][0/20], lr: 0.00100	Time 3.557 (3.557)	Data 2.530 (2.530)	Loss 0.0566 (0.0566)	Loss CE 0.0022 (0.0022)	Loss KD (Logit) 0.0179 (0.0179)	Loss KD (GCAM) 0.0083 (0.0083)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5061 (0.5061)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9226], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0887], device='cuda:0', requires_grad=True)
2022-03-24 10:45:24.259513
Epoch: [11][0/20], lr: 0.00100	Time 3.685 (3.685)	Data 1.929 (1.929)	Loss 0.0638 (0.0638)	Loss CE 0.0030 (0.0030)	Loss KD (Logit) 0.0172 (0.0172)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5725 (0.5725)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9256], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0907], device='cuda:0', requires_grad=True)
2022-03-24 10:45:45.944881
Epoch: [12][0/20], lr: 0.00100	Time 3.658 (3.658)	Data 2.245 (2.245)	Loss 0.0900 (0.0900)	Loss CE 0.0300 (0.0300)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0078 (0.0078)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5640 (0.5640)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9268], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0917], device='cuda:0', requires_grad=True)
2022-03-24 10:46:07.094303
Epoch: [13][0/20], lr: 0.00100	Time 3.573 (3.573)	Data 2.069 (2.069)	Loss 0.0787 (0.0787)	Loss CE 0.0159 (0.0159)	Loss KD (Logit) 0.0175 (0.0175)	Loss KD (GCAM) 0.0081 (0.0081)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5915 (0.5915)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9312], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0943], device='cuda:0', requires_grad=True)
2022-03-24 10:46:28.594566
Epoch: [14][0/20], lr: 0.00100	Time 3.616 (3.616)	Data 2.657 (2.657)	Loss 0.0572 (0.0572)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5353 (0.5353)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9348], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0963], device='cuda:0', requires_grad=True)
2022-03-24 10:46:49.951181
Epoch: [15][0/20], lr: 0.00100	Time 3.480 (3.480)	Data 2.399 (2.399)	Loss 0.0590 (0.0590)	Loss CE 0.0029 (0.0029)	Loss KD (Logit) 0.0172 (0.0172)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5263 (0.5263)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9386], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0988], device='cuda:0', requires_grad=True)
2022-03-24 10:47:10.991812
Epoch: [16][0/20], lr: 0.00100	Time 3.547 (3.547)	Data 2.415 (2.415)	Loss 0.0591 (0.0591)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0174 (0.0174)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5495 (0.5495)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9410], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.0999], device='cuda:0', requires_grad=True)
2022-03-24 10:47:32.148141
Epoch: [17][0/20], lr: 0.00100	Time 3.317 (3.317)	Data 1.912 (1.912)	Loss 0.1098 (0.1098)	Loss CE 0.0523 (0.0523)	Loss KD (Logit) 0.0178 (0.0178)	Loss KD (GCAM) 0.0080 (0.0080)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5387 (0.5387)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9411], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1003], device='cuda:0', requires_grad=True)
2022-03-24 10:47:53.119722
Epoch: [18][0/20], lr: 0.00100	Time 3.320 (3.320)	Data 2.243 (2.243)	Loss 0.0672 (0.0672)	Loss CE 0.0104 (0.0104)	Loss KD (Logit) 0.0178 (0.0178)	Loss KD (GCAM) 0.0079 (0.0079)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5321 (0.5321)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9447], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1026], device='cuda:0', requires_grad=True)
2022-03-24 10:48:14.253434
Epoch: [19][0/20], lr: 0.00100	Time 3.397 (3.397)	Data 2.341 (2.341)	Loss 0.0658 (0.0658)	Loss CE 0.0047 (0.0047)	Loss KD (Logit) 0.0170 (0.0170)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5774 (0.5774)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9477], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1044], device='cuda:0', requires_grad=True)
2022-03-24 10:48:35.869420
Epoch: [20][0/20], lr: 0.00010	Time 3.562 (3.562)	Data 2.156 (2.156)	Loss 0.0597 (0.0597)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0175 (0.0175)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5569 (0.5569)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9478], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1044], device='cuda:0', requires_grad=True)
2022-03-24 10:48:57.248008
Epoch: [21][0/20], lr: 0.00010	Time 3.443 (3.443)	Data 2.004 (2.004)	Loss 0.0560 (0.0560)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0174 (0.0174)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5221 (0.5221)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9481], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1046], device='cuda:0', requires_grad=True)
2022-03-24 10:49:18.436136
Epoch: [22][0/20], lr: 0.00010	Time 3.438 (3.438)	Data 2.458 (2.458)	Loss 0.0617 (0.0617)	Loss CE 0.0015 (0.0015)	Loss KD (Logit) 0.0177 (0.0177)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5675 (0.5675)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9484], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1047], device='cuda:0', requires_grad=True)
2022-03-24 10:49:39.347137
Epoch: [23][0/20], lr: 0.00010	Time 3.288 (3.288)	Data 2.316 (2.316)	Loss 0.0575 (0.0575)	Loss CE 0.0012 (0.0012)	Loss KD (Logit) 0.0177 (0.0177)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5276 (0.5276)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9486], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1048], device='cuda:0', requires_grad=True)
2022-03-24 10:50:00.642782
Epoch: [24][0/20], lr: 0.00010	Time 3.637 (3.637)	Data 2.614 (2.614)	Loss 0.1358 (0.1358)	Loss CE 0.0784 (0.0784)	Loss KD (Logit) 0.0173 (0.0173)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5403 (0.5403)	Loss REG 0.0000 (0.0000)	Prec@1 96.875 (96.875)
Sigma : Parameter containing:
tensor([3.9485], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1048], device='cuda:0', requires_grad=True)
2022-03-24 10:50:21.987521
Epoch: [25][0/20], lr: 0.00010	Time 3.522 (3.522)	Data 2.109 (2.109)	Loss 0.0583 (0.0583)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0172 (0.0172)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5473 (0.5473)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9487], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1049], device='cuda:0', requires_grad=True)
2022-03-24 10:50:43.294803
Epoch: [26][0/20], lr: 0.00010	Time 3.742 (3.742)	Data 2.751 (2.751)	Loss 0.0624 (0.0624)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0175 (0.0175)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5785 (0.5785)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9489], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1050], device='cuda:0', requires_grad=True)
2022-03-24 10:51:04.820105
Epoch: [27][0/20], lr: 0.00010	Time 3.841 (3.841)	Data 1.944 (1.944)	Loss 0.0595 (0.0595)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5347 (0.5347)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9492], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1052], device='cuda:0', requires_grad=True)
2022-03-24 10:51:26.013749
Epoch: [28][0/20], lr: 0.00010	Time 3.637 (3.637)	Data 2.568 (2.568)	Loss 0.0567 (0.0567)	Loss CE 0.0001 (0.0001)	Loss KD (Logit) 0.0171 (0.0171)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5325 (0.5325)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9493], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1052], device='cuda:0', requires_grad=True)
2022-03-24 10:51:47.343130
Epoch: [29][0/20], lr: 0.00010	Time 3.467 (3.467)	Data 2.129 (2.129)	Loss 0.0611 (0.0611)	Loss CE 0.0003 (0.0003)	Loss KD (Logit) 0.0175 (0.0175)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5736 (0.5736)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9496], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:52:08.852863
Epoch: [30][0/20], lr: 0.00001	Time 3.555 (3.555)	Data 2.481 (2.481)	Loss 0.0574 (0.0574)	Loss CE 0.0019 (0.0019)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0067 (0.0067)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5223 (0.5223)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9496], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:52:29.894569
Epoch: [31][0/20], lr: 0.00001	Time 3.259 (3.259)	Data 2.437 (2.437)	Loss 0.0614 (0.0614)	Loss CE 0.0011 (0.0011)	Loss KD (Logit) 0.0173 (0.0173)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5697 (0.5697)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:52:49.557967
Epoch: [32][0/20], lr: 0.00001	Time 3.664 (3.664)	Data 2.297 (2.297)	Loss 0.0566 (0.0566)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0176 (0.0176)	Loss KD (GCAM) 0.0076 (0.0076)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5260 (0.5260)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:53:08.428589
Epoch: [33][0/20], lr: 0.00001	Time 3.237 (3.237)	Data 2.144 (2.144)	Loss 0.0574 (0.0574)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0172 (0.0172)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5361 (0.5361)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:53:27.463750
Epoch: [34][0/20], lr: 0.00001	Time 3.214 (3.214)	Data 2.186 (2.186)	Loss 0.0624 (0.0624)	Loss CE 0.0020 (0.0020)	Loss KD (Logit) 0.0175 (0.0175)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5692 (0.5692)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:53:45.164791
Epoch: [35][0/20], lr: 0.00001	Time 3.417 (3.417)	Data 2.652 (2.652)	Loss 0.0602 (0.0602)	Loss CE 0.0043 (0.0043)	Loss KD (Logit) 0.0174 (0.0174)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5260 (0.5260)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:54:02.446419
Epoch: [36][0/20], lr: 0.00001	Time 3.270 (3.270)	Data 1.923 (1.923)	Loss 0.0620 (0.0620)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0173 (0.0173)	Loss KD (GCAM) 0.0066 (0.0066)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5860 (0.5860)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:54:20.038737
Epoch: [37][0/20], lr: 0.00001	Time 3.302 (3.302)	Data 2.087 (2.087)	Loss 0.0577 (0.0577)	Loss CE 0.0007 (0.0007)	Loss KD (Logit) 0.0174 (0.0174)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5372 (0.5372)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:54:37.349353
Epoch: [38][0/20], lr: 0.00001	Time 3.206 (3.206)	Data 2.161 (2.161)	Loss 0.0556 (0.0556)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0178 (0.0178)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5162 (0.5162)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:54:55.067159
Epoch: [39][0/20], lr: 0.00001	Time 3.515 (3.515)	Data 2.581 (2.581)	Loss 0.0605 (0.0605)	Loss CE 0.0008 (0.0008)	Loss KD (Logit) 0.0174 (0.0174)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5641 (0.5641)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:55:13.202672
Epoch: [40][0/20], lr: 0.00001	Time 3.458 (3.458)	Data 2.667 (2.667)	Loss 0.0613 (0.0613)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0175 (0.0175)	Loss KD (GCAM) 0.0070 (0.0070)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5663 (0.5663)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:55:31.173745
Epoch: [41][0/20], lr: 0.00001	Time 3.271 (3.271)	Data 1.911 (1.911)	Loss 0.0603 (0.0603)	Loss CE 0.0013 (0.0013)	Loss KD (Logit) 0.0177 (0.0177)	Loss KD (GCAM) 0.0075 (0.0075)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5547 (0.5547)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9497], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:55:49.482604
Epoch: [42][0/20], lr: 0.00001	Time 3.547 (3.547)	Data 2.464 (2.464)	Loss 0.0625 (0.0625)	Loss CE 0.0067 (0.0067)	Loss KD (Logit) 0.0173 (0.0173)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5243 (0.5243)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:56:07.870279
Epoch: [43][0/20], lr: 0.00001	Time 3.606 (3.606)	Data 2.759 (2.759)	Loss 0.0622 (0.0622)	Loss CE 0.0049 (0.0049)	Loss KD (Logit) 0.0174 (0.0174)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5398 (0.5398)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:56:25.631155
Epoch: [44][0/20], lr: 0.00001	Time 3.113 (3.113)	Data 1.927 (1.927)	Loss 0.0571 (0.0571)	Loss CE 0.0004 (0.0004)	Loss KD (Logit) 0.0174 (0.0174)	Loss KD (GCAM) 0.0071 (0.0071)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5331 (0.5331)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:56:43.526434
Epoch: [45][0/20], lr: 0.00001	Time 3.391 (3.391)	Data 2.406 (2.406)	Loss 0.0781 (0.0781)	Loss CE 0.0145 (0.0145)	Loss KD (Logit) 0.0171 (0.0171)	Loss KD (GCAM) 0.0072 (0.0072)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6025 (0.6025)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:57:01.566045
Epoch: [46][0/20], lr: 0.00001	Time 3.234 (3.234)	Data 2.144 (2.144)	Loss 0.0568 (0.0568)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0172 (0.0172)	Loss KD (GCAM) 0.0074 (0.0074)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5283 (0.5283)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:57:19.345553
Epoch: [47][0/20], lr: 0.00001	Time 3.241 (3.241)	Data 1.953 (1.953)	Loss 0.0542 (0.0542)	Loss CE 0.0005 (0.0005)	Loss KD (Logit) 0.0177 (0.0177)	Loss KD (GCAM) 0.0068 (0.0068)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5047 (0.5047)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:57:37.248044
Epoch: [48][0/20], lr: 0.00001	Time 3.283 (3.283)	Data 2.475 (2.475)	Loss 0.0562 (0.0562)	Loss CE 0.0026 (0.0026)	Loss KD (Logit) 0.0178 (0.0178)	Loss KD (GCAM) 0.0073 (0.0073)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5012 (0.5012)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9499], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
2022-03-24 10:57:55.230765
Epoch: [49][0/20], lr: 0.00001	Time 3.221 (3.221)	Data 2.221 (2.221)	Loss 0.0607 (0.0607)	Loss CE 0.0002 (0.0002)	Loss KD (Logit) 0.0179 (0.0179)	Loss KD (GCAM) 0.0069 (0.0069)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5726 (0.5726)	Loss REG 0.0000 (0.0000)	Prec@1 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9499], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1055], device='cuda:0', requires_grad=True)
Update Importance Mask...
Phase 3 : Manage Exemplar Sets
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Construct Exemplar Set
Load the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([3.9499]), eta=tensor([3.1055])
  (fc1): CosineLinear(input_features=512, output_features=297, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
Exemplar per class : 5
video number : 160
video number + exemplar : 160
Phase 4 : Class-balanced Fine-Tuning
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Model
SplitCosineLinear(
  input_features=512, output_features=303, sigma=tensor([3.9499]), eta=tensor([3.1055])
  (fc1): CosineLinear(input_features=512, output_features=297, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
exemplar : 505
DataLoader CBF Constructed : Train 15
Optimizer Constructed
2022-03-24 10:58:29.095972
Epoch: [0][0/15], lr: 0.00050	Time 3.076 (3.076)	Data 1.861 (1.861)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9498], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1054], device='cuda:0', requires_grad=True)
2022-03-24 10:58:40.010282
Epoch: [1][0/15], lr: 0.00050	Time 3.020 (3.020)	Data 2.245 (2.245)	Loss 0.0044 (0.0044)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9480], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1042], device='cuda:0', requires_grad=True)
2022-03-24 10:58:51.354104
Epoch: [2][0/15], lr: 0.00050	Time 3.097 (3.097)	Data 2.017 (2.017)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9478], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1038], device='cuda:0', requires_grad=True)
2022-03-24 10:59:02.653434
Epoch: [3][0/15], lr: 0.00050	Time 3.164 (3.164)	Data 2.048 (2.048)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9481], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1038], device='cuda:0', requires_grad=True)
2022-03-24 10:59:13.784104
Epoch: [4][0/15], lr: 0.00050	Time 3.082 (3.082)	Data 2.056 (2.056)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9482], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1037], device='cuda:0', requires_grad=True)
2022-03-24 10:59:24.978398
Epoch: [5][0/15], lr: 0.00050	Time 3.235 (3.235)	Data 2.059 (2.059)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9478], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1034], device='cuda:0', requires_grad=True)
2022-03-24 10:59:36.486405
Epoch: [6][0/15], lr: 0.00050	Time 3.130 (3.130)	Data 2.228 (2.228)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9484], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1036], device='cuda:0', requires_grad=True)
2022-03-24 10:59:47.730708
Epoch: [7][0/15], lr: 0.00050	Time 2.865 (2.865)	Data 1.950 (1.950)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9489], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1038], device='cuda:0', requires_grad=True)
2022-03-24 10:59:59.097766
Epoch: [8][0/15], lr: 0.00050	Time 3.027 (3.027)	Data 2.479 (2.479)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9492], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1039], device='cuda:0', requires_grad=True)
2022-03-24 11:00:10.245166
Epoch: [9][0/15], lr: 0.00050	Time 3.154 (3.154)	Data 2.090 (2.090)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9496], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1040], device='cuda:0', requires_grad=True)
2022-03-24 11:00:22.039150
Epoch: [10][0/15], lr: 0.00050	Time 3.071 (3.071)	Data 2.198 (2.198)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9494], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1037], device='cuda:0', requires_grad=True)
2022-03-24 11:00:33.223172
Epoch: [11][0/15], lr: 0.00050	Time 2.904 (2.904)	Data 2.066 (2.066)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9490], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1034], device='cuda:0', requires_grad=True)
2022-03-24 11:00:44.558861
Epoch: [12][0/15], lr: 0.00050	Time 3.181 (3.181)	Data 1.947 (1.947)	Loss 0.0050 (0.0050)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9475], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1024], device='cuda:0', requires_grad=True)
2022-03-24 11:00:55.956445
Epoch: [13][0/15], lr: 0.00050	Time 3.303 (3.303)	Data 2.175 (2.175)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9463], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1015], device='cuda:0', requires_grad=True)
2022-03-24 11:01:07.431172
Epoch: [14][0/15], lr: 0.00050	Time 3.125 (3.125)	Data 2.096 (2.096)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9457], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1009], device='cuda:0', requires_grad=True)
2022-03-24 11:01:19.172913
Epoch: [15][0/15], lr: 0.00050	Time 3.319 (3.319)	Data 2.450 (2.450)	Loss 0.0058 (0.0058)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9465], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1011], device='cuda:0', requires_grad=True)
2022-03-24 11:01:30.793155
Epoch: [16][0/15], lr: 0.00050	Time 3.289 (3.289)	Data 2.404 (2.404)	Loss 0.0076 (0.0076)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9472], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1013], device='cuda:0', requires_grad=True)
2022-03-24 11:01:41.892943
Epoch: [17][0/15], lr: 0.00050	Time 2.882 (2.882)	Data 2.241 (2.241)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9476], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1014], device='cuda:0', requires_grad=True)
2022-03-24 11:01:53.303181
Epoch: [18][0/15], lr: 0.00050	Time 3.085 (3.085)	Data 2.436 (2.436)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9475], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1011], device='cuda:0', requires_grad=True)
2022-03-24 11:02:04.463042
Epoch: [19][0/15], lr: 0.00050	Time 3.134 (3.134)	Data 2.342 (2.342)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Sigma : Parameter containing:
tensor([3.9472], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([3.1007], device='cuda:0', requires_grad=True)
Phase 5 : Eval RGB Model for the Tasks Trained so far
=> base model: resnet34
----------------------resnet34 pretraining----------------------
------------------------------success---------------------------
Load the Trained Model from checkpoint/ucf101/51/2/007/task_025.pth.tar
exemplar : 505
Computing the class mean vectors...
Eval Task 0 for Age 25
Current Task : [90, 2, 46, 4, 78, 8, 32, 22, 13, 60, 47, 80, 75, 74, 82, 56, 51, 30, 6, 35, 92, 28, 37, 84, 3, 23, 59, 98, 61, 34, 68, 97, 45, 58, 31, 76, 72, 55, 81, 20, 43, 73, 77, 39, 69, 65, 9, 95, 27, 100, 67]
video number : 1920
video number + exemplar : 1920
DataLoader Constructed
Test: [0/120]	Time 5.253 (5.253)	Prec@1 50.000 (50.000)
Test: [100/120]	Time 0.486 (0.559)	Prec@1 68.750 (58.106)
Testing Results: Prec@1 58.333
Classify using the NME Classifier...
Test (NME): [0/120]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Test (NME): [100/120]	Time 0.000 (0.000)	Prec@1 75.000 (63.614)
Testing Results (NME): Prec@1 63.958
Eval Task 1 for Age 25
Current Task : [17, 71]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 3.894 (3.894)	Prec@1 25.000 (25.000)
Testing Results: Prec@1 41.791
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 52.239
Eval Task 2 for Age 25
Current Task : [96, 64]
video number : 79
video number + exemplar : 79
DataLoader Constructed
Test: [0/5]	Time 3.829 (3.829)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 73.418
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 77.215
Eval Task 3 for Age 25
Current Task : [11, 53]
video number : 85
video number + exemplar : 85
DataLoader Constructed
Test: [0/6]	Time 3.656 (3.656)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 81.176
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 81.176
Eval Task 4 for Age 25
Current Task : [89, 42]
video number : 73
video number + exemplar : 73
DataLoader Constructed
Test: [0/5]	Time 3.951 (3.951)	Prec@1 68.750 (68.750)
Testing Results: Prec@1 57.534
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 58.904
Eval Task 5 for Age 25
Current Task : [40, 15]
video number : 78
video number + exemplar : 78
DataLoader Constructed
Test: [0/5]	Time 4.223 (4.223)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 84.615
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 84.615
Eval Task 6 for Age 25
Current Task : [83, 18]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.051 (4.051)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 49.254
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 43.750 (43.750)
Testing Results (NME): Prec@1 47.761
Eval Task 7 for Age 25
Current Task : [99, 19]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 4.252 (4.252)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 54.321
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 54.321
Eval Task 8 for Age 25
Current Task : [36, 10]
video number : 66
video number + exemplar : 66
DataLoader Constructed
Test: [0/5]	Time 3.938 (3.938)	Prec@1 56.250 (56.250)
Testing Results: Prec@1 60.606
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 56.250 (56.250)
Testing Results (NME): Prec@1 63.636
Eval Task 9 for Age 25
Current Task : [25, 93]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.994 (3.994)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 80.519
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 87.013
Eval Task 10 for Age 25
Current Task : [41, 87]
video number : 82
video number + exemplar : 82
DataLoader Constructed
Test: [0/6]	Time 3.480 (3.480)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 92.683
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 100.000 (100.000)
Testing Results (NME): Prec@1 92.683
Eval Task 11 for Age 25
Current Task : [14, 38]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.900 (3.900)	Prec@1 43.750 (43.750)
Testing Results: Prec@1 43.662
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 42.254
Eval Task 12 for Age 25
Current Task : [79, 5]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.079 (4.079)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 56.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 75.000 (75.000)
Testing Results (NME): Prec@1 60.000
Eval Task 13 for Age 25
Current Task : [52, 54]
video number : 67
video number + exemplar : 67
DataLoader Constructed
Test: [0/5]	Time 4.250 (4.250)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 71.642
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 74.627
Eval Task 14 for Age 25
Current Task : [50, 16]
video number : 88
video number + exemplar : 88
DataLoader Constructed
Test: [0/6]	Time 4.352 (4.352)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 42.045
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 42.045
Eval Task 15 for Age 25
Current Task : [49, 63]
video number : 62
video number + exemplar : 62
DataLoader Constructed
Test: [0/4]	Time 3.798 (3.798)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 82.258
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 90.323
Eval Task 16 for Age 25
Current Task : [48, 66]
video number : 64
video number + exemplar : 64
DataLoader Constructed
Test: [0/4]	Time 3.626 (3.626)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 68.750
Classify using the NME Classifier...
Test (NME): [0/4]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 71.875
Eval Task 17 for Age 25
Current Task : [26, 1]
video number : 77
video number + exemplar : 77
DataLoader Constructed
Test: [0/5]	Time 3.358 (3.358)	Prec@1 87.500 (87.500)
Testing Results: Prec@1 83.117
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 74.026
Eval Task 18 for Age 25
Current Task : [7, 33]
video number : 68
video number + exemplar : 68
DataLoader Constructed
Test: [0/5]	Time 4.098 (4.098)	Prec@1 37.500 (37.500)
Testing Results: Prec@1 55.882
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 37.500 (37.500)
Testing Results (NME): Prec@1 45.588
Eval Task 19 for Age 25
Current Task : [88, 70]
video number : 81
video number + exemplar : 81
DataLoader Constructed
Test: [0/6]	Time 3.477 (3.477)	Prec@1 62.500 (62.500)
Testing Results: Prec@1 62.963
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 64.198
Eval Task 20 for Age 25
Current Task : [12, 24]
video number : 71
video number + exemplar : 71
DataLoader Constructed
Test: [0/5]	Time 3.965 (3.965)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 53.521
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 64.789
Eval Task 21 for Age 25
Current Task : [21, 29]
video number : 75
video number + exemplar : 75
DataLoader Constructed
Test: [0/5]	Time 4.140 (4.140)	Prec@1 75.000 (75.000)
Testing Results: Prec@1 76.000
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 87.500 (87.500)
Testing Results (NME): Prec@1 82.667
Eval Task 22 for Age 25
Current Task : [91, 62]
video number : 92
video number + exemplar : 92
DataLoader Constructed
Test: [0/6]	Time 3.668 (3.668)	Prec@1 81.250 (81.250)
Testing Results: Prec@1 75.000
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 68.750 (68.750)
Testing Results (NME): Prec@1 59.783
Eval Task 23 for Age 25
Current Task : [44, 86]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 4.093 (4.093)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 81.538
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 62.500 (62.500)
Testing Results (NME): Prec@1 69.231
Eval Task 24 for Age 25
Current Task : [94, 0]
video number : 87
video number + exemplar : 87
DataLoader Constructed
Test: [0/6]	Time 4.215 (4.215)	Prec@1 93.750 (93.750)
Testing Results: Prec@1 89.655
Classify using the NME Classifier...
Test (NME): [0/6]	Time 0.000 (0.000)	Prec@1 81.250 (81.250)
Testing Results (NME): Prec@1 79.310
Eval Task 25 for Age 25
Current Task : [57, 85]
video number : 65
video number + exemplar : 65
DataLoader Constructed
Test: [0/5]	Time 3.489 (3.489)	Prec@1 100.000 (100.000)
Testing Results: Prec@1 90.769
Classify using the NME Classifier...
Test (NME): [0/5]	Time 0.000 (0.000)	Prec@1 93.750 (93.750)
Testing Results (NME): Prec@1 80.000
num_test_videos [1920, 67, 79, 85, 73, 78, 67, 81, 66, 77, 82, 71, 75, 67, 88, 62, 64, 77, 68, 81, 71, 75, 92, 65, 87, 65]
n_vids [1920   67   79   85   73   78   67   81   66   77   82   71   75   67
   88   62   64   77   68   81   71   75   92   65   87   65]
n_vids_pad [[1920.]
 [  67.]
 [  79.]
 [  85.]
 [  73.]
 [  78.]
 [  67.]
 [  81.]
 [  66.]
 [  77.]
 [  82.]
 [  71.]
 [  75.]
 [  67.]
 [  88.]
 [  62.]
 [  64.]
 [  77.]
 [  68.]
 [  81.]
 [  71.]
 [  75.]
 [  92.]
 [  65.]
 [  87.]
 [  65.]]
tmp [[158300.         149400.         141800.         143300.
  134400.         135500.         131900.         129600.
  128200.         130100.         128100.         122500.
  122700.         120900.         122000.         122100.
  118700.         116300.         115600.         113000.
  110900.         118500.         113500.         111700.
  118300.         112000.        ]
 [-13400.           5900.           5600.           5900.
    4400.           4600.           4400.           2799.99999237
    3300.           4800.           4400.           3299.99999237
    3600.           1999.99999237   2199.99999237   3299.99999237
    2699.99999237   2599.99999237   2499.99999237   3499.99999237
    1599.99999237   2499.99999237   2799.99999237   2299.99999237
    2799.99999237   2800.        ]
 [-15800.         -15800.           7900.           7699.99992371
    7399.99992371   7199.99992371   6799.99996185   6999.99996185
    6999.99992371   6799.99996185   6699.99996185   6999.99992371
    6599.99996185   6499.99996185   6599.99996185   6200.
    6500.           6799.99992371   5999.99992371   6299.99996185
    6699.99996185   6699.99996185   5399.99996185   5299.99992371
    5999.99996185   5799.99996185]
 [-17000.         -17000.         -17000.           8400.
    8200.           7800.           7700.           7500.
    6700.           7000.           7000.           6500.
    6900.           6900.           7400.           7400.
    7200.           7000.           6700.           7300.
    6500.           6600.           6700.           7200.
    7100.           6900.        ]
 [-14600.         -14600.         -14600.         -14600.
    7099.99996948   6499.99993896   5899.99997711   5999.99996948
    5799.99997711   5699.99993896   5899.99996948   5199.99997711
    5199.99997711   5099.99996948   5099.99997711   5499.99996948
    5499.99996948   5199.99993896   4999.99997711   4999.99997711
    4899.99997711   5199.99993896   5399.99997711   4899.99997711
    5299.99997711   4199.99998093]
 [-15600.         -15600.         -15600.         -15600.
  -15600.           7700.           7500.           7500.
    7400.           7400.           6899.99995422   6900.
    6799.99995422   6599.99995422   6699.99995422   6899.99995422
    7100.           6900.           6699.99996948   6499.99996948
    6899.99995422   6799.99995422   6200.00003052   6999.99995422
    6799.99995422   6600.00001526]
 [-13400.         -13400.         -13400.         -13400.
  -13400.         -13400.           6600.           6400.
    3799.99999237   3999.99999237   4599.99999237   3599.99999237
    3299.99999237   4699.99999237   3199.99999237   3799.99999237
    4199.99999237   5099.99999237   3899.99999237   3999.99999237
    3699.99999237   3599.99999237   2799.99999237   2999.99999237
    3199.99999237   3299.99999237]
 [-16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.           8000.
    7200.           7200.           7200.           7400.
    7400.           7300.           7300.           7800.
    7400.           5400.           4400.           4700.
    4600.           5300.           5200.           5400.
    4500.           4400.        ]
 [-13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
    6400.           6100.           5300.           4800.
    4400.           4500.           4300.           4400.
    4100.           4100.           3600.           3900.
    4100.           3900.           4100.           4300.
    3700.           4000.        ]
 [-15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.           7399.99993134   6999.99994659   6899.99994659
    6599.99994659   6699.99994659   6599.99996185   6599.99996185
    6699.99994659   6599.99996185   6299.99996185   5599.99997711
    5799.99996185   6199.99994659   5999.99996185   6499.99994659
    6199.99994659   6199.99994659]
 [-16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.           8100.           8000.
    7800.           8100.           7900.           7900.
    7400.           7500.           7600.           7600.
    7300.           7500.           7500.           7600.
    7300.           7600.        ]
 [-14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.           6500.
    6100.           3800.00001526   2699.99999809   4099.99999619
    3799.99999619   2999.99999809   2399.99999809   3599.99999619
    2400.00000381   2899.99999809   2199.99999809   3600.00000381
    2799.99999809   3099.99999809]
 [-15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
    7099.99996948   4199.99999619   4299.99999619   5199.99999619
    6000.00000381   5500.00000381   5200.00000381   4700.00001526
    5600.00000381   5500.00000381   5400.00000381   5599.99999237
    4699.99998474   4199.99998474]
 [-13400.         -13400.         -13400.         -13400.
  -13400.         -13400.         -13400.         -13400.
  -13400.         -13400.         -13400.         -13400.
  -13400.           6700.           6099.99999237   5799.99999237
    5399.99999237   5699.99999237   5499.99999619   6099.99999237
    5199.99999237   4499.99999619   5399.99999237   5199.99999619
    5399.99999619   4799.99999619]
 [-17600.         -17600.         -17600.         -17600.
  -17600.         -17600.         -17600.         -17600.
  -17600.         -17600.         -17600.         -17600.
  -17600.         -17600.           8500.           7800.
    7400.           7400.           5400.           6500.
    3800.           4200.           3700.           3300.
    5300.           3700.        ]
 [-12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.           6200.
    5699.99995422   5799.99995422   3600.00001526   5000.
    4600.           4600.00001526   4400.00001526   5700.
    5000.           5100.        ]
 [-12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
    6200.           5600.           5400.           5200.
    4900.           4800.           4300.           4500.
    5000.           4400.        ]
 [-15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.           7400.           7500.00001526   7400.
    6799.99993134   6700.00001526   6499.99993134   6800.00001526
    6700.00001526   6399.99993134]
 [-13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.           6700.           6100.
    3500.           4200.           3000.           3100.
    2100.           3800.        ]
 [-16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.           7700.
    7200.           6400.           6200.           6800.
    7400.           5100.        ]
 [-14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
    5900.00000763   5100.00000763   5200.00001526   5000.00001526
    4600.00001526   3799.99999619]
 [-15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.           7500.           6900.           5699.99999237
    5699.99999237   5699.99999237]
 [-18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.           8900.           6999.99993896
    7200.           6899.99996948]
 [-13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.           5600.
    5600.           5300.        ]
 [-17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
    7800.00000763   7800.00001526]
 [-13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.           5900.        ]]
tmp [[ 8.90000000e+03  7.60000000e+03 -1.50000000e+03  8.90000000e+03
  -1.10000000e+03  3.60000000e+03  2.30000000e+03  1.40000000e+03
  -1.90000000e+03  2.00000000e+03  5.60000000e+03 -2.00000000e+02
   1.80000000e+03 -1.10000000e+03 -1.00000000e+02  3.40000000e+03
   2.40000000e+03  7.00000000e+02  2.60000000e+03  2.10000000e+03
  -7.60000000e+03  5.00000000e+03  1.80000000e+03 -6.60000000e+03
   6.30000000e+03]
 [-1.93000000e+04  3.00000000e+02 -3.00000000e+02  1.50000000e+03
  -2.00000000e+02  2.00000000e+02  1.60000001e+03 -5.00000008e+02
  -1.50000000e+03  4.00000000e+02  1.10000001e+03 -3.00000008e+02
   1.60000001e+03 -2.00000000e+02 -1.10000000e+03  6.00000000e+02
   1.00000000e+02  1.00000000e+02 -1.00000000e+03  1.90000000e+03
  -9.00000000e+02 -3.00000000e+02  5.00000000e+02 -5.00000000e+02
  -7.62939453e-06]
 [-0.00000000e+00 -2.37000000e+04  2.00000076e+02  3.00000000e+02
   2.00000000e+02  3.99999962e+02 -2.00000000e+02  3.81469736e-05
   1.99999962e+02  1.00000000e+02 -2.99999962e+02  3.99999962e+02
   1.00000000e+02 -1.00000000e+02  3.99999962e+02 -3.00000000e+02
  -2.99999924e+02  8.00000000e+02 -3.00000038e+02 -4.00000000e+02
  -0.00000000e+00  1.30000000e+03  1.00000038e+02 -7.00000038e+02
   2.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -2.54000000e+04  2.00000000e+02
   4.00000000e+02  1.00000000e+02  2.00000000e+02  8.00000000e+02
  -3.00000000e+02 -0.00000000e+00  5.00000000e+02 -4.00000000e+02
  -0.00000000e+00 -5.00000000e+02 -0.00000000e+00  2.00000000e+02
   2.00000000e+02  3.00000000e+02 -6.00000000e+02  8.00000000e+02
  -1.00000000e+02 -1.00000000e+02 -5.00000000e+02  1.00000000e+02
   2.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.17000000e+04
   6.00000031e+02  5.99999962e+02 -9.99999924e+01  1.99999992e+02
   1.00000038e+02 -2.00000031e+02  6.99999992e+02 -0.00000000e+00
   1.00000008e+02 -7.62939362e-06 -3.99999992e+02 -0.00000000e+00
   3.00000031e+02  1.99999962e+02 -0.00000000e+00  1.00000000e+02
  -2.99999962e+02 -2.00000038e+02  5.00000000e+02 -4.00000000e+02
   1.10000000e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.33000000e+04  2.00000000e+02 -0.00000000e+00  1.00000000e+02
  -0.00000000e+00  5.00000046e+02 -4.57763672e-05  1.00000046e+02
   2.00000000e+02 -1.00000000e+02 -2.00000000e+02 -2.00000046e+02
   2.00000000e+02  2.00000031e+02  2.00000000e+02 -3.99999985e+02
   1.00000000e+02  5.99999924e+02 -7.99999924e+02  2.00000000e+02
   1.99999939e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.00000000e+04  2.00000000e+02  2.60000001e+03
  -2.00000000e+02 -6.00000000e+02  1.00000000e+03  3.00000000e+02
  -1.40000000e+03  1.50000000e+03 -6.00000000e+02 -4.00000000e+02
  -9.00000000e+02  1.20000000e+03 -1.00000000e+02  3.00000000e+02
   1.00000000e+02  8.00000000e+02 -2.00000000e+02 -2.00000000e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.42000000e+04  8.00000000e+02
  -0.00000000e+00 -0.00000000e+00 -2.00000000e+02 -0.00000000e+00
   1.00000000e+02 -0.00000000e+00 -5.00000000e+02  4.00000000e+02
   2.00000000e+03  1.00000000e+03 -3.00000000e+02  1.00000000e+02
  -7.00000000e+02  1.00000000e+02 -2.00000000e+02  9.00000000e+02
   1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.96000000e+04
   3.00000000e+02  8.00000000e+02  5.00000000e+02  4.00000000e+02
  -1.00000000e+02  2.00000000e+02 -1.00000000e+02  3.00000000e+02
  -0.00000000e+00  5.00000000e+02 -3.00000000e+02 -2.00000000e+02
   2.00000000e+02 -2.00000000e+02 -2.00000000e+02  6.00000000e+02
  -3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.27999999e+04  3.99999985e+02  1.00000000e+02  3.00000000e+02
  -1.00000000e+02  9.99999847e+01 -0.00000000e+00 -9.99999847e+01
   9.99999847e+01  3.00000000e+02  6.99999985e+02 -1.99999985e+02
  -3.99999985e+02  1.99999985e+02 -4.99999985e+02  3.00000000e+02
  -0.00000000e+00]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.45000000e+04  1.00000000e+02  2.00000000e+02
  -3.00000000e+02  2.00000000e+02 -0.00000000e+00  5.00000000e+02
  -1.00000000e+02 -1.00000000e+02 -0.00000000e+00  3.00000000e+02
  -2.00000000e+02 -0.00000000e+00 -1.00000000e+02  3.00000000e+02
  -3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.07000000e+04  4.00000000e+02
   2.29999998e+03  1.10000002e+03 -1.40000000e+03  3.00000000e+02
   7.99999998e+02  6.00000000e+02 -1.20000000e+03  1.19999999e+03
  -4.99999994e+02  7.00000000e+02 -1.40000001e+03  8.00000006e+02
  -3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.21000000e+04
   2.89999997e+03 -1.00000000e+02 -9.00000000e+02 -8.00000008e+02
   5.00000000e+02  3.00000000e+02  4.99999989e+02 -8.99999989e+02
   1.00000000e+02  1.00000000e+02 -1.99999989e+02  9.00000008e+02
   5.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.01000000e+04  6.00000008e+02  3.00000000e+02  4.00000000e+02
  -3.00000000e+02  1.99999996e+02 -5.99999996e+02  9.00000000e+02
   6.99999996e+02 -8.99999996e+02  1.99999996e+02 -2.00000000e+02
   6.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.61000000e+04  7.00000000e+02  4.00000000e+02
  -0.00000000e+00  2.00000000e+03 -1.10000000e+03  2.70000000e+03
  -4.00000000e+02  5.00000000e+02  4.00000000e+02 -2.00000000e+03
   1.60000000e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.86000000e+04  5.00000046e+02
  -1.00000000e+02  2.19999994e+03 -1.39999998e+03  4.00000000e+02
  -1.52587891e-05  2.00000000e+02 -1.29999998e+03  7.00000000e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.90000000e+04
   6.00000000e+02  2.00000000e+02  2.00000000e+02  3.00000000e+02
   1.00000000e+02  5.00000000e+02 -2.00000000e+02 -5.00000000e+02
   6.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.28000000e+04 -1.00000015e+02  1.00000015e+02  6.00000069e+02
   9.99999161e+01  2.00000084e+02 -3.00000084e+02  1.00000000e+02
   3.00000084e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.03000000e+04  6.00000000e+02  2.60000000e+03
  -7.00000000e+02  1.20000000e+03 -1.00000000e+02  1.00000000e+03
  -1.70000000e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.39000000e+04  5.00000000e+02
   8.00000000e+02  2.00000000e+02 -6.00000000e+02 -6.00000000e+02
   2.30000000e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.01000000e+04
   8.00000000e+02 -1.00000008e+02  2.00000000e+02  4.00000000e+02
   8.00000019e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.25000000e+04  6.00000000e+02  1.20000001e+03 -0.00000000e+00
  -0.00000000e+00]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.73000000e+04  1.90000006e+03 -2.00000061e+02
   3.00000031e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.86000000e+04 -0.00000000e+00
   3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.52000000e+04
  -7.62939453e-06]]
tmp [[ 8.90000000e+03  7.60000000e+03 -1.50000000e+03  8.90000000e+03
  -1.10000000e+03  3.60000000e+03  2.30000000e+03  1.40000000e+03
  -1.90000000e+03  2.00000000e+03  5.60000000e+03 -2.00000000e+02
   1.80000000e+03 -1.10000000e+03 -1.00000000e+02  3.40000000e+03
   2.40000000e+03  7.00000000e+02  2.60000000e+03  2.10000000e+03
  -7.60000000e+03  5.00000000e+03  1.80000000e+03 -6.60000000e+03
   6.30000000e+03]
 [ 0.00000000e+00  3.00000000e+02 -3.00000000e+02  1.50000000e+03
  -2.00000000e+02  2.00000000e+02  1.60000001e+03 -5.00000008e+02
  -1.50000000e+03  4.00000000e+02  1.10000001e+03 -3.00000008e+02
   1.60000001e+03 -2.00000000e+02 -1.10000000e+03  6.00000000e+02
   1.00000000e+02  1.00000000e+02 -1.00000000e+03  1.90000000e+03
  -9.00000000e+02 -3.00000000e+02  5.00000000e+02 -5.00000000e+02
  -7.62939453e-06]
 [ 0.00000000e+00  0.00000000e+00  2.00000076e+02  3.00000000e+02
   2.00000000e+02  3.99999962e+02 -2.00000000e+02  3.81469736e-05
   1.99999962e+02  1.00000000e+02 -2.99999962e+02  3.99999962e+02
   1.00000000e+02 -1.00000000e+02  3.99999962e+02 -3.00000000e+02
  -2.99999924e+02  8.00000000e+02 -3.00000038e+02 -4.00000000e+02
  -0.00000000e+00  1.30000000e+03  1.00000038e+02 -7.00000038e+02
   2.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.00000000e+02
   4.00000000e+02  1.00000000e+02  2.00000000e+02  8.00000000e+02
  -3.00000000e+02 -0.00000000e+00  5.00000000e+02 -4.00000000e+02
  -0.00000000e+00 -5.00000000e+02 -0.00000000e+00  2.00000000e+02
   2.00000000e+02  3.00000000e+02 -6.00000000e+02  8.00000000e+02
  -1.00000000e+02 -1.00000000e+02 -5.00000000e+02  1.00000000e+02
   2.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   6.00000031e+02  5.99999962e+02 -9.99999924e+01  1.99999992e+02
   1.00000038e+02 -2.00000031e+02  6.99999992e+02 -0.00000000e+00
   1.00000008e+02 -7.62939362e-06 -3.99999992e+02 -0.00000000e+00
   3.00000031e+02  1.99999962e+02 -0.00000000e+00  1.00000000e+02
  -2.99999962e+02 -2.00000038e+02  5.00000000e+02 -4.00000000e+02
   1.10000000e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  2.00000000e+02 -0.00000000e+00  1.00000000e+02
  -0.00000000e+00  5.00000046e+02 -4.57763672e-05  1.00000046e+02
   2.00000000e+02 -1.00000000e+02 -2.00000000e+02 -2.00000046e+02
   2.00000000e+02  2.00000031e+02  2.00000000e+02 -3.99999985e+02
   1.00000000e+02  5.99999924e+02 -7.99999924e+02  2.00000000e+02
   1.99999939e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  2.00000000e+02  2.60000001e+03
  -2.00000000e+02 -6.00000000e+02  1.00000000e+03  3.00000000e+02
  -1.40000000e+03  1.50000000e+03 -6.00000000e+02 -4.00000000e+02
  -9.00000000e+02  1.20000000e+03 -1.00000000e+02  3.00000000e+02
   1.00000000e+02  8.00000000e+02 -2.00000000e+02 -2.00000000e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  8.00000000e+02
  -0.00000000e+00 -0.00000000e+00 -2.00000000e+02 -0.00000000e+00
   1.00000000e+02 -0.00000000e+00 -5.00000000e+02  4.00000000e+02
   2.00000000e+03  1.00000000e+03 -3.00000000e+02  1.00000000e+02
  -7.00000000e+02  1.00000000e+02 -2.00000000e+02  9.00000000e+02
   1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   3.00000000e+02  8.00000000e+02  5.00000000e+02  4.00000000e+02
  -1.00000000e+02  2.00000000e+02 -1.00000000e+02  3.00000000e+02
  -0.00000000e+00  5.00000000e+02 -3.00000000e+02 -2.00000000e+02
   2.00000000e+02 -2.00000000e+02 -2.00000000e+02  6.00000000e+02
  -3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  3.99999985e+02  1.00000000e+02  3.00000000e+02
  -1.00000000e+02  9.99999847e+01 -0.00000000e+00 -9.99999847e+01
   9.99999847e+01  3.00000000e+02  6.99999985e+02 -1.99999985e+02
  -3.99999985e+02  1.99999985e+02 -4.99999985e+02  3.00000000e+02
  -0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  1.00000000e+02  2.00000000e+02
  -3.00000000e+02  2.00000000e+02 -0.00000000e+00  5.00000000e+02
  -1.00000000e+02 -1.00000000e+02 -0.00000000e+00  3.00000000e+02
  -2.00000000e+02 -0.00000000e+00 -1.00000000e+02  3.00000000e+02
  -3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  4.00000000e+02
   2.29999998e+03  1.10000002e+03 -1.40000000e+03  3.00000000e+02
   7.99999998e+02  6.00000000e+02 -1.20000000e+03  1.19999999e+03
  -4.99999994e+02  7.00000000e+02 -1.40000001e+03  8.00000006e+02
  -3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   2.89999997e+03 -1.00000000e+02 -9.00000000e+02 -8.00000008e+02
   5.00000000e+02  3.00000000e+02  4.99999989e+02 -8.99999989e+02
   1.00000000e+02  1.00000000e+02 -1.99999989e+02  9.00000008e+02
   5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  6.00000008e+02  3.00000000e+02  4.00000000e+02
  -3.00000000e+02  1.99999996e+02 -5.99999996e+02  9.00000000e+02
   6.99999996e+02 -8.99999996e+02  1.99999996e+02 -2.00000000e+02
   6.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  7.00000000e+02  4.00000000e+02
  -0.00000000e+00  2.00000000e+03 -1.10000000e+03  2.70000000e+03
  -4.00000000e+02  5.00000000e+02  4.00000000e+02 -2.00000000e+03
   1.60000000e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.00000046e+02
  -1.00000000e+02  2.19999994e+03 -1.39999998e+03  4.00000000e+02
  -1.52587891e-05  2.00000000e+02 -1.29999998e+03  7.00000000e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   6.00000000e+02  2.00000000e+02  2.00000000e+02  3.00000000e+02
   1.00000000e+02  5.00000000e+02 -2.00000000e+02 -5.00000000e+02
   6.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00 -1.00000015e+02  1.00000015e+02  6.00000069e+02
   9.99999161e+01  2.00000084e+02 -3.00000084e+02  1.00000000e+02
   3.00000084e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  6.00000000e+02  2.60000000e+03
  -7.00000000e+02  1.20000000e+03 -1.00000000e+02  1.00000000e+03
  -1.70000000e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.00000000e+02
   8.00000000e+02  2.00000000e+02 -6.00000000e+02 -6.00000000e+02
   2.30000000e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   8.00000000e+02 -1.00000008e+02  2.00000000e+02  4.00000000e+02
   8.00000019e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  6.00000000e+02  1.20000001e+03 -0.00000000e+00
  -0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  1.90000006e+03 -2.00000061e+02
   3.00000031e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00
   3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  -7.62939453e-06]]
tmp [ 8900.          7900.         -1599.99992371 10900.
   -99.99996948  5099.99992371  4000.00001526  5400.00003052
 -3300.          3400.          9099.99999237  1200.
  7199.9999733   1600.00000191 -3900.00002861  5200.00000763
  5500.00008965 10599.99991226 -2000.00002861 12700.000103
 -8800.00004387 10399.99995041   200.00013161 -5600.00008583
 12600.00005341]
cumsum_n_vids [1920 1987 2066 2151 2224 2302 2369 2450 2516 2593 2675 2746 2821 2888
 2976 3038 3102 3179 3247 3328 3399 3474 3566 3631 3718]
fgt [ 4.63541667  3.97584298 -0.77444333  5.06741051 -0.04496402  2.21546478
  1.68847616  2.20408165 -1.31160572  1.31122252  3.40186916  0.43699927
  2.55228641  0.55401662 -1.31048388  1.71165241  1.77304967  3.33438185
 -0.6159532   3.8161058  -2.58899678  2.99366723  0.05608529 -1.54227488
  3.38891879]
fgt 1.4771290380937783
fgt [1.47712904]
n_vids [1920   67   79   85   73   78   67   81   66   77   82   71   75   67
   88   62   64   77   68   81   71   75   92   65   87   65]
n_vids_pad [[1920.]
 [  67.]
 [  79.]
 [  85.]
 [  73.]
 [  78.]
 [  67.]
 [  81.]
 [  66.]
 [  77.]
 [  82.]
 [  71.]
 [  75.]
 [  67.]
 [  88.]
 [  62.]
 [  64.]
 [  77.]
 [  68.]
 [  81.]
 [  71.]
 [  75.]
 [  92.]
 [  65.]
 [  87.]
 [  65.]]
tmp [[153800.         152300.         148100.         149100.
  138900.         145500.         141500.         138500.
  138000.         135400.         136900.         137100.
  135100.         132200.         133500.         135300.
  130600.         130600.         128600.         126500.
  123800.         127600.         129000.         126100.
  126000.         122800.        ]
 [-13400.           5200.           5000.           5400.
    4000.           4500.           4700.           4000.
    3400.           4200.           4100.           3700.
    4000.           3399.99999237   3499.99999237   4099.99999237
    2799.99999237   2399.99999237   3399.99999237   3199.99999237
    3299.99999237   3299.99999237   3499.99999237   2999.99999237
    3600.           3499.99999237]
 [-15800.         -15800.           7499.99992371   6199.99992371
    5899.99992371   6199.99996185   6599.99996185   6099.99992371
    5800.           6000.           6200.           6099.99996185
    6199.99996185   6000.           5899.99992371   6000.
    6000.           6100.           5600.           5500.
    5399.99992371   6000.           5799.99996185   5800.
    5500.           6100.        ]
 [-17000.         -17000.         -17000.           7500.
    7700.           7300.           7300.           7400.
    7200.           7200.           7000.           7100.
    7100.           7300.           7000.           7200.
    7000.           7000.           7000.           7100.
    6700.           6900.           6700.           7100.
    7200.           6900.        ]
 [-14600.         -14600.         -14600.         -14600.
    6099.99996948   6099.99996948   5399.99993896   5599.99993896
    5199.99993896   4799.99996948   5299.99996948   4699.99993896
    4399.99993896   4699.99993896   4699.99996948   4499.99996948
    4099.99993896   4399.99993896   4099.99997711   4499.99997711
    4499.99998093   4499.99996948   4299.99993896   4799.99996948
    4399.99997711   4299.99997711]
 [-15600.         -15600.         -15600.         -15600.
  -15600.           7000.           6999.99995422   6899.99995422
    6899.99995422   6899.99995422   6600.00001526   6600.00001526
    6700.00001526   6799.99995422   6999.99995422   6999.99995422
    6899.99995422   6799.99995422   6500.00001526   6400.00001526
    6499.99996948   6600.00001526   6699.99995422   6699.99995422
    6799.99995422   6600.00001526]
 [-13400.         -13400.         -13400.         -13400.
  -13400.         -13400.           6000.           5700.
    4899.99999237   4599.99999237   4099.99999237   3199.99999237
    3699.99999237   4099.99999237   4199.99999237   3799.99999237
    3599.99999619   4599.99999237   3599.99999237   3799.99999237
    3299.99999237   3299.99999237   3199.99999237   2999.99999237
    2999.99999237   3199.99999237]
 [-16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.           7500.
    7400.           7300.           7200.           6900.
    6700.           7000.           6900.           7200.
    7700.           4900.           3900.           4500.
    4900.           5300.           5000.           4700.
    4700.           4400.        ]
 [-13200.         -13200.         -13200.         -13200.
  -13200.         -13200.         -13200.         -13200.
    5300.           5200.           4600.           4200.
    4100.           4200.           4100.           4100.
    4100.           3800.           4000.           4100.
    3900.           3600.           3800.           3800.
    4000.           4200.        ]
 [-15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.           6699.99994659   6700.           6899.99994659
    6599.99994659   6599.99996185   6499.99996185   6399.99996185
    6299.99996185   6299.99996185   6099.99996185   5399.99996185
    5599.99996185   6199.99994659   5799.99996185   6399.99993134
    6399.99996185   6700.00001526]
 [-16400.         -16400.         -16400.         -16400.
  -16400.         -16400.         -16400.         -16400.
  -16400.         -16400.           7800.           7400.
    7700.           8000.           7700.           7600.
    7600.           7400.           7500.           7500.
    7600.           7600.           7400.           7600.
    7400.           7600.        ]
 [-14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.           5500.00000763
    5900.           5100.00000763   4199.99999619   4199.99999619
    4500.00000381   3899.99999619   3699.99999619   4200.00001526
    2600.00000381   4200.00001526   3599.99999619   3999.99999619
    3300.00000381   2999.99999809]
 [-15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
    6799.99996948   5400.00001526   5500.00001526   5399.99998474
    5700.00000381   5500.00001526   5300.00000381   5200.00001526
    5100.00000381   5500.00000381   5600.00000381   5700.00000381
    5600.00000381   4499.99998474]
 [-13400.         -13400.         -13400.         -13400.
  -13400.         -13400.         -13400.         -13400.
  -13400.         -13400.         -13400.         -13400.
  -13400.           5699.99999619   5400.           5200.
    4800.           5000.           5100.           5100.
    5000.           4700.           5200.           5300.
    5000.           5000.        ]
 [-17600.         -17600.         -17600.         -17600.
  -17600.         -17600.         -17600.         -17600.
  -17600.         -17600.         -17600.         -17600.
  -17600.         -17600.           7100.           6900.
    5500.           5700.           6100.           6500.
    5400.           5400.           5500.           5100.
    5000.           3700.        ]
 [-12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.         -12400.
  -12400.         -12400.         -12400.           6100.
    5900.           5599.99995422   4999.99995422   5100.
    4100.00001526   5099.99995422   4899.99995422   5099.99995422
    5500.           5600.        ]
 [-12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
  -12800.         -12800.         -12800.         -12800.
    5000.           4700.           4800.           4300.
    4400.           4200.           4200.           3900.
    4600.           4600.        ]
 [-15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.         -15400.         -15400.         -15400.
  -15400.           6600.00001526   6499.99993134   6399.99994659
    5999.99994659   5799.99994659   5899.99994659   5899.99994659
    5599.99996185   5699.99994659]
 [-13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.         -13600.         -13600.
  -13600.         -13600.           5800.           5600.
    3600.           4000.           4000.           4000.
    3100.           3100.        ]
 [-16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.         -16200.
  -16200.         -16200.         -16200.           6900.
    6400.           6000.           5600.           6000.
    5800.           5200.        ]
 [-14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
  -14200.         -14200.         -14200.         -14200.
    5900.           5200.           5400.           4900.
    5100.00000763   4600.00000763]
 [-15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.         -15000.         -15000.         -15000.
  -15000.           6899.99999237   6599.99999237   6199.99999237
    5900.00001526   6199.99999237]
 [-18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.         -18400.         -18400.
  -18400.         -18400.           5499.99998474   4899.99998474
    5299.99998474   5500.        ]
 [-13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.           4800.
    4800.           4500.        ]
 [-17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
  -17400.         -17400.         -17400.         -17400.
    7300.00000763   6900.00001526]
 [-13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.         -13000.         -13000.         -13000.
  -13000.           5200.        ]]
tmp [[ 1.50000000e+03  4.20000000e+03 -1.00000000e+03  1.02000000e+04
  -6.60000000e+03  4.00000000e+03  3.00000000e+03  5.00000000e+02
   2.60000000e+03 -1.50000000e+03 -2.00000000e+02  2.00000000e+03
   2.90000000e+03 -1.30000000e+03 -1.80000000e+03  4.70000000e+03
  -0.00000000e+00  2.00000000e+03  2.10000000e+03  2.70000000e+03
  -3.80000000e+03 -1.40000000e+03  2.90000000e+03  1.00000000e+02
   3.20000000e+03]
 [-1.86000000e+04  2.00000000e+02 -4.00000000e+02  1.40000000e+03
  -5.00000000e+02 -2.00000000e+02  7.00000000e+02  6.00000000e+02
  -8.00000000e+02  1.00000000e+02  4.00000000e+02 -3.00000000e+02
   6.00000008e+02 -1.00000000e+02 -6.00000000e+02  1.30000000e+03
   4.00000000e+02 -1.00000000e+03  2.00000000e+02 -1.00000000e+02
  -0.00000000e+00 -2.00000000e+02  5.00000000e+02 -6.00000008e+02
   1.00000008e+02]
 [-0.00000000e+00 -2.32999999e+04  1.30000000e+03  3.00000000e+02
  -3.00000038e+02 -4.00000000e+02  5.00000038e+02  2.99999924e+02
  -2.00000000e+02 -2.00000000e+02  1.00000038e+02 -1.00000000e+02
   1.99999962e+02  1.00000076e+02 -1.00000076e+02 -0.00000000e+00
  -1.00000000e+02  5.00000000e+02  1.00000000e+02  1.00000076e+02
  -6.00000076e+02  2.00000038e+02 -3.81469717e-05  3.00000000e+02
  -6.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -2.45000000e+04 -2.00000000e+02
   4.00000000e+02 -0.00000000e+00 -1.00000000e+02  2.00000000e+02
  -0.00000000e+00  2.00000000e+02 -1.00000000e+02 -0.00000000e+00
  -2.00000000e+02  3.00000000e+02 -2.00000000e+02  2.00000000e+02
  -0.00000000e+00 -0.00000000e+00 -1.00000000e+02  4.00000000e+02
  -2.00000000e+02  2.00000000e+02 -4.00000000e+02 -1.00000000e+02
   3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.07000000e+04
  -0.00000000e+00  7.00000031e+02 -2.00000000e+02  4.00000000e+02
   3.99999969e+02 -5.00000000e+02  6.00000031e+02  3.00000000e+02
  -3.00000000e+02 -3.05175790e-05  2.00000000e+02  4.00000031e+02
  -3.00000000e+02  2.99999962e+02 -4.00000000e+02 -3.81469727e-06
   1.14440918e-05  2.00000031e+02 -5.00000031e+02  3.99999992e+02
   1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.26000000e+04  4.57763663e-05  1.00000000e+02 -0.00000000e+00
  -0.00000000e+00  2.99999939e+02 -0.00000000e+00 -1.00000000e+02
  -9.99999390e+01 -2.00000000e+02 -0.00000000e+00  1.00000000e+02
   1.00000000e+02  2.99999939e+02  1.00000000e+02 -9.99999542e+01
  -1.00000046e+02 -9.99999390e+01 -0.00000000e+00 -1.00000000e+02
   1.99999939e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -1.94000000e+04  3.00000000e+02  8.00000008e+02
   3.00000000e+02  5.00000000e+02  9.00000000e+02 -5.00000000e+02
  -4.00000000e+02 -1.00000000e+02  4.00000000e+02  1.99999996e+02
  -9.99999996e+02  1.00000000e+03 -2.00000000e+02  5.00000000e+02
  -0.00000000e+00  1.00000000e+02  2.00000000e+02 -0.00000000e+00
  -2.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.37000000e+04  1.00000000e+02
   1.00000000e+02  1.00000000e+02  3.00000000e+02  2.00000000e+02
  -3.00000000e+02  1.00000000e+02 -3.00000000e+02 -5.00000000e+02
   2.80000000e+03  1.00000000e+03 -6.00000000e+02 -4.00000000e+02
  -4.00000000e+02  3.00000000e+02  3.00000000e+02 -0.00000000e+00
   3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.85000000e+04
   1.00000000e+02  6.00000000e+02  4.00000000e+02  1.00000000e+02
  -1.00000000e+02  1.00000000e+02 -0.00000000e+00 -0.00000000e+00
   3.00000000e+02 -2.00000000e+02 -1.00000000e+02  2.00000000e+02
   3.00000000e+02 -2.00000000e+02 -0.00000000e+00 -2.00000000e+02
  -2.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.20999999e+04 -5.34057608e-05 -1.99999947e+02  3.00000000e+02
  -1.52587891e-05  1.00000000e+02  1.00000000e+02  1.00000000e+02
  -0.00000000e+00  2.00000000e+02  7.00000000e+02 -2.00000000e+02
  -5.99999985e+02  3.99999985e+02 -5.99999969e+02 -3.05175799e-05
  -3.00000053e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.42000000e+04  4.00000000e+02 -3.00000000e+02
  -3.00000000e+02  3.00000000e+02  1.00000000e+02 -0.00000000e+00
   2.00000000e+02 -1.00000000e+02 -0.00000000e+00 -1.00000000e+02
  -0.00000000e+00  2.00000000e+02 -2.00000000e+02  2.00000000e+02
  -2.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.97000000e+04 -3.99999992e+02
   7.99999992e+02  9.00000011e+02 -0.00000000e+00 -3.00000008e+02
   6.00000008e+02  2.00000000e+02 -5.00000019e+02  1.60000001e+03
  -1.60000001e+03  6.00000019e+02 -4.00000000e+02  6.99999992e+02
   3.00000006e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.18000000e+04
   1.39999995e+03 -1.00000000e+02  1.00000031e+02 -3.00000019e+02
   1.99999989e+02  2.00000011e+02  9.99999886e+01  1.00000011e+02
  -4.00000000e+02 -1.00000000e+02 -1.00000000e+02  1.00000000e+02
   1.10000002e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -1.91000000e+04  2.99999996e+02  2.00000000e+02  4.00000000e+02
  -2.00000000e+02 -1.00000000e+02 -0.00000000e+00  1.00000000e+02
   3.00000000e+02 -5.00000000e+02 -1.00000000e+02  3.00000000e+02
  -0.00000000e+00]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.47000000e+04  2.00000000e+02  1.40000000e+03
  -2.00000000e+02 -4.00000000e+02 -4.00000000e+02  1.10000000e+03
  -0.00000000e+00 -1.00000000e+02  4.00000000e+02  1.00000000e+02
   1.30000000e+03]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.85000000e+04  2.00000000e+02
   3.00000046e+02  6.00000000e+02 -1.00000046e+02  9.99999985e+02
  -9.99999939e+02  2.00000000e+02 -2.00000000e+02 -4.00000046e+02
  -1.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.78000000e+04
   3.00000000e+02 -1.00000000e+02  5.00000000e+02 -1.00000000e+02
   2.00000000e+02 -0.00000000e+00  3.00000000e+02 -7.00000000e+02
  -0.00000000e+00]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.20000000e+04  1.00000084e+02  9.99999847e+01  4.00000000e+02
   2.00000000e+02 -1.00000000e+02 -0.00000000e+00  2.99999985e+02
  -9.99999847e+01]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -1.94000000e+04  2.00000000e+02  2.00000000e+03
  -4.00000000e+02 -0.00000000e+00 -0.00000000e+00  9.00000000e+02
  -0.00000000e+00]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -2.31000000e+04  5.00000000e+02
   4.00000000e+02  4.00000000e+02 -4.00000000e+02  2.00000000e+02
   6.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.01000000e+04
   7.00000000e+02 -2.00000000e+02  5.00000000e+02 -2.00000008e+02
   5.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -2.19000000e+04  3.00000000e+02  4.00000000e+02  2.99999977e+02
  -2.99999977e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -2.39000000e+04  6.00000000e+02 -4.00000000e+02
  -2.00000015e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -1.78000000e+04 -0.00000000e+00
   3.00000000e+02]
 [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00
  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.47000000e+04
   3.99999992e+02]]
tmp [[ 1.50000000e+03  4.20000000e+03 -1.00000000e+03  1.02000000e+04
  -6.60000000e+03  4.00000000e+03  3.00000000e+03  5.00000000e+02
   2.60000000e+03 -1.50000000e+03 -2.00000000e+02  2.00000000e+03
   2.90000000e+03 -1.30000000e+03 -1.80000000e+03  4.70000000e+03
  -0.00000000e+00  2.00000000e+03  2.10000000e+03  2.70000000e+03
  -3.80000000e+03 -1.40000000e+03  2.90000000e+03  1.00000000e+02
   3.20000000e+03]
 [ 0.00000000e+00  2.00000000e+02 -4.00000000e+02  1.40000000e+03
  -5.00000000e+02 -2.00000000e+02  7.00000000e+02  6.00000000e+02
  -8.00000000e+02  1.00000000e+02  4.00000000e+02 -3.00000000e+02
   6.00000008e+02 -1.00000000e+02 -6.00000000e+02  1.30000000e+03
   4.00000000e+02 -1.00000000e+03  2.00000000e+02 -1.00000000e+02
  -0.00000000e+00 -2.00000000e+02  5.00000000e+02 -6.00000008e+02
   1.00000008e+02]
 [ 0.00000000e+00  0.00000000e+00  1.30000000e+03  3.00000000e+02
  -3.00000038e+02 -4.00000000e+02  5.00000038e+02  2.99999924e+02
  -2.00000000e+02 -2.00000000e+02  1.00000038e+02 -1.00000000e+02
   1.99999962e+02  1.00000076e+02 -1.00000076e+02 -0.00000000e+00
  -1.00000000e+02  5.00000000e+02  1.00000000e+02  1.00000076e+02
  -6.00000076e+02  2.00000038e+02 -3.81469717e-05  3.00000000e+02
  -6.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.00000000e+02
   4.00000000e+02 -0.00000000e+00 -1.00000000e+02  2.00000000e+02
  -0.00000000e+00  2.00000000e+02 -1.00000000e+02 -0.00000000e+00
  -2.00000000e+02  3.00000000e+02 -2.00000000e+02  2.00000000e+02
  -0.00000000e+00 -0.00000000e+00 -1.00000000e+02  4.00000000e+02
  -2.00000000e+02  2.00000000e+02 -4.00000000e+02 -1.00000000e+02
   3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  -0.00000000e+00  7.00000031e+02 -2.00000000e+02  4.00000000e+02
   3.99999969e+02 -5.00000000e+02  6.00000031e+02  3.00000000e+02
  -3.00000000e+02 -3.05175790e-05  2.00000000e+02  4.00000031e+02
  -3.00000000e+02  2.99999962e+02 -4.00000000e+02 -3.81469727e-06
   1.14440918e-05  2.00000031e+02 -5.00000031e+02  3.99999992e+02
   1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  4.57763663e-05  1.00000000e+02 -0.00000000e+00
  -0.00000000e+00  2.99999939e+02 -0.00000000e+00 -1.00000000e+02
  -9.99999390e+01 -2.00000000e+02 -0.00000000e+00  1.00000000e+02
   1.00000000e+02  2.99999939e+02  1.00000000e+02 -9.99999542e+01
  -1.00000046e+02 -9.99999390e+01 -0.00000000e+00 -1.00000000e+02
   1.99999939e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  3.00000000e+02  8.00000008e+02
   3.00000000e+02  5.00000000e+02  9.00000000e+02 -5.00000000e+02
  -4.00000000e+02 -1.00000000e+02  4.00000000e+02  1.99999996e+02
  -9.99999996e+02  1.00000000e+03 -2.00000000e+02  5.00000000e+02
  -0.00000000e+00  1.00000000e+02  2.00000000e+02 -0.00000000e+00
  -2.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+02
   1.00000000e+02  1.00000000e+02  3.00000000e+02  2.00000000e+02
  -3.00000000e+02  1.00000000e+02 -3.00000000e+02 -5.00000000e+02
   2.80000000e+03  1.00000000e+03 -6.00000000e+02 -4.00000000e+02
  -4.00000000e+02  3.00000000e+02  3.00000000e+02 -0.00000000e+00
   3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.00000000e+02  6.00000000e+02  4.00000000e+02  1.00000000e+02
  -1.00000000e+02  1.00000000e+02 -0.00000000e+00 -0.00000000e+00
   3.00000000e+02 -2.00000000e+02 -1.00000000e+02  2.00000000e+02
   3.00000000e+02 -2.00000000e+02 -0.00000000e+00 -2.00000000e+02
  -2.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00 -5.34057608e-05 -1.99999947e+02  3.00000000e+02
  -1.52587891e-05  1.00000000e+02  1.00000000e+02  1.00000000e+02
  -0.00000000e+00  2.00000000e+02  7.00000000e+02 -2.00000000e+02
  -5.99999985e+02  3.99999985e+02 -5.99999969e+02 -3.05175799e-05
  -3.00000053e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  4.00000000e+02 -3.00000000e+02
  -3.00000000e+02  3.00000000e+02  1.00000000e+02 -0.00000000e+00
   2.00000000e+02 -1.00000000e+02 -0.00000000e+00 -1.00000000e+02
  -0.00000000e+00  2.00000000e+02 -2.00000000e+02  2.00000000e+02
  -2.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.99999992e+02
   7.99999992e+02  9.00000011e+02 -0.00000000e+00 -3.00000008e+02
   6.00000008e+02  2.00000000e+02 -5.00000019e+02  1.60000001e+03
  -1.60000001e+03  6.00000019e+02 -4.00000000e+02  6.99999992e+02
   3.00000006e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   1.39999995e+03 -1.00000000e+02  1.00000031e+02 -3.00000019e+02
   1.99999989e+02  2.00000011e+02  9.99999886e+01  1.00000011e+02
  -4.00000000e+02 -1.00000000e+02 -1.00000000e+02  1.00000000e+02
   1.10000002e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  2.99999996e+02  2.00000000e+02  4.00000000e+02
  -2.00000000e+02 -1.00000000e+02 -0.00000000e+00  1.00000000e+02
   3.00000000e+02 -5.00000000e+02 -1.00000000e+02  3.00000000e+02
  -0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  2.00000000e+02  1.40000000e+03
  -2.00000000e+02 -4.00000000e+02 -4.00000000e+02  1.10000000e+03
  -0.00000000e+00 -1.00000000e+02  4.00000000e+02  1.00000000e+02
   1.30000000e+03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.00000000e+02
   3.00000046e+02  6.00000000e+02 -1.00000046e+02  9.99999985e+02
  -9.99999939e+02  2.00000000e+02 -2.00000000e+02 -4.00000046e+02
  -1.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   3.00000000e+02 -1.00000000e+02  5.00000000e+02 -1.00000000e+02
   2.00000000e+02 -0.00000000e+00  3.00000000e+02 -7.00000000e+02
  -0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  1.00000084e+02  9.99999847e+01  4.00000000e+02
   2.00000000e+02 -1.00000000e+02 -0.00000000e+00  2.99999985e+02
  -9.99999847e+01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  2.00000000e+02  2.00000000e+03
  -4.00000000e+02 -0.00000000e+00 -0.00000000e+00  9.00000000e+02
  -0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.00000000e+02
   4.00000000e+02  4.00000000e+02 -4.00000000e+02  2.00000000e+02
   6.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   7.00000000e+02 -2.00000000e+02  5.00000000e+02 -2.00000008e+02
   5.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  3.00000000e+02  4.00000000e+02  2.99999977e+02
  -2.99999977e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  6.00000000e+02 -4.00000000e+02
  -2.00000015e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00
   3.00000000e+02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   3.99999992e+02]]
tmp [ 1500.          4400.          -100.         11700.
 -7000.00003815  4100.00007629  4300.00003815  2899.99993134
  2499.99996948  -400.00011444  2600.00012207  1200.00000763
  4199.99996185   400.00005341 -1700.00004578  7900.
  3400.00004578  4499.99999619  1699.99990845  9700.00012589
 -7000.00004578   200.00013351  3199.99996185  1199.99985504
  6499.99993324]
cumsum_n_vids [1920 1987 2066 2151 2224 2302 2369 2450 2516 2593 2675 2746 2821 2888
 2976 3038 3102 3179 3247 3328 3399 3474 3566 3631 3718]
fgt [ 0.78125     2.21439356 -0.04840271  5.43933054 -3.14748203  1.78105998
  1.81511188  1.18367344  0.99364069 -0.15426152  0.97196266  0.43699927
  1.48883373  0.13850417 -0.57123657  2.600395    1.09606707  1.41553948
  0.52356018  2.9146635  -2.05942926  0.05757056  0.89736398  0.33048743
  1.74825173]
fgt 0.913913870741848
fgt [0.91391387]