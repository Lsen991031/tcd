ucf101: 101 classes
Method : OURS
----AGE 2----
current_task  [18, 90]
current_head  55
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
Load the Previous Model
Copy the old Model
lambda_0  : [1.0, 0.051478150704935006]
Increment the Model
SplitCosineLinear(
  input_features=512, output_features=165, sigma=tensor([3.7415]), eta=tensor([2.8144])
  (fc1): CosineLinear(input_features=512, output_features=159, sigma=1.0, eta=1.0)
  (fc2): CosineLinear(input_features=512, output_features=6, sigma=1.0, eta=1.0)
)
video number : 145
video number + exemplar : 410
DataLoader Constructed : Train 12
Optimizer Constructed
video number : 145
video number + exemplar : 145
Initialize Cosine Classifier
Computing the class mean vectors...
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Traceback (most recent call last):
  File "main.py", line 101, in <module>
    main()
  File "main.py", line 71, in main
    train_i_cl.train_task(args, i, current_task, current_head, class_indexer, model_flow=model_flow, prefix=prefix)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 461, in train_task
    _train(args, train_loader, model, criterion, optimizer, epoch, age, regularizer=regularizer, lambda_0=lambda_0, model_old=model_old, importance_list=importance_list)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 88, in _train
    outputs_old = model_old(input=input)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 152, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 162, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 83, in parallel_apply
    raise output
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 59, in _worker
    output = module(*input, **kwargs)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ustc/ls/tcd_code/ops/models.py", line 450, in forward
    base_out, int_features = self.base_model(input.view((-1, sample_len) + input.size()[-2:]))
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ustc/ls/tcd_code/ops/resnet_models.py", line 198, in forward
    x = self.conv1(x)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 338, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 1; 11.91 GiB total capacity; 5.29 GiB already allocated; 90.00 MiB free; 111.47 MiB cached)