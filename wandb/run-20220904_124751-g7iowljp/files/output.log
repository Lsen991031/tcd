ucf101: 101 classes
Method : OURS
----AGE 0----
current_task  [37, 97, 56, 55, 33, 84, 3, 4, 72, 59, 66, 48, 65, 91, 99, 39, 34, 22, 67, 74, 19, 35, 9, 86, 88, 63, 85, 38, 54, 25, 57, 62, 83, 76, 6, 13, 2, 53, 8, 24, 44, 12, 100, 29, 5, 17, 15, 73, 47, 27, 46]
current_head  51
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet50
CosineLinear(input_features=2048, output_features=153, sigma=tensor([1.]), eta=tensor([1.]))
video number : 4793
video number + exemplar : 4793
DataLoader Constructed : Train 299
Optimizer Constructed
torch.Size([16, 24, 224, 224])
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Traceback (most recent call last):
  File "main.py", line 102, in <module>
    main()
  File "main.py", line 72, in main
    train_i_cl.train_task(args, i, current_task, current_head, class_indexer, model_flow=model_flow, prefix=prefix)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 521, in train_task
    _train(args, train_loader, model, criterion, optimizer, epoch, age, regularizer=regularizer, lambda_0=lambda_0, model_old=model_old, importance_list=importance_list)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 83, in _train
    new_feats = model.module.base_model.extract_feat_res(input.view((-1, 3) + input.size()[-2:]))
  File "/home/ustc/ls/tcd_code/ops/resnet_models.py", line 338, in extract_feat_res
    feat = self.layer2[0](feat)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ustc/ls/tcd_code/ops/resnet_models.py", line 147, in forward
    out = self.bn1(out)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/functional.py", line 2422, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 11.91 GiB total capacity; 10.97 GiB already allocated; 91.12 MiB free; 11.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF