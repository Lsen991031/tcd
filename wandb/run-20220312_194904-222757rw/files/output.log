ucf101: 101 classes
Method : OURS
----AGE 0----
current_task  [37, 97, 56, 55, 33, 84, 3, 4, 72, 59, 66, 48, 65, 91, 99, 39, 34, 22, 67, 74, 19, 35, 9, 86, 88, 63, 85, 38, 54, 25, 57, 62, 83, 76, 6, 13, 2, 53, 8, 24, 44, 12, 100, 29, 5, 17, 15, 73, 47, 27, 46]
current_head  51
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet34
torch.Size([8, 64])
CosineLinear(input_features=512, output_features=153, sigma=tensor([1.]), eta=tensor([1.]))
video number : 4793
video number + exemplar : 4793
DataLoader Constructed : Train 149
Optimizer Constructed
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-03-12 19:49:19.750949
Epoch: [0][0/149], lr: 0.00100	Time 7.464 (7.464)	Data 2.146 (2.146)	Loss 3.9937 (3.9937)	Loss CE 3.9317 (3.9317)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6197 (0.6197)	Loss REG 0.0000 (0.0000)	Prec@1 3.125 (3.125)
2022-03-12 19:50:16.705083
Epoch: [0][100/149], lr: 0.00100	Time 0.595 (0.638)	Data 0.000 (0.021)	Loss 3.9762 (3.9905)	Loss CE 3.9161 (3.9284)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6010 (0.6215)	Loss REG 0.0000 (0.0000)	Prec@1 3.125 (3.094)
Sigma : Parameter containing:
tensor([1.0662], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.0312], device='cuda:0', requires_grad=True)
2022-03-12 19:50:47.990215
Epoch: [1][0/149], lr: 0.00100	Time 2.677 (2.677)	Data 1.966 (1.966)	Loss 3.9782 (3.9782)	Loss CE 3.9159 (3.9159)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6225 (0.6225)	Loss REG 0.0000 (0.0000)	Prec@1 6.250 (6.250)
2022-03-12 19:51:46.129022
Epoch: [1][100/149], lr: 0.00100	Time 0.563 (0.602)	Data 0.000 (0.020)	Loss 3.9726 (3.9692)	Loss CE 3.9145 (3.9088)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.5807 (0.6041)	Loss REG 0.0000 (0.0000)	Prec@1 9.375 (7.302)
Sigma : Parameter containing:
tensor([1.4152], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([1.2188], device='cuda:0', requires_grad=True)
2022-03-12 19:52:17.429655
Epoch: [2][0/149], lr: 0.00100	Time 2.493 (2.493)	Data 1.642 (1.642)	Loss 3.9150 (3.9150)	Loss CE 3.8549 (3.8549)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6007 (0.6007)	Loss REG 0.0000 (0.0000)	Prec@1 21.875 (21.875)
2022-03-12 19:53:15.303368
Epoch: [2][100/149], lr: 0.00100	Time 0.574 (0.598)	Data 0.000 (0.016)	Loss 3.4061 (3.7632)	Loss CE 3.3428 (3.7010)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6325 (0.6220)	Loss REG 0.0000 (0.0000)	Prec@1 12.500 (21.999)
Sigma : Parameter containing:
tensor([3.3401], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.4495], device='cuda:0', requires_grad=True)
2022-03-12 19:53:46.872371
Epoch: [3][0/149], lr: 0.00100	Time 2.672 (2.672)	Data 1.960 (1.960)	Loss 2.1599 (2.1599)	Loss CE 2.0952 (2.0952)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6465 (0.6465)	Loss REG 0.0000 (0.0000)	Prec@1 50.000 (50.000)
2022-03-12 19:54:45.554698
Epoch: [3][100/149], lr: 0.00100	Time 0.563 (0.607)	Data 0.000 (0.020)	Loss 1.6487 (1.7744)	Loss CE 1.5809 (1.7087)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6773 (0.6574)	Loss REG 0.0000 (0.0000)	Prec@1 56.250 (55.724)
Sigma : Parameter containing:
tensor([3.6668], device='cuda:0', requires_grad=True), Eta : Parameter containing:
tensor([2.7653], device='cuda:0', requires_grad=True)
2022-03-12 19:55:17.097088
Epoch: [4][0/149], lr: 0.00100	Time 2.712 (2.712)	Data 1.822 (1.822)	Loss 1.3821 (1.3821)	Loss CE 1.3138 (1.3138)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6828 (0.6828)	Loss REG 0.0000 (0.0000)	Prec@1 68.750 (68.750)
2022-03-12 19:56:15.344835
Epoch: [4][100/149], lr: 0.00100	Time 0.594 (0.604)	Data 0.000 (0.018)	Loss 1.2174 (1.1049)	Loss CE 1.1489 (1.0390)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6850 (0.6589)	Loss REG 0.0000 (0.0000)	Prec@1 65.625 (70.978)
Traceback (most recent call last):
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/queues.py", line 242, in _feed
    send_bytes(obj)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
Traceback (most recent call last):
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/queues.py", line 242, in _feed
    send_bytes(obj)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "main.py", line 101, in <module>
    main()
  File "main.py", line 71, in main
    train_i_cl.train_task(args, i, current_task, current_head, class_indexer, model_flow=model_flow, prefix=prefix)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 461, in train_task
    _train(args, train_loader, model, criterion, optimizer, epoch, age, regularizer=regularizer, lambda_0=lambda_0, model_old=model_old, importance_list=importance_list)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 167, in _train
    if loss_reg != 0:
KeyboardInterrupt