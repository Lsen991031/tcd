ucf101: 101 classes
Method : OURS
----AGE 0----
current_task  [37, 97, 56, 55, 33, 84, 3, 4, 72, 59, 66, 48, 65, 91, 99, 39, 34, 22, 67, 74, 19, 35, 9, 86, 88, 63, 85, 38, 54, 25, 57, 62, 83, 76, 6, 13, 2, 53, 8, 24, 44, 12, 100, 29, 5, 17, 15, 73, 47, 27, 46]
current_head  51
Phase 2 : Train RGB Model in an Incremental Manner
=> base model: resnet50
CosineLinear(input_features=2048, output_features=153, sigma=tensor([1.]), eta=tensor([1.]))
video number : 4793
video number + exemplar : 4793
DataLoader Constructed : Train 1198
Optimizer Constructed
torch.Size([4, 24, 224, 224])
/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-09-04 14:50:02.706533
Epoch: [0][0/1198], lr: 0.00100	Time 7.971 (7.971)	Data 0.688 (0.688)	Loss 4.0086 (4.0086)	Loss CE 3.9400 (3.9400)	Loss KD (Logit) 0.0000 (0.0000)	Loss KD (GCAM) 0.0000 (0.0000)	Loss MR 0.0000 (0.0000)	Loss DIV 0.6861 (0.6861)	Loss REG 0.0000 (0.0000)	Prec@1 0.000 (0.000)
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
torch.Size([4, 24, 224, 224])
Traceback (most recent call last):
  File "main.py", line 102, in <module>
    main()
  File "main.py", line 72, in main
    train_i_cl.train_task(args, i, current_task, current_head, class_indexer, model_flow=model_flow, prefix=prefix)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 524, in train_task
    _train(args, train_loader, model, criterion, optimizer, epoch, age, regularizer=regularizer, lambda_0=lambda_0, model_old=model_old, importance_list=importance_list)
  File "/home/ustc/ls/tcd_code/train/train_i_cl.py", line 221, in _train
    loss.backward()
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/ustc/anaconda3/envs/lhc/lib/python3.7/site-packages/torch/autograd/__init__.py", line 175, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt